{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "piano-stereo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:14.459392Z",
     "start_time": "2021-08-30T10:24:11.174565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn not installed\n",
      "pandas 1.1.5\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "torch not installed\n",
      "torchvision not installed\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "onnx 1.10.1\n",
      "onnxruntime 1.8.1\n",
      "tf2onnx 1.9.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p cv2,PIL,matplotlib\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard\n",
    "%watermark -p onnx,onnxruntime,tf2onnx\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        segs = x.split(' ')\n",
    "        g = globals()\n",
    "        if 'github.com' in segs[1]:\n",
    "            uri = segs[1].replace('github.com', 'raw.githubusercontent.com')\n",
    "            mod = uri.split('/')\n",
    "            for s in ['main', 'master']:\n",
    "                uri = 'https://' + '/'.join(mod[:-1]) + '/main/' + mod[-1] + '.py'\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "                    break\n",
    "        elif 'gitee.com' in segs[1]:\n",
    "            mod = segs[1].split('/')\n",
    "            for s in ['/raw/main/', '/raw/master/']:\n",
    "                uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:]) + '.py'\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "                    break\n",
    "        elif segs[1][0] == '/':\n",
    "            with open(segs[1] + '.py') as fr:\n",
    "                x = fr.read()\n",
    "        exec(x, g)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unable-velvet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:14.625048Z",
     "start_time": "2021-08-30T10:24:14.463572Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'tensorboard-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_cell_magic\n",
    "def template_writefile(line, cell):\n",
    "    with open(line, 'w') as fw:\n",
    "        fw.write(cell.format(**globals()))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), 600\n",
    "    if len(args) == 3:\n",
    "        height = int(args[2])\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #     pid = int(res[0].split(' ')[1])\n",
    "    #     !kill -9 $pid\n",
    "    import netron\n",
    "    netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    display_html(port, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfec991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:59:34.202745Z",
     "start_time": "2021-08-30T10:59:34.147422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "younger-execution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:59:53.057839Z",
     "start_time": "2021-08-30T10:59:52.904915Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "import cv2\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Javascript\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# import tensorflow.compat.v2 as tf\n",
    "\n",
    "# ! pip install youtube_dl\n",
    "# import youtube_dl\n",
    "\n",
    "# from google.colab import drive\n",
    "# from google.colab import output\n",
    "# from google.colab.output import eval_js\n",
    "\n",
    "# Model definition\n",
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers\n",
    "\n",
    "\n",
    "def get_sims(embs, temperature):\n",
    "  \"\"\"Calculates self-similarity between batch of sequence of embeddings.\"\"\"\n",
    "  batch_size = tf.shape(embs)[0]\n",
    "  seq_len = tf.shape(embs)[1]\n",
    "  embs = tf.reshape(embs, [batch_size, seq_len, -1])\n",
    "\n",
    "  def _get_sims(embs):\n",
    "    \"\"\"Calculates self-similarity between sequence of embeddings.\"\"\"\n",
    "    dist = pairwise_l2_distance(embs, embs)\n",
    "    sims = -1.0 * dist\n",
    "    return sims\n",
    "\n",
    "  sims = tf.map_fn(_get_sims, embs)\n",
    "  sims /= temperature\n",
    "  sims = tf.nn.softmax(sims, axis=-1)\n",
    "  sims = tf.expand_dims(sims, -1)\n",
    "  return sims\n",
    "\n",
    "\n",
    "def flatten_sequential_feats(x, batch_size, seq_len):\n",
    "  \"\"\"Flattens sequential features with known batch size and seq_len.\"\"\"\n",
    "  x = tf.reshape(x, [batch_size, seq_len, -1])\n",
    "  return x\n",
    "\n",
    "\n",
    "# Transformer from https://www.tensorflow.org/tutorials/text/transformer .\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    outputs: shape == (..., seq_len_q, depth_v)\n",
    "    attention_weights: shape == (..., seq_len_q, seq_len_k)\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk.\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  # (..., seq_len_q, seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "  outputs = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return outputs, attention_weights\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model)\n",
    "  ])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  \"\"\"Multi-headed attention layer.\"\"\"\n",
    "\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(\n",
    "        q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(\n",
    "        k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(\n",
    "        v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(\n",
    "        scaled_attention,\n",
    "        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(\n",
    "        scaled_attention,\n",
    "        (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    outputs = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return outputs, attention_weights\n",
    "\n",
    "\n",
    "class TransformerLayer(tf.keras.layers.Layer):\n",
    "  \"\"\"Implements a single transformer layer (https://arxiv.org/abs/1706.03762).\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff,\n",
    "               dropout_rate=0.1,\n",
    "               reorder_ln=False):\n",
    "    super(TransformerLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    self.reorder_ln = reorder_ln\n",
    "\n",
    "  def call(self, x):\n",
    "    inp_x = x\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      x = self.layernorm1(x)\n",
    "\n",
    "    # (batch_size, input_seq_len, d_model)\n",
    "    attn_output, _ = self.mha(x, x, x, mask=None)\n",
    "    attn_output = self.dropout1(attn_output)\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      out1 = inp_x + attn_output\n",
    "      x = out1\n",
    "    else:\n",
    "      # (batch_size, input_seq_len, d_model)\n",
    "      out1 = self.layernorm1(x + attn_output)\n",
    "      x = out1\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      x = self.layernorm2(x)\n",
    "\n",
    "    # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.ffn(x)\n",
    "    ffn_output = self.dropout2(ffn_output)\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      out2 = out1 + ffn_output\n",
    "    else:\n",
    "      # (batch_size, input_seq_len, d_model)\n",
    "      out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    return out2\n",
    "\n",
    "\n",
    "def pairwise_l2_distance(a, b):\n",
    "  \"\"\"Computes pairwise distances between all rows of a and all rows of b.\"\"\"\n",
    "  norm_a = tf.reduce_sum(tf.square(a), 1)\n",
    "  norm_a = tf.reshape(norm_a, [-1, 1])\n",
    "  norm_b = tf.reduce_sum(tf.square(b), 1)\n",
    "  norm_b = tf.reshape(norm_b, [1, -1])\n",
    "  dist = tf.maximum(norm_a - 2.0 * tf.matmul(a, b, False, True) + norm_b, 0.0)\n",
    "  return dist\n",
    "\n",
    "\n",
    "def get_repnet_model(logdir):\n",
    "  \"\"\"Returns a trained RepNet model.\n",
    "\n",
    "  Args:\n",
    "    logdir (string): Path to directory where checkpoint will be downloaded.\n",
    "\n",
    "  Returns:\n",
    "    model (Keras model): Trained RepNet model.\n",
    "  \"\"\"\n",
    "  # Check if we are in eager mode.\n",
    "  assert tf.executing_eagerly()\n",
    "\n",
    "  # Models will be called in eval mode.\n",
    "  tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "  # Define RepNet model.\n",
    "  model = ResnetPeriodEstimator()\n",
    "  # tf.function for speed.\n",
    "  model.call = tf.function(model.call)\n",
    "\n",
    "  # Define checkpoint and checkpoint manager.\n",
    "  ckpt = tf.train.Checkpoint(model=model)\n",
    "  ckpt_manager = tf.train.CheckpointManager(\n",
    "      ckpt, directory=logdir, max_to_keep=10)\n",
    "  latest_ckpt = ckpt_manager.latest_checkpoint\n",
    "  print('Loading from: ', latest_ckpt)\n",
    "  if not latest_ckpt:\n",
    "    raise ValueError('Path does not have a checkpoint to load.')\n",
    "  # Restore weights.\n",
    "  ckpt.restore(latest_ckpt).expect_partial()\n",
    "\n",
    "  # Pass dummy frames to build graph.\n",
    "  model(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "  return model\n",
    "\n",
    "\n",
    "def unnorm(query_frame):\n",
    "  min_v = query_frame.min()\n",
    "  max_v = query_frame.max()\n",
    "  query_frame = (query_frame - min_v) / max(1e-7, (max_v - min_v))\n",
    "  return query_frame\n",
    "\n",
    "class ResnetPeriodEstimator(tf.keras.models.Model):\n",
    "  \"\"\"RepNet model.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      num_frames=64,\n",
    "      image_size=112,\n",
    "      base_model_layer_name='conv4_block3_out',\n",
    "      temperature=13.544,\n",
    "      dropout_rate=0.25,\n",
    "      l2_reg_weight=1e-6,\n",
    "      temporal_conv_channels=512,\n",
    "      temporal_conv_kernel_size=3,\n",
    "      temporal_conv_dilation_rate=3,\n",
    "      conv_channels=32,\n",
    "      conv_kernel_size=3,\n",
    "      transformer_layers_config=((512, 4, 512),),\n",
    "      transformer_dropout_rate=0.0,\n",
    "      transformer_reorder_ln=True,\n",
    "      period_fc_channels=(512, 512),\n",
    "      within_period_fc_channels=(512, 512)):\n",
    "    super(ResnetPeriodEstimator, self).__init__()\n",
    "\n",
    "    # Model params.\n",
    "    self.num_frames = num_frames\n",
    "    self.image_size = image_size\n",
    "\n",
    "    self.base_model_layer_name = base_model_layer_name\n",
    "\n",
    "    self.temperature = temperature\n",
    "\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.l2_reg_weight = l2_reg_weight\n",
    "\n",
    "    self.temporal_conv_channels = temporal_conv_channels\n",
    "    self.temporal_conv_kernel_size = temporal_conv_kernel_size\n",
    "    self.temporal_conv_dilation_rate = temporal_conv_dilation_rate\n",
    "\n",
    "    self.conv_channels = conv_channels\n",
    "    self.conv_kernel_size = conv_kernel_size\n",
    "    # Transformer config in form of (channels, heads, bottleneck channels).\n",
    "    self.transformer_layers_config = transformer_layers_config\n",
    "    self.transformer_dropout_rate = transformer_dropout_rate\n",
    "    self.transformer_reorder_ln = transformer_reorder_ln\n",
    "\n",
    "    self.period_fc_channels = period_fc_channels\n",
    "    self.within_period_fc_channels = within_period_fc_channels\n",
    "\n",
    "    # Base ResNet50 Model.\n",
    "    base_model = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, pooling='max')\n",
    "    self.base_model = tf.keras.models.Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(self.base_model_layer_name).output)\n",
    "\n",
    "    # 3D Conv on k Frames\n",
    "    self.temporal_conv_layers = [\n",
    "        layers.Conv3D(self.temporal_conv_channels,\n",
    "                      self.temporal_conv_kernel_size,\n",
    "                      padding='same',\n",
    "                      dilation_rate=(self.temporal_conv_dilation_rate, 1, 1),\n",
    "                      kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                      kernel_initializer='he_normal', name='RE_temporal_conv_layers')]\n",
    "    self.temporal_bn_layers = [layers.BatchNormalization(name='RE_temporal_bn_layers')\n",
    "                               for _ in self.temporal_conv_layers]\n",
    "\n",
    "    # Counting Module (Self-sim > Conv > Transformer > Classifier)\n",
    "    self.conv_3x3_layer = layers.Conv2D(self.conv_channels,\n",
    "                                        self.conv_kernel_size,\n",
    "                                        padding='same',\n",
    "                                        activation=tf.nn.relu, name='RE_conv_3x3_layer')\n",
    "\n",
    "    channels = self.transformer_layers_config[0][0]\n",
    "    self.input_projection = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None, name='RE_input_projection')\n",
    "\n",
    "    self.input_projection2 = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None, name='RE_input_projection2')\n",
    "\n",
    "    length = self.num_frames\n",
    "    self.pos_encoding = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "    self.pos_encoding2 = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding2',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    self.transformer_layers = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    self.transformer_layers2 = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers2.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    # Period Prediction Module.\n",
    "    self.dropout_layer = layers.Dropout(self.dropout_rate, name='RE_dropout_layer')\n",
    "    num_preds = self.num_frames//2\n",
    "    self.fc_layers = []\n",
    "    for i, channels in enumerate(self.period_fc_channels):\n",
    "      self.fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu, name=f'RE_fc_layers_{i}'))\n",
    "    self.fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight), name='RE_fc_layers_x'))\n",
    "\n",
    "    # Within Period Module\n",
    "    num_preds = 1\n",
    "    self.within_period_fc_layers = []\n",
    "    for i, channels in enumerate(self.within_period_fc_channels):\n",
    "      self.within_period_fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu, name=f'RE_within_period_fc_layers_{i}'))\n",
    "    self.within_period_fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight), name='RE_within_period_fc_layers_x'))\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensures we are always using the right batch_size during train/eval.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    # Conv Feature Extractor.\n",
    "    x = tf.reshape(x, [-1, self.image_size, self.image_size, 3])\n",
    "    x = self.base_model(x)\n",
    "    h = tf.shape(x)[1]\n",
    "    w = tf.shape(x)[2]\n",
    "    c = tf.shape(x)[3]\n",
    "    x = tf.reshape(x, [batch_size, -1, h, w, c])\n",
    "\n",
    "    # 3D Conv to give temporal context to per-frame embeddings. \n",
    "    for bn_layer, conv_layer in zip(self.temporal_bn_layers,\n",
    "                                    self.temporal_conv_layers):\n",
    "      print('1conv_layer:', x.shape)\n",
    "      x = conv_layer(x)\n",
    "      print('2conv_layer:', x.shape)\n",
    "      x = bn_layer(x)\n",
    "      print('bn_layer:', x.shape)\n",
    "      x = tf.nn.relu(x)\n",
    "      print('relu layer:', x.shape)\n",
    "    \n",
    "\n",
    "    x = tf.reduce_max(x, [2, 3])\n",
    "    \n",
    "\n",
    "    # Reshape and prepare embs for output.\n",
    "    final_embs = x\n",
    "\n",
    "    # Get self-similarity matrix.\n",
    "    x = get_sims(x, self.temperature)\n",
    "    \n",
    "    # 3x3 conv layer on self-similarity matrix.\n",
    "    x = self.conv_3x3_layer(x)\n",
    "    x = tf.reshape(x, [batch_size, self.num_frames, -1])\n",
    "    within_period_x = x\n",
    "\n",
    "    # Period prediction.\n",
    "    x = self.input_projection(x)\n",
    "    x += self.pos_encoding\n",
    "    for transformer_layer in self.transformer_layers:\n",
    "      x = transformer_layer(x)\n",
    "    x = flatten_sequential_feats(x, batch_size, self.num_frames)\n",
    "    for fc_layer in self.fc_layers:\n",
    "      x = self.dropout_layer(x)\n",
    "      x = fc_layer(x)\n",
    "\n",
    "    # Within period prediction.\n",
    "    within_period_x = self.input_projection2(within_period_x)\n",
    "    within_period_x += self.pos_encoding2\n",
    "    for transformer_layer in self.transformer_layers2:\n",
    "      within_period_x = transformer_layer(within_period_x)\n",
    "    within_period_x = flatten_sequential_feats(within_period_x,\n",
    "                                               batch_size,\n",
    "                                               self.num_frames)\n",
    "    for fc_layer in self.within_period_fc_layers:\n",
    "      within_period_x = self.dropout_layer(within_period_x)\n",
    "      within_period_x = fc_layer(within_period_x)\n",
    "\n",
    "    return x, within_period_x, final_embs\n",
    "\n",
    "#   @tf.function\n",
    "#   def preprocess(self, imgs):\n",
    "#     imgs = tf.cast(imgs, tf.float32)\n",
    "#     imgs -= 127.5\n",
    "#     imgs /= 127.5\n",
    "#     imgs = tf.image.resize(imgs, (self.image_size, self.image_size))\n",
    "#     return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rocky-investigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:59:59.318101Z",
     "start_time": "2021-08-30T10:59:56.761338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 1)\n",
      "tf.Tensor([-0.00950385], shape=(1,), dtype=float32)\n",
      "--------------------\n",
      "(1, 64, 512)\n",
      "tf.Tensor(\n",
      "[0.02054866 0.02054866 0.02054866 0.02054866 0.02054866 0.02054866\n",
      " 0.02054866 0.02054866 0.02054866 0.02054866], shape=(10,), dtype=float32)\n",
      "1conv_layer: (2, 64, 7, 7, 1024)\n",
      "2conv_layer: (2, 64, 7, 7, 512)\n",
      "bn_layer: (2, 64, 7, 7, 512)\n",
      "relu layer: (2, 64, 7, 7, 512)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "model1 = ResnetPeriodEstimator()\n",
    "print(model1.pos_encoding.shape)\n",
    "print(model1.pos_encoding[0][0][:10])\n",
    "ckpt = tf.train.Checkpoint(model=model1)\n",
    "ckpt.restore('/data/pretrained/cv/repnet/ckpt-88').expect_partial()\n",
    "print('-'*20)\n",
    "model1.pos_encoding = tf.tile(model1.pos_encoding, multiples=[1, 1, 512])\n",
    "model1.pos_encoding2 = tf.tile(model1.pos_encoding2, multiples=[1, 1, 512])\n",
    "print(model1.pos_encoding.shape)\n",
    "print(model1.pos_encoding[0][0][:10]) # 0.02054866\n",
    "test_inputs = np.random.randn(2, 64, 112, 112, 3).astype(np.float32)\n",
    "model1(tf.convert_to_tensor(test_inputs))\n",
    "print('end')\n",
    "# predictions = model1.predict(test_inputs)\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alpha-salon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:00:37.582286Z",
     "start_time": "2021-08-30T11:00:03.006111Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n",
      "1conv_layer: (None, None, None, None, None)\n",
      "2conv_layer: (None, None, None, None, 512)\n",
      "bn_layer: (None, None, None, None, 512)\n",
      "relu layer: (None, None, None, None, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_6_layer_call_and_return_conditional_losses, multi_head_attention_6_layer_call_fn, layer_normalization_12_layer_call_and_return_conditional_losses, layer_normalization_12_layer_call_fn, layer_normalization_13_layer_call_and_return_conditional_losses while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/bb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/bb/assets\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "os.system('rm -rf /data/bb')\n",
    "model1.save(\"/data/bb\", save_format='tf', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de91b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.568124Z",
     "start_time": "2021-08-30T10:24:11.155Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_saved_model('/data/aa/')\n",
    "# tflite_model = converter.convert()\n",
    "# with open('/data/aa/repnet.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pressed-mechanism",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:48:02.050326Z",
     "start_time": "2021-08-30T11:47:06.359665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-08-30 19:47:09,761 - WARNING - tf2onnx.tf_loader: '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-08-30 19:47:20,627 - INFO - tf2onnx.tf_loader: Signatures found in model: [serving_default].\n",
      "2021-08-30 19:47:20,627 - WARNING - tf2onnx.tf_loader: '--signature_def' not specified, using first signature: serving_default\n",
      "2021-08-30 19:47:20,629 - INFO - tf2onnx.tf_loader: Output names: ['output_1', 'output_2', 'output_3']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-08-30 19:47:25,525 - WARNING - tensorflow: From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-08-30 19:47:27,920 - INFO - tf2onnx: inputs: ['input_1:0']\n",
      "2021-08-30 19:47:27,923 - INFO - tf2onnx: outputs: ['Identity:0', 'Identity_1:0', 'Identity_2:0']\n",
      "2021-08-30 19:47:28,562 - INFO - tf2onnx.tfonnx: Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-08-30 19:47:28,562 - INFO - tf2onnx.tfonnx: Using opset <onnx, 11>\n",
      "2021-08-30 19:47:36,044 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding\n",
      "2021-08-30 19:47:36,056 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding\n",
      "2021-08-30 19:47:41,821 - INFO - tf2onnx.tf_utils: Computed 3 values for constant folding\n",
      "2021-08-30 19:47:49,223 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator_3/strided_slice_1\n",
      "2021-08-30 19:47:49,224 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator_3/strided_slice_2\n",
      "2021-08-30 19:47:49,224 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator_3/strided_slice_3\n",
      "2021-08-30 19:47:49,252 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-08-30 19:47:49,257 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 10, 'Identity': 8, 'Placeholder': 6, 'AddV2': 3, 'Square': 2, 'Sum': 2, 'Mul': 2, 'Reshape': 2, 'TensorListGetItem': 1, 'MatMul': 1, 'Sub': 1, 'Maximum': 1, 'TensorListSetItem': 1})\n",
      "\ttensorflow attr: Counter({'dtype': 16, 'value': 10, 'shape': 6, 'element_dtype': 2, 'Tidx': 2, 'keep_dims': 2, 'transpose_a': 1, 'transpose_b': 1})\n",
      "\tonnx mapped: Counter({'Const': 10, 'Placeholder': 6, 'Identity': 4, 'AddV2': 3, 'Square': 2, 'Sum': 2, 'Reshape': 2, 'Mul': 2, 'TensorListGetItem': 1, 'MatMul': 1, 'Sub': 1, 'Maximum': 1, 'TensorListSetItem': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-08-30 19:47:49,263 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-08-30 19:47:49,265 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Placeholder': 6, 'Less': 2, 'Identity': 2, 'LogicalAnd': 1})\n",
      "\ttensorflow attr: Counter({'dtype': 6, 'shape': 5})\n",
      "\tonnx mapped: Counter({'Placeholder': 6, 'Less': 2, 'LogicalAnd': 1, 'Identity': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-08-30 19:47:49,814 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-08-30 19:47:50,993 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 577, 'Reshape': 54, 'Identity': 47, 'Pack': 42, 'GatherV2': 40, 'Prod': 40, 'Relu': 38, 'Conv2D': 35, 'BiasAdd': 34, 'Shape': 32, 'FusedBatchNormV3': 31, 'AddV2': 26, 'ConcatV2': 20, 'MatMul': 20, 'StridedSlice': 17, 'Mul': 13, 'Pad': 12, 'Mean': 8, 'Transpose': 8, 'Sub': 5, 'StopGradient': 4, 'SquaredDifference': 4, 'Rsqrt': 4, 'BatchMatMulV2': 4, 'NoOp': 3, 'MaxPool': 3, 'Softmax': 3, 'FloorMod': 2, 'Cast': 2, 'Sqrt': 2, 'RealDiv': 2, 'Placeholder': 1, 'SpaceToBatchND': 1, 'Conv3D': 1, 'BatchToSpaceND': 1, 'Max': 1, 'TensorListFromTensor': 1, 'TensorListReserve': 1, 'StatelessWhile': 1, 'TensorListStack': 1, 'ExpandDims': 1})\n",
      "\ttensorflow attr: Counter({'value': 577, 'dtype': 575, 'data_format': 104, 'Tidx': 69, 'N': 62, 'keep_dims': 49, 'axis': 42, 'batch_dims': 40, 'padding': 39, 'strides': 39, 'explicit_paddings': 38, 'dilations': 36, 'out_type': 32, 'epsilon': 31, 'exponential_avg_factor': 31, 'is_training': 31, 'transpose_a': 20, 'transpose_b': 20, 'begin_mask': 17, 'ellipsis_mask': 17, 'end_mask': 17, 'new_axis_mask': 17, 'shrink_axis_mask': 17, 'adj_x': 4, 'adj_y': 4, 'ksize': 3, 'element_dtype': 3, '_acd_function_control_output': 2, 'Truncate': 2, 'to': 2, 'shape': 1, '_read_only_resource_inputs': 1, '_stateful_parallelism': 1, 'body': 1, 'cond': 1, 'num_elements': 1})\n",
      "\tonnx mapped: Counter({'Const': 509, 'Reshape': 54, 'Identity': 44, 'Pack': 42, 'GatherV2': 40, 'Prod': 40, 'Relu': 38, 'FusedBatchNormV3': 31, 'Shape': 29, 'AddV2': 26, 'Conv2D': 24, 'BiasAdd': 20, 'ConcatV2': 20, 'MatMul': 20, 'StridedSlice': 17, 'Mul': 13, 'Mean': 8, 'Transpose': 8, 'Sub': 5, 'StopGradient': 4, 'SquaredDifference': 4, 'Rsqrt': 4, 'BatchMatMulV2': 4, 'MaxPool': 3, 'Softmax': 3, 'FloorMod': 2, 'Cast': 2, 'Sqrt': 2, 'RealDiv': 2, 'Placeholder': 1, 'Pad': 1, 'SpaceToBatchND': 1, 'Conv3D': 1, 'BatchToSpaceND': 1, 'Max': 1, 'TensorListFromTensor': 1, 'TensorListReserve': 1, 'StatelessWhile': 1, 'TensorListStack': 1, 'ExpandDims': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-08-30 19:47:50,994 - INFO - tf2onnx.optimizer: Optimizing ONNX model\n",
      "2021-08-30 19:47:51,002 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-08-30 19:47:51,559 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Add -1 (48->47), Concat +1 (68->69), Const -171 (588->417), Gather +2 (42->44), Identity -1 (70->69), Placeholder -1 (6->5), Reshape +1 (66->67), Shape +1 (33->34), Split +1 (0->1), Transpose -134 (158->24)\n",
      "2021-08-30 19:47:51,559 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-08-30 19:47:51,745 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-08-30 19:47:51,745 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-08-30 19:47:51,970 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -4 (99->95), Concat -1 (69->68), Const -1 (417->416), Reshape -1 (67->66), Split -1 (1->0), Transpose -1 (24->23), Unsqueeze -39 (109->70)\n",
      "2021-08-30 19:47:51,970 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-08-30 19:47:52,959 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-08-30 19:47:52,959 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-08-30 19:47:53,158 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-08-30 19:47:53,158 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-08-30 19:47:54,458 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Cast -24 (95->71), Concat -16 (68->52), Const -145 (416->271), Gather -10 (44->34), ReduceProd -10 (40->30), Shape -8 (34->26), Unsqueeze -19 (70->51)\n",
      "2021-08-30 19:47:54,459 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-08-30 19:47:54,621 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: Cast -2 (71->69), Concat -1 (52->51), Const +1 (271->272), Gather -1 (34->33), Shape -2 (26->24), Slice -2 (25->23), Squeeze -2 (19->17), Unsqueeze -1 (51->50)\n",
      "2021-08-30 19:47:54,621 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-08-30 19:47:54,779 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: GlobalAveragePool +8 (0->8), ReduceMean -8 (8->0)\n",
      "2021-08-30 19:47:54,779 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-08-30 19:47:54,929 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-08-30 19:47:54,930 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-08-30 19:47:55,213 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Const -1 (272->271), Identity -69 (69->0)\n",
      "2021-08-30 19:47:55,214 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-30 19:47:55,525 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: BatchNormalization -20 (31->11), Const -60 (271->211), Squeeze -12 (17->5), Unsqueeze -12 (50->38)\n",
      "2021-08-30 19:47:55,525 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-08-30 19:47:55,658 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-08-30 19:47:55,658 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-08-30 19:47:55,809 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-08-30 19:47:55,809 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-08-30 19:47:55,934 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-08-30 19:47:55,934 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-08-30 19:47:56,072 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -2 (69->67), Const +2 (211->213)\n",
      "2021-08-30 19:47:56,073 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-08-30 19:47:56,199 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-08-30 19:47:56,199 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-08-30 19:47:56,322 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-08-30 19:47:56,322 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-08-30 19:47:56,847 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Cast -1 (67->66), Const -1 (213->212), Less -1 (4->3), Reshape -5 (66->61)\n",
      "2021-08-30 19:47:56,847 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-08-30 19:47:56,985 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: Cast -15 (66->51), Concat -15 (51->36), Const +14 (212->226), Gather -15 (33->18), ReduceProd -30 (30->0), Squeeze +3 (5->8), Unsqueeze -30 (38->8)\n",
      "2021-08-30 19:47:56,985 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-08-30 19:47:57,089 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-08-30 19:47:57,090 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-08-30 19:47:57,334 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-08-30 19:47:57,335 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-08-30 19:47:57,453 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-08-30 19:47:57,453 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-08-30 19:47:57,566 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-08-30 19:47:57,567 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-08-30 19:47:57,671 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-08-30 19:47:57,671 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-08-30 19:47:57,799 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-08-30 19:47:57,799 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-08-30 19:47:57,908 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-08-30 19:47:57,908 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-08-30 19:47:58,021 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2021-08-30 19:47:58,021 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-08-30 19:47:58,130 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-08-30 19:47:58,130 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-08-30 19:47:58,233 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-08-30 19:47:58,233 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-08-30 19:47:58,593 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -13 (226->213)\n",
      "2021-08-30 19:47:58,593 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-08-30 19:47:58,700 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2021-08-30 19:47:58,701 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-08-30 19:47:58,807 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-08-30 19:47:58,808 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-08-30 19:47:59,074 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-08-30 19:47:59,074 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-08-30 19:47:59,181 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-08-30 19:47:59,181 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-08-30 19:47:59,292 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-08-30 19:47:59,292 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-08-30 19:47:59,400 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-08-30 19:47:59,401 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-08-30 19:47:59,530 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-08-30 19:47:59,530 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-08-30 19:47:59,637 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-08-30 19:47:59,637 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-08-30 19:47:59,752 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2021-08-30 19:47:59,752 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-08-30 19:47:59,865 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-08-30 19:47:59,865 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-08-30 19:47:59,983 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-08-30 19:47:59,984 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-08-30 19:48:00,240 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: no change\n",
      "2021-08-30 19:48:00,240 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-08-30 19:48:00,354 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2021-08-30 19:48:00,354 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-08-30 19:48:00,468 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-08-30 19:48:00,468 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-08-30 19:48:00,741 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-08-30 19:48:00,741 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-08-30 19:48:00,855 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-08-30 19:48:00,856 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-08-30 19:48:00,972 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-08-30 19:48:00,972 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-08-30 19:48:01,085 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-08-30 19:48:01,106 - INFO - tf2onnx.optimizer: After optimization: Add -1 (48->47), BatchNormalization -20 (31->11), Cast -48 (99->51), Concat -32 (68->36), Const -375 (588->213), Gather -24 (42->18), GlobalAveragePool +8 (0->8), Identity -70 (70->0), Less -1 (4->3), Placeholder -1 (6->5), ReduceMean -8 (8->0), ReduceProd -40 (40->0), Reshape -5 (66->61), Shape -9 (33->24), Slice -2 (25->23), Squeeze -11 (19->8), Transpose -135 (158->23), Unsqueeze -101 (109->8)\n",
      "2021-08-30 19:48:01,355 - INFO - tf2onnx: \n",
      "2021-08-30 19:48:01,355 - INFO - tf2onnx: Successfully converted TensorFlow model /data/bb to ONNX\n",
      "2021-08-30 19:48:01,355 - INFO - tf2onnx: Model inputs: ['input_1']\n",
      "2021-08-30 19:48:01,356 - INFO - tf2onnx: Model outputs: ['output_1', 'output_2', 'output_3']\n",
      "2021-08-30 19:48:01,356 - INFO - tf2onnx: ONNX model is saved at /data/bb/test.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 11 \\\n",
    "    --saved-model /data/bb --output /data/bb/test.onnx --verbose --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "vertical-equivalent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:54:26.494721Z",
     "start_time": "2021-08-30T12:54:26.038902Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx.helper as OH\n",
    "import onnxruntime as rt\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import onnxruntime as rt\n",
    "\n",
    "# sess = rt.InferenceSession('/data/bb/test.onnx', providers=[\"CPUExecutionProvider\"])  \n",
    "sess = rt.InferenceSession('/data/bb/test.onnx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09f12021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:29:52.940218Z",
     "start_time": "2021-08-30T11:29:52.743384Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92794aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:39:45.881811Z",
     "start_time": "2021-08-30T11:39:45.820853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 112, 112, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60e823d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:48:21.587094Z",
     "start_time": "2021-08-30T11:48:19.214056Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('/data/bb/test.onnx')\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18ea107e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:46:48.422654Z",
     "start_time": "2021-08-30T11:46:48.363660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['input_1'], ['output_1', 'output_2', 'output_3'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rep.inputs, tf_rep.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5899f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:46:49.681258Z",
     "start_time": "2021-08-30T11:46:49.627927Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_rep.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb637ea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:48:32.642057Z",
     "start_time": "2021-08-30T11:48:28.097552Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/backend_tf_module.py:99 __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/backend.py:333 _onnx_node_to_tensorflow_op  *\n        return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/handler.py:59 handle  *\n        return ver_handle(node, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/transpose.py:14 version_1  *\n        return [cls.make_tensor_from_onnx_node(node, **kwargs)]\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend_handler.py:157 make_tensor_from_onnx_node  *\n        return cls._run_tf_func(tf_func, inputs, attrs)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend_handler.py:237 _run_tf_func  *\n        return tf_func(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:2228 transpose_v2\n        return transpose(a=a, perm=perm, name=name, conjugate=conjugate)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:2309 transpose\n        return transpose_fn(a, perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:11659 transpose\n        \"Transpose\", x=x, perm=perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension must be 5 but is 4 for '{{node onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__515}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_conv_layers/BiasAdd, onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__515/perm)' with input shapes: [?,?,?,?,512], [4].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-3cde7236e7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tf_rep.export_graph(\"output_path\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx_tf/backend_rep.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0moutput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mo_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3988\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3989\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3990\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3991\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/backend_tf_module.py:99 __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/backend.py:333 _onnx_node_to_tensorflow_op  *\n        return handler.handle(node, tensor_dict=tensor_dict, strict=strict)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/handler.py:59 handle  *\n        return ver_handle(node, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend/transpose.py:14 version_1  *\n        return [cls.make_tensor_from_onnx_node(node, **kwargs)]\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend_handler.py:157 make_tensor_from_onnx_node  *\n        return cls._run_tf_func(tf_func, inputs, attrs)\n    /usr/local/lib/python3.6/dist-packages/onnx_tf/handlers/backend_handler.py:237 _run_tf_func  *\n        return tf_func(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:2228 transpose_v2\n        return transpose(a=a, perm=perm, name=name, conjugate=conjugate)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:2309 transpose\n        return transpose_fn(a, perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:11659 transpose\n        \"Transpose\", x=x, perm=perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:601 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3569 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2042 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension must be 5 but is 4 for '{{node onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__515}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_conv_layers/BiasAdd, onnx_tf_prefix_StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__515/perm)' with input shapes: [?,?,?,?,512], [4].\n"
     ]
    }
   ],
   "source": [
    "# tf_rep.export_graph(\"output_path\")\n",
    "tf_rep.run(test_inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16e8a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:27:50.268287Z",
     "start_time": "2021-08-30T10:27:50.195151Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/aa/test.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c724b7f42adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/aa/test.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# onnx.helper.printable_graph(model.graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(f, format, load_external_data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mLoaded\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mModelProto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     '''\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/__init__.py\u001b[0m in \u001b[0;36m_load_bytes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/aa/test.onnx'"
     ]
    }
   ],
   "source": [
    "model = onnx.load(\"/data/bb/test.onnx\")\n",
    "onnx.checker.check_model(model, full_check=True)\n",
    "# onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "revolutionary-topic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:27:51.068273Z",
     "start_time": "2021-08-30T10:27:51.014321Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e82711b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:07:32.514968Z",
     "start_time": "2021-08-30T11:07:32.453441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_inference_session',\n",
       " '_enable_fallback',\n",
       " '_fallback_providers',\n",
       " '_inputs_meta',\n",
       " '_model_bytes',\n",
       " '_model_meta',\n",
       " '_model_path',\n",
       " '_outputs_meta',\n",
       " '_overridable_initializers',\n",
       " '_profiling_start_time_ns',\n",
       " '_provider_options',\n",
       " '_providers',\n",
       " '_read_config_from_model',\n",
       " '_reset_session',\n",
       " '_sess',\n",
       " '_sess_options',\n",
       " '_sess_options_initial',\n",
       " 'disable_fallback',\n",
       " 'enable_fallback',\n",
       " 'end_profiling',\n",
       " 'get_inputs',\n",
       " 'get_modelmeta',\n",
       " 'get_outputs',\n",
       " 'get_overridable_initializers',\n",
       " 'get_profiling_start_time_ns',\n",
       " 'get_provider_options',\n",
       " 'get_providers',\n",
       " 'get_session_options',\n",
       " 'io_binding',\n",
       " 'run',\n",
       " 'run_with_iobinding',\n",
       " 'set_providers']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "constitutional-brown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:01:45.332973Z",
     "start_time": "2021-08-30T11:01:42.975804Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Transpose node. Name:'StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__564' Status Message: perm: [ 0 3 1 2 ] does not align with rank of input data: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-54be5638c2e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Non-zero status code returned while running Transpose node. Name:'StatefulPartitionedCall/resnet_period_estimator_3/RE_temporal_bn_layers/FusedBatchNormV3__564' Status Message: perm: [ 0 3 1 2 ] does not align with rank of input data: 5"
     ]
    }
   ],
   "source": [
    "# test_inputs = tf.random.uniform((1, 64, 112, 112, 3))\n",
    "test_inputs = np.random.randn(2, 64, 112, 112, 3).astype(np.float32)\n",
    "inputs = {sess.get_inputs()[0].name: test_inputs}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "predictions = sess.run(outputs, inputs)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-essex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.579739Z",
     "start_time": "2021-08-30T10:24:11.173Z"
    }
   },
   "outputs": [],
   "source": [
    "%netron /data/aa/test.onnx 8228 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-marsh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.581191Z",
     "start_time": "2021-08-30T10:24:11.175Z"
    }
   },
   "outputs": [],
   "source": [
    "# inputs = tf.convert_to_tensor(test_inputs)\n",
    "\n",
    "inputs = tf.random.uniform((1, 64, 112, 112, 3))\n",
    "predictions = model1.predict(inputs)\n",
    "model1.summary()\n",
    "full_model = tf.function(lambda x: model1(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(inputs.shape, inputs.dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "# frozen_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-samuel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.582744Z",
     "start_time": "2021-08-30T10:24:11.177Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = frozen_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-rebel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.584426Z",
     "start_time": "2021-08-30T10:24:11.179Z"
    }
   },
   "outputs": [],
   "source": [
    "operations = frozen_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-corporation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.585689Z",
     "start_time": "2021-08-30T10:24:11.181Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for op in operations:\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-portable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.587265Z",
     "start_time": "2021-08-30T10:24:11.183Z"
    },
    "cell_style": "center",
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_func.graph,\n",
    "    logdir=\"/data/nb_data/tmp/frozen_models\",\n",
    "    name=\"simple_frozen_graph1.pb\",\n",
    "    as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-syndication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.588781Z",
     "start_time": "2021-08-30T10:24:11.184Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --input /data/nb_data/tmp/frozen_models/simple_frozen_graph1.pb \\\n",
    "    --inputs x:0 --outputs Identity:0,Identity_1:0,Identity_2:0 \\\n",
    "    --opset 10 --output /data/nb_data/tmp/repnet3.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-competition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.590010Z",
     "start_time": "2021-08-30T10:24:11.186Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession('/data/nb_data/tmp/repnet3.onnx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-jamaica",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.591408Z",
     "start_time": "2021-08-30T10:24:11.188Z"
    }
   },
   "outputs": [],
   "source": [
    "%netron /data/nb_data/tmp/repnet3.onnx 8222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5363203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:24:47.592733Z",
     "start_time": "2021-08-30T10:24:11.189Z"
    }
   },
   "outputs": [],
   "source": [
    "%watermark -p onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5f7c7",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da404e",
   "metadata": {},
   "source": [
    "- https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md\n",
    "- https://segmentfault.com/a/1190000039936376\n",
    "- https://github.com/onnx/tensorflow-onnx/issues/1606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da08f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
