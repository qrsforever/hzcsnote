{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-twelve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:11:02.334798Z",
     "start_time": "2021-08-25T08:11:01.872512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "netron 5.1.6\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx 1.10.0\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concerned-blame",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:11:11.049381Z",
     "start_time": "2021-08-25T08:11:10.474910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "Saved checkpoint for step 10: ./tf_ckpts/ckpt-1\n",
      "loss 30.41\n",
      "Saved checkpoint for step 20: ./tf_ckpts/ckpt-2\n",
      "loss 23.83\n",
      "Saved checkpoint for step 30: ./tf_ckpts/ckpt-3\n",
      "loss 17.27\n",
      "Saved checkpoint for step 40: ./tf_ckpts/ckpt-4\n",
      "loss 10.82\n",
      "Saved checkpoint for step 50: ./tf_ckpts/ckpt-5\n",
      "loss 4.73\n",
      "Restored from ./tf_ckpts/ckpt-5\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# -----  Toy Context  -----\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "class Net(tf.keras.Model):\n",
    "    \"\"\"A simple linear model.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "def toy_dataset():\n",
    "    inputs = tf.range(10.0)[:, None]\n",
    "    labels = inputs * 5.0 + tf.range(5.0)[None, :]\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices(dict(x=inputs, y=labels)).repeat().batch(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def train_step(net, example, optimizer):\n",
    "    \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = net(example[\"x\"])\n",
    "        loss = tf.reduce_mean(tf.abs(output - example[\"y\"]))\n",
    "    variables = net.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# -----  Create Objects  -----\n",
    "# ----------------------------\n",
    "\n",
    "net = Net()\n",
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator\n",
    ")\n",
    "manager = tf.train.CheckpointManager(ckpt, \"./tf_ckpts\", max_to_keep=3)\n",
    "\n",
    "# ----------------------------\n",
    "# -----  Train and Save  -----\n",
    "# ----------------------------\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "for _ in range(50):\n",
    "    example = next(iterator)\n",
    "    loss = train_step(net, example, opt)\n",
    "    ckpt.step.assign_add(1)\n",
    "    if int(ckpt.step) % 10 == 0:\n",
    "        save_path = manager.save()\n",
    "        print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "        print(\"loss {:1.2f}\".format(loss.numpy()))\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# -----  Restore  -----\n",
    "# ---------------------\n",
    "\n",
    "# In another script, re-initialize objects\n",
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "net = Net()\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(\n",
    "    step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator\n",
    ")\n",
    "manager = tf.train.CheckpointManager(ckpt, \"./tf_ckpts\", max_to_keep=3)\n",
    "\n",
    "# Re-use the manager code above ^\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "for _ in range(50):\n",
    "    example = next(iterator)\n",
    "    # Continue training or evaluate etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-sussex",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-peninsula",
   "metadata": {},
   "source": [
    "- [TensorFlow2中Keras模型保存与加载][1]\n",
    "\n",
    "[1]: https://www.cnblogs.com/chenzhen0530/p/13943172.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
