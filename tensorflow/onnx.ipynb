{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cac9a6b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1><span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-&amp;-Tools\" data-toc-modified-id=\"Import-&amp;-Tools-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import &amp; Tools</a></span></li><li><span><a href=\"#Repnet-Model\" data-toc-modified-id=\"Repnet-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Repnet Model</a></span></li><li><span><a href=\"#Load-Model\" data-toc-modified-id=\"Load-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modify-Add-OP-Shape-Align(Dim-Tile)\" data-toc-modified-id=\"Modify-Add-OP-Shape-Align(Dim-Tile)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Modify Add OP Shape Align(Dim Tile)</a></span></li><li><span><a href=\"#Simple-Conv3D-Model\" data-toc-modified-id=\"Simple-Conv3D-Model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Simple Conv3D Model</a></span></li></ul></li><li><span><a href=\"#Frozen-Graph\" data-toc-modified-id=\"Frozen-Graph-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Frozen Graph</a></span></li><li><span><a href=\"#Saved-Model\" data-toc-modified-id=\"Saved-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Saved Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modify-Transpose-Perm-Attributes(FusedBatchNormV3)\" data-toc-modified-id=\"Modify-Transpose-Perm-Attributes(FusedBatchNormV3)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Modify Transpose Perm Attributes(FusedBatchNormV3)</a></span></li><li><span><a href=\"#Original-Model-Outputs-VS-Modified-Model-Outputs\" data-toc-modified-id=\"Original-Model-Outputs-VS-Modified-Model-Outputs-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Original Model Outputs VS Modified Model Outputs</a></span></li><li><span><a href=\"#Onnx-Optimizer\" data-toc-modified-id=\"Onnx-Optimizer-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Onnx Optimizer</a></span></li><li><span><a href=\"#Fix-Unsqueeze-Op-(axis-attr)-Error-(TF--->-Onnx--->-OpenVINO)\" data-toc-modified-id=\"Fix-Unsqueeze-Op-(axis-attr)-Error-(TF--->-Onnx--->-OpenVINO)-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Fix Unsqueeze Op (axis attr) Error (TF --&gt; Onnx --&gt; OpenVINO)</a></span></li><li><span><a href=\"#Repnet-Inference\" data-toc-modified-id=\"Repnet-Inference-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Repnet Inference</a></span></li><li><span><a href=\"#Calculate-Count\" data-toc-modified-id=\"Calculate-Count-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Calculate Count</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inv-Period-Confidence-Score\" data-toc-modified-id=\"Inv-Period-Confidence-Score-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>Inv-Period Confidence Score</a></span></li><li><span><a href=\"#Within-Period-Confience-Scores\" data-toc-modified-id=\"Within-Period-Confience-Scores-5.6.2\"><span class=\"toc-item-num\">5.6.2&nbsp;&nbsp;</span>Within Period Confience Scores</a></span></li><li><span><a href=\"#Period-Count\" data-toc-modified-id=\"Period-Count-5.6.3\"><span class=\"toc-item-num\">5.6.3&nbsp;&nbsp;</span>Period Count</a></span></li></ul></li></ul></li><li><span><a href=\"#TFlite\" data-toc-modified-id=\"TFlite-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TFlite</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b7e37",
   "metadata": {},
   "source": [
    "## Import & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-stereo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T07:43:59.645169Z",
     "start_time": "2021-10-14T07:43:58.462646Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 95))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7daa8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T13:42:49.754549Z",
     "start_time": "2021-10-13T13:42:49.616705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnxsim 0.3.6\n"
     ]
    }
   ],
   "source": [
    "%watermark -p onnxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1506b211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:03:22.162817Z",
     "start_time": "2021-10-09T13:03:21.897087Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n",
    "\n",
    "def show_video(vidsrc, width=None, height=None):\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if vidsrc.startswith('http'):\n",
    "        data_url = vidsrc\n",
    "    else:\n",
    "        mp4 = open(vidsrc, 'rb').read()\n",
    "        data_url = 'data:video/mp4;base64,' + base64.b64encode(mp4).decode()\n",
    "    return HTML('<center><video %s %s controls src=\"%s\" type=\"video/mp4\"/></center>' % (W, H, data_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unable-velvet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:01:15.663475Z",
     "start_time": "2021-10-14T12:01:15.301661Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'erlangai-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), int(args[2]) if len(args) == 3 else 600\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #     pid = int(res[0].split(' ')[1])\n",
    "    #     !kill -9 $pid\n",
    "    import netron\n",
    "    try:\n",
    "        netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    except:\n",
    "        pass\n",
    "    display_html(port, height)\n",
    "    \n",
    "@register_line_magic\n",
    "def tensorboard(line):\n",
    "    import signal, shlex\n",
    "    from tensorboard import manager as tbmanager\n",
    "\n",
    "    args = line.split()\n",
    "    logdir, port, height = args[0], int(args[1]), int(args[2]) if len(args) == 3 else 600\n",
    "    \n",
    "    infos = tbmanager.get_all()\n",
    "    for info in infos:\n",
    "        if info.port != port: continue\n",
    "        try:\n",
    "            os.kill(info.pid, signal.SIGKILL)\n",
    "            os.unlink(os.path.join(tbmanager._get_info_dir(), f'pid-{info.pid}.info'))\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.ENOENT: raise\n",
    "        except Exception:\n",
    "            pass\n",
    "        break\n",
    "\n",
    "    strargs = f'--host 0.0.0.0 --port {port} --logdir {logdir} --reload_interval 10'\n",
    "    command = shlex.split(strargs, comments=True, posix=True)\n",
    "    tbmanager.start(command)\n",
    "    display_html(port, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfec991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:00:28.859017Z",
     "start_time": "2021-10-14T12:00:28.503399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.lite.python.util import run_graph_optimizations, get_grappler_config\n",
    "import onnx\n",
    "import onnx.helper as OH\n",
    "import onnxruntime as rt\n",
    "from onnxsim import simplify\n",
    "from onnx.numpy_helper import to_array, from_array\n",
    "import shutil\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38538d9c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Repnet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e6914",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Repnet模型转换为onnx进行推理时, 存在两个问题:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <li> 加法算子操作输入shape不一致问题(pos_encoding)</li>\n",
    "    <li> 3D卷积(5-D)后进行BatchNormlization时, 不支持5D</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e0a34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:00:25.856008Z",
     "start_time": "2021-10-14T12:00:25.046392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "younger-execution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T09:40:16.099934Z",
     "start_time": "2021-10-11T09:40:10.212426Z"
    },
    "code_folding": [
     132
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 1)\n",
      "(1, 64, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 64, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def flatten_sequential_feats(x, batch_size, seq_len):\n",
    "    \"\"\"Flattens sequential features with known batch size and seq_len.\"\"\"\n",
    "    x = tf.reshape(x, [batch_size, seq_len, -1])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Transformer from https://www.tensorflow.org/tutorials/text/transformer .\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead)\n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "      Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "      Returns:\n",
    "        outputs: shape == (..., seq_len_q, depth_v)\n",
    "        attention_weights: shape == (..., seq_len_q, seq_len_k)\n",
    "      \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk.\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    # (..., seq_len_q, seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    outputs = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return outputs, attention_weights\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"Multi-headed attention layer.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(\n",
    "            q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(\n",
    "            k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(\n",
    "            v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(\n",
    "            scaled_attention,\n",
    "            perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(\n",
    "            scaled_attention,\n",
    "            (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        outputs = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return outputs, attention_weights\n",
    "\n",
    "\n",
    "class TransformerLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Implements a single transformer layer (https://arxiv.org/abs/1706.03762).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, dff,\n",
    "                 dropout_rate=0.1,\n",
    "                 reorder_ln=False):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.reorder_ln = reorder_ln\n",
    "\n",
    "    def call(self, x):\n",
    "        inp_x = x\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            x = self.layernorm1(x)\n",
    "\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        attn_output, _ = self.mha(x, x, x, mask=None)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            out1 = inp_x + attn_output\n",
    "            x = out1\n",
    "        else:\n",
    "            # (batch_size, input_seq_len, d_model)\n",
    "            out1 = self.layernorm1(x + attn_output)\n",
    "            x = out1\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            x = self.layernorm2(x)\n",
    "\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(x)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            out2 = out1 + ffn_output\n",
    "        else:\n",
    "            # (batch_size, input_seq_len, d_model)\n",
    "            out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "def pairwise_l2_distance(a, b):\n",
    "    \"\"\"Computes pairwise distances between all rows of a and all rows of b.\"\"\"\n",
    "    norm_a = tf.reduce_sum(tf.square(a), 1)\n",
    "    norm_a = tf.reshape(norm_a, [-1, 1])\n",
    "    norm_b = tf.reduce_sum(tf.square(b), 1)\n",
    "    norm_b = tf.reshape(norm_b, [1, -1])\n",
    "    dist = tf.maximum(norm_a - 2.0 * tf.matmul(a, b, False, True) + norm_b, 0.0)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def get_sims(embs, temperature):\n",
    "    \"\"\"Calculates self-similarity between batch of sequence of embeddings.\"\"\"\n",
    "    # batch_size = tf.shape(embs)[0]\n",
    "    # seq_len = tf.shape(embs)[1]\n",
    "    # print(tf.shape(embs))\n",
    "    # embs = tf.reshape(embs, [batch_size, seq_len, -1])\n",
    "\n",
    "    def _get_sims(embs):\n",
    "        \"\"\"Calculates self-similarity between sequence of embeddings.\"\"\"\n",
    "        dist = pairwise_l2_distance(embs, embs)\n",
    "        sims = -1.0 * dist\n",
    "        return sims\n",
    "\n",
    "    # sims = tf.map_fn(_get_sims, embs)\n",
    "    # QRS: intel vpu not support while_loop\n",
    "    sims = tf.expand_dims(_get_sims(embs[0]), 0)\n",
    "    sims /= temperature\n",
    "    sims = tf.nn.softmax(sims, axis=-1)\n",
    "    sims = tf.expand_dims(sims, -1)\n",
    "    return sims\n",
    "\n",
    "\n",
    "class ResnetPeriodEstimator(tf.keras.models.Model):\n",
    "    \"\"\"RepNet model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_frames=64,\n",
    "        image_size=112,\n",
    "        base_model_layer_name='conv4_block3_out',\n",
    "        temperature=13.544,\n",
    "        dropout_rate=0.25,\n",
    "        l2_reg_weight=1e-6,\n",
    "        temporal_conv_channels=512,\n",
    "        temporal_conv_kernel_size=3,\n",
    "        temporal_conv_dilation_rate=3,\n",
    "        conv_channels=32,\n",
    "        conv_kernel_size=3,\n",
    "        transformer_layers_config=((512, 4, 512),),\n",
    "        transformer_dropout_rate=0.0,\n",
    "        transformer_reorder_ln=True,\n",
    "        period_fc_channels=(512, 512),\n",
    "        within_period_fc_channels=(512, 512)):\n",
    "        super(ResnetPeriodEstimator, self).__init__()\n",
    "\n",
    "        # Model params.\n",
    "        self.num_frames = num_frames\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.base_model_layer_name = base_model_layer_name\n",
    "\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_reg_weight = l2_reg_weight\n",
    "\n",
    "        self.temporal_conv_channels = temporal_conv_channels\n",
    "        self.temporal_conv_kernel_size = temporal_conv_kernel_size\n",
    "        self.temporal_conv_dilation_rate = temporal_conv_dilation_rate\n",
    "\n",
    "        self.conv_channels = conv_channels\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        # Transformer config in form of (channels, heads, bottleneck channels).\n",
    "        self.transformer_layers_config = transformer_layers_config\n",
    "        self.transformer_dropout_rate = transformer_dropout_rate\n",
    "        self.transformer_reorder_ln = transformer_reorder_ln\n",
    "\n",
    "        self.period_fc_channels = period_fc_channels\n",
    "        self.within_period_fc_channels = within_period_fc_channels\n",
    "\n",
    "        # Base ResNet50 Model.\n",
    "        base_model = tf.keras.applications.ResNet50V2(\n",
    "            include_top=False, weights=None, pooling='max')\n",
    "        self.base_model = tf.keras.models.Model(\n",
    "            inputs=base_model.input,\n",
    "            outputs=base_model.get_layer(self.base_model_layer_name).output)\n",
    "\n",
    "        # 3D Conv on k Frames\n",
    "        self.temporal_conv_layers = [\n",
    "            layers.Conv3D(self.temporal_conv_channels,\n",
    "                          self.temporal_conv_kernel_size,\n",
    "                          padding='same',\n",
    "                          dilation_rate=(self.temporal_conv_dilation_rate, 1, 1),\n",
    "                          kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                          kernel_initializer='he_normal')]\n",
    "        self.temporal_bn_layers = [layers.BatchNormalization()\n",
    "                                   for _ in self.temporal_conv_layers]\n",
    "\n",
    "        # Counting Module (Self-sim > Conv > Transformer > Classifier)\n",
    "        self.conv_3x3_layer = layers.Conv2D(self.conv_channels,\n",
    "                                            self.conv_kernel_size,\n",
    "                                            padding='same',\n",
    "                                            activation=tf.nn.relu)\n",
    "\n",
    "        channels = self.transformer_layers_config[0][0]\n",
    "        self.input_projection = layers.Dense(\n",
    "            channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "            activation=None)\n",
    "\n",
    "        self.input_projection2 = layers.Dense(\n",
    "            channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "            activation=None)\n",
    "\n",
    "        length = self.num_frames\n",
    "        self.pos_encoding = tf.compat.v1.get_variable(\n",
    "            name='resnet_period_estimator/pos_encoding',\n",
    "            shape=[1, length, 1],\n",
    "            initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "        self.pos_encoding2 = tf.compat.v1.get_variable(\n",
    "            name='resnet_period_estimator/pos_encoding2',\n",
    "            shape=[1, length, 1],\n",
    "            initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "        self.transformer_layers = []\n",
    "        for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "            self.transformer_layers.append(\n",
    "                TransformerLayer(d_model, num_heads, dff,\n",
    "                                 self.transformer_dropout_rate,\n",
    "                                 self.transformer_reorder_ln))\n",
    "\n",
    "        self.transformer_layers2 = []\n",
    "        for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "            self.transformer_layers2.append(\n",
    "                TransformerLayer(d_model, num_heads, dff,\n",
    "                                 self.transformer_dropout_rate,\n",
    "                                 self.transformer_reorder_ln))\n",
    "\n",
    "        # Period Prediction Module.\n",
    "        self.dropout_layer = layers.Dropout(self.dropout_rate)\n",
    "        num_preds = self.num_frames//2\n",
    "        self.fc_layers = []\n",
    "        for channels in self.period_fc_channels:\n",
    "            self.fc_layers.append(layers.Dense(\n",
    "                channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                activation=tf.nn.relu))\n",
    "        self.fc_layers.append(layers.Dense(\n",
    "            num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "        # Within Period Module\n",
    "        num_preds = 1\n",
    "        self.within_period_fc_layers = []\n",
    "        for channels in self.within_period_fc_channels:\n",
    "            self.within_period_fc_layers.append(layers.Dense(\n",
    "                channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                activation=tf.nn.relu))\n",
    "        self.within_period_fc_layers.append(layers.Dense(\n",
    "            num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensures we are always using the right batch_size during train/eval.\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        # Conv Feature Extractor.\n",
    "        x = tf.reshape(x, [-1, self.image_size, self.image_size, 3])\n",
    "        x = self.base_model(x) # (64, 7, 7, 1024)\n",
    "        # h = tf.shape(x)[1]\n",
    "        # w = tf.shape(x)[2]\n",
    "        # c = tf.shape(x)[3]\n",
    "        x = tf.reshape(x, [batch_size, -1, 7, 7, 1024])\n",
    "# \n",
    "        # 3D Conv to give temporal context to per-frame embeddings. \n",
    "        # for bn_layer, conv_layer in zip(self.temporal_bn_layers,\n",
    "        #                                 self.temporal_conv_layers):\n",
    "        #     x = conv_layer(x)\n",
    "        #     x = bn_layer(x)\n",
    "        #     x = tf.nn.relu(x)\n",
    "        # \n",
    "        x = self.temporal_conv_layers[0](x) # 1, 64, 7, 7, 512\n",
    "        x = self.temporal_bn_layers[0](x)\n",
    "        x = tf.nn.relu(x)\n",
    "        #     \n",
    "        # (1, 64, 7, 7, 512)\n",
    "        # x = tf.reshape(x, (batch_size, self.num_frames, 7, 7, -1))\n",
    "        # (1, 64, 512)\n",
    "        x = tf.reduce_max(x, axis=[2, 3])\n",
    "        \n",
    "        # Reshape and prepare embs for output.\n",
    "        # final_embs = x\n",
    "# \n",
    "        # Get self-similarity matrix.\n",
    "        x = get_sims(x, self.temperature)\n",
    "        print(x.shape)\n",
    "# \n",
    "        # 3x3 conv layer on self-similarity matrix.\n",
    "        x = self.conv_3x3_layer(x)\n",
    "        x = tf.reshape(x, [batch_size, self.num_frames, -1])\n",
    "        within_period_x = x\n",
    "# \n",
    "        # Period prediction.\n",
    "        x = self.input_projection(x)\n",
    "        x += self.pos_encoding\n",
    "        # for transformer_layer in self.transformer_layers:\n",
    "        #     x = transformer_layer(x)\n",
    "        print(x.shape)\n",
    "        x = self.transformer_layers[0](x)\n",
    "        \n",
    "        x = flatten_sequential_feats(x, batch_size, self.num_frames)\n",
    "        # for fc_layer in self.fc_layers:\n",
    "        #     x = self.dropout_layer(x)\n",
    "        #     x = fc_layer(x)\n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.fc_layers[0](x)\n",
    "        x = self.fc_layers[1](x)\n",
    "        x = self.fc_layers[2](x)\n",
    "# \n",
    "        # Within period prediction.\n",
    "        within_period_x = self.input_projection2(within_period_x)\n",
    "        within_period_x += self.pos_encoding2\n",
    "        # for transformer_layer in self.transformer_layers2:\n",
    "        #     within_period_x = transformer_layer(within_period_x)\n",
    "        within_period_x = self.transformer_layers2[0](within_period_x)\n",
    "        \n",
    "        within_period_x = flatten_sequential_feats(within_period_x, batch_size, self.num_frames)\n",
    "        # for fc_layer in self.within_period_fc_layers:\n",
    "        #     within_period_x = self.dropout_layer(within_period_x)\n",
    "        #     within_period_x = fc_layer(within_period_x)\n",
    "        within_period_x = self.dropout_layer(within_period_x)\n",
    "        within_period_x = self.within_period_fc_layers[0](within_period_x)\n",
    "        within_period_x = self.within_period_fc_layers[1](within_period_x)\n",
    "        within_period_x = self.within_period_fc_layers[2](within_period_x)\n",
    "\n",
    "        return x, within_period_x #, final_embs\n",
    "    \n",
    "model = ResnetPeriodEstimator()\n",
    "test_outputs = model(tf.random.uniform((1,64,112,112,3)))\n",
    "test_outputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f2ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T07:04:02.633001Z",
     "start_time": "2021-08-31T07:04:02.349943Z"
    }
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147969f",
   "metadata": {},
   "source": [
    "### Modify Add OP Shape Align(Dim Tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rocky-investigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:14:16.682427Z",
     "start_time": "2021-10-09T13:14:09.292731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 1)\n",
      "tf.Tensor([-0.00579794], shape=(1,), dtype=float32)\n",
      "--------------------\n",
      "(1, 64, 512)\n",
      "tf.Tensor(\n",
      "[0.02054866 0.02054866 0.02054866 0.02054866 0.02054866 0.02054866\n",
      " 0.02054866 0.02054866 0.02054866 0.02054866], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "print(model.pos_encoding.shape)\n",
    "print(model.pos_encoding[0][0][:10])\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore('/data/pretrained/cv/repnet/ckpt-88').expect_partial()\n",
    "print('-'*20)\n",
    "model.pos_encoding = tf.tile(model.pos_encoding, multiples=[1, 1, 512])\n",
    "model.pos_encoding2 = tf.tile(model.pos_encoding2, multiples=[1, 1, 512])\n",
    "print(model.pos_encoding.shape)\n",
    "print(model.pos_encoding[0][0][:10])\n",
    "test_inputs = np.random.randn(1, 64, 112, 112, 3).astype(np.float32)\n",
    "test_inputs_tensor = tf.convert_to_tensor(test_inputs)\n",
    "test_outputs = model(test_inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d5d3480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:14:22.434281Z",
     "start_time": "2021-10-09T13:14:22.186776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 32]), TensorShape([1, 64, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs[0].shape, test_outputs[1].shape # , test_outputs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72d943fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:14:24.839268Z",
     "start_time": "2021-10-09T13:14:24.387543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_period_estimator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_2 (Functional)         (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer_4 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_5 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,689,953\n",
      "Trainable params: 25,673,185\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411d10f",
   "metadata": {},
   "source": [
    "### Simple Conv3D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196a301",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "tool | version\n",
    "---: | :---:\n",
    "tensorflow | 2.6.0\n",
    "tensorboard | 2.6.0\n",
    "onnx | 1.10.1\n",
    "onnxruntime | 1.8.1\n",
    "tf2onnx | 1.9.2\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "针对上面版本, 转换onnx格式时, BatchNormalization会和Transpose操作融合为FusedBatchNormV3, Transpose的dim参数让人疑惑\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e7cdfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:03:41.250354Z",
     "start_time": "2021-10-14T12:03:40.916791Z"
    }
   },
   "outputs": [],
   "source": [
    "@register_line_magic\n",
    "def netron(line):\n",
    "    if not line or line.strip() == 'help':\n",
    "        print('%netron file port [height]')\n",
    "        return\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), int(args[2]) if len(args) == 3 else 600\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #     pid = int(res[0].split(' ')[1])\n",
    "    #     !kill -9 $pid\n",
    "    import netron\n",
    "    try:\n",
    "        netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    except:\n",
    "        pass\n",
    "    display_html(port, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7950928d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:00:38.769882Z",
     "start_time": "2021-10-14T12:00:36.888433Z"
    }
   },
   "outputs": [],
   "source": [
    "model3d = tf.keras.models.Sequential([\n",
    "    layers.Conv3D(\n",
    "        512, 3, padding='same',\n",
    "        dilation_rate=(3, 1, 1),\n",
    "        kernel_regularizer=regularizers.l2(1e-6),\n",
    "        kernel_initializer='he_normal'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU()\n",
    "])\n",
    "\n",
    "inputs3d = np.random.randn(1, 64, 7, 7, 1024).astype(np.float32)\n",
    "outputs3d = model3d(inputs3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512a2af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:00:46.070300Z",
     "start_time": "2021-10-14T12:00:42.072411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nb_data/saved_models/frozen_graph_3d.pb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_opt = False\n",
    "full_model = tf.function(lambda x: model3d(x))\n",
    "full_model = full_model.get_concrete_function(tf.TensorSpec(inputs3d.shape, inputs3d.dtype))\n",
    "frozen_func = convert_variables_to_constants_v2(full_model, lower_control_flow=False)\n",
    "\n",
    "frozen_graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "frozen_graph_proto_path = '/data/nb_data/saved_models/'\n",
    "as_text = False\n",
    "frozen_graph3d_file = tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_graph_def,\n",
    "    logdir=frozen_graph_proto_path,\n",
    "    name='frozen_graph_3d%s.pb%s' % ('_opt' if graph_opt else '', 'txt' if as_text else ''),\n",
    "    as_text=as_text)\n",
    "frozen_graph3d_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf57d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:04:24.961447Z",
     "start_time": "2021-10-14T12:04:24.632270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-a00e0295680fe699' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-a00e0295680fe699\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8999;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {frozen_graph_file} 8999 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0245077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T13:43:38.916583Z",
     "start_time": "2021-09-24T13:43:35.848526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model3d_path = '/data/nb_data/saved_models'\n",
    "model3d.save(saved_model3d_path, save_format='tf', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65e8dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T12:19:36.631466Z",
     "start_time": "2021-09-23T12:19:16.831934Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {saved_model3d_path} --output {saved_model3d_path}/saved_model3d.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81907ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T12:19:39.934125Z",
     "start_time": "2021-09-23T12:19:39.374687Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%netron {saved_model3d_path}/saved_model3d.onnx 8131 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28bc36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T12:23:12.741652Z",
     "start_time": "2021-09-23T12:23:11.779637Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(f'{saved_model3d_path}/saved_model3d.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: inputs3d}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "predictions = sess.run(outputs, inputs)\n",
    "predictions[-1].shape, outputs3d[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739203af",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Frozen Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a963c7ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T14:16:14.289433Z",
     "start_time": "2021-09-24T14:16:02.604300Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nb_data/saved_models/frozen_graph.pb'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_opt = False\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(tf.TensorSpec(test_inputs.shape, test_inputs.dtype))\n",
    "frozen_func = convert_variables_to_constants_v2(full_model, lower_control_flow=False) # lower_control_flow == True -> error \"unused_control_xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1e3e5f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T12:24:37.944022Z",
     "start_time": "2021-09-24T12:24:37.677952Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.python.eager.wrap_function.WrappedFunction'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('[\"add_gradient_functions_to_graph\", \"add_to_graph\", \"captured_inputs\", \"function_def\", \"graph\", \"inputs\", \"name\", \"output_dtypes\", \"output_shapes\", \"outputs\", \"pretty_printed_signature\", \"prune\", \"structured_input_signature\", \"structured_outputs\", \"trainable_variables\", \"variables\"]',\n",
       " '------------------------------------------------------------',\n",
       " [<tf.Tensor 'x:0' shape=(1, 64, 112, 112, 3) dtype=float32>],\n",
       " [<tf.Tensor 'Identity:0' shape=(64, 7, 7, 1024) dtype=float32>])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR_(frozen_func), '-' * 60, \\\n",
    "frozen_func.inputs, frozen_func.outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2dda0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T09:10:07.213741Z",
     "start_time": "2021-09-24T09:10:06.372039Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_DIR_(frozen_func.graph), '-' * 60, \\\n",
    "frozen_func.graph.inputs, frozen_func.graph.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91f9e30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T10:32:41.433452Z",
     "start_time": "2021-09-24T10:32:41.296496Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"resnet_period_estimator_4/transformer_layer_8/multi_head_attention_8/strided_slice\"\n",
      "op: \"StridedSlice\"\n",
      "input: \"resnet_period_estimator_4/transformer_layer_8/multi_head_attention_8/Shape\"\n",
      "input: \"resnet_period_estimator_4/transformer_layer_8/multi_head_attention_8/strided_slice/stack\"\n",
      "input: \"resnet_period_estimator_4/transformer_layer_8/multi_head_attention_8/strided_slice/stack_1\"\n",
      "input: \"resnet_period_estimator_4/transformer_layer_8/multi_head_attention_8/strided_slice/stack_2\"\n",
      "attr {\n",
      "  key: \"Index\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"begin_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"ellipsis_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"end_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"new_axis_mask\"\n",
      "  value {\n",
      "    i: 0\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shrink_axis_mask\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "type: <class 'tensorflow.python.framework.ops.Operation'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"colocation_groups\", \"control_inputs\", \"device\", \"get_attr\", \"graph\", \"inputs\", \"name\", \"node_def\", \"op_def\", \"outputs\", \"run\", \"traceback\", \"type\", \"values\"]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = frozen_func.graph.get_operations()\n",
    "print(operations[590])\n",
    "_DIR_(operations[590])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8f28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T09:10:35.552500Z",
     "start_time": "2021-09-24T09:10:34.561767Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, op in enumerate(operations, 1):\n",
    "    if op.name.startswith('unused'):\n",
    "        print('%5d' % i, op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cb7a8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T12:21:01.360623Z",
     "start_time": "2021-09-24T12:20:56.312025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "graph_opt = True\n",
    "\n",
    "input_tensors = [x for x in frozen_func.inputs if x.dtype != tf.resource]\n",
    "output_tensors = frozen_func.outputs\n",
    "\n",
    "if graph_opt:\n",
    "    config = [\n",
    "        'pruning', 'function', 'constfold', 'shape', 'remap', 'memory', 'loop',\n",
    "        'common_subgraph_elimination', 'arithmetic', 'dependency', 'debug_stripper'\n",
    "    ]\n",
    "\n",
    "    frozen_graph_def = run_graph_optimizations(\n",
    "        frozen_graph_def,\n",
    "        input_tensors,\n",
    "        output_tensors,\n",
    "        config=get_grappler_config(config),\n",
    "        graph=frozen_func.graph\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1edf6f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T12:40:14.555914Z",
     "start_time": "2021-09-24T12:40:13.899462Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nb_data/saved_models/frozen_graph.pb'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_graph_proto_path = '/data/nb_data/saved_models/'\n",
    "as_text = False\n",
    "frozen_graph_file = tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_graph_def,\n",
    "    logdir=frozen_graph_proto_path,\n",
    "    name='frozen_graph%s.pb%s' % ('_opt' if graph_opt else '', 'txt' if as_text else ''),\n",
    "    as_text=as_text)\n",
    "frozen_graph_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d7a3f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T13:11:40.628545Z",
     "start_time": "2021-09-24T13:11:40.317551Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8120\n",
      "Serving '/data/nb_data/saved_models/frozen_graph.pb' at http://0.0.0.0:8120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-808ab17fdd7bc253' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-808ab17fdd7bc253\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8120;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {frozen_graph_file} 8120 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b199d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:31:59.444620Z",
     "start_time": "2021-09-08T08:30:45.861594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = ','.join([x.name for x in frozen_func.inputs])\n",
    "outputs = ','.join([x.name for x in frozen_func.outputs])\n",
    "\n",
    "!python3 -m tf2onnx.convert --opset 14 --input {frozen_graph_file} \\\n",
    "    --inputs {inputs} --outputs {outputs} --output {frozen_graph_file}.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96c133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T08:31:59.601049Z",
     "start_time": "2021-09-08T08:31:59.447256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%netron {frozen_graph_file}.onnx 8132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b81c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T07:39:33.076829Z",
     "start_time": "2021-09-10T07:39:32.433216Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(f'{frozen_graph_file}.onnx')\n",
    "try:\n",
    "    onnx.checker.check_model(onnx_model, full_check=True) \n",
    "except Exception as err:\n",
    "    print(err)\n",
    "graph_def = onnx_model.graph\n",
    "_DIR_(graph_def), '-'*60, graph_def.input, '-'*60, graph_def.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e2cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:53.730937Z",
     "start_time": "2021-08-31T10:29:19.717963Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, node in enumerate(graph_def.node[95:99], 95):\n",
    "    print('%5d' % i, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22b8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:17.739861Z",
     "start_time": "2021-09-01T07:34:16.979480Z"
    }
   },
   "source": [
    "## Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de59d74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:46:47.253095Z",
     "start_time": "2021-10-08T06:46:47.112809Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model_path = '/data/nb_data/saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4a8766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:48:10.482116Z",
     "start_time": "2021-10-08T06:46:47.826515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_2_layer_call_and_return_conditional_losses, multi_head_attention_2_layer_call_fn, layer_normalization_4_layer_call_and_return_conditional_losses, layer_normalization_4_layer_call_fn, layer_normalization_5_layer_call_and_return_conditional_losses while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models_/assets\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(saved_model_path, save_format='tf', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ade440a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:48:40.787326Z",
     "start_time": "2021-10-08T06:48:10.510122Z"
    }
   },
   "outputs": [],
   "source": [
    "logdir=f'{saved_model_path}/log'\n",
    "model_tf = tf.saved_model.load(saved_model_path)\n",
    "sig = model_tf.signatures[\"serving_default\"]\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "with writer.as_default():\n",
    "    tf.summary.graph(sig.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d09732ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:48:41.023529Z",
     "start_time": "2021-10-08T06:48:40.794107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "unknown\n",
      "unknown_0\n"
     ]
    }
   ],
   "source": [
    "for node in sig.graph.as_graph_def().node[:3]:\n",
    "    print(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc4e9df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:48:49.877484Z",
     "start_time": "2021-10-08T06:48:41.026189Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-3c34d17467972f' width='100%' height='1000' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-3c34d17467972f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8421;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard {logdir} 8421 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dd67a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T08:11:31.339726Z",
     "start_time": "2021-09-23T08:11:31.179879Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python3 -m tf2onnx.convert --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5088419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:54:34.447443Z",
     "start_time": "2021-10-08T06:52:32.715271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-08 14:53:03,937 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-08 14:53:03,939 - INFO - Output names: ['output_1', 'output_2']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-08 14:53:14,951 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-08 14:53:20,676 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-10-08 14:53:20,676 - INFO - Using opset <onnx, 13>\n",
      "2021-10-08 14:53:48,791 - INFO - Computed 2 values for constant folding\n",
      "2021-10-08 14:54:04,830 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator_1/conv3d_1/Conv3D/strided_slice_1\n",
      "2021-10-08 14:54:04,831 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator_1/conv3d_1/Conv3D/strided_slice_2\n",
      "2021-10-08 14:54:08,408 - INFO - Optimizing ONNX model\n",
      "2021-10-08 14:54:09,834 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n",
      "2021-10-08 14:54:19,561 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n",
      "2021-10-08 14:54:24,739 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n",
      "2021-10-08 14:54:29,162 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n",
      "2021-10-08 14:54:32,808 - INFO - After optimization: BatchNormalization -20 (31->11), Cast -46 (90->44), Concat -31 (67->36), Const -479 (686->207), Gather -25 (41->16), GlobalAveragePool +8 (0->8), Identity -43 (43->0), Mul -1 (25->24), ReduceMean -8 (8->0), ReduceProd -40 (40->0), ReduceSum -1 (2->1), Reshape -10 (69->59), Shape -7 (30->23), Squeeze -7 (15->8), Transpose -48 (158->110), Unsqueeze -99 (107->8)\n",
      "2021-10-08 14:54:33,177 - INFO - \n",
      "2021-10-08 14:54:33,183 - INFO - Successfully converted TensorFlow model /data/nb_data/saved_models_ to ONNX\n",
      "2021-10-08 14:54:33,188 - INFO - Model inputs: ['input_1']\n",
      "2021-10-08 14:54:33,188 - INFO - Model outputs: ['output_1', 'output_2']\n",
      "2021-10-08 14:54:33,188 - INFO - ONNX model is saved at /data/nb_data/saved_models_/saved_model_op13_foldconst_dynamic.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {saved_model_path} --output {saved_model_path}/saved_model_op13_foldconst_dynamic.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691576b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T12:04:13.509580Z",
     "start_time": "2021-09-23T12:03:15.522959Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 --inputs input_1:0[1,64,112,112,3] \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {saved_model_path} --output {saved_model_path}/saved_model_op13_foldconst.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10fb3fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T06:54:34.623829Z",
     "start_time": "2021-10-08T06:54:34.450262Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/saved_models_/saved_model_op13_foldconst_dynamic.onnx' at http://0.0.0.0:8133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-936cc3e8dad8b0f1' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-936cc3e8dad8b0f1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8133;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %netron {saved_model_path}/saved_model_op13_foldconst.onnx 8133 500\n",
    "%netron {saved_model_path}/saved_model_op13_foldconst_dynamic.onnx 8133 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49169a",
   "metadata": {},
   "source": [
    "### Modify Transpose Perm Attributes(FusedBatchNormV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800e378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T12:06:31.636580Z",
     "start_time": "2021-09-23T12:06:30.640743Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onnx_filename_prefix = 'saved_model_op13_foldconst_dynamic'\n",
    "\n",
    "onnx_model = onnx.load(f'{saved_model_path}/{onnx_filename_prefix}.onnx')\n",
    "onnx_model = onnx.shape_inference.infer_shapes(onnx_model, check_type=True) # for value_info\n",
    "onnx_graph_def = onnx_model.graph\n",
    "for i, node in enumerate(onnx_graph_def.node[100:200], 100):\n",
    "    # print('%5d' % i, node.name)\n",
    "    if 'FusedBatchNormV3' in node.name and 'Transpose' == node.op_type:\n",
    "        print('-'*60)\n",
    "        print(node)\n",
    "        print('+'*60)\n",
    "        attr = node.attribute.pop()\n",
    "        if attr.ints[1] == 3:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 4, 1, 2, 3]))\n",
    "        elif attr.ints[1] == 2:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 2, 3, 4, 1]))\n",
    "        print('+'*60)\n",
    "        print(node)\n",
    "        print('-'*60)\n",
    "        \n",
    "onnx.save(onnx_model, f'{saved_model_path}/${onnx_filename_prefix}_mod.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdd30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:05:19.442905Z",
     "start_time": "2021-09-23T09:05:19.241017Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model.graph.node[0].input[0], onnx_model.graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b2ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:27.274057Z",
     "start_time": "2021-09-01T07:34:27.206510Z"
    }
   },
   "outputs": [],
   "source": [
    "len(onnx_graph_def.node), len(onnx_graph_def.value_info), len(onnx_graph_def.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17166bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:23.669329Z",
     "start_time": "2021-09-01T07:35:23.609303Z"
    }
   },
   "outputs": [],
   "source": [
    "target_idx = 189\n",
    "onnx_graph_def.value_info[target_idx], '-'*80, onnx_graph_def.node[target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8558fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:30.064157Z",
     "start_time": "2021-09-01T07:35:29.973956Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, w in enumerate(onnx_graph_def.initializer):\n",
    "    if onnx_graph_def.node[target_idx].input[0][:-2] in w.name:\n",
    "        print(w.dims, w.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e06b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, proto in enumerate(onnx_model.graph.value_info):\n",
    "    if 'ExpandDims' in proto.name:\n",
    "        print('%5d' % i, proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04269150",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, node in enumerate(onnx_graph_def.node):\n",
    "    if 'ExpandDims' in node.name:\n",
    "        print('%5d'%i, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce95f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:45:35.237347Z",
     "start_time": "2021-09-23T09:45:34.926825Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, node in enumerate(onnx_graph_def.node):\n",
    "#     print(node.name)\n",
    "    \n",
    "for i, proto in enumerate(onnx_model.graph.value_info):\n",
    "    print(proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d43761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T11:51:21.763469Z",
     "start_time": "2021-09-23T11:51:21.511396Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%netron {saved_model_path}/{onnx_filename_prefix}_mod.onnx 8134 600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968aa687",
   "metadata": {},
   "source": [
    "### Original Model Outputs VS Modified Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T11:40:43.551106Z",
     "start_time": "2021-09-23T11:40:41.964920Z"
    }
   },
   "outputs": [],
   "source": [
    "# sess = rt.InferenceSession(f'{saved_model_path}/saved_model_op13_foldconst_mod.onnx')  \n",
    "sess = rt.InferenceSession(f'{saved_model_path}/saved_model_op13_foldconst_dynamic_mod.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: test_inputs}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "outputs_onnx = sess.run(outputs, inputs)\n",
    "outputs_onnx[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88277511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:07:32.486745Z",
     "start_time": "2021-09-23T09:07:32.267349Z"
    }
   },
   "outputs": [],
   "source": [
    "test_inputs.shape, sess.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c09e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:07:33.844849Z",
     "start_time": "2021-09-23T09:07:33.628811Z"
    }
   },
   "outputs": [],
   "source": [
    "test_outputs[0][0][0][:3].numpy(), '-'*60, outputs_onnx[0][0][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169472b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:07:34.602435Z",
     "start_time": "2021-09-23T09:07:34.368714Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_outputs[1][0][:3].numpy().T, '-'*60, outputs_onnx[1][0][:3].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77eb5a",
   "metadata": {},
   "source": [
    "### Onnx Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01e75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:07:52.382079Z",
     "start_time": "2021-09-23T09:07:40.203175Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(f'{saved_model_path}/saved_model_op13_foldconst_mod.onnx')  \n",
    "model_simp, check = simplify(\n",
    "    onnx_model, dynamic_input_shape=False, \n",
    "    input_shapes={sess.get_inputs()[0].name: [1, 64, 112, 112, 3]})\n",
    "if not check:\n",
    "    raise\n",
    "model_simp.graph.input, model_simp.graph.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeabeec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fix Unsqueeze Op (axis attr) Error (TF --> Onnx --> OpenVINO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bd8cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the script will crash, error info as below.\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "CUR_DIR=$(cd $(dirname ${BASH_SOURCE[0]}); pwd)\n",
    "\n",
    "EXEBIN=/opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_onnx.py\n",
    "\n",
    "$EXEBIN --input_model $CUR_DIR/saved_model_simp.onnx  --output_dir $CUR_DIR \\\n",
    "    --model_name repnet --input_shape [1,64,112,112,3] \\\n",
    "    --log_level DEBUG\n",
    "```\n",
    "\n",
    "<font color=\"red\"><B>Error Info:</B></font>\n",
    "\n",
    "```\n",
    "[ 2021-09-03 18:45:59,828 ] [ DEBUG ] [ infer:117 ]  Partial infer for StatefulPartitionedCall/resnet_period_estimator/ExpandDims\n",
    "[ 2021-09-03 18:45:59,828 ] [ DEBUG ] [ infer:118 ]  Op: ExpandDims\n",
    "[ 2021-09-03 18:45:59,828 ] [ DEBUG ] [ infer:119 ]  Inputs:\n",
    "[ 2021-09-03 18:45:59,828 ] [ DEBUG ] [ infer:19 ]  input[0]: shape = [ 1 64 64], value = <UNKNOWN>\n",
    "[ 2021-09-03 18:45:59,829 ] [ DEBUG ] [ infer:19 ]  input[1]: shape = [1], value = [-1]\n",
    "[ ERROR ]  Cannot infer shapes or values for node \"StatefulPartitionedCall/resnet_period_estimator/ExpandDims\".\n",
    "[ ERROR ]  Wrong number of inputs to the layer StatefulPartitionedCall/resnet_period_estimator/ExpandDims\n",
    "[ ERROR ]  \n",
    "[ ERROR ]  It can happen due to bug in custom shape infer function <function ExpandDims.infer at 0x7f16e38afdc0>.\n",
    "[ ERROR ]  Or because the node inputs have incorrect values/shapes.\n",
    "[ ERROR ]  Or because input shapes are incorrect (embedded to the model or passed via --input_shape).\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "IF dynamic_input_shape is true (input batch size is dynamic), the mo_onnx will crash. \n",
    "</div>\n",
    "\n",
    "```    \n",
    "[ ERROR ]  -------------------------------------------------\n",
    "[ ERROR ]  ----------------- INTERNAL ERROR ----------------\n",
    "[ ERROR ]  Unexpected exception happened.\n",
    "[ ERROR ]  Please contact Model Optimizer developers and forward the following information:\n",
    "[ ERROR ]  Exception occurred during running replacer \"REPLACEMENT_ID (<class 'extensions.middle.ApplyPermutations.ApplyPermutation'>)\": Cannot infer `StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/SpaceToBatchND_transpose__511` due to both order and reverse_order was set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333f03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:09:10.605620Z",
     "start_time": "2021-09-23T09:09:10.406022Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for node in onnx_model.graph.node:\n",
    "#     if 'conv3d/Conv3D/SpaceToBatchND_cast__479' in node.name or \\\n",
    "#     'required_space_to_batch_paddings' in node.name:\n",
    "#         print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97822411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:09:47.971848Z",
     "start_time": "2021-09-23T09:09:47.768567Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_simp.graph.value_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9467d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:09:37.155594Z",
     "start_time": "2021-09-23T09:09:36.940394Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for weight in onnx_model.graph.initializer:\n",
    "#     if 'conv3d/Conv3D/required_space_to_batch_paddings/paddings_Concat__462' in weight.name:\n",
    "#         print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ebf7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:10:18.639999Z",
     "start_time": "2021-09-23T09:10:18.425051Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_simp_ = copy.deepcopy(model_simp)\n",
    "for i, node in enumerate(model_simp_.graph.node):\n",
    "    if 'ExpandDims' in node.name or node.op_type == 'Unsqueeze':\n",
    "        for j, weight in enumerate(model_simp_.graph.initializer):\n",
    "            for x in node.input:\n",
    "                if x.startswith('const_') and x in weight.name and weight.data_type == onnx.TensorProto.INT64:\n",
    "                    tensor_value = to_array(weight)\n",
    "                    for attr in node.attribute:\n",
    "                        if attr.name == 'axes':\n",
    "                            node.attribute.remove(attr)\n",
    "                            break\n",
    "                    node.input.remove(x)\n",
    "                    node.attribute.append(OH.make_attribute('axes', tensor_value))\n",
    "                    print('(%d,%d)\\n%s\\n'%(i, j, '-'*60))\n",
    "                    print(node, weight, tensor_value, type(tensor_value[0]), '\\n')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ffed37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:25:29.272360Z",
     "start_time": "2021-09-23T09:25:29.005313Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, node in enumerate(model_simp_.graph.node):\n",
    "    if 'Sum' in node.name:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc93b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:10:47.353877Z",
     "start_time": "2021-09-23T09:10:46.881110Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model_simp.CopyFrom(model_simp_)\n",
    "onnx.save(model_simp, f'{saved_model_path}/saved_model_op13_foldconst_mod_simp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a7cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:27:15.579246Z",
     "start_time": "2021-09-23T09:27:15.277746Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%netron {saved_model_path}/saved_model_op13_foldconst_mod_simp.onnx 8135 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c498b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T12:23:14.666681Z",
     "start_time": "2021-09-09T12:23:11.454993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sess = rt.InferenceSession(f'{saved_model_path}/saved_model_op13_foldconst_mod_simp.onnx')  \n",
    "# inputs = {sess.get_inputs()[0].name: test_inputs}\n",
    "# outputs = [o.name for o in sess.get_outputs()]\n",
    "# outputs_onnx = sess.run(outputs, inputs)\n",
    "# outputs_onnx[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a677a40",
   "metadata": {},
   "source": [
    "### Repnet Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d3ddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:16:15.242731Z",
     "start_time": "2021-09-23T09:15:51.185507Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy.signal import medfilt\n",
    "from scipy.special import softmax\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "num_frames = 64\n",
    "# video_path = '/data/testvids/test1.mp4'\n",
    "video_path = 'https://frepai.s3.didiyunapi.com/datasets/test/repnet_bird.gif'\n",
    "\n",
    "def read_video(video_filename, width=112, height=112):\n",
    "    cap = cv2.VideoCapture(video_filename)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "    if cap.isOpened():\n",
    "        while True:\n",
    "            success, frame_bgr = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb = cv2.resize(frame_rgb, (width, height))\n",
    "            frames.append(frame_rgb)\n",
    "        frames = np.asarray(frames)\n",
    "    return frames, fps\n",
    "\n",
    "video_frames, fps = read_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69521f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ec8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:16:42.188630Z",
     "start_time": "2021-09-23T09:16:41.938054Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = len(video_frames)\n",
    "diff = math.ceil(seq_len / num_frames) * num_frames - seq_len\n",
    "fps, seq_len, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1434f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:16:45.465905Z",
     "start_time": "2021-09-23T09:16:45.203862Z"
    }
   },
   "outputs": [],
   "source": [
    "# align num_frames\n",
    "frames = np.take(video_frames, indices=list(range(seq_len)) + [seq_len-1] * diff, axis=0)\n",
    "batch_size = int(len(frames) / num_frames)\n",
    "len(frames), batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad9338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:16:46.518512Z",
     "start_time": "2021-09-23T09:16:46.206688Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess image\n",
    "inputs_numpy = np.reshape(frames, (batch_size, 64, 112, 112, 3)).astype(np.float32)\n",
    "inputs_numpy -= 127.5\n",
    "inputs_numpy /= 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1cb555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:18:34.928139Z",
     "start_time": "2021-09-23T09:18:32.292899Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_numpy = np.random.randn(1, 64, 112, 112, 3).astype(np.float32)\n",
    "sess = rt.InferenceSession(f'{saved_model_path}/saved_model_op13_foldconst_mod_simp.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: inputs_numpy}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "outputs_onnx = sess.run(outputs, inputs)\n",
    "\n",
    "inputs_tensor = tf.convert_to_tensor(inputs_numpy)\n",
    "outputs_tensor = model(inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5052d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T09:18:35.946193Z",
     "start_time": "2021-09-23T09:18:35.694490Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs_tensor[1][0][:3].numpy().T, '-'*60, outputs_onnx[1][0][:3].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77adec",
   "metadata": {},
   "source": [
    "### Calculate Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores1, within_period1, sim1 = outputs_tensor[0].numpy(), outputs_tensor[1].numpy(), outputs_tensor[2].numpy()\n",
    "raw_scores2, within_period2, sim2 = outputs_onnx\n",
    "(raw_scores1.shape, within_period1.shape, sim1.shape), '-'*50, (raw_scores2.shape, within_period2.shape, sim2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_used = True\n",
    "if not onnx_used:\n",
    "    period_matrix = raw_scores1.reshape((-1, raw_scores1.shape[-1]))[:seq_len]\n",
    "    within_period = within_period1.reshape((-1, within_period1.shape[-1]))[:seq_len]\n",
    "else:\n",
    "    period_matrix = raw_scores2.reshape((-1, raw_scores2.shape[-1]))[:seq_len]\n",
    "    within_period = within_period2.reshape((-1, within_period2.shape[-1]))[:seq_len]\n",
    "(period_matrix.shape, within_period.shape), '-'*60, \\\n",
    "period_matrix[0][:3], '-'*60, within_period[:3].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd9a77",
   "metadata": {},
   "source": [
    "####  Inv-Period Confidence Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best value from [3, 32] as the inv-period\n",
    "per_frame_inv_period = np.argmax(period_matrix, axis=-1) + 1\n",
    "per_frame_inv_period[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee357eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_period_conf = np.max(softmax(period_matrix, axis=-1), axis=-1)\n",
    "inv_period_conf = np.where(np.less(per_frame_inv_period, 3), 0.0, inv_period_conf)\n",
    "inv_period_conf[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d637f",
   "metadata": {},
   "source": [
    "#### Within Period Confience Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_period_conf = sigmoid(within_period)[:, 0]\n",
    "within_period_conf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_period_conf  = np.sqrt(np.multiply(within_period_conf, inv_period_conf))\n",
    "within_period_conf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d56c34",
   "metadata": {},
   "source": [
    "#### Period Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d08f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_filter\n",
    "within_period_binary = np.asarray(within_period_conf > 0.5)\n",
    "within_period_binary = medfilt(within_period_binary, 5)\n",
    "within_period_binary[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374dd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_frame_counts = np.where(np.less(per_frame_inv_period, 3), 0.0, np.divide(1.0, per_frame_inv_period))\n",
    "per_frame_counts = medfilt(per_frame_counts, 5)\n",
    "per_frame_counts *= np.asarray(within_period_binary)\n",
    "per_frame_counts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87611738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(per_frame_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da38f2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c8bdbede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T10:00:15.743547Z",
     "start_time": "2021-09-28T10:00:15.217131Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'type'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"ABS\", \"ADD\", \"ADD_N\", \"ARG_MAX\", \"ARG_MIN\", \"AVERAGE_POOL_2D\", \"BATCH_MATMUL\", \"BATCH_TO_SPACE_ND\", \"BIDIRECTIONAL_SEQUENCE_LSTM\", \"BIDIRECTIONAL_SEQUENCE_RNN\", \"CALL\", \"CAST\", \"CEIL\", \"CONCATENATION\", \"CONCAT_EMBEDDINGS\", \"CONV_2D\", \"COS\", \"CUMSUM\", \"CUSTOM\", \"DELEGATE\", \"DENSIFY\", \"DEPTHWISE_CONV_2D\", \"DEPTH_TO_SPACE\", \"DEQUANTIZE\", \"DIV\", \"ELU\", \"EMBEDDING_LOOKUP\", \"EMBEDDING_LOOKUP_SPARSE\", \"EQUAL\", \"EXP\", \"EXPAND_DIMS\", \"FAKE_QUANT\", \"FILL\", \"FLOOR\", \"FLOOR_DIV\", \"FLOOR_MOD\", \"FULLY_CONNECTED\", \"GATHER\", \"GATHER_ND\", \"GREATER\", \"GREATER_EQUAL\", \"HARD_SWISH\", \"HASHTABLE_LOOKUP\", \"IF\", \"L2_NORMALIZATION\", \"L2_POOL_2D\", \"LEAKY_RELU\", \"LESS\", \"LESS_EQUAL\", \"LOCAL_RESPONSE_NORMALIZATION\", \"LOG\", \"LOGICAL_AND\", \"LOGICAL_NOT\", \"LOGICAL_OR\", \"LOGISTIC\", \"LOG_SOFTMAX\", \"LSH_PROJECTION\", \"LSTM\", \"MATRIX_DIAG\", \"MATRIX_SET_DIAG\", \"MAXIMUM\", \"MAX_POOL_2D\", \"MEAN\", \"MINIMUM\", \"MIRROR_PAD\", \"MUL\", \"NEG\", \"NON_MAX_SUPPRESSION_V4\", \"NON_MAX_SUPPRESSION_V5\", \"NOT_EQUAL\", \"ONE_HOT\", \"PACK\", \"PAD\", \"PADV2\", \"PLACEHOLDER_FOR_GREATER_OP_CODES\", \"POW\", \"PRELU\", \"QUANTIZE\", \"RANGE\", \"RANK\", \"REDUCE_ANY\", \"REDUCE_MAX\", \"REDUCE_MIN\", \"REDUCE_PROD\", \"RELU\", \"RELU6\", \"RELU_N1_TO_1\", \"RESHAPE\", \"RESIZE_BILINEAR\", \"RESIZE_NEAREST_NEIGHBOR\", \"REVERSE_SEQUENCE\", \"REVERSE_V2\", \"RNN\", \"ROUND\", \"RSQRT\", \"SCATTER_ND\", \"SEGMENT_SUM\", \"SELECT\", \"SELECT_V2\", \"SHAPE\", \"SIN\", \"SKIP_GRAM\", \"SLICE\", \"SOFTMAX\", \"SPACE_TO_BATCH_ND\", \"SPACE_TO_DEPTH\", \"SPARSE_TO_DENSE\", \"SPLIT\", \"SPLIT_V\", \"SQRT\", \"SQUARE\", \"SQUARED_DIFFERENCE\", \"SQUEEZE\", \"STRIDED_SLICE\", \"SUB\", \"SUM\", \"SVDF\", \"TANH\", \"TILE\", \"TOPK_V2\", \"TRANSPOSE\", \"TRANSPOSE_CONV\", \"UNIDIRECTIONAL_SEQUENCE_LSTM\", \"UNIDIRECTIONAL_SEQUENCE_RNN\", \"UNIQUE\", \"UNPACK\", \"WHERE\", \"WHILE\", \"ZEROS_LIKE\"]'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tflite.BuiltinOperator import BuiltinOperator\n",
    "_DIR_(BuiltinOperator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6cdfc9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:39:40.652440Z",
     "start_time": "2021-09-28T09:39:08.408631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_period_estimator_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_29 (Functional)        (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_580 (Dense)            multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_581 (Dense)            multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer_58 (Transf multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_59 (Transf multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_594 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_596 (Dense)            multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,690,081\n",
      "Trainable params: 25,673,313\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(saved_model_path)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "41801a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T11:08:50.329941Z",
     "start_time": "2021-09-28T11:08:49.810383Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'module'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"Interpreter\", \"OpsSet\", \"Optimize\", \"RepresentativeDataset\", \"TFLiteConverter\", \"TargetSpec\", \"experimental\"]'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR_(tf.lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd2057a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T11:28:25.840167Z",
     "start_time": "2021-09-28T11:28:25.791607Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346f2afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T11:31:19.976014Z",
     "start_time": "2021-09-28T11:30:55.642608Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/SpaceToBatchND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.SpaceToBatchND' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/SpaceToBatchND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/BatchToSpaceND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.BatchToSpaceND' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/BatchToSpaceND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/BiasAdd@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.BiasAdd' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/BiasAdd@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.Mul' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.AddV2' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: AddV2, BatchToSpaceND, BiasAdd, Mul, SpaceToBatchND\nDetails:\n\ttf.AddV2(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>)\n\ttf.BatchToSpaceND(tensor<?x?x?x?x512xf32>, tensor<3xi32>, tensor<3x2xi32>) -> (tensor<?x?x?x?x512xf32>) : {device = \"\"}\n\ttf.BiasAdd(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.Mul(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>)\n\ttf.SpaceToBatchND(tensor<?x?x7x7x1024xf32>, tensor<3xi32>, tensor<3x2xi32>) -> (tensor<?x?x?x?x1024xf32>) : {device = \"\"}\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f689a298e344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mOPT_FLOAT16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlitemodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtf_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s/saved_model%s.tflite'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_f16'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mOPT_FLOAT16\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     return self._optimize_tflite_model(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[0;34m(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# input_data, unused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# debug_info_str, unused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       enable_mlir_converter=True)\n\u001b[0m\u001b[1;32m    827\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    311\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0merror_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_metrics_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_collected_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m   return _run_toco_binary(model_flags_str, toco_flags_str, input_data_str,\n",
      "\u001b[0;31mConverterError\u001b[0m: <unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/SpaceToBatchND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.SpaceToBatchND' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/SpaceToBatchND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/BatchToSpaceND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.BatchToSpaceND' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/Conv3D/BatchToSpaceND@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/BiasAdd@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.BiasAdd' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/conv3d_32/BiasAdd@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.Mul' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): 'tf.AddV2' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"resnet_period_estimator_29/batch_normalization_32/FusedBatchNormV3@__inference__wrapped_model_176814\" at \"StatefulPartitionedCall@__inference_signature_wrapper_194321\") at \"StatefulPartitionedCall\")): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: AddV2, BatchToSpaceND, BiasAdd, Mul, SpaceToBatchND\nDetails:\n\ttf.AddV2(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>)\n\ttf.BatchToSpaceND(tensor<?x?x?x?x512xf32>, tensor<3xi32>, tensor<3x2xi32>) -> (tensor<?x?x?x?x512xf32>) : {device = \"\"}\n\ttf.BiasAdd(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>) : {data_format = \"NHWC\", device = \"\"}\n\ttf.Mul(tensor<?x?x?x?x512xf32>, tensor<512xf32>) -> (tensor<?x?x?x?x512xf32>)\n\ttf.SpaceToBatchND(tensor<?x?x7x7x1024xf32>, tensor<3xi32>, tensor<3x2xi32>) -> (tensor<?x?x?x?x1024xf32>) : {device = \"\"}\n\n"
     ]
    }
   ],
   "source": [
    "OPT_FLOAT16 = True\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.allow_custom_ops = False\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    # tf.lite.OpsSet.SELECT_TF_OPS, # tflite: some op not support\n",
    "]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "if OPT_FLOAT16:\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "litemodel = converter.convert()\n",
    "\n",
    "tf_model_path='%s/saved_model%s.tflite' % (saved_model_path, '_f16' if OPT_FLOAT16 else '')\n",
    "with open(tf_model_path, 'wb') as f:\n",
    "    f.write(litemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6f606269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:06:42.685455Z",
     "start_time": "2021-09-28T09:06:42.179957Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.lite.python.lite.TFLiteKerasModelConverterV2'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"allow_custom_ops\", \"convert\", \"experimental_enable_resource_variables\", \"experimental_new_converter\", \"experimental_new_quantizer\", \"inference_input_type\", \"inference_output_type\", \"optimizations\", \"representative_dataset\", \"saved_model_dir\", \"target_spec\"]'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR_(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "57cd3cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:10:24.206046Z",
     "start_time": "2021-09-28T09:10:23.472229Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tflite\n",
    "with open(tf_model_path, 'rb') as fr:                              \n",
    "    tflite_model = tflite.Model.GetRootAsModel(fr.read(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ffa721dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:10:33.493729Z",
     "start_time": "2021-09-28T09:10:32.974300Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tflite.Model.Model'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"Buffers\", \"BuffersLength\", \"Description\", \"GetRootAsModel\", \"Init\", \"Metadata\", \"MetadataBuffer\", \"MetadataBufferAsNumpy\", \"MetadataBufferLength\", \"MetadataLength\", \"OperatorCodes\", \"OperatorCodesLength\", \"SignatureDefs\", \"SignatureDefsLength\", \"Subgraphs\", \"SubgraphsLength\", \"Version\"]'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR_(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8df52356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:13:50.408910Z",
     "start_time": "2021-09-28T09:13:49.872387Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, <tflite.SubGraph.SubGraph at 0x7f87b7f6dee8>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model.SubgraphsLength(), tflite_model.Subgraphs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f72ec4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:14:58.452693Z",
     "start_time": "2021-09-28T09:14:57.856641Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tflite.SubGraph.SubGraph'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"GetRootAsSubGraph\", \"Init\", \"Inputs\", \"InputsAsNumpy\", \"InputsLength\", \"Name\", \"Operators\", \"OperatorsLength\", \"Outputs\", \"OutputsAsNumpy\", \"OutputsLength\", \"Tensors\", \"TensorsLength\"]'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph = tflite_model.Subgraphs(0)\n",
    "_DIR_(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5bb06af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:47:05.130609Z",
     "start_time": "2021-09-28T09:47:04.420933Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tflite.Operator.Operator'>\n",
      "[\"BuiltinOptions\", \"BuiltinOptionsType\", \"CustomOptions\", \"CustomOptionsAsNumpy\", \"CustomOptionsFormat\", \"CustomOptionsLength\", \"GetRootAsOperator\", \"Init\", \"Inputs\", \"InputsAsNumpy\", \"InputsLength\", \"Intermediates\", \"IntermediatesAsNumpy\", \"IntermediatesLength\", \"MutatingVariableInputs\", \"MutatingVariableInputsAsNumpy\", \"MutatingVariableInputsLength\", \"OpcodeIndex\", \"Outputs\", \"OutputsAsNumpy\", \"OutputsLength\"]\n",
      "b'FlexSpaceToBatchND'\n",
      "b'FlexBatchToSpaceND'\n",
      "b'FlexBiasAdd'\n",
      "b'FlexMul'\n",
      "b'FlexAddV2'\n"
     ]
    }
   ],
   "source": [
    "print(_DIR_(subgraph.Operators(0)))\n",
    "for i in range(subgraph.OperatorsLength()):\n",
    "    op = subgraph.Operators(i)\n",
    "    opc = tflite_model.OperatorCodes(op.OpcodeIndex())\n",
    "    x = opc.CustomCode()\n",
    "    if x is not None:\n",
    "        print(x)\n",
    "    # print(opc.CustomCode())\n",
    "    # if opc.CustomCode() is not None:\n",
    "    #     for j in range(op.CustomOptionsLength()):\n",
    "    #         print('%03d' % j, opc.CustomOptions(j), opc.CustomCode() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cee84733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T09:11:41.000693Z",
     "start_time": "2021-09-28T09:11:40.453395Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OperatorCodes() missing 1 required positional argument: 'j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-e7c204d9ad7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mopc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtflite_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: OperatorCodes() missing 1 required positional argument: 'j'"
     ]
    }
   ],
   "source": [
    "for opc in tflite_model.OperatorCodes():\n",
    "    print(opc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f9c56797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T07:21:59.884333Z",
     "start_time": "2021-09-28T07:21:59.348239Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'x',\n",
       "   'index': 0,\n",
       "   'shape': array([  1,  64, 112, 112,   3], dtype=int32),\n",
       "   'shape_signature': array([ -1,  64, 112, 112,   3], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}}],\n",
       " [{'name': 'Identity',\n",
       "   'index': 444,\n",
       "   'shape': array([ 1,  1, 32], dtype=int32),\n",
       "   'shape_signature': array([-1, -1, 32], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}},\n",
       "  {'name': 'Identity_1',\n",
       "   'index': 568,\n",
       "   'shape': array([1, 1, 1], dtype=int32),\n",
       "   'shape_signature': array([-1, -1,  1], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}}])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tf_model_path)\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], test_inputs.shape) # modify input shape\n",
    "interpreter.allocate_tensors()\n",
    "input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5081b980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T07:22:28.595496Z",
     "start_time": "2021-09-28T07:22:20.564388Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_inputs)\n",
    "interpreter.invoke()\n",
    "output_data1 = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data2 = interpreter.get_tensor(output_details[1]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "14ee9cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T07:22:28.983723Z",
     "start_time": "2021-09-28T07:22:28.598235Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.671763  ],\n",
       "       [0.83729875],\n",
       "       [1.1195688 ],\n",
       "       [1.40729   ],\n",
       "       [1.6208458 ],\n",
       "       [1.4918776 ],\n",
       "       [1.3537045 ],\n",
       "       [1.1293862 ],\n",
       "       [1.4433823 ],\n",
       "       [1.3766811 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data2[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5f7c7",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da404e",
   "metadata": {},
   "source": [
    "- https://github.com/onnx/onnx/blob/master/docs/Operators.md\n",
    "- https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md\n",
    "- https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md\n",
    "- https://segmentfault.com/a/1190000039936376\n",
    "- https://github.com/onnx/tensorflow-onnx/issues/1606\n",
    "- https://github.com/onnx/tensorflow-onnx/issues/1634\n",
    "- https://chowdera.com/2020/12/20201210193138753r.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108552f5",
   "metadata": {},
   "source": [
    "## FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d92bd",
   "metadata": {},
   "source": [
    "- [TensorFlow Lite: TensorListFromTensor, TensorListReserve, TensorListStack, While][1]\n",
    "- [Encountered unknown input type of a loop v5::Loop][2]\n",
    "\n",
    "[1]: https://github.com/tensorflow/tensorflow/issues/33416\n",
    "[2]: https://github.com/luxonis/blobconverter/issues/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadc5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "210px",
    "width": "283.026px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "224.361px",
    "left": "1173.46px",
    "top": "405.293px",
    "width": "407.088px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
