{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:13:46.420842Z",
     "start_time": "2021-08-27T13:13:45.882948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.19.5\n",
      "sklearn 0.24.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.1\n",
      "PIL 6.2.2\n",
      "matplotlib 3.3.3\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.0.dev20210103+cu101\n",
      "torchvision 0.9.0.dev20210103+cu101\n",
      "torchaudio not installed\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio\n",
    "%watermark -v -p tensorflow,tensorboard\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        segs = x.split(' ')\n",
    "        g = globals()\n",
    "        if 'github.com' in segs[1]:\n",
    "            uri = segs[1].replace('github.com', 'raw.githubusercontent.com')\n",
    "            mod = uri.split('/')\n",
    "            for s in ['main', 'master']:\n",
    "                uri = 'https://' + '/'.join(mod[:-1]) + '/main/' + mod[-1] + '.py'\n",
    "                x = requests.get(uri).text\n",
    "                if x.status == 200:\n",
    "                    break\n",
    "        elif 'gitee.com' in segs[1]:\n",
    "            mod = segs[1].split('/')\n",
    "            for s in ['/raw/main/', '/raw/master/']:\n",
    "                uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:]) + '.py'\n",
    "                x = requests.get(uri).text\n",
    "                if x.status == 200:\n",
    "                    break\n",
    "        elif segs[1][0] == '/':\n",
    "            with open(segs[1] + '.py') as fr:\n",
    "                x = fr.read()\n",
    "        exec(x, g)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'tensorboard-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_cell_magic\n",
    "def template_writefile(line, cell):\n",
    "    with open(line, 'w') as fw:\n",
    "        fw.write(cell.format(**globals()))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), 600\n",
    "    if len(args) == 3:\n",
    "        height = int(args[2])\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #    pid = int(res[0].split(' ')[1])\n",
    "    #    !kill -9 $pid\n",
    "    import netron\n",
    "    netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    display_html(port, height)\n",
    "\n",
    "# tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:14:05.379684Z",
     "start_time": "2021-08-27T13:14:05.264461Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:14:06.466601Z",
     "start_time": "2021-08-27T13:14:06.350639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f6862cf57f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:14:07.167458Z",
     "start_time": "2021-08-27T13:14:07.051767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:14:54.647744Z",
     "start_time": "2021-08-27T13:14:54.344156Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76L5XFonl_Bw",
    "outputId": "e6e2032e-3b45-4c00-a85a-46ec53d53bbc"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "import cv2\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Javascript\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# import tensorflow.compat.v2 as tf\n",
    "import tensorflow as tf\n",
    "\n",
    "# ! pip install youtube_dl\n",
    "# import youtube_dl\n",
    "\n",
    "# from google.colab import drive\n",
    "# from google.colab import output\n",
    "# from google.colab.output import eval_js\n",
    "\n",
    "# Model definition\n",
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers\n",
    "\n",
    "\n",
    "class ResnetPeriodEstimator(tf.keras.models.Model):\n",
    "  \"\"\"RepNet model.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      num_frames=64,\n",
    "      image_size=112,\n",
    "      base_model_layer_name='conv4_block3_out',\n",
    "      temperature=13.544,\n",
    "      dropout_rate=0.25,\n",
    "      l2_reg_weight=1e-6,\n",
    "      temporal_conv_channels=512,\n",
    "      temporal_conv_kernel_size=3,\n",
    "      temporal_conv_dilation_rate=3,\n",
    "      conv_channels=32,\n",
    "      conv_kernel_size=3,\n",
    "      transformer_layers_config=((512, 4, 512),),\n",
    "      transformer_dropout_rate=0.0,\n",
    "      transformer_reorder_ln=True,\n",
    "      period_fc_channels=(512, 512),\n",
    "      within_period_fc_channels=(512, 512)):\n",
    "    super(ResnetPeriodEstimator, self).__init__()\n",
    "\n",
    "    # Model params.\n",
    "    self.num_frames = num_frames\n",
    "    self.image_size = image_size\n",
    "\n",
    "    self.base_model_layer_name = base_model_layer_name\n",
    "\n",
    "    self.temperature = temperature\n",
    "\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.l2_reg_weight = l2_reg_weight\n",
    "\n",
    "    self.temporal_conv_channels = temporal_conv_channels\n",
    "    self.temporal_conv_kernel_size = temporal_conv_kernel_size\n",
    "    self.temporal_conv_dilation_rate = temporal_conv_dilation_rate\n",
    "\n",
    "    self.conv_channels = conv_channels\n",
    "    self.conv_kernel_size = conv_kernel_size\n",
    "    # Transformer config in form of (channels, heads, bottleneck channels).\n",
    "    self.transformer_layers_config = transformer_layers_config\n",
    "    self.transformer_dropout_rate = transformer_dropout_rate\n",
    "    self.transformer_reorder_ln = transformer_reorder_ln\n",
    "\n",
    "    self.period_fc_channels = period_fc_channels\n",
    "    self.within_period_fc_channels = within_period_fc_channels\n",
    "\n",
    "    # Base ResNet50 Model.\n",
    "    base_model = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, pooling='max')\n",
    "    self.base_model = tf.keras.models.Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(self.base_model_layer_name).output)\n",
    "\n",
    "    # 3D Conv on k Frames\n",
    "    self.temporal_conv_layers = [\n",
    "        layers.Conv3D(self.temporal_conv_channels,\n",
    "                      self.temporal_conv_kernel_size,\n",
    "                      padding='same',\n",
    "                      dilation_rate=(self.temporal_conv_dilation_rate, 1, 1),\n",
    "                      kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                      kernel_initializer='he_normal', name='RE_conv3D')]\n",
    "    self.temporal_bn_layers = [layers.BatchNormalization()\n",
    "                               for _ in self.temporal_conv_layers]\n",
    "\n",
    "    # Counting Module (Self-sim > Conv > Transformer > Classifier)\n",
    "    self.conv_3x3_layer = layers.Conv2D(self.conv_channels,\n",
    "                                        self.conv_kernel_size,\n",
    "                                        padding='same',\n",
    "                                        activation=tf.nn.relu)\n",
    "\n",
    "    channels = self.transformer_layers_config[0][0]\n",
    "    self.input_projection = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None)\n",
    "    self.input_projection2 = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None)\n",
    "\n",
    "    length = self.num_frames\n",
    "    self.pos_encoding = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "    self.pos_encoding2 = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding2',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    self.transformer_layers = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    self.transformer_layers2 = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers2.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    # Period Prediction Module.\n",
    "    self.dropout_layer = layers.Dropout(self.dropout_rate)\n",
    "    num_preds = self.num_frames//2\n",
    "    self.fc_layers = []\n",
    "    for channels in self.period_fc_channels:\n",
    "      self.fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu))\n",
    "    self.fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "    # Within Period Module\n",
    "    num_preds = 1\n",
    "    self.within_period_fc_layers = []\n",
    "    for channels in self.within_period_fc_channels:\n",
    "      self.within_period_fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu))\n",
    "    self.within_period_fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensures we are always using the right batch_size during train/eval.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    # Conv Feature Extractor.\n",
    "    x = tf.reshape(x, [-1, self.image_size, self.image_size, 3])\n",
    "    x = self.base_model(x)\n",
    "    h = tf.shape(x)[1]\n",
    "    w = tf.shape(x)[2]\n",
    "    c = tf.shape(x)[3]\n",
    "    x = tf.reshape(x, [batch_size, -1, h, w, c])\n",
    "\n",
    "    # 3D Conv to give temporal context to per-frame embeddings. \n",
    "    for bn_layer, conv_layer in zip(self.temporal_bn_layers,\n",
    "                                    self.temporal_conv_layers):\n",
    "      x = conv_layer(x)\n",
    "      x = bn_layer(x)\n",
    "      x = tf.nn.relu(x)\n",
    "    \n",
    "    print('temporal:', x.shape)\n",
    "\n",
    "    x = tf.reduce_max(x, [2, 3])\n",
    "\n",
    "    # Reshape and prepare embs for output.\n",
    "    final_embs = x\n",
    "\n",
    "    print('before get_sims', x.shape)\n",
    "    # Get self-similarity matrix.\n",
    "    x = get_sims(x, self.temperature)\n",
    "\n",
    "    # 3x3 conv layer on self-similarity matrix.\n",
    "    x = self.conv_3x3_layer(x)\n",
    "    print('before reshape', x.shape)\n",
    "    x = tf.reshape(x, [batch_size, self.num_frames, -1])\n",
    "    within_period_x = x\n",
    "    print('x-------', x.shape)\n",
    "\n",
    "    # Period prediction.\n",
    "    x = self.input_projection(x)\n",
    "    x += self.pos_encoding\n",
    "    for transformer_layer in self.transformer_layers:\n",
    "      x = transformer_layer(x)\n",
    "    x = flatten_sequential_feats(x, batch_size, self.num_frames)\n",
    "    for fc_layer in self.fc_layers:\n",
    "      x = self.dropout_layer(x)\n",
    "      x = fc_layer(x)\n",
    "\n",
    "    print('x-----2-', x.shape)\n",
    "    # Within period prediction.\n",
    "    within_period_x = self.input_projection2(within_period_x)\n",
    "    within_period_x += self.pos_encoding2\n",
    "    for transformer_layer in self.transformer_layers2:\n",
    "      within_period_x = transformer_layer(within_period_x)\n",
    "    within_period_x = flatten_sequential_feats(within_period_x,\n",
    "                                               batch_size,\n",
    "                                               self.num_frames)\n",
    "    for fc_layer in self.within_period_fc_layers:\n",
    "      within_period_x = self.dropout_layer(within_period_x)\n",
    "      within_period_x = fc_layer(within_period_x)\n",
    "\n",
    "    print('x-----3-', x.shape)\n",
    "    print('x-----4-', within_period_x.shape)\n",
    "    return x, within_period_x, final_embs\n",
    "\n",
    "  @tf.function\n",
    "  def preprocess(self, imgs):\n",
    "    imgs = tf.cast(imgs, tf.float32)\n",
    "    imgs -= 127.5\n",
    "    imgs /= 127.5\n",
    "    imgs = tf.image.resize(imgs, (self.image_size, self.image_size))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def get_sims(embs, temperature):\n",
    "  \"\"\"Calculates self-similarity between batch of sequence of embeddings.\"\"\"\n",
    "  batch_size = tf.shape(embs)[0]\n",
    "  seq_len = tf.shape(embs)[1]\n",
    "  embs = tf.reshape(embs, [batch_size, seq_len, -1])\n",
    "\n",
    "  def _get_sims(embs):\n",
    "    \"\"\"Calculates self-similarity between sequence of embeddings.\"\"\"\n",
    "    dist = pairwise_l2_distance(embs, embs)\n",
    "    sims = -1.0 * dist\n",
    "    return sims\n",
    "\n",
    "  sims = tf.map_fn(_get_sims, embs)\n",
    "  sims /= temperature\n",
    "  sims = tf.nn.softmax(sims, axis=-1)\n",
    "  sims = tf.expand_dims(sims, -1)\n",
    "  return sims\n",
    "\n",
    "\n",
    "def flatten_sequential_feats(x, batch_size, seq_len):\n",
    "  \"\"\"Flattens sequential features with known batch size and seq_len.\"\"\"\n",
    "  x = tf.reshape(x, [batch_size, seq_len, -1])\n",
    "  return x\n",
    "\n",
    "\n",
    "# Transformer from https://www.tensorflow.org/tutorials/text/transformer .\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    outputs: shape == (..., seq_len_q, depth_v)\n",
    "    attention_weights: shape == (..., seq_len_q, seq_len_k)\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk.\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  # (..., seq_len_q, seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "  outputs = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return outputs, attention_weights\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model)\n",
    "  ])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  \"\"\"Multi-headed attention layer.\"\"\"\n",
    "\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "\n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    q = self.split_heads(\n",
    "        q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(\n",
    "        k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(\n",
    "        v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(\n",
    "        scaled_attention,\n",
    "        perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(\n",
    "        scaled_attention,\n",
    "        (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    outputs = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    return outputs, attention_weights\n",
    "\n",
    "\n",
    "class TransformerLayer(tf.keras.layers.Layer):\n",
    "  \"\"\"Implements a single transformer layer (https://arxiv.org/abs/1706.03762).\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, d_model, num_heads, dff,\n",
    "               dropout_rate=0.1,\n",
    "               reorder_ln=False):\n",
    "    super(TransformerLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    self.reorder_ln = reorder_ln\n",
    "\n",
    "  def call(self, x):\n",
    "    inp_x = x\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      x = self.layernorm1(x)\n",
    "\n",
    "    # (batch_size, input_seq_len, d_model)\n",
    "    attn_output, _ = self.mha(x, x, x, mask=None)\n",
    "    attn_output = self.dropout1(attn_output)\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      out1 = inp_x + attn_output\n",
    "      x = out1\n",
    "    else:\n",
    "      # (batch_size, input_seq_len, d_model)\n",
    "      out1 = self.layernorm1(x + attn_output)\n",
    "      x = out1\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      x = self.layernorm2(x)\n",
    "\n",
    "    # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.ffn(x)\n",
    "    ffn_output = self.dropout2(ffn_output)\n",
    "\n",
    "    if self.reorder_ln:\n",
    "      out2 = out1 + ffn_output\n",
    "    else:\n",
    "      # (batch_size, input_seq_len, d_model)\n",
    "      out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    return out2\n",
    "\n",
    "\n",
    "def pairwise_l2_distance(a, b):\n",
    "  \"\"\"Computes pairwise distances between all rows of a and all rows of b.\"\"\"\n",
    "  norm_a = tf.reduce_sum(tf.square(a), 1)\n",
    "  norm_a = tf.reshape(norm_a, [-1, 1])\n",
    "  norm_b = tf.reduce_sum(tf.square(b), 1)\n",
    "  norm_b = tf.reshape(norm_b, [1, -1])\n",
    "  dist = tf.maximum(norm_a - 2.0 * tf.matmul(a, b, False, True) + norm_b, 0.0)\n",
    "  return dist\n",
    "\n",
    "\n",
    "def get_repnet_model(logdir):\n",
    "  \"\"\"Returns a trained RepNet model.\n",
    "\n",
    "  Args:\n",
    "    logdir (string): Path to directory where checkpoint will be downloaded.\n",
    "\n",
    "  Returns:\n",
    "    model (Keras model): Trained RepNet model.\n",
    "  \"\"\"\n",
    "  # Check if we are in eager mode.\n",
    "  assert tf.executing_eagerly()\n",
    "\n",
    "  # Models will be called in eval mode.\n",
    "  tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "  # Define RepNet model.\n",
    "  model = ResnetPeriodEstimator()\n",
    "  # tf.function for speed.\n",
    "  model.call = tf.function(model.call)\n",
    "\n",
    "  # Define checkpoint and checkpoint manager.\n",
    "  ckpt = tf.train.Checkpoint(model=model)\n",
    "  ckpt_manager = tf.train.CheckpointManager(\n",
    "      ckpt, directory=logdir, max_to_keep=10)\n",
    "  latest_ckpt = ckpt_manager.latest_checkpoint\n",
    "  print('Loading from: ', latest_ckpt)\n",
    "  if not latest_ckpt:\n",
    "    raise ValueError('Path does not have a checkpoint to load.')\n",
    "  # Restore weights.\n",
    "  ckpt.restore(latest_ckpt).expect_partial()\n",
    "\n",
    "  # Pass dummy frames to build graph.\n",
    "  model(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "  return model\n",
    "\n",
    "\n",
    "def unnorm(query_frame):\n",
    "  min_v = query_frame.min()\n",
    "  max_v = query_frame.max()\n",
    "  query_frame = (query_frame - min_v) / max(1e-7, (max_v - min_v))\n",
    "  return query_frame\n",
    "\n",
    "\n",
    "def create_count_video(frames,\n",
    "                       per_frame_counts,\n",
    "                       within_period,\n",
    "                       score,\n",
    "                       fps,\n",
    "                       output_file,\n",
    "                       delay,\n",
    "                       plot_count=True,\n",
    "                       plot_within_period=False,\n",
    "                       plot_score=False):\n",
    "  \"\"\"Creates video with running count and within period predictions.\n",
    "\n",
    "  Args:\n",
    "    frames (List): List of images in form of NumPy arrays.\n",
    "    per_frame_counts (List): List of floats indicating repetition count for\n",
    "      each frame. This is the rate of repetition for that particular frame.\n",
    "      Summing this list up gives count over entire video.\n",
    "    within_period (List): List of floats indicating score between 0 and 1 if the\n",
    "      frame is inside the periodic/repeating portion of a video or not.\n",
    "    score (float): Score between 0 and 1 indicating the confidence of the\n",
    "      RepNet model's count predictions.\n",
    "    fps (int): Frames per second of the input video. Used to scale the\n",
    "      repetition rate predictions to Hz.\n",
    "    output_file (string): Path of the output video.\n",
    "    delay (integer): Delay between each frame in the output video.\n",
    "    plot_count (boolean): if True plots the count in the output video.\n",
    "    plot_within_period (boolean): if True plots the per-frame within period\n",
    "      scores.\n",
    "    plot_score (boolean): if True plots the confidence of the model along with\n",
    "      count ot within_period scores.\n",
    "  \"\"\"\n",
    "  if output_file[-4:] not in ['.mp4', '.gif']:\n",
    "    raise ValueError('Output format can only be mp4 or gif')\n",
    "  num_frames = len(frames)\n",
    "\n",
    "  running_counts = np.cumsum(per_frame_counts)\n",
    "  final_count = running_counts[-1]\n",
    "\n",
    "  def count(idx):\n",
    "    return int(np.round(running_counts[idx]))\n",
    "\n",
    "  def rate(idx):\n",
    "    return per_frame_counts[idx] * fps\n",
    "\n",
    "  if plot_count and not plot_within_period:\n",
    "    fig = plt.figure(figsize=(10, 12), tight_layout=True)\n",
    "    im = plt.imshow(unnorm(frames[0]))\n",
    "    if plot_score:\n",
    "      plt.suptitle('Pred Count: %d, '\n",
    "                   'Prob: %0.1f' % (int(np.around(final_count)), score),\n",
    "                   fontsize=24)\n",
    "\n",
    "    plt.title('Count 0,create_count_video Rate: 0', fontsize=24)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    def update_count_plot(i):\n",
    "      \"\"\"Updates the count plot.\"\"\"\n",
    "      im.set_data(unnorm(frames[i]))\n",
    "      plt.title('Count %d, Rate: %0.4f Hz' % (count(i), rate(i)), fontsize=24)\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig,\n",
    "        update_count_plot,\n",
    "        frames=np.arange(1, num_frames),\n",
    "        interval=delay,\n",
    "        blit=False)\n",
    "    if output_file[-3:] == 'mp4':\n",
    "      anim.save(output_file, dpi=100, fps=24)\n",
    "    elif output_file[-3:] == 'gif':\n",
    "      anim.save(output_file, writer='imagemagick', fps=24, dpi=100)\n",
    "\n",
    "  elif plot_within_period:\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    im = axs[0].imshow(unnorm(frames[0]))\n",
    "    axs[1].plot(0, within_period[0])\n",
    "    axs[1].set_xlim((0, len(frames)))\n",
    "    axs[1].set_ylim((0, 1))\n",
    "\n",
    "    if plot_score:\n",
    "      plt.suptitle('Pred Count: %d, '\n",
    "                   'Prob: %0.1f' % (int(np.around(final_count)), score),\n",
    "                   fontsize=24)\n",
    "\n",
    "    if plot_count:\n",
    "      axs[0].set_title('Count 0, Rate: 0', fontsize=20)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "\n",
    "    def update_within_period_plot(i):\n",
    "      \"\"\"Updates the within period plot along with count.\"\"\"\n",
    "      im.set_data(unnorm(frames[i]))\n",
    "      axs[0].set_xticks([])\n",
    "      axs[0].set_yticks([])\n",
    "      xs = []\n",
    "      ys = []\n",
    "      if plot_count:\n",
    "        axs[0].set_title('Count %d, Rate: %0.4f Hz' % (count(i), rate(i)),\n",
    "                         fontsize=20)\n",
    "      for idx in range(i):\n",
    "        xs.append(idx)\n",
    "        ys.append(within_period[int(idx * len(within_period) / num_frames)])\n",
    "      axs[1].clear()\n",
    "      axs[1].set_title('Within Period or Not', fontsize=20)\n",
    "      axs[1].set_xlim((0, num_frames))\n",
    "      axs[1].set_ylim((-0.05, 1.05))\n",
    "      axs[1].plot(xs, ys)\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig,\n",
    "        update_within_period_plot,\n",
    "        frames=np.arange(1, num_frames),\n",
    "        interval=delay,\n",
    "        blit=False,\n",
    "    )\n",
    "    if output_file[-3:] == 'mp4':\n",
    "      anim.save(output_file, dpi=100, fps=24)\n",
    "    elif output_file[-3:] == 'gif':\n",
    "      anim.save(output_file, writer='imagemagick', fps=24, dpi=100)\n",
    "\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "def show_video(video_path):\n",
    "  mp4 = open(video_path, 'rb').read()\n",
    "  data_url = 'data:video/mp4;base64,' + base64.b64encode(mp4).decode()\n",
    "  return HTML(\"\"\"<video width=600 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\"></video>\n",
    "  \"\"\" % data_url)\n",
    "\n",
    "\n",
    "def viz_reps(frames,\n",
    "             count,\n",
    "             score,\n",
    "             alpha=1.0,\n",
    "             pichart=True,\n",
    "             colormap=plt.cm.PuBu,\n",
    "             num_frames=None,\n",
    "             interval=30,\n",
    "             plot_score=True):\n",
    "  \"\"\"Visualize repetitions.\"\"\"\n",
    "  if isinstance(count, list):\n",
    "    counts = len(frames) * [count/len(frames)]\n",
    "  else:\n",
    "    counts = count\n",
    "    \n",
    "  sum_counts = np.cumsum(counts)\n",
    "  tmp_path = '/tmp/output.mp4'\n",
    "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(5, 5),\n",
    "                         tight_layout=True,)\n",
    "\n",
    "  h, w, _ = np.shape(frames[0])\n",
    "  wedge_x = 95 / 112 * w\n",
    "  wedge_y = 17 / 112 * h\n",
    "  wedge_r = 15 / 112 * h\n",
    "  txt_x = 95 / 112 * w\n",
    "  txt_y = 19 / 112 * h\n",
    "  otxt_size = 62 / 112 * h\n",
    "\n",
    "  if plot_score:\n",
    "    plt.title('Score:%.2f' % score, fontsize=20)\n",
    "  im0 = ax.imshow(unnorm(frames[0]))\n",
    "\n",
    "  if not num_frames:\n",
    "    num_frames = len(frames)\n",
    "\n",
    "  if pichart:\n",
    "    wedge1 = matplotlib.patches.Wedge(\n",
    "        center=(wedge_x, wedge_y),\n",
    "        r=wedge_r,\n",
    "        theta1=0,\n",
    "        theta2=0,\n",
    "        color=colormap(1.),\n",
    "        alpha=alpha)\n",
    "    wedge2 = matplotlib.patches.Wedge(\n",
    "        center=(wedge_x, wedge_y),\n",
    "        r=wedge_r,\n",
    "        theta1=0,\n",
    "        theta2=0,\n",
    "        color=colormap(0.5),\n",
    "        alpha=alpha)\n",
    "\n",
    "    ax.add_patch(wedge1)\n",
    "    ax.add_patch(wedge2)\n",
    "    txt = ax.text(\n",
    "        txt_x,\n",
    "        txt_y,\n",
    "        '0',\n",
    "        size=35,\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        alpha=0.9,\n",
    "        color='white',\n",
    "    )\n",
    "\n",
    "  else:\n",
    "    txt = ax.text(\n",
    "        txt_x,\n",
    "        txt_y,\n",
    "        '0',\n",
    "        size=otxt_size,\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        alpha=0.8,\n",
    "        color=colormap(0.4),\n",
    "    )\n",
    "\n",
    "  def update(i):\n",
    "    \"\"\"Update plot with next frame.\"\"\"\n",
    "    im0.set_data(unnorm(frames[i]))\n",
    "    ctr = int(sum_counts[i])\n",
    "    if pichart:\n",
    "      if ctr%2 == 0:\n",
    "        wedge1.set_color(colormap(1.0))\n",
    "        wedge2.set_color(colormap(0.5))\n",
    "      else:\n",
    "        wedge1.set_color(colormap(0.5))\n",
    "        wedge2.set_color(colormap(1.0))\n",
    "\n",
    "      wedge1.set_theta1(-90)\n",
    "      wedge1.set_theta2(-90 - 360 * (1 - sum_counts[i] % 1.0))\n",
    "      wedge2.set_theta1(-90 - 360 * (1 - sum_counts[i] % 1.0))\n",
    "      wedge2.set_theta2(-90)\n",
    "\n",
    "    txt.set_text(int(sum_counts[i]))\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "  anim = FuncAnimation(\n",
    "      fig,\n",
    "      update,\n",
    "      frames=num_frames,\n",
    "      interval=interval,\n",
    "      blit=False)\n",
    "  anim.save(tmp_path, dpi=80)\n",
    "  plt.close()\n",
    "  return show_video(tmp_path)\n",
    "\n",
    "\n",
    "def record_video(interval_in_ms, num_frames, quality=0.8):\n",
    "  \"\"\"Capture video from webcam.\"\"\"\n",
    "  # https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb.\n",
    "\n",
    "  # Give warning before recording.\n",
    "  for i in range(0, 3):\n",
    "    print('Opening webcam in %d seconds'%(3-i))\n",
    "    time.sleep(1)\n",
    "    output.clear('status_text')\n",
    "\n",
    "  js = Javascript('''\n",
    "    async function recordVideo(interval_in_ms, num_frames, quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      // show the video in the HTML element\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight,\n",
    "        true);\n",
    "\n",
    "      for (let i = 0; i < num_frames; i++) {\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        img = canvas.toDataURL('image/jpeg', quality);\n",
    "        google.colab.kernel.invokeFunction(\n",
    "        'notebook.get_webcam_video', [img], {});\n",
    "        await new Promise(resolve => setTimeout(resolve, interval_in_ms));\n",
    "      }\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  eval_js('recordVideo({},{},{})'.format(interval_in_ms, num_frames, quality))\n",
    "\n",
    "\n",
    "def data_uri_to_img(uri):\n",
    "  \"\"\"Convert base64image to Numpy array.\"\"\"\n",
    "  image = base64.b64decode(uri.split(',')[1], validate=True)\n",
    "  # Binary string to PIL image.\n",
    "  image = Image.open(io.BytesIO(image))\n",
    "  image = image.resize((224, 224))\n",
    "  # PIL to Numpy array.\n",
    "  image = np.array(np.array(image, dtype=np.uint8), np.float32)\n",
    "  return image\n",
    "\n",
    "\n",
    "def read_video(video_filename, width=224, height=224):\n",
    "  \"\"\"Read video from file.\"\"\"\n",
    "  cap = cv2.VideoCapture(video_filename)\n",
    "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "  frames = []\n",
    "  if cap.isOpened():\n",
    "    while True:\n",
    "      success, frame_bgr = cap.read()\n",
    "      if not success:\n",
    "        break\n",
    "      frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "      frame_rgb = cv2.resize(frame_rgb, (width, height))\n",
    "      frames.append(frame_rgb)\n",
    "  frames = np.asarray(frames)\n",
    "  return frames, fps\n",
    "\n",
    "\n",
    "def get_webcam_video(img_b64):\n",
    "  \"\"\"Populates global variable imgs by converting image URI to Numpy array.\"\"\"\n",
    "  image = data_uri_to_img(img_b64)\n",
    "  imgs.append(image)\n",
    "\n",
    "\n",
    "def download_video_from_url(url_to_video,\n",
    "                            path_to_video='/tmp/video.mp4'):\n",
    "  if os.path.exists(path_to_video):\n",
    "    os.remove(path_to_video)\n",
    "  ydl_opts = {\n",
    "      'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
    "      'outtmpl': str(path_to_video),\n",
    "  }\n",
    "  with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url_to_video])\n",
    "\n",
    "\n",
    "def get_score(period_score, within_period_score):\n",
    "  \"\"\"Combine the period and periodicity scores.\"\"\"\n",
    "  within_period_score = tf.nn.sigmoid(within_period_score)[:, 0]\n",
    "  per_frame_periods = tf.argmax(period_score, axis=-1) + 1\n",
    "  pred_period_conf = tf.reduce_max(\n",
    "      tf.nn.softmax(period_score, axis=-1), axis=-1)\n",
    "  pred_period_conf = tf.where(\n",
    "      tf.math.less(per_frame_periods, 3), 0.0, pred_period_conf)\n",
    "  within_period_score *= pred_period_conf\n",
    "  within_period_score = np.sqrt(within_period_score)\n",
    "  pred_score = tf.reduce_mean(within_period_score)\n",
    "  return pred_score, within_period_score\n",
    "\n",
    "\n",
    "def get_counts(model, frames, strides, batch_size,\n",
    "               threshold,\n",
    "               within_period_threshold,\n",
    "               constant_speed=False,\n",
    "               median_filter=False,\n",
    "               fully_periodic=False):\n",
    "  \"\"\"Pass frames through model and conver period predictions to count.\"\"\"\n",
    "  seq_len = len(frames)\n",
    "  raw_scores_list = []\n",
    "  scores = []\n",
    "  within_period_scores_list = []\n",
    "\n",
    "  if fully_periodic:\n",
    "    within_period_threshold = 0.0\n",
    "\n",
    "  frames = model.preprocess(frames)\n",
    "\n",
    "  for stride in strides:\n",
    "    num_batches = int(np.ceil(seq_len/model.num_frames/stride/batch_size))\n",
    "    raw_scores_per_stride = []\n",
    "    within_period_score_stride = []\n",
    "    for batch_idx in range(num_batches):\n",
    "      idxes = tf.range(batch_idx*batch_size*model.num_frames*stride,\n",
    "                       (batch_idx+1)*batch_size*model.num_frames*stride,\n",
    "                       stride)\n",
    "      idxes = tf.clip_by_value(idxes, 0, seq_len-1)\n",
    "      curr_frames = tf.gather(frames, idxes)\n",
    "      curr_frames = tf.reshape(\n",
    "          curr_frames,\n",
    "          [batch_size, model.num_frames, model.image_size, model.image_size, 3])\n",
    "\n",
    "      raw_scores, within_period_scores, _ = model(curr_frames)\n",
    "      raw_scores_per_stride.append(np.reshape(raw_scores.numpy(),\n",
    "                                              [-1, model.num_frames//2]))\n",
    "      within_period_score_stride.append(np.reshape(within_period_scores.numpy(),\n",
    "                                                   [-1, 1]))\n",
    "    raw_scores_per_stride = np.concatenate(raw_scores_per_stride, axis=0)\n",
    "    raw_scores_list.append(raw_scores_per_stride)\n",
    "    within_period_score_stride = np.concatenate(\n",
    "        within_period_score_stride, axis=0)\n",
    "    pred_score, within_period_score_stride = get_score(\n",
    "        raw_scores_per_stride, within_period_score_stride)\n",
    "    scores.append(pred_score)\n",
    "    within_period_scores_list.append(within_period_score_stride)\n",
    "\n",
    "  # Stride chooser\n",
    "  argmax_strides = np.argmax(scores)\n",
    "  chosen_stride = strides[argmax_strides]\n",
    "  raw_scores = np.repeat(\n",
    "      raw_scores_list[argmax_strides], chosen_stride, axis=0)[:seq_len]\n",
    "  within_period = np.repeat(\n",
    "      within_period_scores_list[argmax_strides], chosen_stride,\n",
    "      axis=0)[:seq_len]\n",
    "  within_period_binary = np.asarray(within_period > within_period_threshold)\n",
    "  if median_filter:\n",
    "    within_period_binary = medfilt(within_period_binary, 5)\n",
    "\n",
    "  # Select Periodic frames\n",
    "  periodic_idxes = np.where(within_period_binary)[0]\n",
    "\n",
    "  if constant_speed:\n",
    "    # Count by averaging predictions. Smoother but\n",
    "    # assumes constant speed.\n",
    "    scores = tf.reduce_mean(\n",
    "        tf.nn.softmax(raw_scores[periodic_idxes], axis=-1), axis=0)\n",
    "    max_period = np.argmax(scores)\n",
    "    pred_score = scores[max_period]\n",
    "    pred_period = chosen_stride * (max_period + 1)\n",
    "    per_frame_counts = (\n",
    "        np.asarray(seq_len * [1. / pred_period]) *\n",
    "        np.asarray(within_period_binary))\n",
    "  else:\n",
    "    # Count each frame. More noisy but adapts to changes in speed.\n",
    "    pred_score = tf.reduce_mean(within_period)\n",
    "    per_frame_periods = tf.argmax(raw_scores, axis=-1) + 1\n",
    "    per_frame_counts = tf.where(\n",
    "        tf.math.less(per_frame_periods, 3),\n",
    "        0.0,\n",
    "        tf.math.divide(1.0,\n",
    "                       tf.cast(chosen_stride * per_frame_periods, tf.float32)),\n",
    "    )\n",
    "    if median_filter:\n",
    "      per_frame_counts = medfilt(per_frame_counts, 5)\n",
    "\n",
    "    per_frame_counts *= np.asarray(within_period_binary)\n",
    "\n",
    "    pred_period = seq_len/np.sum(per_frame_counts)\n",
    "\n",
    "  if pred_score < threshold:\n",
    "    print('No repetitions detected in video as score '\n",
    "          '%0.2f is less than threshold %0.2f.'%(pred_score, threshold))\n",
    "    per_frame_counts = np.asarray(len(per_frame_counts) * [0.])\n",
    "\n",
    "  return (pred_period, pred_score, within_period,\n",
    "          per_frame_counts, chosen_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPpgGXG_aalo"
   },
   "source": [
    "## Load trained RepNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:02.620712Z",
     "start_time": "2021-08-27T13:15:02.462091Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPeriodEstimator(tf.keras.models.Model):\n",
    "  \"\"\"RepNet model.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      num_frames=64,\n",
    "      image_size=112,\n",
    "      base_model_layer_name='conv4_block3_out',\n",
    "      temperature=13.544,\n",
    "      dropout_rate=0.25,\n",
    "      l2_reg_weight=1e-6,\n",
    "      temporal_conv_channels=512,\n",
    "      temporal_conv_kernel_size=3,\n",
    "      temporal_conv_dilation_rate=3,\n",
    "      conv_channels=32,\n",
    "      conv_kernel_size=3,\n",
    "      transformer_layers_config=((512, 4, 512),),\n",
    "      transformer_dropout_rate=0.0,\n",
    "      transformer_reorder_ln=True,\n",
    "      period_fc_channels=(512, 512),\n",
    "      within_period_fc_channels=(512, 512)):\n",
    "    super(ResnetPeriodEstimator, self).__init__()\n",
    "\n",
    "    # Model params.\n",
    "    self.num_frames = num_frames\n",
    "    self.image_size = image_size\n",
    "\n",
    "    self.base_model_layer_name = base_model_layer_name\n",
    "\n",
    "    self.temperature = temperature\n",
    "\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.l2_reg_weight = l2_reg_weight\n",
    "\n",
    "    self.temporal_conv_channels = temporal_conv_channels\n",
    "    self.temporal_conv_kernel_size = temporal_conv_kernel_size\n",
    "    self.temporal_conv_dilation_rate = temporal_conv_dilation_rate\n",
    "\n",
    "    self.conv_channels = conv_channels\n",
    "    self.conv_kernel_size = conv_kernel_size\n",
    "    # Transformer config in form of (channels, heads, bottleneck channels).\n",
    "    self.transformer_layers_config = transformer_layers_config\n",
    "    self.transformer_dropout_rate = transformer_dropout_rate\n",
    "    self.transformer_reorder_ln = transformer_reorder_ln\n",
    "\n",
    "    self.period_fc_channels = period_fc_channels\n",
    "    self.within_period_fc_channels = within_period_fc_channels\n",
    "\n",
    "    # Base ResNet50 Model.\n",
    "    base_model = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, pooling='max')\n",
    "    self.base_model = tf.keras.models.Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(self.base_model_layer_name).output)\n",
    "\n",
    "    # 3D Conv on k Frames\n",
    "    self.temporal_conv_layers = [\n",
    "        layers.Conv3D(self.temporal_conv_channels,\n",
    "                      self.temporal_conv_kernel_size,\n",
    "                      padding='same',\n",
    "                      dilation_rate=(self.temporal_conv_dilation_rate, 1, 1),\n",
    "                      kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                      kernel_initializer='he_normal', name='RE_temporal_conv_layers')]\n",
    "    self.temporal_bn_layers = [layers.BatchNormalization(name='RE_temporal_bn_layers')\n",
    "                               for _ in self.temporal_conv_layers]\n",
    "\n",
    "    # Counting Module (Self-sim > Conv > Transformer > Classifier)\n",
    "    self.conv_3x3_layer = layers.Conv2D(self.conv_channels,\n",
    "                                        self.conv_kernel_size,\n",
    "                                        padding='same',\n",
    "                                        activation=tf.nn.relu, name='RE_conv_3x3_layer')\n",
    "\n",
    "    channels = self.transformer_layers_config[0][0]\n",
    "    self.input_projection = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None, name='RE_input_projection')\n",
    "\n",
    "    self.input_projection2 = layers.Dense(\n",
    "        channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "        activation=None, name='RE_input_projection2')\n",
    "\n",
    "    length = self.num_frames\n",
    "    self.pos_encoding = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "    self.pos_encoding2 = tf.compat.v1.get_variable(\n",
    "        name='resnet_period_estimator/pos_encoding2',\n",
    "        shape=[1, length, 1],\n",
    "        initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    self.transformer_layers = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    self.transformer_layers2 = []\n",
    "    for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "      self.transformer_layers2.append(\n",
    "          TransformerLayer(d_model, num_heads, dff,\n",
    "                           self.transformer_dropout_rate,\n",
    "                           self.transformer_reorder_ln))\n",
    "\n",
    "    # Period Prediction Module.\n",
    "    self.dropout_layer = layers.Dropout(self.dropout_rate, name='RE_dropout_layer')\n",
    "    num_preds = self.num_frames//2\n",
    "    self.fc_layers = []\n",
    "    for i, channels in enumerate(self.period_fc_channels):\n",
    "      self.fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu, name=f'RE_fc_layers_{i}'))\n",
    "    self.fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight), name='RE_fc_layers_x'))\n",
    "\n",
    "    # Within Period Module\n",
    "    num_preds = 1\n",
    "    self.within_period_fc_layers = []\n",
    "    for i, channels in enumerate(self.within_period_fc_channels):\n",
    "      self.within_period_fc_layers.append(layers.Dense(\n",
    "          channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "          activation=tf.nn.relu, name=f'RE_within_period_fc_layers_{i}'))\n",
    "    self.within_period_fc_layers.append(layers.Dense(\n",
    "        num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight), name='RE_within_period_fc_layers_x'))\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensures we are always using the right batch_size during train/eval.\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    # Conv Feature Extractor.\n",
    "    print('input x:', x.shape)\n",
    "    x = tf.reshape(x, [-1, self.image_size, self.image_size, 3])\n",
    "    print('before base_model', x.shape)\n",
    "    x = self.base_model(x)\n",
    "    print('after base_model', x.shape)\n",
    "    h = tf.shape(x)[1]\n",
    "    w = tf.shape(x)[2]\n",
    "    c = tf.shape(x)[3]\n",
    "    x = tf.reshape(x, [batch_size, -1, h, w, c])\n",
    "    print('reshape:', x.shape)\n",
    "\n",
    "    # 3D Conv to give temporal context to per-frame embeddings. \n",
    "    for bn_layer, conv_layer in zip(self.temporal_bn_layers,\n",
    "                                    self.temporal_conv_layers):\n",
    "      x = conv_layer(x)\n",
    "      x = bn_layer(x)\n",
    "      x = tf.nn.relu(x)\n",
    "    \n",
    "    print('temporal shape:', x.shape)\n",
    "\n",
    "    x = tf.reduce_max(x, [2, 3])\n",
    "    \n",
    "    print('reduce max shape:', x.shape)\n",
    "\n",
    "    # Reshape and prepare embs for output.\n",
    "    final_embs = x\n",
    "\n",
    "    # Get self-similarity matrix.\n",
    "    x = get_sims(x, self.temperature)\n",
    "    \n",
    "    print('sims x:', x.shape)\n",
    "\n",
    "    # 3x3 conv layer on self-similarity matrix.\n",
    "    x = self.conv_3x3_layer(x)\n",
    "    print('before reshape: ', x.shape)\n",
    "    x = tf.reshape(x, [batch_size, self.num_frames, -1])\n",
    "    print('after reshape', x.shape)\n",
    "    within_period_x = x\n",
    "\n",
    "    # Period prediction.\n",
    "    x = self.input_projection(x)\n",
    "    print('input_projection:', x.shape)\n",
    "    x += self.pos_encoding\n",
    "    for transformer_layer in self.transformer_layers:\n",
    "      x = transformer_layer(x)\n",
    "    x = flatten_sequential_feats(x, batch_size, self.num_frames)\n",
    "    for fc_layer in self.fc_layers:\n",
    "      x = self.dropout_layer(x)\n",
    "      x = fc_layer(x)\n",
    "\n",
    "    # Within period prediction.\n",
    "    within_period_x = self.input_projection2(within_period_x)\n",
    "    within_period_x += self.pos_encoding2\n",
    "    for transformer_layer in self.transformer_layers2:\n",
    "      within_period_x = transformer_layer(within_period_x)\n",
    "    within_period_x = flatten_sequential_feats(within_period_x,\n",
    "                                               batch_size,\n",
    "                                               self.num_frames)\n",
    "    for fc_layer in self.within_period_fc_layers:\n",
    "      within_period_x = self.dropout_layer(within_period_x)\n",
    "      within_period_x = fc_layer(within_period_x)\n",
    "\n",
    "    return x, within_period_x, final_embs\n",
    "\n",
    "  @tf.function\n",
    "  def preprocess(self, imgs):\n",
    "    imgs = tf.cast(imgs, tf.float32)\n",
    "    imgs -= 127.5\n",
    "    imgs /= 127.5\n",
    "    imgs = tf.image.resize(imgs, (self.image_size, self.image_size))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:07.086256Z",
     "start_time": "2021-08-27T13:15:03.678803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from:  /data/pretrained/cv/repnet/ckpt-88\n",
      "input x: (1, 64, 112, 112, 3)\n",
      "before base_model (64, 112, 112, 3)\n",
      "after base_model (64, 7, 7, 1024)\n",
      "reshape: (1, 64, 7, 7, 1024)\n",
      "temporal shape: (1, 64, 7, 7, 512)\n",
      "reduce max shape: (1, 64, 512)\n",
      "sims x: (1, 64, 64, 1)\n",
      "before reshape:  (1, 64, 64, 32)\n",
      "after reshape (1, 64, 2048)\n",
      "input_projection: (1, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "def get_repnet_model(logdir):\n",
    "    # Models will be called in eval mode.\n",
    "    # tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "    # Define RepNet model.\n",
    "    model = ResnetPeriodEstimator()\n",
    "    \n",
    "    # tf.function for speed.\n",
    "    # model.call = tf.function(model.call)\n",
    "\n",
    "    # Define checkpoint and checkpoint manager.\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    ckpt_manager = tf.train.CheckpointManager(\n",
    "        ckpt, directory=logdir, max_to_keep=10)\n",
    "    latest_ckpt = ckpt_manager.latest_checkpoint\n",
    "    print('Loading from: ', latest_ckpt)\n",
    "    if not latest_ckpt:\n",
    "        raise ValueError('Path does not have a checkpoint to load.')\n",
    "        # Restore weights.\n",
    "    ckpt.restore(latest_ckpt).expect_partial()\n",
    "    # Pass dummy frames to build graph.\n",
    "    model(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "    return model\n",
    "\n",
    "PATH_TO_CKPT = '/data/pretrained/cv/repnet'\n",
    "model = get_repnet_model(PATH_TO_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:11.118625Z",
     "start_time": "2021-08-27T13:15:09.161248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6862b591d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ResnetPeriodEstimator()\n",
    "ckpt = tf.train.Checkpoint(model=model1)\n",
    "ckpt.restore('/data/pretrained/cv/repnet/ckpt-88').expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:12.217547Z",
     "start_time": "2021-08-27T13:15:12.095353Z"
    }
   },
   "outputs": [],
   "source": [
    "test_inputs = tf.random.uniform((1, 64, 112, 112, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:18.011813Z",
     "start_time": "2021-08-27T13:15:13.897346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x: (1, 64, 112, 112, 3)\n",
      "before base_model (64, 112, 112, 3)\n",
      "after base_model (64, 7, 7, 1024)\n",
      "reshape: (1, 64, 7, 7, 1024)\n",
      "temporal shape: (1, 64, 7, 7, 512)\n",
      "reduce max shape: (1, 64, 512)\n",
      "sims x: (1, 64, 64, 1)\n",
      "before reshape:  (1, 64, 64, 32)\n",
      "after reshape (1, 64, 2048)\n",
      "input_projection: (1, 64, 512)\n",
      "input x: (None, 64, 112, 112, 3)\n",
      "before base_model (None, 112, 112, 3)\n",
      "after base_model (None, 7, 7, 1024)\n",
      "reshape: (None, None, None, None, None)\n",
      "temporal shape: (None, None, None, None, 512)\n",
      "reduce max shape: (None, None, 512)\n",
      "sims x: (None, None, None, 1)\n",
      "before reshape:  (None, None, None, 32)\n",
      "after reshape (None, 64, None)\n",
      "input_projection: (None, 64, 512)\n",
      "Model: \"resnet_period_estimator_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_5 (Functional)         (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "RE_temporal_conv_layers (Con multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "RE_temporal_bn_layers (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "RE_conv_3x3_layer (Conv2D)   multiple                  320       \n",
      "_________________________________________________________________\n",
      "RE_input_projection (Dense)  multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "RE_input_projection2 (Dense) multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer_6 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_7 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "RE_dropout_layer (Dropout)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "RE_fc_layers_0 (Dense)       multiple                  262656    \n",
      "_________________________________________________________________\n",
      "RE_fc_layers_1 (Dense)       multiple                  262656    \n",
      "_________________________________________________________________\n",
      "RE_fc_layers_x (Dense)       multiple                  16416     \n",
      "_________________________________________________________________\n",
      "RE_within_period_fc_layers_0 multiple                  262656    \n",
      "_________________________________________________________________\n",
      "RE_within_period_fc_layers_1 multiple                  262656    \n",
      "_________________________________________________________________\n",
      "RE_within_period_fc_layers_x multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,690,081\n",
      "Trainable params: 25,673,313\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1(test_inputs)\n",
    "predictions = model1.predict(test_inputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:18.134728Z",
     "start_time": "2021-08-27T13:15:18.014510Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:15:38.215956Z",
     "start_time": "2021-08-27T13:15:33.730781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x: (1, 64, 112, 112, 3)\n",
      "before base_model (64, 112, 112, 3)\n",
      "after base_model (64, 7, 7, 1024)\n",
      "reshape: (1, 64, 7, 7, 1024)\n",
      "temporal shape: (1, 64, 7, 7, 512)\n",
      "reduce max shape: (1, 64, 512)\n",
      "sims x: (1, 64, 64, 1)\n",
      "before reshape:  (1, 64, 64, 32)\n",
      "after reshape (1, 64, 2048)\n",
      "input_projection: (1, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "full_model = tf.function(lambda x: model1(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(test_inputs.shape, test_inputs.dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "# frozen_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:16:53.006753Z",
     "start_time": "2021-08-27T13:16:52.648923Z"
    }
   },
   "outputs": [],
   "source": [
    "# frozen_func.graph.as_graph_def()\n",
    "graph = frozen_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:19:24.540757Z",
     "start_time": "2021-08-27T13:19:24.417323Z"
    }
   },
   "outputs": [],
   "source": [
    "operations = frozen_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T14:31:15.149807Z",
     "start_time": "2021-08-27T14:31:15.025664Z"
    }
   },
   "outputs": [],
   "source": [
    "T1 = {}\n",
    "T2 = {}\n",
    "for op in operations:\n",
    "    if 'RE_input_projection' in op.name:\n",
    "        T1[op.name] = op\n",
    "    else:\n",
    "        T2[op.name] = op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:40:26.921935Z",
     "start_time": "2021-08-27T13:40:26.808812Z"
    }
   },
   "source": [
    "```\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape/shape\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp/resource\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/MatMul\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot/shape\n",
    "resnet_period_estimator_5/RE_input_projection/Tensordot\n",
    "resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp/resource\n",
    "resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp\n",
    "resnet_period_estimator_5/RE_input_projection/BiasAdd\n",
    "resnet_period_estimator_5/add\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T14:29:54.411933Z",
     "start_time": "2021-08-27T14:29:54.294775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape/shape', 'resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape', 'resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp/resource', 'resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp', 'resnet_period_estimator_5/RE_input_projection/Tensordot/MatMul', 'resnet_period_estimator_5/RE_input_projection/Tensordot/shape', 'resnet_period_estimator_5/RE_input_projection/Tensordot', 'resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp/resource', 'resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp', 'resnet_period_estimator_5/RE_input_projection/BiasAdd', 'resnet_period_estimator_5/RE_input_projection2/BiasAdd/ReadVariableOp/resource', 'resnet_period_estimator_5/RE_input_projection2/BiasAdd/ReadVariableOp', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/ReadVariableOp/resource', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/ReadVariableOp', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/Reshape/shape', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/Reshape', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/MatMul', 'resnet_period_estimator_5/RE_input_projection2/Tensordot/shape', 'resnet_period_estimator_5/RE_input_projection2/Tensordot', 'resnet_period_estimator_5/RE_input_projection2/BiasAdd'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T14:31:29.336241Z",
     "start_time": "2021-08-27T14:31:29.221194Z"
    }
   },
   "outputs": [],
   "source": [
    "add = T2['resnet_period_estimator_5/add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T14:31:43.810299Z",
     "start_time": "2021-08-27T14:31:43.699404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor 'resnet_period_estimator_5/RE_input_projection/BiasAdd:0' shape=(1, 64, 512) dtype=float32>,\n",
       "  <tf.Tensor 'resnet_period_estimator_5/add/ReadVariableOp:0' shape=(1, 64, 1) dtype=float32>),\n",
       " [<tf.Tensor 'resnet_period_estimator_5/add:0' shape=(1, 64, 512) dtype=float32>])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.inputs, add.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:42:59.351196Z",
     "start_time": "2021-08-27T13:42:59.224015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor 'resnet_period_estimator_5/RE_input_projection/Tensordot:0' shape=(1, 64, 512) dtype=float32>,\n",
       "  <tf.Tensor 'resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp:0' shape=(512,) dtype=float32>),\n",
       " [<tf.Tensor 'resnet_period_estimator_5/RE_input_projection/BiasAdd:0' shape=(1, 64, 512) dtype=float32>])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.inputs, t1.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:19:38.728740Z",
     "start_time": "2021-08-27T13:19:38.341020Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "resnet_period_estimator_5/Shape_4\n",
      "resnet_period_estimator_5/strided_slice_4/stack\n",
      "resnet_period_estimator_5/strided_slice_4/stack_1\n",
      "resnet_period_estimator_5/strided_slice_4/stack_2\n",
      "resnet_period_estimator_5/strided_slice_4\n",
      "resnet_period_estimator_5/Shape_5\n",
      "resnet_period_estimator_5/strided_slice_5/stack\n",
      "resnet_period_estimator_5/strided_slice_5/stack_1\n",
      "resnet_period_estimator_5/strided_slice_5/stack_2\n",
      "resnet_period_estimator_5/strided_slice_5\n",
      "resnet_period_estimator_5/Reshape_2/shape/2\n",
      "resnet_period_estimator_5/Reshape_2/shape\n",
      "unused_control_flow_input\n",
      "resnet_period_estimator_5/Reshape_2\n",
      "resnet_period_estimator_5/map/TensorArrayUnstack/TensorListFromTensor/element_shape\n",
      "resnet_period_estimator_5/map/TensorArrayUnstack/TensorListFromTensor\n",
      "resnet_period_estimator_5/map/while/enter/_6\n",
      "unused_control_flow_input_1\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output/_47\n",
      "resnet_period_estimator_5/map/while/next_iteration/_29\n",
      "resnet_period_estimator_5/map/while/merge/_11\n",
      "unused_control_flow_input_2\n",
      "resnet_period_estimator_5/map/while/resnet_period_estimator_5/map/TensorArrayUnstack/TensorListFromTensor_switch/_17\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input/_42\n",
      "resnet_period_estimator_5/Reshape/shape\n",
      "resnet_period_estimator_5/Reshape\n",
      "resnet_period_estimator_5/model_5/conv1_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv1_pad/Pad\n",
      "resnet_period_estimator_5/model_5/conv1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv1_conv/Conv2D\n",
      "unused_control_flow_input_3\n",
      "resnet_period_estimator_5/model_5/conv1_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/pool1_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/pool1_pad/Pad\n",
      "resnet_period_estimator_5/model_5/pool1_pool/MaxPool\n",
      "unused_control_flow_input_4\n",
      "unused_control_flow_input_5\n",
      "unused_control_flow_input_6\n",
      "unused_control_flow_input_7\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_relu/Relu\n",
      "unused_control_flow_input_8\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/Conv2D\n",
      "unused_control_flow_input_9\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/BiasAdd\n",
      "unused_control_flow_input_10\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_conv/Conv2D\n",
      "unused_control_flow_input_11\n",
      "unused_control_flow_input_12\n",
      "unused_control_flow_input_13\n",
      "unused_control_flow_input_14\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_pad/Pad\n",
      "unused_control_flow_input_15\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "unused_control_flow_input_16\n",
      "unused_control_flow_input_17\n",
      "unused_control_flow_input_18\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_relu/Relu\n",
      "unused_control_flow_input_19\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv2_block1_out/add\n",
      "unused_control_flow_input_20\n",
      "unused_control_flow_input_21\n",
      "unused_control_flow_input_22\n",
      "unused_control_flow_input_23\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_conv/Conv2D\n",
      "unused_control_flow_input_24\n",
      "unused_control_flow_input_25\n",
      "unused_control_flow_input_26\n",
      "unused_control_flow_input_27\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_pad/Pad\n",
      "unused_control_flow_input_28\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_conv/Conv2D\n",
      "unused_control_flow_input_29\n",
      "unused_control_flow_input_30\n",
      "unused_control_flow_input_31\n",
      "unused_control_flow_input_32\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_relu/Relu\n",
      "unused_control_flow_input_33\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/Conv2D\n",
      "unused_control_flow_input_34\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv2_block2_out/add\n",
      "resnet_period_estimator_5/model_5/max_pooling2d_15/MaxPool\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "unused_control_flow_input_35\n",
      "unused_control_flow_input_36\n",
      "unused_control_flow_input_37\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_relu/Relu\n",
      "unused_control_flow_input_38\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/ReadVariableOp\n",
      "unused_control_flow_input_39\n",
      "unused_control_flow_input_40\n",
      "unused_control_flow_input_41\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_pad/Pad\n",
      "unused_control_flow_input_42\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "unused_control_flow_input_43\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_relu/Relu\n",
      "unused_control_flow_input_44\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/Conv2D\n",
      "unused_control_flow_input_45\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv2_block3_out/add\n",
      "unused_control_flow_input_46\n",
      "unused_control_flow_input_47\n",
      "unused_control_flow_input_48\n",
      "unused_control_flow_input_49\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_relu/Relu\n",
      "unused_control_flow_input_50\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/Conv2D\n",
      "unused_control_flow_input_51\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/BiasAdd\n",
      "unused_control_flow_input_52\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_conv/Conv2D\n",
      "unused_control_flow_input_53\n",
      "unused_control_flow_input_54\n",
      "unused_control_flow_input_55\n",
      "unused_control_flow_input_56\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_pad/Pad\n",
      "unused_control_flow_input_57\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_conv/Conv2D\n",
      "unused_control_flow_input_58\n",
      "unused_control_flow_input_59\n",
      "unused_control_flow_input_60\n",
      "unused_control_flow_input_61\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_relu/Relu\n",
      "unused_control_flow_input_62\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/Conv2D\n",
      "unused_control_flow_input_63\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv3_block1_out/add\n",
      "unused_control_flow_input_64\n",
      "unused_control_flow_input_65\n",
      "unused_control_flow_input_66\n",
      "unused_control_flow_input_67\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_relu/Relu\n",
      "unused_control_flow_input_68\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_conv/Conv2D\n",
      "unused_control_flow_input_69\n",
      "unused_control_flow_input_70\n",
      "unused_control_flow_input_71\n",
      "unused_control_flow_input_72\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_pad/Pad\n",
      "unused_control_flow_input_73\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_conv/Conv2D\n",
      "unused_control_flow_input_74\n",
      "unused_control_flow_input_75\n",
      "unused_control_flow_input_76\n",
      "unused_control_flow_input_77\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_relu/Relu\n",
      "unused_control_flow_input_78\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/Conv2D\n",
      "unused_control_flow_input_79\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv3_block2_out/add\n",
      "unused_control_flow_input_80\n",
      "unused_control_flow_input_81\n",
      "unused_control_flow_input_82\n",
      "unused_control_flow_input_83\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_relu/Relu\n",
      "unused_control_flow_input_84\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_conv/Conv2D\n",
      "unused_control_flow_input_85\n",
      "unused_control_flow_input_86\n",
      "unused_control_flow_input_87\n",
      "unused_control_flow_input_88\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_pad/Pad\n",
      "unused_control_flow_input_89\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_conv/Conv2D\n",
      "unused_control_flow_input_90\n",
      "unused_control_flow_input_91\n",
      "unused_control_flow_input_92\n",
      "unused_control_flow_input_93\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_relu/Relu\n",
      "unused_control_flow_input_94\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/Conv2D\n",
      "unused_control_flow_input_95\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv3_block3_out/add\n",
      "resnet_period_estimator_5/model_5/max_pooling2d_16/MaxPool\n",
      "unused_control_flow_input_96\n",
      "unused_control_flow_input_97\n",
      "unused_control_flow_input_98\n",
      "unused_control_flow_input_99\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_relu/Relu\n",
      "unused_control_flow_input_100\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_conv/Conv2D\n",
      "unused_control_flow_input_101\n",
      "unused_control_flow_input_102\n",
      "unused_control_flow_input_103\n",
      "unused_control_flow_input_104\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_pad/Pad\n",
      "unused_control_flow_input_105\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/Conv2D\n",
      "unused_control_flow_input_106\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv3_block4_out/add\n",
      "unused_control_flow_input_107\n",
      "unused_control_flow_input_108\n",
      "unused_control_flow_input_109\n",
      "unused_control_flow_input_110\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_relu/Relu\n",
      "unused_control_flow_input_111\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/Conv2D\n",
      "unused_control_flow_input_112\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/BiasAdd\n",
      "unused_control_flow_input_113\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_conv/Conv2D\n",
      "unused_control_flow_input_114\n",
      "unused_control_flow_input_115\n",
      "unused_control_flow_input_116\n",
      "unused_control_flow_input_117\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_pad/Pad\n",
      "unused_control_flow_input_118\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_conv/Conv2D\n",
      "unused_control_flow_input_119\n",
      "unused_control_flow_input_120\n",
      "unused_control_flow_input_121\n",
      "unused_control_flow_input_122\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_relu/Relu\n",
      "unused_control_flow_input_123\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/Conv2D\n",
      "unused_control_flow_input_124\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv4_block1_out/add\n",
      "unused_control_flow_input_125\n",
      "unused_control_flow_input_126\n",
      "unused_control_flow_input_127\n",
      "unused_control_flow_input_128\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_relu/Relu\n",
      "unused_control_flow_input_129\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "unused_control_flow_input_130\n",
      "unused_control_flow_input_131\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_pad/Pad\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_conv/Conv2D\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/ReadVariableOp\n",
      "unused_control_flow_input_132\n",
      "unused_control_flow_input_133\n",
      "unused_control_flow_input_134\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_relu/Relu\n",
      "unused_control_flow_input_135\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/Conv2D\n",
      "unused_control_flow_input_136\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv4_block2_out/add\n",
      "unused_control_flow_input_137\n",
      "unused_control_flow_input_138\n",
      "unused_control_flow_input_139\n",
      "unused_control_flow_input_140\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_relu/Relu\n",
      "unused_control_flow_input_141\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_conv/Conv2D\n",
      "unused_control_flow_input_142\n",
      "unused_control_flow_input_143\n",
      "unused_control_flow_input_144\n",
      "unused_control_flow_input_145\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_relu/Relu\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_pad/Pad/paddings\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_pad/Pad\n",
      "unused_control_flow_input_146\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_conv/Conv2D\n",
      "unused_control_flow_input_147\n",
      "unused_control_flow_input_148\n",
      "unused_control_flow_input_149\n",
      "unused_control_flow_input_150\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/FusedBatchNormV3\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_relu/Relu\n",
      "unused_control_flow_input_151\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/Conv2D\n",
      "unused_control_flow_input_152\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/BiasAdd\n",
      "resnet_period_estimator_5/model_5/conv4_block3_out/add\n",
      "resnet_period_estimator_5/Reshape_1/shape/1\n",
      "resnet_period_estimator_5/Shape_1\n",
      "resnet_period_estimator_5/strided_slice_1/stack\n",
      "resnet_period_estimator_5/strided_slice_1/stack_1\n",
      "resnet_period_estimator_5/strided_slice_1/stack_2\n",
      "resnet_period_estimator_5/strided_slice_1\n",
      "resnet_period_estimator_5/Shape_2\n",
      "resnet_period_estimator_5/strided_slice_2/stack\n",
      "resnet_period_estimator_5/strided_slice_2/stack_1\n",
      "resnet_period_estimator_5/strided_slice_2/stack_2\n",
      "resnet_period_estimator_5/strided_slice_2\n",
      "resnet_period_estimator_5/Shape_3\n",
      "resnet_period_estimator_5/strided_slice_3/stack\n",
      "resnet_period_estimator_5/strided_slice_3/stack_1\n",
      "resnet_period_estimator_5/strided_slice_3/stack_2\n",
      "resnet_period_estimator_5/strided_slice_3\n",
      "unused_control_flow_input_153\n",
      "resnet_period_estimator_5/Reshape_1/shape\n",
      "resnet_period_estimator_5/Reshape_1\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/SpaceToBatchND/block_shape\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/SpaceToBatchND/paddings\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/SpaceToBatchND\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/BatchToSpaceND/block_shape\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/BatchToSpaceND/crops\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/Conv3D/BatchToSpaceND\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_temporal_conv_layers/BiasAdd\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/FusedBatchNormV3/ReadVariableOp\n",
      "unused_control_flow_input_154\n",
      "unused_control_flow_input_155\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/FusedBatchNormV3\n",
      "resnet_period_estimator_5/Relu\n",
      "resnet_period_estimator_5/Max/reduction_indices\n",
      "resnet_period_estimator_5/Max\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/Shape\n",
      "resnet_period_estimator_5/strided_slice/stack\n",
      "resnet_period_estimator_5/strided_slice/stack_1\n",
      "resnet_period_estimator_5/strided_slice/stack_2\n",
      "resnet_period_estimator_5/strided_slice\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/map/while/maximum_iterations\n",
      "resnet_period_estimator_5/map/while/enter/_3\n",
      "unused_control_flow_input_156\n",
      "unused_control_flow_input_157\n",
      "resnet_period_estimator_5/map/while/resnet_period_estimator_5/map/while/maximum_iterations_switch/_14\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input/_39\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Identity_1\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output/_44\n",
      "resnet_period_estimator_5/map/while/next_iteration/_26\n",
      "resnet_period_estimator_5/map/while/merge/_8\n",
      "resnet_period_estimator_5/map/while/loop_counter\n",
      "resnet_period_estimator_5/map/while/enter/_2\n",
      "unused_control_flow_input_158\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input/_38\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/add_2/y\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/add_2\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Identity\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output/_43\n",
      "resnet_period_estimator_5/map/while/next_iteration/_25\n",
      "resnet_period_estimator_5/map/while/merge/_7\n",
      "Func/resnet_period_estimator_5/map/while/cond/_0/input_control_node/_30\n",
      "Func/resnet_period_estimator_5/map/while/cond/_0/input/_31\n",
      "Func/resnet_period_estimator_5/map/while/cond/_0/input/_32\n",
      "resnet_period_estimator_5/map/while/cond/_0/resnet_period_estimator_5/map/while/Less_1\n",
      "unused_control_flow_input_159\n",
      "Func/resnet_period_estimator_5/map/while/cond/_0/input/_33\n",
      "resnet_period_estimator_5/map/while/cond/_0/resnet_period_estimator_5/map/while/Less/y\n",
      "resnet_period_estimator_5/map/while/cond/_0/resnet_period_estimator_5/map/while/Less\n",
      "resnet_period_estimator_5/map/while/cond/_0/resnet_period_estimator_5/map/while/LogicalAnd\n",
      "resnet_period_estimator_5/map/while/cond/_0/resnet_period_estimator_5/map/while/Identity\n",
      "Func/resnet_period_estimator_5/map/while/cond/_0/output/_36\n",
      "resnet_period_estimator_5/map/while/LoopCond/_12\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/RE_temporal_bn_layers/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/map/while/resnet_period_estimator_5/map/while/loop_counter_switch/_13\n",
      "resnet_period_estimator_5/map/Const\n",
      "resnet_period_estimator_5/map/while/enter/_4\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/add_1/y\n",
      "unused_control_flow_input_160\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/add_1\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Identity_2\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output/_45\n",
      "resnet_period_estimator_5/map/while/next_iteration/_27\n",
      "resnet_period_estimator_5/map/while/merge/_9\n",
      "resnet_period_estimator_5/map/while/resnet_period_estimator_5/map/Const_switch/_15\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input/_40\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv1_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv1_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/map/while/loop_body_control/_18\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input_control_node/_37\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output_control_node/_48\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/map/TensorArrayV2_1/element_shape\n",
      "resnet_period_estimator_5/map/TensorArrayV2_1/num_elements\n",
      "resnet_period_estimator_5/map/TensorArrayV2_1\n",
      "resnet_period_estimator_5/map/while/enter/_5\n",
      "unused_control_flow_input_161\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/input/_41\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/mul_1/x\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/TensorArrayV2Read/TensorListGetItem/element_shape\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/TensorArrayV2Read/TensorListGetItem\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Square\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Sum/reduction_indices\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Sum\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Reshape/shape\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Reshape\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/mul/x\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/MatMul\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/mul\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/sub\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Square_1\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Sum_1/reduction_indices\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Sum_1\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Reshape_1/shape\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Reshape_1\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/add\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Maximum/y\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Maximum\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/mul_1\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/TensorArrayV2Write/TensorListSetItem\n",
      "resnet_period_estimator_5/map/while/body/_1/resnet_period_estimator_5/map/while/Identity_3\n",
      "Func/resnet_period_estimator_5/map/while/body/_1/output/_46\n",
      "resnet_period_estimator_5/map/while/next_iteration/_28\n",
      "resnet_period_estimator_5/map/while/merge/_10\n",
      "resnet_period_estimator_5/map/while/resnet_period_estimator_5/map/TensorArrayV2_1_switch/_16\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block3_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block1_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block3_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_3_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block2_preact_bn/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_1_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/FusedBatchNormV3/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block2_2_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_preact_bn/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_preact_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv3_block4_2_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block1_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_conv/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/model_5/conv4_block2_1_conv/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1/resource\n",
      "resnet_period_estimator_5/model_5/conv2_block3_1_bn/FusedBatchNormV3/ReadVariableOp_1\n",
      "resnet_period_estimator_5/map/while/exit/_22\n",
      "resnet_period_estimator_5/map/TensorArrayV2Stack/TensorListStack/element_shape\n",
      "resnet_period_estimator_5/map/TensorArrayV2Stack/TensorListStack\n",
      "resnet_period_estimator_5/truediv/y\n",
      "resnet_period_estimator_5/truediv\n",
      "resnet_period_estimator_5/Softmax\n",
      "resnet_period_estimator_5/ExpandDims/dim\n",
      "resnet_period_estimator_5/ExpandDims\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/Conv2D/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/Conv2D/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/Conv2D\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/BiasAdd\n",
      "resnet_period_estimator_5/RE_conv_3x3_layer/Relu\n",
      "resnet_period_estimator_5/Reshape_3/shape/1\n",
      "resnet_period_estimator_5/Reshape_3/shape/2\n",
      "resnet_period_estimator_5/Reshape_3/shape\n",
      "resnet_period_estimator_5/Reshape_3\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_input_projection/Tensordot\n",
      "resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_input_projection/BiasAdd\n",
      "resnet_period_estimator_5/add/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/add/ReadVariableOp\n",
      "resnet_period_estimator_5/add\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/mean/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/mean\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/StopGradient\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/SquaredDifference\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/variance/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/moments/variance\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/add/y\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/add\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/Rsqrt\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/mul/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/mul/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/mul\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/mul_1\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/mul_2\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/sub\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_12/batchnorm/add_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_36/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice/stack\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice/stack_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice/stack_2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose/perm\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_37/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_1/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_1/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_1/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_1/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_1/perm\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Shape_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice_1/stack\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice_1/stack_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice_1/stack_2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/strided_slice_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Cast\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Sqrt\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/truediv\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Softmax\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_38/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_2/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_2/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_2/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_2/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_2/perm\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/MatMul_1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_3/perm\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/transpose_3\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_3/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_3/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_3/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/Reshape_3\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/multi_head_attention_6/dense_39/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/dropout_12/Identity\n",
      "resnet_period_estimator_5/transformer_layer_6/add\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/mean/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/mean\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/StopGradient\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/SquaredDifference\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/variance/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/moments/variance\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/add/y\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/add\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/Rsqrt\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/mul/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/mul/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/mul\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/mul_1\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/mul_2\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/sub\n",
      "resnet_period_estimator_5/transformer_layer_6/layer_normalization_13/batchnorm/add_1\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_40/Relu\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_6/sequential_8/dense_41/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_6/dropout_13/Identity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_period_estimator_5/transformer_layer_6/add_1\n",
      "resnet_period_estimator_5/Reshape_4/shape/1\n",
      "resnet_period_estimator_5/Reshape_4/shape/2\n",
      "resnet_period_estimator_5/Reshape_4/shape\n",
      "resnet_period_estimator_5/Reshape_4\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Tensordot\n",
      "resnet_period_estimator_5/RE_fc_layers_0/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_0/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_0/BiasAdd\n",
      "resnet_period_estimator_5/RE_fc_layers_0/Relu\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity_1\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Tensordot\n",
      "resnet_period_estimator_5/RE_fc_layers_1/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_1/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_1/BiasAdd\n",
      "resnet_period_estimator_5/RE_fc_layers_1/Relu\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity_2\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_fc_layers_x/Tensordot\n",
      "resnet_period_estimator_5/RE_fc_layers_x/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_fc_layers_x/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_fc_layers_x/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_input_projection2/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_input_projection2/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/add_1/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/add_1/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/mul/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/mul/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/BiasAdd/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/BiasAdd/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/mul/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/mul/ReadVariableOp\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/ReadVariableOp/resource\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/ReadVariableOp\n",
      "NoOp\n",
      "Identity\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_input_projection2/Tensordot\n",
      "resnet_period_estimator_5/RE_input_projection2/BiasAdd\n",
      "resnet_period_estimator_5/add_1\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/mean/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/mean\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/StopGradient\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/SquaredDifference\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/variance/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/moments/variance\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/add/y\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/add\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/Rsqrt\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/mul\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/mul_1\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/mul_2\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/sub\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_14/batchnorm/add_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_42/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice/stack\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice/stack_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice/stack_2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose/perm\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_43/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_1/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_1/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_1/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_1/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_1/perm\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Shape_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice_1/stack\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice_1/stack_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice_1/stack_2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/strided_slice_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Cast\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Sqrt\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/truediv\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Softmax\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_44/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_2/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_2/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_2/shape/3\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_2/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_2/perm\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/MatMul_1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_3/perm\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/transpose_3\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_3/shape/1\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_3/shape/2\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_3/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/Reshape_3\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/multi_head_attention_7/dense_45/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/dropout_14/Identity\n",
      "resnet_period_estimator_5/transformer_layer_7/add\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/mean/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/mean\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/StopGradient\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/SquaredDifference\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/variance/reduction_indices\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/moments/variance\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/add/y\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/add\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/Rsqrt\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/mul\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/mul_1\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/mul_2\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/sub\n",
      "resnet_period_estimator_5/transformer_layer_7/layer_normalization_15/batchnorm/add_1\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_46/Relu\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/Reshape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/MatMul\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot/shape\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/Tensordot\n",
      "resnet_period_estimator_5/transformer_layer_7/sequential_9/dense_47/BiasAdd\n",
      "resnet_period_estimator_5/transformer_layer_7/dropout_15/Identity\n",
      "resnet_period_estimator_5/transformer_layer_7/add_1\n",
      "resnet_period_estimator_5/Reshape_5/shape/1\n",
      "resnet_period_estimator_5/Reshape_5/shape/2\n",
      "resnet_period_estimator_5/Reshape_5/shape\n",
      "resnet_period_estimator_5/Reshape_5\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity_3\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Tensordot\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/BiasAdd\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_0/Relu\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity_4\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Tensordot\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/BiasAdd\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_1/Relu\n",
      "resnet_period_estimator_5/RE_dropout_layer/Identity_5\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/Reshape/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/Reshape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/MatMul\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot/shape\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/Tensordot\n",
      "resnet_period_estimator_5/RE_within_period_fc_layers_x/BiasAdd\n",
      "Identity_1\n",
      "Identity_2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4c14b8bd4050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:21:16.635150Z",
     "start_time": "2021-08-27T13:21:16.519201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(1, 64, 112, 112, 3) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(1, 64, 32) dtype=float32>, <tf.Tensor 'Identity_1:0' shape=(1, 64, 1) dtype=float32>, <tf.Tensor 'Identity_2:0' shape=(None, None, 512) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:21:55.910307Z",
     "start_time": "2021-08-27T13:21:55.312973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nb_data/tmp/frozen_models/simple_frozen_graph.pb'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_func.graph,\n",
    "    logdir=\"/data/nb_data/tmp/frozen_models\",\n",
    "    name=\"simple_frozen_graph.pb\",\n",
    "    as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.077Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model1 = ResnetPeriodEstimator()\n",
    "model1(tf.random.uniform((1, 64, 112, 112, 3)));\n",
    "os.system('rm -rf /data/cc')\n",
    "model1.save(\"/data/cc\", save_format='tf', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.080Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --tag serve --signature_def serving_default --opset 13 \\\n",
    "    --saved-model /data/cc --output /data/cc/test.onnx --verbose --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T13:33:46.981237Z",
     "start_time": "2021-08-27T13:33:40.130786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-27 21:33:41.238675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2021-08-27 21:33:41.238766: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-08-27 21:33:42.948477: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-27 21:33:42.948524: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: k12nb\n",
      "2021-08-27 21:33:42.948554: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: k12nb\n",
      "2021-08-27 21:33:42.948682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.67.0\n",
      "2021-08-27 21:33:42.948728: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.67.0\n",
      "2021-08-27 21:33:42.948781: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.67.0\n",
      "2021-08-27 21:33:42.949216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:262: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "2021-08-27 21:33:44,311 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:262: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:927: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-08-27 21:33:44,312 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:927: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-08-27 21:33:44.448061: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2021-08-27 21:33:44.448318: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2021-08-27 21:33:45.735061: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 733 nodes (-308), 1032 edges (-317), time = 677.545ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 1.953ms.\n",
      "  constant_folding: Graph size after: 733 nodes (0), 1032 edges (0), time = 241.013ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 4.86ms.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 497, in _import_graph_def_internal\n",
      "    graph._c_graph, serialized, options)  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 1 and 512 for '{{node resnet_period_estimator_5/RE_input_projection/BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\"](resnet_period_estimator_5/add/ReadVariableOp, resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp)' with input shapes: [1,64,1], [512].\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/convert.py\", line 605, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/convert.py\", line 265, in main\n",
      "    output_path=args.output)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/convert.py\", line 153, in _convert_common\n",
      "    tf.import_graph_def(frozen_graph, name='')\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 549, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 405, in import_graph_def\n",
      "    producer_op_list=producer_op_list)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py\", line 501, in _import_graph_def_internal\n",
      "    raise ValueError(str(e))\n",
      "ValueError: Dimensions must be equal, but are 1 and 512 for '{{node resnet_period_estimator_5/RE_input_projection/BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\"](resnet_period_estimator_5/add/ReadVariableOp, resnet_period_estimator_5/RE_input_projection/BiasAdd/ReadVariableOp)' with input shapes: [1,64,1], [512].\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --input /data/nb_data/tmp/frozen_models/simple_frozen_graph.pb \\\n",
    "    --inputs x:0 --outputs Identity:0,Identity_1:0,Identity_2:0 \\\n",
    "    --output /data/nb_data/tmp/repnet.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.083Z"
    }
   },
   "outputs": [],
   "source": [
    "%netron /data/cc/test.onnx 8228 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.087Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = ResnetPeriodEstimator()\n",
    "model.predict(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "# model2.build(input_shape=(1, 64, 112, 112, 3))\n",
    "model2.save('/data/gg', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.090Z"
    }
   },
   "outputs": [],
   "source": [
    "model.base_model.save(\"/data/aa_base\", overwrite=True, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.093Z"
    }
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /data/cc --tag_set serve  --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.097Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --tag serve --signature_def serving_default --opset 13 \\\n",
    "    --saved-model /data/cc --output /data/aa/test.onnx --verbose --debug\n",
    "\n",
    "#     --inputs serving_default_input_1:0 \\\n",
    "#     --outputs StatefulPartitionedCall:0,StatefulPartitionedCall:0,StatefulPartitionedCall:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m tf2onnx.convert --tag serve --signature_def serving_default --opset 10 --verbose \\\n",
    "    --input /data/aa/saved_model.pb --output /data/aa/test.onnx \\\n",
    "    --inputs serving_default_input_1:0 \\\n",
    "    --outputs StatefulPartitionedCall:0,StatefulPartitionedCall:0,StatefulPartitionedCall:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.104Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls $PATH_TO_CKPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.108Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.111Z"
    }
   },
   "outputs": [],
   "source": [
    "dir(tf.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.115Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def traceme(x):\n",
    "    return model1(x)\n",
    "\n",
    "\n",
    "logdir = \"log2\"\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "# Forward pass\n",
    "traceme(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.118Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "model(tf.random.uniform((1, 64, 112, 112, 3)))\n",
    "model.save('/data/aa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.121Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.124Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, '/data/bb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.127Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load('/data/bb')\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.131Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.134Z"
    }
   },
   "outputs": [],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.137Z"
    }
   },
   "outputs": [],
   "source": [
    "a, b, c, = loaded(tf.random.uniform((1, 64, 112, 112, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.140Z"
    }
   },
   "outputs": [],
   "source": [
    "a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.144Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(loaded, '/data/cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\n",
    "    \"/data/cc\", signature_keys=['serving_default'])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter = True\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "# with open('/data/model.tflite', 'wb') as f:\n",
    "#   f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNR6sVATy8yX"
   },
   "source": [
    "## Set Params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.151Z"
    },
    "id": "PaCB432zUrZu"
   },
   "outputs": [],
   "source": [
    "##@title \n",
    "\n",
    "# FPS while recording video from webcam.\n",
    "WEBCAM_FPS = 16#@param {type:\"integer\"}\n",
    "\n",
    "# Time in seconds to record video on webcam. \n",
    "RECORDING_TIME_IN_SECONDS = 8. #@param {type:\"number\"}\n",
    "\n",
    "# Threshold to consider periodicity in entire video.\n",
    "THRESHOLD = 0.2#@param {type:\"number\"}\n",
    "\n",
    "# Threshold to consider periodicity for individual frames in video.\n",
    "WITHIN_PERIOD_THRESHOLD = 0.5#@param {type:\"number\"}\n",
    "\n",
    "# Use this setting for better results when it is \n",
    "# known action is repeating at constant speed.\n",
    "CONSTANT_SPEED = False#@param {type:\"boolean\"}\n",
    "\n",
    "# Use median filtering in time to ignore noisy frames.\n",
    "MEDIAN_FILTER = True#@param {type:\"boolean\"}\n",
    "\n",
    "# Use this setting for better results when it is \n",
    "# known the entire video is periodic/reapeating and\n",
    "# has no aperiodic frames.\n",
    "FULLY_PERIODIC = False#@param {type:\"boolean\"}\n",
    "\n",
    "# Plot score in visualization video.\n",
    "PLOT_SCORE = False#@param {type:\"boolean\"}\n",
    "\n",
    "# Visualization video's FPS.\n",
    "VIZ_FPS = 30#@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.154Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "IScNPW9C2Urp",
    "outputId": "887bc8cc-be55-435c-e687-4cb8c295fe41"
   },
   "outputs": [],
   "source": [
    "vfile = \"/data/test-9.mp4\"\n",
    "imgs, vid_fps = read_video(vfile)\n",
    "show_video(vfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.157Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(imgs), vid_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKWkGlEsa3Tg"
   },
   "source": [
    "# Run RepNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.161Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "FUg2vSYhmsT0",
    "outputId": "14171077-b308-411a-a901-bdab6fb3e7f5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Running RepNet...') \n",
    "(pred_period, pred_score, within_period,\n",
    " per_frame_counts, chosen_stride) = get_counts(\n",
    "     model,\n",
    "     imgs,\n",
    "     strides=[1,2,3,4],\n",
    "     batch_size=20,\n",
    "     threshold=THRESHOLD,\n",
    "     within_period_threshold=WITHIN_PERIOD_THRESHOLD,\n",
    "     constant_speed=CONSTANT_SPEED,\n",
    "     median_filter=MEDIAN_FILTER,\n",
    "     fully_periodic=True)\n",
    "print('Visualizing results...') \n",
    "viz_reps(imgs, per_frame_counts, pred_score, interval=1000/VIZ_FPS,\n",
    "         plot_score=PLOT_SCORE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-27T13:09:33.164Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "IYcthjnIJC3P",
    "outputId": "85baf822-7dbf-40b0-eb9f-78b847d3bd24"
   },
   "outputs": [],
   "source": [
    "# Debugging video showing scores, per-frame frequency prediction and \n",
    "# within_period scores.\n",
    "# create_count_video(imgs,\n",
    "#                    per_frame_counts,\n",
    "#                    within_period,\n",
    "#                    score=pred_score,\n",
    "#                    fps=vid_fps,\n",
    "#                    output_file='/tmp/debug_video.mp4',\n",
    "#                    delay=1000/VIZ_FPS,\n",
    "#                    plot_count=True,\n",
    "#                    plot_within_period=True,\n",
    "#                    plot_score=True)\n",
    "# show_video('/tmp/debug_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T11:55:30.073015Z",
     "start_time": "2021-08-27T11:55:29.988382Z"
    }
   },
   "source": [
    "1. https://github.com/onnx/onnx/blob/master/docs/Operators.md\n",
    "2. https://gitee.com/eyecloud/openncc/tree/master\n",
    "3. https://leimao.github.io/blog/Save-Load-Inference-From-TF-Frozen-Graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "repnet_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
