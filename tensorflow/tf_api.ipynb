{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239c1234",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#tf.map_fn\" data-toc-modified-id=\"tf.map_fn-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>tf.map_fn</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3513bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "netron 5.1.6\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx 1.10.0\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bf3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'erlangai-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "    \n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    parser = argparse.ArgumentParser(prog='netron')\n",
    "    parser.add_argument('--file', '-f', type=str, required=True, help='netron model file')\n",
    "    parser.add_argument('--port', '-p', type=int, default=0, help='netron server port')\n",
    "    parser.add_argument('--height', type=int, default=500, help='display netron html window hight')\n",
    "    import netron\n",
    "    try:\n",
    "        args = parser.parse_args(shlex.split(line))\n",
    "        address = netron.start(args.file, address=('0.0.0.0', args.port), browse=False)\n",
    "        display_html(address[1], args.height)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14802c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### Tensorflow ###\n",
    "###\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "\n",
    "NB_TMP_DATA='/data/nb_data/tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354d0d0",
   "metadata": {},
   "source": [
    "## tf.map_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5899d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ONNX Failed to infer shapes and dtypes for [while/strided_slice__34, type: Squeeze]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/schemas.py\", line 154, in infer_onnx_shape_dtype\n",
      "    inferred_model = shape_inference.infer_shapes(model_proto, strict_mode=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/onnx/shape_inference.py\", line 42, in infer_shapes\n",
      "    inferred_model_str = C.infer_shapes(model_str, check_type, strict_mode, data_prop)\n",
      "onnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] Shape inference error(s): (op_type:Squeeze, node name: while/strided_slice__34): [ShapeInferenceError] Dimension of input 0 must be 1 instead of 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_f1(x):\n",
    "    return tf.map_fn(lambda y: y + 2, x)\n",
    "\n",
    "@tf.function\n",
    "def test_f2(x):\n",
    "    # a = tf.expand_dims(x[0]+2, 0)\n",
    "    # b = tf.expand_dims(x[1]+2, 0)\n",
    "    # c = tf.expand_dims(x[2]+2, 0)\n",
    "    # return tf.concat([a, b, c], 0)\n",
    "    z = tf.TensorArray(tf.float32, size=x.shape[0])\n",
    "    for i in tf.range(x.shape[0]):\n",
    "        z = z.write(i, x[i] + 2)\n",
    "    return z.stack()\n",
    "    \n",
    "func_proto = tf2onnx.convert.from_function(\n",
    "    function=test_f2, opset=11,\n",
    "    input_signature=(\n",
    "        tf.TensorSpec(shape=(3, 2, 2), name=\"x\"),\n",
    "    ),\n",
    "    output_path=f'{NB_TMP_DATA}/tf_array.onnx'\n",
    ")[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d6bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 2),\n",
       " array([[[ 1., 10.],\n",
       "         [ 2., 20.]],\n",
       " \n",
       "        [[ 3., 30.],\n",
       "         [ 4., 40.]],\n",
       " \n",
       "        [[ 5., 50.],\n",
       "         [ 6., 60.]]], dtype=float32),\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
       " array([[[ 3., 12.],\n",
       "         [ 4., 22.]],\n",
       " \n",
       "        [[ 5., 32.],\n",
       "         [ 6., 42.]],\n",
       " \n",
       "        [[ 7., 52.],\n",
       "         [ 8., 62.]]], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
       " array([[[ 3., 12.],\n",
       "         [ 4., 22.]],\n",
       " \n",
       "        [[ 5., 32.],\n",
       "         [ 6., 42.]],\n",
       " \n",
       "        [[ 7., 52.],\n",
       "         [ 8., 62.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\n",
    "    [[1, 10], [2, 20]],\n",
    "    [[3, 30], [4, 40]],\n",
    "    [[5, 50], [6, 60]],\n",
    "]\n",
    "\n",
    "x = np.array(x, dtype=np.float32)\n",
    "x.shape, x, '-'*60, test_f1(x), '-'*60, test_f2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6a491f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func_proto = tf2onnx.convert.from_function(\n",
    "    function=test_f1, opset=11,\n",
    "    input_signature=(\n",
    "        tf.TensorSpec(shape=(None, 2, 2), name=\"x\"),\n",
    "    ),\n",
    "    output_path=f'{NB_TMP_DATA}/map_fn.onnx'\n",
    ")[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec543c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ONNX Failed to infer shapes and dtypes for [while/strided_slice__99, type: Squeeze]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tf2onnx/schemas.py\", line 154, in infer_onnx_shape_dtype\n",
      "    inferred_model = shape_inference.infer_shapes(model_proto, strict_mode=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/onnx/shape_inference.py\", line 42, in infer_shapes\n",
      "    inferred_model_str = C.infer_shapes(model_str, check_type, strict_mode, data_prop)\n",
      "onnx.onnx_cpp2py_export.shape_inference.InferenceError: [ShapeInferenceError] Shape inference error(s): (op_type:Squeeze, node name: while/strided_slice__99): [ShapeInferenceError] Dimension of input 0 must be 1 instead of 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from tf2onnx import logging, utils\n",
    "# logging.basicConfig(level=0)\n",
    "# utils.set_debug_mode(False)\n",
    "func_proto = tf2onnx.convert.from_function(\n",
    "    function=test_f2, opset=11,\n",
    "    input_signature=(\n",
    "        tf.TensorSpec(shape=(3, 2, 2), name=\"x\"),\n",
    "    ),\n",
    "    output_path=f'{NB_TMP_DATA}/tf_array.onnx'\n",
    ")[0];"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "187px",
    "left": "1314px",
    "top": "66px",
    "width": "392px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
