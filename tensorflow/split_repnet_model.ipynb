{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553054a8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Download-and-Restore-Model-Weights\" data-toc-modified-id=\"Download-and-Restore-Model-Weights-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Download and Restore Model Weights</a></span></li><li><span><a href=\"#Full-Model-Netron\" data-toc-modified-id=\"Full-Model-Netron-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Full Model Netron</a></span></li><li><span><a href=\"#Split-Model\" data-toc-modified-id=\"Split-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Split Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Part-1\" data-toc-modified-id=\"Model-Part-1-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Model Part-1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define\" data-toc-modified-id=\"Define-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Define</a></span></li><li><span><a href=\"#Netron\" data-toc-modified-id=\"Netron-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Netron</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf2onnx:-from_saved_model\" data-toc-modified-id=\"tf2onnx:-from_saved_model-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>tf2onnx: from_saved_model</a></span></li><li><span><a href=\"#tf2onnx:-from_keras\" data-toc-modified-id=\"tf2onnx:-from_keras-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>tf2onnx: from_keras</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Part-2\" data-toc-modified-id=\"Model-Part-2-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Model Part-2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define\" data-toc-modified-id=\"Define-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Define</a></span></li><li><span><a href=\"#Netron\" data-toc-modified-id=\"Netron-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Netron</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf2onnx:-from_saved_model\" data-toc-modified-id=\"tf2onnx:-from_saved_model-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span>tf2onnx: from_saved_model</a></span></li><li><span><a href=\"#tf2onnx:-from_keras\" data-toc-modified-id=\"tf2onnx:-from_keras-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span>tf2onnx: from_keras</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Part-3\" data-toc-modified-id=\"Model-Part-3-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Model Part-3</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define\" data-toc-modified-id=\"Define-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Define</a></span></li><li><span><a href=\"#Netron\" data-toc-modified-id=\"Netron-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Netron</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf2onnx:-from_saved_model\" data-toc-modified-id=\"tf2onnx:-from_saved_model-3.3.2.1\"><span class=\"toc-item-num\">3.3.2.1&nbsp;&nbsp;</span>tf2onnx: from_saved_model</a></span></li><li><span><a href=\"#tf2onnx:-from_keras\" data-toc-modified-id=\"tf2onnx:-from_keras-3.3.2.2\"><span class=\"toc-item-num\">3.3.2.2&nbsp;&nbsp;</span>tf2onnx: from_keras</a></span></li></ul></li></ul></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Test</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e5869a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.481197Z",
     "start_time": "2021-10-14T12:24:19.923530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "netron 5.1.6\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx 1.10.0\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07b4dffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.668317Z",
     "start_time": "2021-10-14T12:24:31.486038Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'erlangai-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    parser = argparse.ArgumentParser(prog='netron')\n",
    "    parser.add_argument('--file', '-f', type=str, required=True, help='netron model file')\n",
    "    parser.add_argument('--port', '-p', type=int, default=0, help='netron server port')\n",
    "    parser.add_argument('--height', type=int, default=500, help='display netron html window hight')\n",
    "    import netron\n",
    "    try:\n",
    "        args = parser.parse_args(shlex.split(line))\n",
    "        address = netron.start(args.file, address=('0.0.0.0', args.port), browse=False)\n",
    "        display_html(address[1], args.height)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02af090a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.836686Z",
     "start_time": "2021-10-14T12:24:31.671363Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.saved_model.signature_constants import DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "from tensorflow.python.saved_model.tag_constants import SERVING\n",
    "import tf2onnx\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "import onnxruntime as ORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "981b3641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:33.085729Z",
     "start_time": "2021-10-14T12:24:31.840452Z"
    }
   },
   "outputs": [],
   "source": [
    "_IMPORT('https://gitee.com/qrsforever/blog_source_codes/blob/master/AI/tensorflow/misc/ResnetPeriodEstimator.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb2354b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:33.259827Z",
     "start_time": "2021-10-14T12:24:33.088717Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1 # get_sims_with_noloop if batch_size == 1 else get_sims(build trt will fail)\n",
    "IMAGE_W = 112\n",
    "IMAGE_H = IMAGE_W\n",
    "NUM_FRAMES = 64\n",
    "SIM_TEMPERATURE = 13.544\n",
    "\n",
    "SAVED_MODEL_ROOT = '/data/nb_data/split_repnet_model'\n",
    "PATH_TO_CKPT = '/data/pretrained/cv/repnet/'\n",
    "INPUTS_NPY = f'{SAVED_MODEL_ROOT}/model_inputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}.npy'\n",
    "MODEL1_OUTPUTS = f'{SAVED_MODEL_ROOT}/model1_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}.npy'\n",
    "MODEL2_OUTPUTS = f'{SAVED_MODEL_ROOT}/model2_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}.npy'\n",
    "MODEL3_0_OUTPUTS = f'{SAVED_MODEL_ROOT}/model3_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}_0.npy'\n",
    "MODEL3_1_OUTPUTS = f'{SAVED_MODEL_ROOT}/model3_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}_1.npy'\n",
    "OUTPUTS_0_NPY = f'{SAVED_MODEL_ROOT}/model_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}_0.npy'\n",
    "OUTPUTS_1_NPY = f'{SAVED_MODEL_ROOT}/model_outputs_{BATCH_SIZE}_{IMAGE_H}_{NUM_FRAMES}_1.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102ca92",
   "metadata": {},
   "source": [
    "## Download and Restore Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8f02979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:34.473703Z",
     "start_time": "2021-10-14T12:24:33.262720Z"
    }
   },
   "outputs": [],
   "source": [
    "!test ! -d $PATH_TO_CKPT && mkdir -p $PATH_TO_CKPT && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/checkpoint && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00000-of-00002 && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00001-of-00002 && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "873bbe61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:40.117470Z",
     "start_time": "2021-10-14T12:24:34.483105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nb_data/split_repnet_model/model_inputs_1_112_64.npy'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "model.call = tf.function(model.call)\n",
    "tf.train.Checkpoint(model=model).restore(f'{PATH_TO_CKPT}/ckpt-88').expect_partial()\n",
    "if not os.path.exists(INPUTS_NPY):\n",
    "    test_inputs = np.random.randn(BATCH_SIZE, NUM_FRAMES, IMAGE_H, IMAGE_W, 3).astype(np.float32)\n",
    "    np.save(INPUTS_NPY, test_inputs)\n",
    "else:\n",
    "    test_inputs = np.load(INPUTS_NPY)\n",
    "test_inputs_tensor = tf.convert_to_tensor(test_inputs)\n",
    "INPUTS_NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77f0d3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.079604Z",
     "start_time": "2021-10-14T12:24:40.126369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 32]), TensorShape([1, 64, 1]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs = model(test_inputs_tensor)\n",
    "if not os.path.exists(OUTPUTS_0_NPY):\n",
    "    np.save(OUTPUTS_0_NPY, test_outputs[0])\n",
    "    np.save(OUTPUTS_1_NPY, test_outputs[1])\n",
    "else:\n",
    "    test_outputs_0 = np.load(OUTPUTS_0_NPY)\n",
    "    test_outputs_1 = np.load(OUTPUTS_1_NPY)\n",
    "test_outputs[0].shape, test_outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b384e110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.2658531665802002, 1.3311336040496826, 1.4469563961029053],\n",
       " [1.2658531665802002, 1.3311336040496826, 1.4469563961029053])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs_1.reshape(-1)[:3].tolist(), test_outputs[1].numpy().reshape(-1)[:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a15711d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-12.783597946166992, 3.1049232482910156, 0.4515947699546814],\n",
       " [-12.783597946166992, 3.1049232482910156, 0.4515947699546814])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs_0.reshape(-1)[:3].tolist(), test_outputs[0].numpy().reshape(-1)[:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a77f5576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.300472Z",
     "start_time": "2021-10-14T12:24:47.082822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_period_estimator_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_4 (Functional)         (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer_8 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_9 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,689,953\n",
      "Trainable params: 25,673,185\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd2c9f",
   "metadata": {},
   "source": [
    "## Full Model Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa39d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "if 1 == model.pos_encoding.shape[-1]:\n",
    "    model.pos_encoding  = tf.tile(model.pos_encoding,  multiples=[1, 1, 512])\n",
    "    model.pos_encoding2 = tf.tile(model.pos_encoding2, multiples=[1, 1, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8fe1e87c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-5b3029326ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     output_path=f'{SAVED_MODEL_ROOT}/model.onnx')[0];\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/convert.py\u001b[0m in \u001b[0;36mfrom_keras\u001b[0;34m(model, input_signature, opset, custom_ops, custom_op_handlers, custom_rewriter, inputs_as_nchw, extra_opset, shape_override, target, large_model, output_path)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mtensors_to_rename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensors_to_rename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0minitialized_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_tables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             output_path=output_path)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_tensor_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/convert.py\u001b[0m in \u001b[0;36m_convert_common\u001b[0;34m(frozen_graph, name, large_model, output_path, output_frozen_graph, custom_ops, custom_op_handlers, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         g = process_tf_graph(tf_graph, const_node_values=const_node_values,\n\u001b[0;32m--> 163\u001b[0;31m                              custom_op_handlers=custom_op_handlers, **kwargs)\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENV_TF2ONNX_CATCH_ERRORS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mcatch_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENV_TF2ONNX_CATCH_ERRORS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"TRUE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/tfonnx.py\u001b[0m in \u001b[0;36mprocess_tf_graph\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         main_g, subgraphs = graphs_from_tf(tf_graph, input_names, output_names, shape_override, const_node_values,\n\u001b[0;32m--> 434\u001b[0;31m                                            ignore_default, use_default)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmain_g\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/tfonnx.py\u001b[0m in \u001b[0;36mgraphs_from_tf\u001b[0;34m(tf_graph, input_names, output_names, shape_override, const_node_values, ignore_default, use_default)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0monnx_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mtensorflow_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_override\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_node_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/tf_utils.py\u001b[0m in \u001b[0;36mtensorflow_to_onnx\u001b[0;34m(graph, shape_override, const_node_values, ignore_default, use_default)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0mLoad\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdo\u001b[0m \u001b[0ma\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \"\"\"\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtflist_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_override\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_node_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/tf_utils.py\u001b[0m in \u001b[0;36mtflist_to_onnx\u001b[0;34m(g, shape_override, const_node_values, ignore_default, use_default)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_attr_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_tf_node_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0mattr_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_attr_cnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mtakeit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf2onnx/tf_utils.py\u001b[0m in \u001b[0;36mread_tf_node_attrs\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mattr_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mattr_cnt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tf_node_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_proto = tf2onnx.convert.from_keras(\n",
    "    model, opset=11, \n",
    "    input_signature=(tf.TensorSpec(shape=test_inputs.shape, name=\"x\"),),\n",
    "    output_path=f'{SAVED_MODEL_ROOT}/model.onnx')[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48a80136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"x\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 3\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 32\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " , name: \"output_2\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proto.graph.input, model_proto.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f274476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %netron -f {SAVED_MODEL_ROOT}/model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1eec0d",
   "metadata": {},
   "source": [
    "## Split Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48537fe0",
   "metadata": {},
   "source": [
    "### Model Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddf538",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9d9453d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.652337Z",
     "start_time": "2021-10-14T12:24:47.475725Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPart1(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart1')\n",
    "        self.base_model = tf.keras.models.Model(\n",
    "            name='base_model', inputs=model.base_model.input,\n",
    "            outputs=model.base_model.get_layer('conv4_block3_out').output)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (-1, IMAGE_H, IMAGE_W, 3))\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2393d436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:49.001864Z",
     "start_time": "2021-10-14T12:24:47.656777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.6067329 , -0.3791368 , -0.15414873], dtype=float32)>,\n",
       " '------------------------------------------------------------------------------------------',\n",
       " TensorShape([64, 7, 7, 1024]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ResnetPart1(model)\n",
    "model_part1_outputs = model1(test_inputs_tensor)\n",
    "tf.reshape(model_part1_outputs, (-1,))[:3], '-'*90, model_part1_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd6b4cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:49.191772Z",
     "start_time": "2021-10-14T12:24:49.004174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart1\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "base_model (Functional)                 (None, None, None, 1024)            5209600       \n",
      "==========================================================================================\n",
      "Total params: 5,209,600\n",
      "Trainable params: 5,193,856\n",
      "Non-trainable params: 15,744\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e378d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(MODEL1_OUTPUTS, model_part1_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b6dfa",
   "metadata": {},
   "source": [
    "#### Netron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2af93a",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bb06b818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:41.539025Z",
     "start_time": "2021-10-14T12:24:49.194128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.save(filepath=f'{SAVED_MODEL_ROOT}/model1', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "159694c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-11-02 12:02:54,606 - INFO - Signatures found in model: [serving_default].\n",
      "2021-11-02 12:02:54,608 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-11-02 12:02:57,619 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-11-02 12:02:58,841 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.10.0/42e800\n",
      "2021-11-02 12:02:58,847 - INFO - Using opset <onnx, 11>\n",
      "2021-11-02 12:03:04,565 - INFO - Computed 0 values for constant folding\n",
      "2021-11-02 12:03:08,584 - INFO - Optimizing ONNX model\n",
      "2021-11-02 12:03:12,578 - INFO - After optimization: Add -1 (11->10), BatchNormalization -20 (30->10), Cast -1 (1->0), Const -61 (171->110), Identity -5 (5->0), Transpose -132 (134->2)\n",
      "2021-11-02 12:03:12,677 - INFO - \n",
      "2021-11-02 12:03:12,677 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model1 to ONNX\n",
      "2021-11-02 12:03:12,677 - INFO - Model inputs: ['input_1']\n",
      "2021-11-02 12:03:12,677 - INFO - Model outputs: ['output_1']\n",
      "2021-11-02 12:03:12,677 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model1/model_opset11.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 11 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model1 --output {SAVED_MODEL_ROOT}/model1/model_opset11.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2cdee6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %netron -f {SAVED_MODEL_ROOT}/model1/model_opset11.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4620659",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8dfe4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_proto = tf2onnx.convert.from_keras(\n",
    "    model1, opset=11, \n",
    "    input_signature=(tf.TensorSpec(shape=test_inputs_tensor.shape, name=\"model1_x\"),),\n",
    "    output_path=f'{SAVED_MODEL_ROOT}/model1.onnx')[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c539f9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"model1_x\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 3\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_proto.graph.input, model1_proto.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7658c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %netron -f {SAVED_MODEL_ROOT}/model1.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38776fc2",
   "metadata": {},
   "source": [
    "### Model Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3f0b3",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9537183b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:41.748606Z",
     "start_time": "2021-10-14T12:25:41.559091Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPart2(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart2')\n",
    "        self.temporal_conv_layer = layers.Conv3D(\n",
    "            512, 3, padding='same', name='temporal_conv_layer',\n",
    "            dilation_rate=(3, 1, 1), weights=model.temporal_conv_layers[0].get_weights())\n",
    "        self.temporal_bn_layers = layers.BatchNormalization(\n",
    "            name='temporal_bn_layers', weights=model.temporal_bn_layers[0].get_weights())                  \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, [BATCH_SIZE, -1] + x.shape.as_list()[1:])\n",
    "        x = self.temporal_conv_layer(x)\n",
    "        x = self.temporal_bn_layers(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return tf.reduce_max(x, [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ff8b049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:42.953387Z",
     "start_time": "2021-10-14T12:25:41.753712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 2.9224107, 0.       ], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResnetPart2(model)\n",
    "model_part2_outputs = model2(model_part1_outputs)\n",
    "tf.reshape(model_part2_outputs, (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c265cb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:43.140974Z",
     "start_time": "2021-10-14T12:25:42.959896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart2\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "temporal_conv_layer (Conv3D)            multiple                            14156288      \n",
      "__________________________________________________________________________________________\n",
      "temporal_bn_layers (BatchNormalization) multiple                            2048          \n",
      "==========================================================================================\n",
      "Total params: 14,158,336\n",
      "Trainable params: 14,157,312\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5317fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(MODEL2_OUTPUTS, model_part2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db015aa2",
   "metadata": {},
   "source": [
    "#### Netron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbcb78",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b4fd6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:47.112653Z",
     "start_time": "2021-10-14T12:25:43.144577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model2/assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(filepath=f'{SAVED_MODEL_ROOT}/model2', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d9be9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-21 19:45:12,444 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-21 19:45:12,444 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-21 19:45:14,465 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-21 19:45:15,998 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.10.0/42e800\n",
      "2021-10-21 19:45:15,998 - INFO - Using opset <onnx, 11>\n",
      "2021-10-21 19:45:23,516 - INFO - Computed 2 values for constant folding\n",
      "2021-10-21 19:45:27,834 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/Conv3D/strided_slice_1\n",
      "2021-10-21 19:45:27,834 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/Conv3D/strided_slice_2\n",
      "2021-10-21 19:45:28,587 - INFO - Optimizing ONNX model\n",
      "2021-10-21 19:45:29,344 - INFO - After optimization: Cast -1 (4->3), Const -53 (84->31), Gather +1 (1->2), Identity -9 (9->0), Squeeze -7 (9->2), Unsqueeze -15 (21->6)\n",
      "2021-10-21 19:45:29,506 - INFO - \n",
      "2021-10-21 19:45:29,506 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model2 to ONNX\n",
      "2021-10-21 19:45:29,507 - INFO - Model inputs: ['input_1']\n",
      "2021-10-21 19:45:29,507 - INFO - Model outputs: ['output_1']\n",
      "2021-10-21 19:45:29,507 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model2/model_opset11.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 11 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model2 --output {SAVED_MODEL_ROOT}/model2/model_opset11.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7af81530",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model2/model_opset11.onnx' at http://0.0.0.0:38712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-ef6307a295e38ff3' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-ef6307a295e38ff3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 38712;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/model2/model_opset11.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc853d0",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fbe0424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_proto = tf2onnx.convert.from_keras(\n",
    "    model2, opset=11, \n",
    "    input_signature=(tf.TensorSpec(shape=model_part1_outputs.shape, name=\"model2_x\"),),\n",
    "    output_path=f'{SAVED_MODEL_ROOT}/model2.onnx')[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "866533f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"model2_x\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_proto.graph.input, model2_proto.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1709244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model2.onnx' at http://0.0.0.0:42016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-28a29f6609c9f8ae' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-28a29f6609c9f8ae\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 42016;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/model2.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bf389",
   "metadata": {},
   "source": [
    "### Model Part-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dfe694",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34287060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:47.349643Z",
     "start_time": "2021-10-14T12:25:47.118120Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sims_with_noloop(embs, temperature):\n",
    "    \"\"\"Calculates self-similarity between batch of sequence of embeddings.\"\"\"\n",
    "    # batch_size = tf.shape(embs)[0]\n",
    "    # seq_len = tf.shape(embs)[1]\n",
    "    # embs = tf.reshape(embs, [batch_size, seq_len, -1])\n",
    "\n",
    "    def _get_sims(embs):\n",
    "        \"\"\"Calculates self-similarity between sequence of embeddings.\"\"\"\n",
    "        dist = pairwise_l2_distance(embs, embs)\n",
    "        sims = -1.0 * dist\n",
    "        return sims\n",
    "    \n",
    "    # batchsize = 4\n",
    "    # a = tf.expand_dims(_get_sims(embs[0]), 0)\n",
    "    # b = tf.expand_dims(_get_sims(embs[1]), 0)\n",
    "    # c = tf.expand_dims(_get_sims(embs[2]), 0)\n",
    "    # d = tf.expand_dims(_get_sims(embs[3]), 0)\n",
    "    # sims = tf.concat([a, b, c, d], 0)\n",
    "    sims = tf.expand_dims(_get_sims(embs[0]), 0)\n",
    "    sims /= temperature\n",
    "    sims = tf.nn.softmax(sims, axis=-1)\n",
    "    sims = tf.expand_dims(sims, -1)\n",
    "    return sims\n",
    "\n",
    "\n",
    "class ResnetPart3(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart3')\n",
    "        self.conv_3x3_layer = layers.Conv2D(\n",
    "            32, 3, padding='same', activation=tf.nn.relu, name='conv_3x3_layer',\n",
    "            weights=model.conv_3x3_layer.get_weights())\n",
    "        \n",
    "        self.input_projection1 = layers.Dense(\n",
    "            512, activation=None, name='input_projection1',\n",
    "            weights=model.input_projection.get_weights())\n",
    "        self.input_projection2 = layers.Dense(\n",
    "            512, activation=None, name='input_projection2',\n",
    "            weights=model.input_projection2.get_weights())\n",
    "        \n",
    "        self.pos_encoding1 = tf.compat.v1.get_variable(name='pos_encoding',  initializer=model.pos_encoding.numpy())\n",
    "        self.pos_encoding2 = tf.compat.v1.get_variable(name='pos_encoding2', initializer=model.pos_encoding2.numpy())\n",
    "        \n",
    "        self.transformer_layer1 = TransformerLayer(512, 4, 512, 0.0, True, name='transformer_layer1')\n",
    "        self.transformer_layer1(tf.random.uniform((BATCH_SIZE, NUM_FRAMES, 512)))\n",
    "        self.transformer_layer1.set_weights(model.transformer_layers[0].get_weights())\n",
    "        \n",
    "        self.transformer_layer2 = TransformerLayer(512, 4, 512, 0.0, True, name='transformer_layer2')\n",
    "        self.transformer_layer2(tf.random.uniform((BATCH_SIZE, NUM_FRAMES, 512)))\n",
    "        self.transformer_layer2.set_weights(model.transformer_layers2[0].get_weights())\n",
    "        \n",
    "        self.dropout_layer = layers.Dropout(0.25, name='dropout', weights=model.dropout_layer.get_weights())\n",
    "        self.fc_layers = [\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='fc_0', weights=model.fc_layers[0].get_weights()),\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='fc_1', weights=model.fc_layers[1].get_weights()),\n",
    "            layers.Dense(NUM_FRAMES//2, name='fc_layers_2', weights=model.fc_layers[2].get_weights()),\n",
    "        ]\n",
    "        \n",
    "        self.within_period_fc_layers = [\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='within_period_fc_0', weights=model.within_period_fc_layers[0].get_weights()),\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='within_period_fc_1', weights=model.within_period_fc_layers[1].get_weights()),\n",
    "            layers.Dense(1, name='within_period_fc_2', weights=model.within_period_fc_layers[2].get_weights()),\n",
    "        ]\n",
    "        \n",
    "        # TODO ValueError: Dimensions must be equal, but are 1 and 512 for Add\n",
    "        \n",
    "        if self.pos_encoding1.shape[-1] == 1:\n",
    "            self.pos_encoding1 = tf.tile(self.pos_encoding1, multiples=[1, 1, 512])\n",
    "            self.pos_encoding2 = tf.tile(self.pos_encoding2, multiples=[1, 1, 512])\n",
    "                                            \n",
    "    def call(self, x):\n",
    "        x = get_sims_with_noloop(x, SIM_TEMPERATURE)\n",
    "        x = self.conv_3x3_layer(x)\n",
    "        x = tf.reshape(x, [BATCH_SIZE, NUM_FRAMES, -1])\n",
    "        within_period_x = x\n",
    "        \n",
    "        x = self.input_projection1(x)\n",
    "        x += self.pos_encoding1\n",
    "        x = self.transformer_layer1(x)\n",
    "        x = flatten_sequential_feats(x, BATCH_SIZE, NUM_FRAMES)\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = self.dropout_layer(x)\n",
    "            x = fc_layer(x)\n",
    "            \n",
    "        within_period_x = self.input_projection2(within_period_x)\n",
    "        within_period_x += self.pos_encoding2\n",
    "        within_period_x = self.transformer_layer2(within_period_x)\n",
    "        within_period_x = flatten_sequential_feats(within_period_x, BATCH_SIZE, NUM_FRAMES)\n",
    "        for fc_layer in self.within_period_fc_layers:\n",
    "            within_period_x = self.dropout_layer(within_period_x)\n",
    "            within_period_x = fc_layer(within_period_x)\n",
    "          \n",
    "        return x, within_period_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77bcbb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:48.253565Z",
     "start_time": "2021-10-14T12:25:47.356687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-13.967211 ,   0.3748341,  -0.9406101], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-12.783598  ,   3.1049232 ,   0.45159477], dtype=float32)>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = ResnetPart3(model)\n",
    "model_part3_outputs = model3(model_part2_outputs)\n",
    "tf.reshape(model_part3_outputs[0], (-1,))[:3], '-'*60, tf.reshape(test_outputs[0], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a537bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:48.452199Z",
     "start_time": "2021-10-14T12:25:48.255886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart3\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "conv_3x3_layer (Conv2D)                 multiple                            320           \n",
      "__________________________________________________________________________________________\n",
      "input_projection1 (Dense)               multiple                            1049088       \n",
      "__________________________________________________________________________________________\n",
      "input_projection2 (Dense)               multiple                            1049088       \n",
      "__________________________________________________________________________________________\n",
      "transformer_layer1 (TransformerLayer)   multiple                            1577984       \n",
      "__________________________________________________________________________________________\n",
      "transformer_layer2 (TransformerLayer)   multiple                            1577984       \n",
      "__________________________________________________________________________________________\n",
      "dropout (Dropout)                       multiple                            0             \n",
      "__________________________________________________________________________________________\n",
      "fc_0 (Dense)                            multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "fc_1 (Dense)                            multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "fc_layers_2 (Dense)                     multiple                            16416         \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_0 (Dense)              multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_1 (Dense)              multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_2 (Dense)              multiple                            513           \n",
      "==========================================================================================\n",
      "Total params: 6,387,553\n",
      "Trainable params: 6,387,553\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a782dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(MODEL3_0_OUTPUTS, model_part3_outputs[0])\n",
    "np.save(MODEL3_1_OUTPUTS, model_part3_outputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b020ce9",
   "metadata": {},
   "source": [
    "#### Netron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3054bc9",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a51000a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:06.360066Z",
     "start_time": "2021-10-14T12:25:48.457569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_2_layer_call_and_return_conditional_losses, multi_head_attention_2_layer_call_fn, layer_normalization_4_layer_call_and_return_conditional_losses, layer_normalization_4_layer_call_fn, layer_normalization_5_layer_call_and_return_conditional_losses while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model3/assets\n"
     ]
    }
   ],
   "source": [
    "model3.save(filepath=f'{SAVED_MODEL_ROOT}/model3', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e921c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-21 19:46:00,960 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-21 19:46:00,961 - INFO - Output names: ['output_1', 'output_2']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-21 19:46:02,217 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-21 19:46:02,690 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.10.0/42e800\n",
      "2021-10-21 19:46:02,690 - INFO - Using opset <onnx, 11>\n",
      "2021-10-21 19:46:06,042 - INFO - Computed 0 values for constant folding\n",
      "2021-10-21 19:46:08,062 - INFO - Optimizing ONNX model\n",
      "2021-10-21 19:46:09,086 - INFO - After optimization: Cast -51 (51->0), Const -70 (137->67), GlobalAveragePool +8 (0->8), Identity -26 (26->0), Mul -1 (23->22), ReduceMean -8 (8->0), ReduceSum -1 (2->1), Reshape -7 (51->44), Transpose -3 (13->10)\n",
      "2021-10-21 19:46:09,138 - INFO - \n",
      "2021-10-21 19:46:09,138 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model3 to ONNX\n",
      "2021-10-21 19:46:09,138 - INFO - Model inputs: ['input_1']\n",
      "2021-10-21 19:46:09,138 - INFO - Model outputs: ['output_1', 'output_2']\n",
      "2021-10-21 19:46:09,138 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model3/model_opset11.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 11 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model3 --output {SAVED_MODEL_ROOT}/model3/model_opset11.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84522cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %netron -f {SAVED_MODEL_ROOT}/model3/model_opset11.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832ceab",
   "metadata": {},
   "source": [
    "##### tf2onnx: from_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b3abf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_proto = tf2onnx.convert.from_keras(\n",
    "    model3, opset=11, \n",
    "    input_signature=(tf.TensorSpec(shape=model_part2_outputs.shape, name=\"model3_x\"),),\n",
    "    output_path=f'{SAVED_MODEL_ROOT}/model3.onnx')[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17ce7f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"model3_x\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 32\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " , name: \"output_2\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_proto.graph.input, model3_proto.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3438f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %netron -f {SAVED_MODEL_ROOT}/model3.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2959827",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "581266cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.541970Z",
     "start_time": "2021-10-14T12:26:06.375684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 64, 32]), TensorShape([2, 64, 1]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model3(model2(model1(test_inputs_tensor)))\n",
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfce1164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.726504Z",
     "start_time": "2021-10-14T12:26:08.544661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-13.291716 ,   0.5982778,  -1.0268755], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-13.29172  ,   0.5982779,  -1.0268753], dtype=float32)>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(outputs[0], (-1,))[:3], '-'*60, tf.reshape(test_outputs[0], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b68ea368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.904583Z",
     "start_time": "2021-10-14T12:26:08.729112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.2658517, 1.3311325, 1.4469559], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.2658532, 1.3311336, 1.4469564], dtype=float32)>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(outputs[1], (-1,))[:3], '-'*60, tf.reshape(test_outputs[1], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dcdaf10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='Resnet')\n",
    "        self.model1 = ResnetPart1(model)\n",
    "        self.model2 = ResnetPart2(model)\n",
    "        self.model3 = ResnetPart3(model)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.model3(self.model2(self.model1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2c3b4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = FullModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a64ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outputs = full_model(test_inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1794d9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-11.92954   ,   1.6399554 ,  -0.06519073], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-11.929536  ,   1.6399661 ,  -0.06518548], dtype=float32)>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(full_outputs[0], (-1,))[:3], '-'*60, tf.reshape(test_outputs[0], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "28acba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_proto = tf2onnx.convert.from_keras(\n",
    "    full_model, opset=11,\n",
    "    input_signature=(tf.TensorSpec(shape=test_inputs.shape, name=\"x\"),),\n",
    "    output_path=f'{SAVED_MODEL_ROOT}/full_model.onnx')[0];\n",
    "# full_model_proto.graph.input, full_model_proto.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb006bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/full_model.onnx' at http://0.0.0.0:33981\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-99b4a18ba554378' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-99b4a18ba554378\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 33981;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/full_model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132508c",
   "metadata": {},
   "source": [
    "<div style=\"margin-top:30px; width: 100%;\">\n",
    "    <div style=\"text-align:right\">\n",
    "        <a\n",
    "           title=\"Back to Top\"\n",
    "           href=\"#Contents\"\n",
    "           onclick=\"window.scrollTo(0, 0);\"\n",
    "           style=\"color:blue;font-size:28px;text-decoration:none;\">\n",
    "               &#128285;\n",
    "        </a>\n",
    "    </div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "313px",
    "width": "596px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "319px",
    "left": "1303px",
    "top": "94px",
    "width": "371.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
