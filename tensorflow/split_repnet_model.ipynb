{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553054a8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1><span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Download-and-Restore-Model-Weights\" data-toc-modified-id=\"Download-and-Restore-Model-Weights-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Download and Restore Model Weights</a></span></li><li><span><a href=\"#Split-Model\" data-toc-modified-id=\"Split-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Split Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Part-1\" data-toc-modified-id=\"Model-Part-1-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Model Part-1</a></span></li><li><span><a href=\"#Model-Part-2\" data-toc-modified-id=\"Model-Part-2-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Model Part-2</a></span></li><li><span><a href=\"#Model-Part-3\" data-toc-modified-id=\"Model-Part-3-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Model Part-3</a></span></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Test</a></span></li></ul></li><li><span><a href=\"#Load-Model-and-Test\" data-toc-modified-id=\"Load-Model-and-Test-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Model and Test</a></span></li><li><span><a href=\"#TF2ONNX\" data-toc-modified-id=\"TF2ONNX-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>TF2ONNX</a></span><ul class=\"toc-item\"><li><span><a href=\"#Part:-Model-1\" data-toc-modified-id=\"Part:-Model-1-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Part: Model-1</a></span></li><li><span><a href=\"#Part:-Model-2\" data-toc-modified-id=\"Part:-Model-2-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Part: Model-2</a></span></li><li><span><a href=\"#Part:-Model-3\" data-toc-modified-id=\"Part:-Model-3-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Part: Model-3</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5869a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.481197Z",
     "start_time": "2021-10-14T12:24:19.923530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 95))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b4dffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.668317Z",
     "start_time": "2021-10-14T12:24:31.486038Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'erlangai-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    if not line or line.strip() == 'help':\n",
    "        print('%netron file port [height]')\n",
    "        return\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), int(args[2]) if len(args) == 3 else 600\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #     pid = int(res[0].split(' ')[1])\n",
    "    #     !kill -9 $pid\n",
    "    import netron\n",
    "    try:\n",
    "        netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    except:\n",
    "        pass\n",
    "    display_html(port, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02af090a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:31.836686Z",
     "start_time": "2021-10-14T12:24:31.671363Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.saved_model.signature_constants import DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "from tensorflow.python.saved_model.tag_constants import SERVING\n",
    "import onnx\n",
    "from onnxsim import simplify\n",
    "import onnxruntime as ORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981b3641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:33.085729Z",
     "start_time": "2021-10-14T12:24:31.840452Z"
    }
   },
   "outputs": [],
   "source": [
    "_IMPORT('gitee.com/qrsforever/blog_source_codes/AI/tensorflow/misc/ResnetPeriodEstimator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2354b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:33.259827Z",
     "start_time": "2021-10-14T12:24:33.088717Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "IMAGE_W = 112\n",
    "IMAGE_H = 112\n",
    "NUM_FRAMES = 64\n",
    "SIM_TEMPERATURE = 13.544\n",
    "\n",
    "SAVED_MODEL_ROOT = '/data/nb_data/split_repnet_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102ca92",
   "metadata": {},
   "source": [
    "## Download and Restore Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f02979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:34.473703Z",
     "start_time": "2021-10-14T12:24:33.262720Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = '/data/pretrained/cv/repnet/'\n",
    "\n",
    "!test ! -d $PATH_TO_CKPT && mkdir -p $PATH_TO_CKPT && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/checkpoint && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00000-of-00002 && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00001-of-00002 && \\\n",
    "    wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873bbe61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:40.117470Z",
     "start_time": "2021-10-14T12:24:34.483105Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "model.call = tf.function(model.call)\n",
    "tf.train.Checkpoint(model=model).restore(f'{PATH_TO_CKPT}/ckpt-88').expect_partial()\n",
    "test_inputs = np.random.randn(BATCH_SIZE, NUM_FRAMES, IMAGE_H, IMAGE_W, 3).astype(np.float32)\n",
    "test_inputs_tensor = tf.convert_to_tensor(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f0d3a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.079604Z",
     "start_time": "2021-10-14T12:24:40.126369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 32]), TensorShape([1, 64, 1]), TensorShape([1, 64, 512]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs = model(test_inputs_tensor)\n",
    "test_outputs[0].shape, test_outputs[1].shape, test_outputs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77f5576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.300472Z",
     "start_time": "2021-10-14T12:24:47.082822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_period_estimator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer (Transform multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_1 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,690,081\n",
      "Trainable params: 25,673,313\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44f56fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.471497Z",
     "start_time": "2021-10-14T12:24:47.302858Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__.ResnetPeriodEstimator: [\"activity_regularizer\", \"add_loss\", \"add_metric\", \"add_update\", \"add_variable\", \"add_weight\", \"apply\", \"base_model\", \"base_model_layer_name\", \"build\", \"built\", \"call\", \"compile\", \"compiled_loss\", \"compiled_metrics\", \"compute_dtype\", \"compute_mask\", \"compute_output_shape\", \"compute_output_signature\", \"conv_3x3_layer\", \"conv_channels\", \"conv_kernel_size\", \"count_params\", \"distribute_strategy\", \"dropout_layer\", \"dropout_rate\", \"dtype\", \"dtype_policy\", \"dynamic\", \"evaluate\", \"evaluate_generator\", \"fc_layers\", \"finalize_state\", \"fit\", \"fit_generator\", \"from_config\", \"get_config\", \"get_input_at\", \"get_input_mask_at\", \"get_input_shape_at\", \"get_layer\", \"get_losses_for\", \"get_output_at\", \"get_output_mask_at\", \"get_output_shape_at\", \"get_updates_for\", \"get_weights\", \"history\", \"image_size\", \"inbound_nodes\", \"input\", \"input_mask\", \"input_names\", \"input_projection\", \"input_projection2\", \"input_shape\", \"input_spec\", \"inputs\", \"l2_reg_weight\", \"layers\", \"load_weights\", \"losses\", \"make_predict_function\", \"make_test_function\", \"make_train_function\", \"metrics\", \"metrics_names\", \"name\", \"name_scope\", \"non_trainable_variables\", \"non_trainable_weights\", \"num_frames\", \"optimizer\", \"outbound_nodes\", \"output\", \"output_mask\", \"output_names\", \"output_shape\", \"outputs\", \"period_fc_channels\", \"pos_encoding\", \"pos_encoding2\", \"predict\", \"predict_function\", \"predict_generator\", \"predict_on_batch\", \"predict_step\", \"preprocess\", \"reset_metrics\", \"reset_states\", \"run_eagerly\", \"save\", \"save_spec\", \"save_weights\", \"set_weights\", \"state_updates\", \"stateful\", \"stop_training\", \"submodules\", \"summary\", \"supports_masking\", \"temperature\", \"temporal_bn_layers\", \"temporal_conv_channels\", \"temporal_conv_dilation_rate\", \"temporal_conv_kernel_size\", \"temporal_conv_layers\", \"test_function\", \"test_on_batch\", \"test_step\", \"to_json\", \"to_yaml\", \"train_function\", \"train_on_batch\", \"train_step\", \"train_tf_function\", \"trainable\", \"trainable_variables\", \"trainable_weights\", \"transformer_dropout_rate\", \"transformer_layers\", \"transformer_layers2\", \"transformer_layers_config\", \"transformer_reorder_ln\", \"updates\", \"variable_dtype\", \"variables\", \"weights\", \"with_name_scope\", \"within_period_fc_channels\", \"within_period_fc_layers\"]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1eec0d",
   "metadata": {},
   "source": [
    "## Split Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48537fe0",
   "metadata": {},
   "source": [
    "### Model Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d9453d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:47.652337Z",
     "start_time": "2021-10-14T12:24:47.475725Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPart1(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart1')\n",
    "        self.base_model = tf.keras.models.Model(\n",
    "            name='base_model', inputs=model.base_model.input,\n",
    "            outputs=model.base_model.get_layer('conv4_block3_out').output)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (-1, IMAGE_H, IMAGE_W, 3))\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2393d436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:49.001864Z",
     "start_time": "2021-10-14T12:24:47.656777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.6783598 , -0.4574377 , -0.11176682], dtype=float32)>,\n",
       " '------------------------------------------------------------------------------------------',\n",
       " TensorShape([64, 7, 7, 1024]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ResnetPart1(model)\n",
    "model_part1_outputs = model1(test_inputs_tensor)\n",
    "tf.reshape(model_part1_outputs, (-1,))[:3], '-'*90, model_part1_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6b4cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:24:49.191772Z",
     "start_time": "2021-10-14T12:24:49.004174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart1\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "base_model (Functional)                 (None, None, None, 1024)            5209600       \n",
      "==========================================================================================\n",
      "Total params: 5,209,600\n",
      "Trainable params: 5,193,856\n",
      "Non-trainable params: 15,744\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb06b818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:41.539025Z",
     "start_time": "2021-10-14T12:24:49.194128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning:\n",
      "\n",
      "Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.save(filepath=f'{SAVED_MODEL_ROOT}/model1', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38776fc2",
   "metadata": {},
   "source": [
    "### Model Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9537183b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:41.748606Z",
     "start_time": "2021-10-14T12:25:41.559091Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPart2(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart2')\n",
    "        self.temporal_conv_layer = layers.Conv3D(\n",
    "            512, 3, padding='same', name='temporal_conv_layer',\n",
    "            dilation_rate=(3, 1, 1), weights=model.temporal_conv_layers[0].get_weights())\n",
    "        self.temporal_bn_layers = layers.BatchNormalization(\n",
    "            name='temporal_bn_layers', weights=model.temporal_bn_layers[0].get_weights())                  \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, [BATCH_SIZE, -1] + x.shape.as_list()[1:])\n",
    "        x = self.temporal_conv_layer(x)\n",
    "        x = self.temporal_bn_layers(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return tf.reduce_max(x, [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ff8b049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:42.953387Z",
     "start_time": "2021-10-14T12:25:41.753712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ResnetPart2(model)\n",
    "model_part2_outputs = model2(model_part1_outputs)\n",
    "tf.reshape(model_part2_outputs, (-1,))[:3], '-'*60, tf.reshape(test_outputs[2], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c265cb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:43.140974Z",
     "start_time": "2021-10-14T12:25:42.959896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart2\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "temporal_conv_layer (Conv3D)            multiple                            14156288      \n",
      "__________________________________________________________________________________________\n",
      "temporal_bn_layers (BatchNormalization) multiple                            2048          \n",
      "==========================================================================================\n",
      "Total params: 14,158,336\n",
      "Trainable params: 14,157,312\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4fd6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:47.112653Z",
     "start_time": "2021-10-14T12:25:43.144577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model2/assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(filepath=f'{SAVED_MODEL_ROOT}/model2', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61bf389",
   "metadata": {},
   "source": [
    "### Model Part-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34287060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:47.349643Z",
     "start_time": "2021-10-14T12:25:47.118120Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResnetPart3(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart3')\n",
    "        self.conv_3x3_layer = layers.Conv2D(\n",
    "            32, 3, padding='same', activation=tf.nn.relu, name='conv_3x3_layer',\n",
    "            weights=model.conv_3x3_layer.get_weights())\n",
    "        \n",
    "        self.input_projection1 = layers.Dense(\n",
    "            512, activation=None, name='input_projection1',\n",
    "            weights=model.input_projection.get_weights())\n",
    "        self.input_projection2 = layers.Dense(\n",
    "            512, activation=None, name='input_projection2',\n",
    "            weights=model.input_projection2.get_weights())\n",
    "        \n",
    "        self.pos_encoding1 = tf.compat.v1.get_variable(name='pos_encoding',  initializer=model.pos_encoding.numpy())\n",
    "        self.pos_encoding2 = tf.compat.v1.get_variable(name='pos_encoding2', initializer=model.pos_encoding2.numpy())\n",
    "        \n",
    "        self.transformer_layer1 = TransformerLayer(512, 4, 512, 0.0, True, name='transformer_layer1')\n",
    "        self.transformer_layer1(tf.random.uniform((BATCH_SIZE, NUM_FRAMES, 512)))\n",
    "        self.transformer_layer1.set_weights(model.transformer_layers[0].get_weights())\n",
    "        \n",
    "        self.transformer_layer2 = TransformerLayer(512, 4, 512, 0.0, True, name='transformer_layer2')\n",
    "        self.transformer_layer2(tf.random.uniform((BATCH_SIZE, NUM_FRAMES, 512)))\n",
    "        self.transformer_layer2.set_weights(model.transformer_layers2[0].get_weights())\n",
    "        \n",
    "        self.dropout_layer = layers.Dropout(0.25, name='dropout', weights=model.dropout_layer.get_weights())\n",
    "        self.fc_layers = [\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='fc_0', weights=model.fc_layers[0].get_weights()),\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='fc_1', weights=model.fc_layers[1].get_weights()),\n",
    "            layers.Dense(NUM_FRAMES//2, name='fc_layers_2', weights=model.fc_layers[2].get_weights()),\n",
    "        ]\n",
    "        \n",
    "        self.within_period_fc_layers = [\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='within_period_fc_0', weights=model.within_period_fc_layers[0].get_weights()),\n",
    "            layers.Dense(512, activation=tf.nn.relu, name='within_period_fc_1', weights=model.within_period_fc_layers[1].get_weights()),\n",
    "            layers.Dense(1, name='within_period_fc_2', weights=model.within_period_fc_layers[2].get_weights()),\n",
    "        ]\n",
    "        \n",
    "        # TODO ValueError: Dimensions must be equal, but are 1 and 512 for Add\n",
    "        self.pos_encoding1 = tf.tile(self.pos_encoding1, multiples=[1, 1, 512])\n",
    "        self.pos_encoding2 = tf.tile(self.pos_encoding2, multiples=[1, 1, 512])\n",
    "                                            \n",
    "    def call(self, x):\n",
    "        x = get_sims_with_noloop(x, SIM_TEMPERATURE)\n",
    "        x = self.conv_3x3_layer(x)\n",
    "        x = tf.reshape(x, [BATCH_SIZE, NUM_FRAMES, -1])\n",
    "        within_period_x = x\n",
    "        \n",
    "        x = self.input_projection1(x)\n",
    "        x += self.pos_encoding1\n",
    "        x = self.transformer_layer1(x)\n",
    "        x = flatten_sequential_feats(x, BATCH_SIZE, NUM_FRAMES)\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = self.dropout_layer(x)\n",
    "            x = fc_layer(x)\n",
    "            \n",
    "        within_period_x = self.input_projection2(within_period_x)\n",
    "        within_period_x += self.pos_encoding2\n",
    "        within_period_x = self.transformer_layer2(within_period_x)\n",
    "        within_period_x = flatten_sequential_feats(within_period_x, BATCH_SIZE, NUM_FRAMES)\n",
    "        for fc_layer in self.within_period_fc_layers:\n",
    "            within_period_x = self.dropout_layer(within_period_x)\n",
    "            within_period_x = fc_layer(within_period_x)\n",
    "          \n",
    "        return x, within_period_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77bcbb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:48.253565Z",
     "start_time": "2021-10-14T12:25:47.356687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-12.723541 ,   0.7942119,  -1.8805947], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-12.723541  ,   0.79420686,  -1.8805971 ], dtype=float32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = ResnetPart3(model)\n",
    "model_part3_outputs = model3(model_part2_outputs)\n",
    "tf.reshape(model_part3_outputs[0], (-1,))[:3], '-'*60, tf.reshape(test_outputs[0], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a537bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:25:48.452199Z",
     "start_time": "2021-10-14T12:25:48.255886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResnetPart3\"\n",
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "conv_3x3_layer (Conv2D)                 multiple                            320           \n",
      "__________________________________________________________________________________________\n",
      "input_projection1 (Dense)               multiple                            1049088       \n",
      "__________________________________________________________________________________________\n",
      "input_projection2 (Dense)               multiple                            1049088       \n",
      "__________________________________________________________________________________________\n",
      "transformer_layer1 (TransformerLayer)   multiple                            1577984       \n",
      "__________________________________________________________________________________________\n",
      "transformer_layer2 (TransformerLayer)   multiple                            1577984       \n",
      "__________________________________________________________________________________________\n",
      "dropout (Dropout)                       multiple                            0             \n",
      "__________________________________________________________________________________________\n",
      "fc_0 (Dense)                            multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "fc_1 (Dense)                            multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "fc_layers_2 (Dense)                     multiple                            16416         \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_0 (Dense)              multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_1 (Dense)              multiple                            262656        \n",
      "__________________________________________________________________________________________\n",
      "within_period_fc_2 (Dense)              multiple                            513           \n",
      "==========================================================================================\n",
      "Total params: 6,322,017\n",
      "Trainable params: 6,322,017\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary(line_length=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a51000a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:06.360066Z",
     "start_time": "2021-10-14T12:25:48.457569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_2_layer_call_fn, multi_head_attention_2_layer_call_and_return_conditional_losses, layer_normalization_4_layer_call_fn, layer_normalization_4_layer_call_and_return_conditional_losses, layer_normalization_5_layer_call_fn while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/split_repnet_model/model3/assets\n"
     ]
    }
   ],
   "source": [
    "model3.save(filepath=f'{SAVED_MODEL_ROOT}/model3', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2959827",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "581266cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.541970Z",
     "start_time": "2021-10-14T12:26:06.375684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 32]), TensorShape([1, 64, 1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model3(model2(model1(test_inputs_tensor)))\n",
    "outputs[0].shape, outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfce1164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.726504Z",
     "start_time": "2021-10-14T12:26:08.544661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-12.723541 ,   0.7942119,  -1.8805947], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-12.723541  ,   0.79420686,  -1.8805971 ], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(outputs[0], (-1,))[:3], '-'*60, tf.reshape(test_outputs[0], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b68ea368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:08.904583Z",
     "start_time": "2021-10-14T12:26:08.729112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.9562206 , 0.98782516, 1.1635792 ], dtype=float32)>,\n",
       " '------------------------------------------------------------',\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.9562211 , 0.98782593, 1.1635787 ], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(outputs[1], (-1,))[:3], '-'*60, tf.reshape(test_outputs[1], (-1,))[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e73cb",
   "metadata": {},
   "source": [
    "## Load Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd44cc01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:10.441372Z",
     "start_time": "2021-10-14T12:26:08.907226Z"
    }
   },
   "outputs": [],
   "source": [
    "model2_loaded = tf.saved_model.load(f'{SAVED_MODEL_ROOT}/model2')\n",
    "model2_graph_infer = model2_loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac9396a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:11.397506Z",
     "start_time": "2021-10-14T12:26:10.448265Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(model2_graph_infer(model_part1_outputs)['output_1'], (-1,))[:3], tf.reshape(model_part2_outputs, (-1,))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7653a64c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:12.251458Z",
     "start_time": "2021-10-14T12:26:11.404489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.       , 1.186679 , 0.7266406], dtype=float32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(model2_loaded(model_part1_outputs), (-1,))[:3], tf.reshape(model_part2_outputs, (-1,))[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb42fa7",
   "metadata": {},
   "source": [
    "## TF2ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4241fc12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:12.423515Z",
     "start_time": "2021-10-14T12:26:12.258567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('serving_default', 'serve')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_SERVING_SIGNATURE_DEF_KEY, SERVING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f2b1e",
   "metadata": {},
   "source": [
    "### Part: Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d72208c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:54.027276Z",
     "start_time": "2021-10-14T12:26:12.425944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-14 21:01:02,339 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-14 21:01:02,340 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:01:05,237 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:01:06,401 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-10-14 21:01:06,401 - INFO - Using opset <onnx, 13>\n",
      "2021-10-14 21:01:12,119 - INFO - Computed 0 values for constant folding\n",
      "2021-10-14 21:01:16,270 - INFO - Optimizing ONNX model\n",
      "2021-10-14 21:01:20,288 - INFO - After optimization: Add -1 (11->10), BatchNormalization -20 (30->10), Cast -2 (2->0), Const -61 (171->110), Identity -5 (5->0), Reshape -1 (2->1), Transpose -133 (135->2)\n",
      "2021-10-14 21:01:20,382 - INFO - \n",
      "2021-10-14 21:01:20,383 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model1 to ONNX\n",
      "2021-10-14 21:01:20,383 - INFO - Model inputs: ['input_1']\n",
      "2021-10-14 21:01:20,383 - INFO - Model outputs: ['output_1']\n",
      "2021-10-14 21:01:20,383 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model1_opset13.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model1 --output {SAVED_MODEL_ROOT}/model1_opset13.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f678678a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:54.245710Z",
     "start_time": "2021-10-14T12:26:54.035165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model1_opset13.onnx' at http://0.0.0.0:8331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-a2036fecb1d8574c' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-a2036fecb1d8574c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8331;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {SAVED_MODEL_ROOT}/model1_opset13.onnx 8331 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2954f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:58.473060Z",
     "start_time": "2021-10-14T12:26:54.253196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"input_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 3\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model1 = onnx.load(f'{SAVED_MODEL_ROOT}/model1_opset13.onnx')\n",
    "model_simp1, check = simplify(\n",
    "    onnx_model1, dynamic_input_shape=False, \n",
    "    input_shapes={'input_1': [1, 64, 112, 112, 3]})\n",
    "if not check:\n",
    "    raise\n",
    "model_simp1.graph.input, model_simp1.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2725c846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:26:58.714179Z",
     "start_time": "2021-10-14T12:26:58.475414Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx.save(model_simp1, f'{SAVED_MODEL_ROOT}/model1_opset13_simp.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ebd1b",
   "metadata": {},
   "source": [
    "### Part: Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc346cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:44.466320Z",
     "start_time": "2021-10-14T12:26:58.717309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-14 21:01:34,523 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-14 21:01:34,524 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:01:38,557 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:01:41,756 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-10-14 21:01:41,756 - INFO - Using opset <onnx, 13>\n",
      "2021-10-14 21:01:57,705 - INFO - Computed 2 values for constant folding\n",
      "2021-10-14 21:02:06,954 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/Conv3D/strided_slice_1\n",
      "2021-10-14 21:02:06,955 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/Conv3D/strided_slice_2\n",
      "2021-10-14 21:02:08,534 - INFO - Optimizing ONNX model\n",
      "2021-10-14 21:02:10,385 - INFO - After optimization: Cast -1 (4->3), Const -83 (114->31), Gather +1 (1->2), Identity -9 (9->0), Squeeze -7 (9->2), Transpose -1 (10->9), Unsqueeze -15 (21->6)\n",
      "2021-10-14 21:02:10,638 - INFO - \n",
      "2021-10-14 21:02:10,638 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model2 to ONNX\n",
      "2021-10-14 21:02:10,638 - INFO - Model inputs: ['input_1']\n",
      "2021-10-14 21:02:10,639 - INFO - Model outputs: ['output_1']\n",
      "2021-10-14 21:02:10,639 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model2_opset13.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model2 --output {SAVED_MODEL_ROOT}/model2_opset13.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4a2124e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:44.677670Z",
     "start_time": "2021-10-14T12:27:44.474274Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model2_opset13.onnx' at http://0.0.0.0:8332\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-1eb9d0fc8f5ed1c9' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-1eb9d0fc8f5ed1c9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8332;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {SAVED_MODEL_ROOT}/model2_opset13.onnx 8332 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "195efa88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:45.884109Z",
     "start_time": "2021-10-14T12:27:44.685392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "input: \"StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/BiasAdd:0\"\n",
      "output: \"StatefulPartitionedCall/ResnetPart2/temporal_bn_layers/FusedBatchNormV3__200:0\"\n",
      "name: \"StatefulPartitionedCall/ResnetPart2/temporal_bn_layers/FusedBatchNormV3__200\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 3\n",
      "  ints: 1\n",
      "  ints: 2\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "input: \"StatefulPartitionedCall/ResnetPart2/temporal_conv_layer/BiasAdd:0\"\n",
      "output: \"StatefulPartitionedCall/ResnetPart2/temporal_bn_layers/FusedBatchNormV3__200:0\"\n",
      "name: \"StatefulPartitionedCall/ResnetPart2/temporal_bn_layers/FusedBatchNormV3__200\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 4\n",
      "  ints: 1\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([name: \"input_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_param: \"unk__231\"\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_param: \"unk__232\"\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx.helper as OH\n",
    "onnx_model2 = onnx.load(f'{SAVED_MODEL_ROOT}/model2_opset13.onnx')\n",
    "onnx_model2 = onnx.shape_inference.infer_shapes(onnx_model2, check_type=True) # for value_info\n",
    "for i, node in enumerate(onnx_model2.graph.node):\n",
    "    # print('%5d' % i, node.name)\n",
    "    if 'FusedBatchNormV3' in node.name and 'Transpose' == node.op_type:\n",
    "        print('-'*60)\n",
    "        print(node)\n",
    "        print('+'*60)\n",
    "        attr = node.attribute.pop()\n",
    "        if attr.ints[1] == 3:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 4, 1, 2, 3]))\n",
    "        elif attr.ints[1] == 2:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 2, 3, 4, 1]))\n",
    "        print('+'*60)\n",
    "        print(node)\n",
    "        print('-'*60)\n",
    "onnx.save(onnx_model2, f'{SAVED_MODEL_ROOT}/model2_opset13_mod.onnx')\n",
    "onnx_model2.graph.input, onnx_model2.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aeae5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:56.401449Z",
     "start_time": "2021-10-14T12:27:45.887410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"input_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_param: \"unk__232\"\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simp2, check = simplify(\n",
    "    onnx_model2, dynamic_input_shape=False, \n",
    "    input_shapes={'input_1': [1, 7, 7, 1024]})\n",
    "if not check:\n",
    "    raise\n",
    "model_simp2.graph.input, model_simp2.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25a39e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:56.847755Z",
     "start_time": "2021-10-14T12:27:56.403772Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx.save(onnx_model2, f'{SAVED_MODEL_ROOT}/model2_opset13_mod_simp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70914a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:27:57.182334Z",
     "start_time": "2021-10-14T12:27:56.850268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8332\n",
      "Serving '/data/nb_data/split_repnet_model/model2_opset13_mod_simp.onnx' at http://0.0.0.0:8332\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-4d2f9a3084727524' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-4d2f9a3084727524\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8332;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {SAVED_MODEL_ROOT}/model2_opset13_mod_simp.onnx 8332 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f3f46",
   "metadata": {},
   "source": [
    "### Part: Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "182233c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:29.015699Z",
     "start_time": "2021-10-14T12:27:57.184099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-14 21:02:36,722 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-14 21:02:36,729 - INFO - Output names: ['output_1', 'output_2']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:02:39,485 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-14 21:02:40,638 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-10-14 21:02:40,638 - INFO - Using opset <onnx, 13>\n",
      "2021-10-14 21:02:47,563 - INFO - Computed 0 values for constant folding\n",
      "2021-10-14 21:02:51,891 - INFO - Optimizing ONNX model\n",
      "2021-10-14 21:02:54,301 - INFO - After optimization: Cast -55 (55->0), Const -74 (142->68), GlobalAveragePool +8 (0->8), Identity -25 (25->0), Mul -1 (23->22), ReduceMean -8 (8->0), ReduceSum -1 (2->1), Reshape -11 (55->44), Transpose -3 (13->10)\n",
      "2021-10-14 21:02:54,407 - INFO - \n",
      "2021-10-14 21:02:54,407 - INFO - Successfully converted TensorFlow model /data/nb_data/split_repnet_model/model3 to ONNX\n",
      "2021-10-14 21:02:54,407 - INFO - Model inputs: ['input_1']\n",
      "2021-10-14 21:02:54,408 - INFO - Model outputs: ['output_1', 'output_2']\n",
      "2021-10-14 21:02:54,408 - INFO - ONNX model is saved at /data/nb_data/split_repnet_model/model3_opset13.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 13 \\\n",
    "    --tag {SERVING} --signature_def {DEFAULT_SERVING_SIGNATURE_DEF_KEY} \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model3 --output {SAVED_MODEL_ROOT}/model3_opset13.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e02d3c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:29.213431Z",
     "start_time": "2021-10-14T12:28:29.018174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model3_opset13.onnx' at http://0.0.0.0:8333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-8d7d3b5ca254fb88' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-8d7d3b5ca254fb88\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8333;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {SAVED_MODEL_ROOT}/model3_opset13.onnx 8333 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60172126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:31.420686Z",
     "start_time": "2021-10-14T12:28:29.218478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([name: \"input_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 32\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " , name: \"output_2\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model3 = onnx.load(f'{SAVED_MODEL_ROOT}/model3_opset13.onnx')\n",
    "model_simp3, check = simplify(\n",
    "    onnx_model3, dynamic_input_shape=False, \n",
    "    input_shapes={'input_1': [1, 64, 512]})\n",
    "if not check:\n",
    "    raise\n",
    "model_simp3.graph.input, model_simp3.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "131919d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:31.677387Z",
     "start_time": "2021-10-14T12:28:31.423819Z"
    }
   },
   "outputs": [],
   "source": [
    "onnx.save(model_simp3, f'{SAVED_MODEL_ROOT}/model3_opset13_simp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dba85682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:28:31.906719Z",
     "start_time": "2021-10-14T12:28:31.679785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/split_repnet_model/model3_opset13_simp.onnx' at http://0.0.0.0:8334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-d109c9fc65076460' width='100%' height='500' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-d109c9fc65076460\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8334;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {SAVED_MODEL_ROOT}/model3_opset13_simp.onnx 8334 500"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "313px",
    "width": "596px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
