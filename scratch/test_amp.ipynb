{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> 自动混合精度 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:14:59.471252Z",
     "start_time": "2020-07-14T09:14:59.297946Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%watermark -v -p numpy,pandas,matplotlib,sklearn,torch,torchvision,pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:57:43.376087Z",
     "start_time": "2020-07-15T04:57:41.486288Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "\n",
    "from apex import amp\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.loggers import TensorBoardLogger  \n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast \n",
    "\n",
    "from k12libs.utils.nb_easy import k12ai_get_top_dir,k12ai_start_tensorboard,k12ai_set_notebook\n",
    "from k12libs.utils.nb_easy import K12AI_NBDATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:32:43.283061Z",
     "start_time": "2020-07-14T09:32:43.242922Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        # self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "        # self.layer_2 = torch.nn.Linear(128, 256)\n",
    "        # self.layer_3 = torch.nn.Linear(256, 10)\n",
    "        self.model = models.resnet50()\n",
    "        self.scaler = GradScaler()\n",
    "        self.amp = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_size, channels, width, height = x.size()\n",
    " \n",
    "        # # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        # x = x.view(batch_size, -1)\n",
    " \n",
    "        # # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "        # x = self.layer_1(x)\n",
    "        # x = torch.relu(x)\n",
    "\n",
    "        # # layer 2 (b, 128) -> (b, 256)\n",
    "        # x = self.layer_2(x)\n",
    "        # x = torch.relu(x)\n",
    " \n",
    "        # # layer 3 (b, 256) -> (b, 10)\n",
    "        # x = self.layer_3(x)\n",
    "\n",
    "        # # probability distribution over labels\n",
    "        # x = torch.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        if self.amp:\n",
    "            with autocast():\n",
    "                logits = self.forward(x)\n",
    "                loss = self.cross_entropy_loss(logits, y)\n",
    "        else:\n",
    "            logits = self.forward(x)\n",
    "            loss = self.cross_entropy_loss(logits, y)\n",
    " \n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        if self.amp:\n",
    "            with autocast():\n",
    "                logits = self.forward(x)\n",
    "                loss = self.cross_entropy_loss(logits, y)\n",
    "        else:\n",
    "            logits = self.forward(x)\n",
    "            loss = self.cross_entropy_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "     \n",
    "    def test_step(self, train_batch, batch_idx):\n",
    "        pass\n",
    " \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        torch.cuda.empty_cache()\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    " \n",
    "    def prepare_data(self):\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))])\n",
    "       \n",
    "        # prepare transforms standard to MNIST\n",
    "        data_path = os.path.join(K12AI_NBDATA_ROOT, 'datasets')\n",
    "        mnist_train = MNIST(data_path, train=True, download=True, transform=transform)\n",
    "        mnist_test = MNIST(data_path, train=False, download=True, transform=transform)\n",
    "     \n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=64)\n",
    " \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=64)\n",
    " \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self,mnist_test, batch_size=64)\n",
    " \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx,        \n",
    "                       second_order_closure, using_native_amp):    \n",
    "        if self.amp:\n",
    "            self.scaler.step(optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            optimizer.step()                                                                \n",
    "\n",
    "    def backward(self, trainer, loss, optimizer, optimizer_idx):\n",
    "        if self.amp:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:30:08.573643Z",
     "start_time": "2020-07-14T09:30:08.564234Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrintingCallback(pl.Callback):\n",
    "\n",
    "    def on_init_start(self, trainer):\n",
    "        print('Starting to init trainer!')\n",
    "\n",
    "    def on_init_end(self, trainer):\n",
    "        print('trainer is init now')\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print('do something when training ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:30:11.315209Z",
     "start_time": "2020-07-14T09:30:09.639293Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(K12AI_NBDATA_ROOT, 'logs')\n",
    "k12ai_set_notebook(cellw=95)\n",
    "k12ai_start_tensorboard(9004, log_dir, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:35:55.869226Z",
     "start_time": "2020-07-14T09:33:02.429758Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=log_dir, name='tb_logs')\n",
    "model = MNISTClassifier()\n",
    "trainer = pl.Trainer(\n",
    "    precision=32,\n",
    "    gpus=1,\n",
    "    logger = logger,\n",
    "    log_gpu_memory='min_max',\n",
    "    callbacks=[PrintingCallback()])\n",
    "trainer.fit(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (New) Using autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T13:31:48.888947Z",
     "start_time": "2020-07-14T13:30:54.834020Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "use_amp = True\n",
    "model = torchvision.models.vgg16().cuda()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "if use_amp:\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(501):\n",
    "    _inputs = torch.randn(20, 3, 32, 32).cuda()\n",
    "    labels = torch.randn(20, 1000).cuda()\n",
    "    \n",
    "    if use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(_inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "    else:\n",
    "        outputs = model(_inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "            \n",
    "    if use_amp:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "        print('%03d' % epoch,\n",
    "              round(torch.cuda.max_memory_allocated()/2**20, 2),\n",
    "              round(torch.cuda.memory_allocated()/2**20, 2),\n",
    "              round(torch.cuda.memory_reserved()/2**20, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T09:25:46.645054Z",
     "start_time": "2020-07-14T09:25:46.511313Z"
    }
   },
   "source": [
    "use_amp = False:  3563MB 1m33s\n",
    "use_amp = True:   3545MB 1m38s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Old) Using apex.amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T15:03:57.872169Z",
     "start_time": "2020-07-14T14:58:53.376681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 8793.74 17016.0 1109.27 4012.0\n",
      "100 8793.88 17016.0 1109.27 3964.0\n",
      "200 8793.88 17016.0 1109.27 3964.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-698a73d0480c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# del inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# del labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         print('%03d' % epoch,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "use_amp = False\n",
    "\n",
    "model = torchvision.models.vgg16().cuda()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "if use_amp:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level='O2')\n",
    "    \n",
    "def step(inputs, targets):\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    if use_amp:\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "    else:\n",
    "        loss.backward()\n",
    "    optimizer.step()\n",
    "    # del outputs\n",
    "    # del loss\n",
    "    \n",
    "optimizer.zero_grad()\n",
    "for epoch in range(301):\n",
    "    inputs = torch.randn(32, 3, 64, 64).cuda()\n",
    "    labels = torch.randn(32, 1000).cuda()\n",
    "    step(inputs, labels)\n",
    "    # del inputs\n",
    "    # del labels\n",
    "    torch.cuda.empty_cache()\n",
    "    if epoch % 100 == 0:\n",
    "        print('%03d' % epoch,\n",
    "              round(torch.cuda.max_memory_allocated()/2**20, 2),\n",
    "              round(torch.cuda.max_memory_reserved()/2**20, 2),\n",
    "              round(torch.cuda.memory_allocated()/2**20, 2),\n",
    "              round(torch.cuda.memory_reserved()/2**20, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_amp = False bs=128\n",
    "\n",
    "    000 2025.62 2964.0 1064.57 2964.0\n",
    "    100 2206.83 2964.0 1064.57 2964.0\n",
    "    200 2206.83 2964.0 1064.57 2964.0\n",
    "    300 2206.83 2964.0 1064.57 2964.0\n",
    "    400 2206.83 2964.0 1064.57 2964.0\n",
    "    500 2206.83 2964.0 1064.57 2964.0\n",
    "\n",
    "---------------\n",
    "\n",
    "use_amp = True\n",
    "\n",
    "    000 1836.56 2652.0 1064.51 2652.0\n",
    "    100 1837.94 2652.0 1064.89 2652.0\n",
    "    200 1837.94 2652.0 1064.89 2652.0\n",
    "    300 1837.94 2652.0 1064.89 2652.0\n",
    "    400 1837.94 2652.0 1064.89 2652.0\n",
    "    500 1837.94 2652.0 1064.89 2652.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    000 8793.74 17016.0 1109.27 4012.0\n",
    "    100 8793.88 17016.0 1109.27 3964.0\n",
    "    200 8793.88 17016.0 1109.27 3964.0\n",
    "\n",
    "--------------\n",
    "\n",
    "    000 7281.77 15746.0 1109.31 3370.0\n",
    "    100 7283.71 16200.0 1109.31 5616.0\n",
    "    200 7283.71 16200.0 1109.31 5616.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:57:55.501538Z",
     "start_time": "2020-07-15T04:57:55.491789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cuda.cufft_plan_cache.max_size, \\\n",
    "torch.backends.cuda.cufft_plan_cache.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
