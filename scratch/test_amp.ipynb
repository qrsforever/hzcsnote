{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> 自动混合精度 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T14:17:03.175809Z",
     "start_time": "2020-07-13T14:17:01.564591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.23.1\n",
      "torch 1.6.0.dev20200609+cu101\n",
      "torchvision 0.7.0.dev20200609+cu101\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%watermark -v -p numpy,pandas,matplotlib,sklearn,torch,torchvision,pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T15:29:37.453861Z",
     "start_time": "2020-07-13T15:29:37.354688Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast \n",
    "\n",
    "from k12libs.utils.nb_easy import k12ai_get_top_dir\n",
    "from k12libs.utils.nb_easy import K12AI_NBDATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T15:35:09.257389Z",
     "start_time": "2020-07-13T15:35:09.142624Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTClassifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "\n",
    "        # mnist images are (1, 28, 28) (channels, width, height)\n",
    "        # self.layer_1 = torch.nn.Linear(28 * 28, 128)\n",
    "        # self.layer_2 = torch.nn.Linear(128, 256)\n",
    "        # self.layer_3 = torch.nn.Linear(256, 10)\n",
    "        self.model = models.resnet50()\n",
    "        self.scaler = GradScaler()\n",
    "        self.amp = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_size, channels, width, height = x.size()\n",
    " \n",
    "        # # (b, 1, 28, 28) -> (b, 1*28*28)\n",
    "        # x = x.view(batch_size, -1)\n",
    " \n",
    "        # # layer 1 (b, 1*28*28) -> (b, 128)\n",
    "        # x = self.layer_1(x)\n",
    "        # x = torch.relu(x)\n",
    "\n",
    "        # # layer 2 (b, 128) -> (b, 256)\n",
    "        # x = self.layer_2(x)\n",
    "        # x = torch.relu(x)\n",
    " \n",
    "        # # layer 3 (b, 256) -> (b, 10)\n",
    "        # x = self.layer_3(x)\n",
    "\n",
    "        # # probability distribution over labels\n",
    "        # x = torch.log_softmax(x, dim=1)\n",
    "        \n",
    "        x = self.model(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        if self.amp:\n",
    "            with autocast():\n",
    "                logits = self.forward(x)\n",
    "                loss = self.cross_entropy_loss(logits, y)\n",
    "        else:\n",
    "            logits = self.forward(x)\n",
    "            loss = self.cross_entropy_loss(logits, y)\n",
    " \n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        if self.amp:\n",
    "            with autocast():\n",
    "                logits = self.forward(x)\n",
    "                loss = self.cross_entropy_loss(logits, y)\n",
    "        else:\n",
    "            logits = self.forward(x)\n",
    "            loss = self.cross_entropy_loss(logits, y)\n",
    "        return {'val_loss': loss}\n",
    "     \n",
    "    def test_step(self, train_batch, batch_idx):\n",
    "        pass\n",
    " \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n",
    " \n",
    "    def prepare_data(self):\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Lambda(lambda img: img.convert('RGB')),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))])\n",
    "       \n",
    "        # prepare transforms standard to MNIST\n",
    "        data_path = os.path.join(K12AI_NBDATA_ROOT, 'datasets')\n",
    "        mnist_train = MNIST(data_path, train=True, download=False, transform=transform)\n",
    "        mnist_test = MNIST(data_path, train=False, download=False, transform=transform)\n",
    "     \n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=64)\n",
    " \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=64)\n",
    " \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self,mnist_test, batch_size=64)\n",
    " \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx,        \n",
    "                       second_order_closure, using_native_amp):    \n",
    "        if self.amp:\n",
    "            self.scaler.step(optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            optimizer.step()                                                                \n",
    "\n",
    "    def backward(self, trainer, loss, optimizer, optimizer_idx):\n",
    "        if self.amp:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T14:53:09.359990Z",
     "start_time": "2020-07-13T14:53:09.282101Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrintingCallback(pl.Callback):\n",
    "\n",
    "    def on_init_start(self, trainer):\n",
    "        print('Starting to init trainer!')\n",
    "\n",
    "    def on_init_end(self, trainer):\n",
    "        print('trainer is init now')\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print('do something when training ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-13T15:35:16.090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 25 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to init trainer!\n",
      "trainer is init now\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aae72a1c374debb00663c01451bcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MNISTClassifier()\n",
    "trainer = pl.Trainer(gpus=1, callbacks=[PrintingCallback()])\n",
    "trainer.fit(model) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
