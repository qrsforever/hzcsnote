{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:26:42.513946Z",
     "start_time": "2020-09-05T00:26:40.547119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.23.1\n",
      "torch 1.6.0.dev20200609+cu101\n",
      "torchvision 0.7.0.dev20200609+cu101\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%watermark -v -p numpy,pandas,matplotlib,sklearn,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:27:10.013201Z",
     "start_time": "2020-09-05T00:27:09.342919Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EasyaiClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8f02a9d50d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mk12libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_easy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mK12AI_DATASETS_ROOT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mk12libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_easy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEasyaiTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEasyaiDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'EasyaiClassifier'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import Sequential, Module\n",
    "from torch.nn import NLLLoss, MSELoss, CrossEntropyLoss\n",
    "from torch.nn import BatchNorm2d, Conv2d, MaxPool2d, Dropout2d, Linear, ReLU, Flatten\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR, MultiStepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from torchvision import transforms\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from k12libs.utils.nb_easy import K12AI_DATASETS_ROOT\n",
    "from k12libs.utils.nb_easy import (EasyaiClassifier, EasyaiTrainer, EasyaiDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单实例\n",
    "\n",
    "该实例没有实际意义, 默认配置的是 resnet18网络, 使用rmnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:27:34.102456Z",
     "start_time": "2020-09-05T00:27:34.039297Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EasyaiTrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-882ad28e3b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEasyaiTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EasyaiTrainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = EasyaiTrainer(max_epochs=2, logger=False)\n",
    "trainer.fit(EasyaiClassifier())\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:27:41.348083Z",
     "start_time": "2020-09-05T00:27:41.271332Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EasyaiClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ebdbe178feb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m##########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m####### Data ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m##########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EasyaiClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomClassifier(EasyaiClassifier):\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Data ######\n",
    "    ##########################################################################\n",
    "    def load_presetting_dataset_(self, dataset_name):\n",
    "        \"\"\"\n",
    "        加载平台预置的数据集\n",
    "        Args:\n",
    "            dataset_name: 数据集的名字, 如: rmnist, flowers等\n",
    "        \n",
    "        Return:\n",
    "            以下几种方式任意一种:\n",
    "            1. EasyaiDataset实例, 表明只进行训练(只返回了训练数据集实例)\n",
    "            2. EasyaiDataset实例列表, 当列表长度为2时, 说明还要进行训练的校验, 当列表长度为3时, 说明还要进行测试评估.\n",
    "            3. EasyaiDataset实例字典, 如: {'train': EasyaiDataset, 'val': EasyaiDataset, 'test':EasyaiDataset}\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        准备数据集, 从磁盘上加载数据集, 不同数据集的描述格式可能不一样, 一般有json/xml/csv等描述格式,\n",
    "        也可能直接是图片目录, 所有这些格式的处理可以在这个接口完成.\n",
    "            \n",
    "        Return:\n",
    "            同prepare_dataset\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Model ######\n",
    "    ##########################################################################\n",
    "    def load_pretrained_model_(self, model_name, num_classes, pretrained):\n",
    "        \"\"\"\n",
    "        加载平台预置的模型\n",
    "        Args:\n",
    "            model_name: 模型的名字\n",
    "            num_classes: 分类个数(数据集labels的数目), 预置的模型默认是1000, 所以需要提供真实的分类个数进行处理\n",
    "            pretrained: 是否加载预置权重\n",
    "            \n",
    "        Return:\n",
    "            Module: 模型实例\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        构建模型, 可以自定义模型, 也可以调用load_pretrained_model_使用平台预置的模型\n",
    "        \n",
    "        Return:\n",
    "            同load_pretrained_model_\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Hypes Parameters ######\n",
    "    ##########################################################################\n",
    "    def configure_criterion(self):\n",
    "        \"\"\"\n",
    "        配置损失函数\n",
    "        \n",
    "        Return:\n",
    "            loss\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizer(self):\n",
    "        \"\"\"\n",
    "        配置优化器\n",
    "        \n",
    "        Return:\n",
    "            optimizer\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def configure_scheduler(self, optimizer):\n",
    "        \"\"\"\n",
    "        配置学习率衰减策略\n",
    "        \n",
    "        Args:\n",
    "            optimizer: 优化器(通过configure_optimizer配置得到的)\n",
    "        \n",
    "        Return:\n",
    "            scheduler\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def loss(self):\n",
    "        \"\"\"\n",
    "        返回configure_criterion配置的损失实例\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: Train ######\n",
    "    ##########################################################################\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        训练数据集批量控制加载器, 可以设置批量的大小, 是否对数据进行洗牌(shuffle)等\n",
    "        \n",
    "        Return:\n",
    "            loader\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        训练过程中, 迭代一次batch数据, 就会触发一次training_step的调用,训练,统计metrics\n",
    "        \n",
    "        Args:\n",
    "            batch: 一个batch的数据内容, 一般包括图片(image), 图片标签(labels), 图片路径(path).\n",
    "                具体batch中内容受prepare_dataset接口的实现会有所不同\n",
    "            batch_idx: 本轮epoch批量迭代次数\n",
    "            \n",
    "        Return:\n",
    "            metrics: 必须包含loss关键字, log(日志模块)和progress_bar(进度条显示)是可选的\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        训练过程中, 每完整的遍历完一次(epoch)数据集,则触发一次training_epoch_end的调用, 汇总metrics\n",
    "        \n",
    "        Args:\n",
    "            outputs: 所有metrics(training_step每次产生的数据的集合)\n",
    "        \n",
    "        Return:\n",
    "            metrics: 同training_step, 可以对metrics做平均处理\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Trainer: validation ######\n",
    "    ##########################################################################\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        同train_dataloader\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        同train_step\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        同train_epoch_end\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: test ######\n",
    "    ##########################################################################\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        同train_dataloader\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        同train_step\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        同train_epoch_end\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例: 预置数据集和预置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:27:46.287969Z",
     "start_time": "2020-09-05T00:27:46.225096Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EasyaiClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88d0eade9ad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"\"\"\n\u001b[1;32m      4\u001b[0m         \u001b[0m加载预设数据集\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchestxray\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m胸部xray判断新冠\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EasyaiClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomClassifier(EasyaiClassifier):\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        加载预设数据集:chestxray (胸部xray判断新冠)\n",
    "        \"\"\"\n",
    "        return self.load_presetting_dataset_(dataset_name='chestxray')\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        加载预置模型: densenet201\n",
    "        \"\"\"\n",
    "        return self.load_pretrained_model_(model_name='densenet201', num_classes=2, pretrained=True)\n",
    "\n",
    "trainer = EasyaiTrainer(max_epochs=3, logger=False, progress_bar_rate=2)\n",
    "# 训练\n",
    "trainer.fit(CustomClassifier())\n",
    "# 评估\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例: 自定义损失函数,优化器, LR策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:27:56.695727Z",
     "start_time": "2020-09-05T00:27:56.626240Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EasyaiClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c3610362dbbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# 配置损失函数: CrossEntropyLoss(交叉熵损失)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         loss = CrossEntropyLoss(\n\u001b[1;32m      5\u001b[0m             \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m \u001b[0;31m# 约简方式: mean(张量各个维度上的元素的平均值)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EasyaiClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomClassifier(EasyaiClassifier):\n",
    "    # 配置损失函数: CrossEntropyLoss(交叉熵损失)\n",
    "    def configure_criterion(self):\n",
    "        loss = CrossEntropyLoss(\n",
    "            reduction='mean' # 约简方式: mean(张量各个维度上的元素的平均值)\n",
    "        )\n",
    "        return loss\n",
    "    \n",
    "    # 配置优化方法:\n",
    "    def configure_optimizer(self):\n",
    "        # self.model是在build_model构造的, 如果build_model没定义, 使用默认的构造的预置模型\n",
    "        \n",
    "        # optim-1: 随机梯度下降\n",
    "        # optimizer = SGD(\n",
    "        #     filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "        #     lr=0.001,           # 基础学习率\n",
    "        #     weight_decay=1e-6,  # 权重衰减, 使得模型参数值更小, 有效防止过拟合\n",
    "        #     momentum=0.9,       # 动量因子, 更快局部收敛\n",
    "        #     nesterov=False      # 使用Nesterov动量, 加快收敛速度\n",
    "        # )\n",
    "        \n",
    "        # optim-2: 亚当\n",
    "        optimizer = Adam(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()), # 过程出可更新的层(参数)\n",
    "            lr=0.001,           # 基础学习率\n",
    "            betas=(0.9, 0.999), # 计算梯度的均值(0.9)和平方(0.999)的系数\n",
    "            eps=1e-8,           # 为了防止分母除零, 分母加上非常小的值\n",
    "            weight_decay=0,     # 权重衰减\n",
    "            amsgrad=False,      # 是否使用AmsGrad变体\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    # 配置学习率策略: \n",
    "    def configure_scheduler(self, optimizer):\n",
    "        # optmizer是在configure_optimizer配置的\n",
    "        \n",
    "        # policy-1: 指数衰减\n",
    "        # scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
    "        \n",
    "        # policy-2: 指标不在变化时, 调整学习率\n",
    "        # scheduler = ReduceLROnPlateau(\n",
    "        #     optimizer,   # 优化器\n",
    "        #     mode='min',  # 指定指标不再下降\n",
    "        #     factor=0.1,  # 衰减因子\n",
    "        #     patience=6,  # 容忍多少次(指标不改变)\n",
    "        #     eps=1e-6,    # 学习率衰减到的最小值eps时,学习率不再改变\n",
    "        # )\n",
    "        \n",
    "        # policy-3: 固定步长衰减\n",
    "        scheduler = StepLR(\n",
    "            optimizer,   # 优化器\n",
    "            step_size=2, # 每间隔2次epoch进行一次LR调整\n",
    "            gamma=0.6    # LR调整为原来0.6倍\n",
    "        )\n",
    "        \n",
    "        # policy-4: 不定步长衰减\n",
    "        # scheduler = MultiStepLR(\n",
    "        #     optimizer,        # 优化器\n",
    "        #     milestones=[3, 7],# 分阶段(epoch)调整,到达指定的epoch时, 学习率调整为原来的gamma倍\n",
    "        #     gamma=0.1         # LR调整为原来0.1倍\n",
    "        # )\n",
    "        return scheduler\n",
    "    \n",
    "trainer = EasyaiTrainer(max_epochs=2, logger=False)\n",
    "trainer.fit(CustomClassifier())\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例: 自定义训练阶段的Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T00:28:20.486486Z",
     "start_time": "2020-09-05T00:28:20.429156Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EasyaiClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d155637cc960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mk12libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_easy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEasyaiTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# 进入模型前, 数据加载参数设置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'EasyaiClassifier'"
     ]
    }
   ],
   "source": [
    "from k12libs.utils.nb_easy import (EasyaiClassifier, EasyaiTrainer)\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "    # 进入模型前, 数据加载参数设置\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self.get_dataloader('train',\n",
    "                batch_size=12,    # 一次进入模型的数据量(批量大小)\n",
    "                num_workers=1,    # 启动多少个进程加载数据(值不要过大)\n",
    "                drop_last=True,   # 是否丢掉最后一次不完整的batch(个数不足batch_szie)\n",
    "                shuffle=False)    # 每次epoch时,是否将数据进行重新洗牌\n",
    "    \n",
    "    # 对每次batch迭代, 计算损失率, 正确率等, 返回metrics \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, p = batch           # images, labels, paths      \n",
    "        y_hat = self.model(x)     # model由build_model返回, 输入images, 返回估计y\n",
    "        loss = self.loss(y_hat, y)# loss有configure_criterion配置, 计算y_hat, y的差异损失\n",
    "        with torch.no_grad():\n",
    "            acc = (torch.argmax(y_hat, axis=1) == y).float().mean() # 计算正确率\n",
    "            \n",
    "        log = {'train_loss': loss, 'train_acc': acc}\n",
    "        output = OrderedDict({\n",
    "            'loss': loss,         # (M) 必须包含loss, 训练损失\n",
    "            'acc': acc,           # (O) 可选, 每次迭代记录正确率, epoch结束时可以用来计算平均acc\n",
    "            'progress_bar': log,  # (O) 可选, 可以在训练进度条上显示该字典里的内容\n",
    "            \"log\": log            # (O) 可选, 如果启动logger模块, 作为logger的输入数据\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    # 对每次eopch的结束, 根据需要计算metrics, 输出日志等\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean() # 对训练loss做平均\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()   # 对训练acc做平均\n",
    "        log = {'train_loss': avg_loss, 'train_acc': avg_acc}        # 封装到字典中\n",
    "        return {'progress_bar': log, 'log': log}                    # 供进度条上和logger模块使用log字段数据\n",
    "     \n",
    "trainer = EasyaiTrainer(max_epochs=2, logger=False)\n",
    "trainer.fit(CustomClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T12:00:54.048794Z",
     "start_time": "2020-07-29T12:00:50.960Z"
    }
   },
   "source": [
    "## 实例: 自定义数据集(解析)及数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:15:48.529099Z",
     "start_time": "2020-08-23T11:15:21.575501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f087e73b19164b288df6d3197454893b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292dfe6c29ae4c6e81a9e0fe289cedcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2a7066c5364d35bb918b50e24ac790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': tensor(0.7850, device='cuda:0'),\n",
      " 'test_loss': tensor(0.5356, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.535595178604126, 'test_acc': 0.7849999666213989}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomClassifier(EasyaiClassifier):\n",
    "    \n",
    "    # 自定义数据集\n",
    "    def prepare_dataset(self):\n",
    "        # 继承EasyaiDataset, 实现data_reader接口\n",
    "        class JsonfileDataset(EasyaiDataset):\n",
    "            \"\"\"\n",
    "            Json文件描述的数据集的解析器\n",
    "            \"\"\"\n",
    "            def data_reader(self, path, phase):\n",
    "                \"\"\"\n",
    "                Args:\n",
    "                    path: the dataset root directory\n",
    "                    phase: the json file name (train.json / val.json / test.json)\n",
    "                \"\"\"\n",
    "                image_list = []\n",
    "                label_list = []\n",
    "                with open(os.path.join(path, f'{phase}.json')) as f:\n",
    "                    items = json.load(f)\n",
    "                    for item in items:\n",
    "                        image_list.append(os.path.join(path, item['image_path']))\n",
    "                        label_list.append(item['label'])\n",
    "                return image_list, label_list\n",
    "\n",
    "        root = f'{K12AI_DATASETS_ROOT}/cv/rDogsVsCats' # 数据集路径\n",
    "        mean = (0.4623, 0.4305, 0.2950)                # 数据集所有像素均值\n",
    "        std  = (0.2520, 0.2242, 0.2091)                # 数据集所有像素的方差\n",
    "        datasets = {\n",
    "            'train': JsonfileDataset(mean=mean, std=std, path=root, phase='train'),\n",
    "            'val':   JsonfileDataset(mean=mean, std=std, path=root, phase='val'),\n",
    "            'test':  JsonfileDataset(mean=mean, std=std, path=root, phase='test'),\n",
    "        }\n",
    "        return datasets\n",
    "    \n",
    "    # 数据集标签不同时, 需要修改对应num_classes\n",
    "    def build_model(self):\n",
    "        return self.load_pretrained_model_('resnet18', 2)\n",
    "    \n",
    "    # 数据增强(场景:数据的样本比较小)\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        对训练集进行增强\n",
    "        \"\"\"\n",
    "        trainloader = self.get_dataloader(\n",
    "            phase='train',  # 训练数据集\n",
    "            data_augment=[\n",
    "                self.random_resized_crop(size=(128, 128)), # 随机对图片裁剪\n",
    "                self.random_contrast(factor=0.25),         # 随机变换图片对比度\n",
    "                self.random_brightness(factor=0.3),        # 随机变换图片的亮度\n",
    "                self.random_rotation(degrees=30)           # 随机旋转图片(范围:-30-30)\n",
    "            ],\n",
    "            random_order=True,  # 变换方法执行顺序: 所有增强变换先随机排序在, 在依次变换\n",
    "            input_size=128,     # 输入到模型的图片大小\n",
    "            normalize=True,     # 是否对图片的Tensor数据进行归一化, 需要知道数据集像素的均值和方差\n",
    "            batch_size=32,      # 一次输入到模型的批量大小\n",
    "            num_workers=1,      # 启动多少进程加载数据(不建议设置过高)\n",
    "            drop_last=False,    # 以后一个batch如果大小小于batch_size是否丢掉\n",
    "            shuffle=False)      # 每一次epoch是否对样本(图片)数据进行随机洗牌(打散)\n",
    "        \n",
    "        return trainloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        对校验集进行增强\n",
    "        \"\"\"\n",
    "        valloader = self.get_dataloader(\n",
    "            phase='val',    # 校验数据集\n",
    "            data_augment=[\n",
    "                self.random_contrast(factor=0.25), # 随机变换图片对比度\n",
    "                self.random_rotation(degrees=30)   # 随机旋转图片(范围:-30-30)\n",
    "            ],\n",
    "            random_order=False, \n",
    "            input_size=128,\n",
    "            normalize=True,\n",
    "            batch_size=16,\n",
    "            num_workers=1,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "        \n",
    "        return valloader\n",
    "\n",
    "trainer = EasyaiTrainer(max_epochs=2, logger=False)\n",
    "trainer.fit(CustomClassifier())\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例: 自定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:18:58.335243Z",
     "start_time": "2020-08-23T11:15:48.533133Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir /data/tmp (started 0:00:00 ago; port 9005, pid 8790).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4ca0a201dc35d2f9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4ca0a201dc35d2f9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 9005;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name           | Type        | Params\n",
      "------------------------------------------------\n",
      "0  | model          | CustomNet   | 341 K \n",
      "1  | model.layer1   | Sequential  | 1 K   \n",
      "2  | model.layer1.0 | Conv2d      | 1 K   \n",
      "3  | model.layer1.1 | BatchNorm2d | 32    \n",
      "4  | model.layer1.2 | ReLU        | 0     \n",
      "5  | model.layer1.3 | MaxPool2d   | 0     \n",
      "6  | model.layer2   | Sequential  | 12 K  \n",
      "7  | model.layer2.0 | Conv2d      | 12 K  \n",
      "8  | model.layer2.1 | BatchNorm2d | 64    \n",
      "9  | model.layer2.2 | ReLU        | 0     \n",
      "10 | model.layer2.3 | MaxPool2d   | 0     \n",
      "11 | model.fc       | Linear      | 327 K \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d1a7bfa0944df7ad3615003a63504a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3415e60e194ab18b4cb33ee128e312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4b387bef3c4b3f920358affee6dde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': tensor(0.1017, device='cuda:0'),\n",
      " 'test_loss': tensor(3.2203, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 3.2203171253204346, 'test_acc': 0.1016865149140358}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomClassifier(EasyaiClassifier):\n",
    "    def build_model(self):\n",
    "        class SmallCNN(Module):\n",
    "            \"\"\"\n",
    "            input_size: 128\n",
    "            \"\"\"\n",
    "            def __init__(self, num_classes=10, hidden_size=100):\n",
    "                super(SmallCNN, self).__init__()\n",
    "                self.features = Sequential(\n",
    "                    Conv2d(3, 32, 3, padding=1),ReLU(), # 128: (128-3+2*1)//1 + 1\n",
    "                    Conv2d(32, 32, 3, padding=1, stride =1), ReLU(), # 128: (128-3+2*1)//1 + 1\n",
    "                    Conv2d(32, 32, 3, padding=1, stride=2), ReLU(), # 64: (128-3+2*1)//2 + 1\n",
    "                    Conv2d(32, 64, 3, padding=1), ReLU(),  # 64: (64-3+2*1)//1 + 1\n",
    "                    Conv2d(64, 64, 3, padding=1, stride=2), ReLU()) # 32: (64-3+2*1)//2 + 1\n",
    "                self.classifier = Sequential(\n",
    "                    Flatten(), # 64*32*32\n",
    "                    Linear(64*32*32, hidden_size), ReLU(),\n",
    "                    Linear(hidden_size, num_classes))\n",
    "    \n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = self.classifier(x)\n",
    "                return x\n",
    "            \n",
    "        class CustomNet(Module):\n",
    "            \"\"\"\n",
    "            input_size: 128\n",
    "            \"\"\"\n",
    "            def __init__(self, num_classes=10):\n",
    "                super(CustomNet, self).__init__()\n",
    "                self.layer1 = Sequential(\n",
    "                    Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "                    BatchNorm2d(16),\n",
    "                    ReLU(),\n",
    "                    MaxPool2d(kernel_size=2, stride=2))\n",
    "                self.layer2 = Sequential(\n",
    "                    Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "                    BatchNorm2d(32),\n",
    "                    ReLU(),\n",
    "                    MaxPool2d(kernel_size=2, stride=2))\n",
    "                self.fc = Linear(32*32*32, num_classes)\n",
    "                # 增加layer3\n",
    "                # self.layer3 = Sequential(\n",
    "                #     Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "                #     BatchNorm2d(64),\n",
    "                #     ReLU(),\n",
    "                #     MaxPool2d(kernel_size=2, stride=2))\n",
    "                # self.fc = Linear(64*16*16, num_classes)\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.layer1(x)\n",
    "                x = self.layer2(x)\n",
    "                # 增加layer3\n",
    "                # x = self.layer3(x)\n",
    "                x = x.reshape(x.size(0), -1)\n",
    "                x = self.fc(x)\n",
    "                return x\n",
    "                \n",
    "        # return SmallCNN(num_classes=10, hidden_size=50)\n",
    "        return CustomNet(num_classes=10)\n",
    "                    \n",
    "    \n",
    "trainer = EasyaiTrainer(\n",
    "    logger=True,              # 启动tensorboard日志. \n",
    "    tb_port=9005,             # Tensorboard启动端口.\n",
    "    max_epochs=20,            # 完整数据集迭代最大次数.\n",
    "    model_summary_mode='full' # 查看模型的内存使用情况.\n",
    ")\n",
    "\n",
    "trainer.fit(CustomClassifier())\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
