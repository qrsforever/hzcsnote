{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composite-charter",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> Loss Functions </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guided-communication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.610473Z",
     "start_time": "2021-05-20T09:26:35.148911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "sklearn 0.24.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.1\n",
      "PIL 6.2.2\n",
      "matplotlib 3.3.3\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.0.dev20210103+cu101\n",
      "torchvision 0.9.0.dev20210103+cu101\n",
      "torchaudio not installed\n",
      "pytorch_lightning 1.2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio,pytorch_lightning\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-omaha",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.644012Z",
     "start_time": "2021-05-20T09:26:37.612846Z"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Torch ###\n",
    "###\n",
    "\n",
    "_IMPORT_('import torch')\n",
    "_IMPORT_('import torch.nn as nn')\n",
    "_IMPORT_('import torch.nn.functional as F')\n",
    "_IMPORT_('import torch.optim as O')\n",
    "_IMPORT_('from torchvision import models as M')\n",
    "_IMPORT_('from torchvision import transforms as T')\n",
    "_IMPORT_('from torch.utils.data import Dataset, DataLoader')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-enough",
   "metadata": {},
   "source": [
    "## NLLLoss vs CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-garden",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.680026Z",
     "start_time": "2021-05-20T09:26:37.646842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0619, -0.1077, -0.6097, -1.1655],\n",
       "         [ 1.5475, -0.6481,  1.1606, -0.7103]]),\n",
       " tensor([0, 1]),\n",
       " torch.Size([2, 4]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(2, 4)\n",
    "y = torch.arange(0, 2)\n",
    "X, y, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-playing",
   "metadata": {},
   "source": [
    "### softmax range:(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "novel-defendant",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.718097Z",
     "start_time": "2021-05-20T09:26:37.682507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1647, 0.4278, 0.2589, 0.1485],\n",
       "         [0.5277, 0.0587, 0.3584, 0.0552]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_output = F.softmax(X, dim=1)  # nn.Softmax(dim=1)\n",
    "soft_output, soft_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-spotlight",
   "metadata": {},
   "source": [
    "### log_softmax range:(-inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "derived-usage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.752057Z",
     "start_time": "2021-05-20T09:26:37.720587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.8034, -0.8491, -1.3511, -1.9070],\n",
       "         [-0.6393, -2.8349, -1.0261, -2.8970]]),\n",
       " torch.Size([2, 4]),\n",
       " tensor([[-1.8034, -0.8491, -1.3511, -1.9070],\n",
       "         [-0.6393, -2.8349, -1.0261, -2.8970]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_output = F.log_softmax(X, dim=1)  # nn.LogSoftmax(dim=1)\n",
    "log_output, log_output.shape, torch.log(soft_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-testing",
   "metadata": {},
   "source": [
    "### nllloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composite-domestic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.784757Z",
     "start_time": "2021-05-20T09:26:37.754109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3191)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlloss_output = F.nll_loss(log_output, y)  # nn.NLLLoss()\n",
    "nlloss_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-termination",
   "metadata": {},
   "source": [
    "### cross_entropy = log_softmax +  nllloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spoken-washer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.816721Z",
     "start_time": "2021-05-20T09:26:37.786630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3191)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_output = F.cross_entropy(X, y)\n",
    "ce_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "french-nature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.850221Z",
     "start_time": "2021-05-20T09:26:37.819770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 32]), torch.Size([4, 64]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(4, 64, 32)\n",
    "y = torch.LongTensor(torch.randint(low=0, high=32, size=(4, 64)))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-injury",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:26:37.892012Z",
     "start_time": "2021-05-20T09:26:37.852476Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8459)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_output = F.cross_entropy(X.transpose(1, 2), y)\n",
    "ce_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "available-mailman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:54:51.979321Z",
     "start_time": "2021-05-20T09:54:51.943121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T = X.transpose(1, 2)\n",
    "\n",
    "torch.argmax(X_T, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accessible-survey",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:51:42.809235Z",
     "start_time": "2021-05-20T09:51:42.749899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-0.9854)\n",
      "1 tensor(0.2662)\n",
      "2 tensor(0.1201)\n",
      "3 tensor(1.1647)\n",
      "4 tensor(0.3448)\n",
      "5 tensor(-0.4662)\n",
      "6 tensor(0.3597)\n",
      "7 tensor(-0.2521)\n",
      "8 tensor(-0.2011)\n",
      "9 tensor(-0.3289)\n",
      "10 tensor(0.2396)\n",
      "11 tensor(0.2461)\n",
      "12 tensor(0.7395)\n",
      "13 tensor(-1.0237)\n",
      "14 tensor(0.4662)\n",
      "15 tensor(0.0393)\n",
      "16 tensor(0.4095)\n",
      "17 tensor(-0.0378)\n",
      "18 tensor(0.3668)\n",
      "19 tensor(-0.0016)\n",
      "20 tensor(-0.4012)\n",
      "21 tensor(-2.2986)\n",
      "22 tensor(0.9346)\n",
      "23 tensor(-0.0021)\n",
      "24 tensor(0.1083)\n",
      "25 tensor(0.1763)\n",
      "26 tensor(1.1837)\n",
      "27 tensor(-0.4458)\n",
      "28 tensor(-1.7021)\n",
      "29 tensor(-0.7174)\n",
      "30 tensor(0.9616)\n",
      "31 tensor(-0.5874)\n"
     ]
    }
   ],
   "source": [
    "y = -100\n",
    "for i in range(32):\n",
    "    x = X_T[0][i][1]\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thorough-principal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T09:50:55.323285Z",
     "start_time": "2021-05-20T09:50:55.287117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5204)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-emergency",
   "metadata": {},
   "source": [
    "```\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-3])\n",
    "        self.temporal_context = nn.Sequential(nn.Conv3d(in_channels=1024,\n",
    "                                out_channels=512,kernel_size=3,padding=[1,0,0]), nn.ReLU())\n",
    "   \n",
    "\n",
    "    def forward(self,x):\n",
    "        b, f, c, h, w = x.size()\n",
    "        features = self.cnn(x.view(b*f, c, h, w))\n",
    "        temp_features = self.temporal_context(features.unsqueeze(0).view(b,features.shape[1], f,features.shape[2],features.shape[3]))\n",
    "        out = nn.AvgPool2d(5)(temp_features.view(b*f,512, temp_features.shape[-1], temp_features.shape[-1])).view(b, f, -1)\n",
    "        return out\n",
    "\n",
    "class PeriodPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3), nn.ReLU())\n",
    "        self.projection = nn.Linear(1922,512)\n",
    "        self.transformer = nn.Transformer(nhead=4,dim_feedforward=128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(x.size(0), 64, -1)\n",
    "        out = self.projection(out)\n",
    "        out = self.transformer(out, out)\n",
    "        return out\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l_network = nn.Sequential(nn.Linear(512,512),nn.ReLU(),nn.Linear(512,32))\n",
    "        self.p_network = nn.Sequential(nn.Linear(512,512),nn.ReLU(),nn.Linear(512,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, f, e = x.size()\n",
    "        l = self.l_network(x.view(b*f,-1))\n",
    "        p = self.p_network(x.view(b*f,-1))\n",
    "        return l.view(b,-1), p.view(b,-1)\n",
    "\n",
    "class RepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.period_predictor = PeriodPredictor()\n",
    "        self.classifier = Classifier()\n",
    "        self.optimizer = torch.optim.SGD(params=self.parameters(),  lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        sim_mat = -torch.matrix_power(torch.cdist(features, features), 2).unsqueeze(1)\n",
    "        period = self.period_predictor(sim_mat)\n",
    "        l, p = self.classifier(period)\n",
    "        return l, p\n",
    "\n",
    "    def train_epoch(self, loader, epoch, device):\n",
    "        self.train()\n",
    "        print(\n",
    "            \"\\n\" + \" \" * 10 + \"****** Epoch {epoch} ******\\n\"\n",
    "            .format(epoch=epoch)\n",
    "        )\n",
    "\n",
    "        training_losses = []\n",
    "        mae = deque(maxlen=30)\n",
    "        self.optimizer.zero_grad()\n",
    "        with tqdm(total=len(loader), ncols=80) as pb:\n",
    "\n",
    "\n",
    "            for batch_idx, d in enumerate(loader):\n",
    "                frames, l, p = d\n",
    "                frames, l, p = frames.to(device), l.to(device), p.to(device)\n",
    "                frames.requires_grad = True\n",
    "                self.optimizer.zero_grad()\n",
    "                l_logits, p_logits = self.forward(frames)\n",
    "                loss = torch.nn.BCELoss()(torch.nn.Sigmoid()(p_logits.view(-1)),p.float().view(-1))\n",
    "                loss += torch.nn.CrossEntropyLoss()(l_logits.view(frames.shape[0]*64,32), l.view(-1))\n",
    "                training_losses.append(loss.data.cpu().numpy())\n",
    "                loss.backward()\n",
    "                clip_gradient(self.optimizer, 0.1)\n",
    "                self.optimizer.step()\n",
    "                counts_t = []\n",
    "                counts_p = []\n",
    "                p_preds = torch.where(torch.nn.Sigmoid()(p_logits) > 0.5, torch.tensor(1).cuda(), torch.tensor(0).cuda())\n",
    "                l_preds = l_logits.view(frames.shape[0],64,32).argmax(2)\n",
    "                for l_i, p_i, ll_i, pl_i in zip(l, p, l_preds, p_preds):\n",
    "                    reps = torch.where(l_i>0)[0]\n",
    "                    counts_t.append( torch.sum(torch.div(p_i[reps].float(),l_i[reps].float())).data.cpu().numpy())\n",
    "                    counts_p.append( torch.sum(torch.div(pl_i[reps].float(),ll_i[reps].float())).data.cpu().numpy())\n",
    "                try:\n",
    "                    mae_i = mean_absolute_error(np.array(counts_t), np.array(counts_p))\n",
    "                    mae.append(mae_i)\n",
    "                    pb.update()\n",
    "                    pb.set_description(\n",
    "                        f\"Loss: {loss.item()}, MAE: {np.mean(mae)}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "\n",
    "\n",
    "    def validate(self, loader):\n",
    "        self.eval()\n",
    "        with tqdm(total=len(loader), ncols=80) as pb:\n",
    "            for batch_idx, frames, l, p in enumerate(loader):\n",
    "                l_logits, p_logits = self.forward(frames)\n",
    "                loss = torch.nn.CrossEntropyLoss()(l_logits, l) + torch.nn.CrossEntropyLoss()(p_logits, p)\n",
    "                pb.update()\n",
    "                pb.set_description(\n",
    "                    \"Loss: {:.4f}\".format(\n",
    "                        loss.item()))```\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
