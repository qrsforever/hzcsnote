{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:57:30.322322Z",
     "start_time": "2020-07-22T07:57:28.075040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.23.1\n",
      "torch 1.6.0.dev20200609+cu101\n",
      "torchvision 0.7.0.dev20200609+cu101\n",
      "pytorch_lightning 0.8.5\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%watermark -v -p numpy,pandas,matplotlib,sklearn,torch,torchvision,pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:57:59.146806Z",
     "start_time": "2020-07-22T07:57:58.740974Z"
    }
   },
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_get_top_dir\n",
    "from k12libs.utils.nb_easy import K12AI_DATASETS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:19:54.838755Z",
     "start_time": "2020-07-22T16:19:54.780819Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Sequence\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:42:00.996687Z",
     "start_time": "2020-07-22T16:42:00.884341Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyaiClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(EasyaiClassifier, self).__init__()\n",
    "        self.model = self.build_model()\n",
    "        self.criterion = None\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        print('setup')\n",
    "    \n",
    "    def teardown(self, stage: str):\n",
    "        print('teardown')\n",
    "    \n",
    "    def load_presetting_dataset(self, dataset_name) -> None:\n",
    "        class JsonfileDataset(Dataset):\n",
    "            def __init__(self, root, phase, info):\n",
    "                self.root = root\n",
    "                self.info = info\n",
    "                image_list = []\n",
    "                label_list = []\n",
    "                with open(os.path.join(self.root, f'{phase}.json')) as f:\n",
    "                    items = json.load(f)\n",
    "                    for item in items:\n",
    "                        image_list.append(os.path.join(self.root, item['image_path']))\n",
    "                        label_list.append(item['label'])\n",
    "                self.image_list, self.label_list = image_list, label_list\n",
    "                \n",
    "                self.augtrans = None\n",
    "                self.imgtrans = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=info['mean'], std=info['std'])\n",
    "                ])\n",
    "            def data_augment(self, augtrans):\n",
    "                self.augtrans = transforms.Compose(augtrans)\n",
    "            def __getitem__(self, index):\n",
    "                img = Image.open(self.image_list[index]).convert('RGB')\n",
    "                if self.augtrans:\n",
    "                    img = self.augtrans(img)\n",
    "                img = self.imgtrans(img)\n",
    "                return img, self.label_list[index]\n",
    "            def __len__(self):\n",
    "                return len(self.image_list)\n",
    "\n",
    "        root = os.path.join('/data/datasets/cv/', dataset_name)\n",
    "        with open(os.path.join(root, 'info.json')) as f:\n",
    "            info = json.load(f)\n",
    "        return {phase:JsonfileDataset(root, phase, info) for phase in ('train', 'val', 'test')}\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        self.datasets = self.load_presetting_dataset('rmnist')\n",
    "    \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['train']\n",
    "        dataset.data_augment([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.RandomHorizontalFlip()                     \n",
    "        ])\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "        \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['val']\n",
    "        dataset.data_augment([\n",
    "            transforms.Resize((32, 32)),\n",
    "        ])\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['test']\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "    \n",
    "    def load_pretrained_model(self, model_name, num_classes=None, pretrained=True):\n",
    "        model = getattr(models, model_name)(pretrained).cuda()\n",
    "        if num_classes:\n",
    "            if model_name.startswith('vgg'):\n",
    "                model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "            elif model_name.startswith('resnet'):\n",
    "                model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "            elif model_name.startswith('alexnet'):\n",
    "                model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "            elif model_name.startswith('mobilenet_v2'):\n",
    "                model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "            elif model_name.startswith('squeezenet'):\n",
    "                model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "            elif model_name.startswith('shufflenet'):\n",
    "                model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "            elif model_name.startswith('densenet'):\n",
    "                in_features = {\n",
    "                    \"densenet121\": 1024,\n",
    "                    \"densenet161\": 2208,\n",
    "                    \"densenet169\": 1664,\n",
    "                    \"densenet201\": 1920,\n",
    "                }\n",
    "                model.classifier = nn.Linear(in_features[model_name], num_classes)\n",
    "            else:\n",
    "                raise NotImplemented(f'{backbon}')\n",
    "        return model\n",
    "    \n",
    "    def build_model(self):\n",
    "        return self.load_pretrained_model('resnet18', 10)\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        if self.criterion is None:\n",
    "            self.criterion = self.configure_criterion()\n",
    "        return self.criterion\n",
    "    \n",
    "    def configure_criterion(self):\n",
    "        # default\n",
    "        loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizer(self):\n",
    "        # default\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def configure_scheduler(self, optimizer):\n",
    "        # default\n",
    "        scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "        return scheduler\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.configure_optimizer()\n",
    "        scheduler = self.configure_scheduler(optimizer)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "    \n",
    "    ## Train\n",
    "    def training_step(self, batch, batch_idx) -> Union[\n",
    "        int, Dict[str, Union[Tensor, Dict[str, Tensor]]]\n",
    "    ]:\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        criterion = self.loss(outputs, labels)\n",
    "        tensorboardLogs = {'train_loss': criterion}\n",
    "        return {'loss': criterion, 'log': tensorboardLogs}\n",
    "    \n",
    "    def training_step_end(self, *args, **kwargs) -> Dict[\n",
    "        str, Union[Tensor, Dict[str, Tensor]]\n",
    "    ]:\n",
    "        pass\n",
    "    \n",
    "    # def training_epoch_end(\n",
    "    #     self,\n",
    "    #     outputs: Union[List[Dict[str, Tensor]], List[List[Dict[str, Tensor]]]]\n",
    "    # ) -> Dict[str, Dict[str, Tensor]]:\n",
    "    #     pass\n",
    "    \n",
    "    ## Valid\n",
    "    def validation_step(self, batch, batch_idx) -> Dict[str, Tensor]:\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        criterion = self.loss(outputs, labels)\n",
    "        _, outputs = torch.max(outputs, dim=1)\n",
    "        valAcc = torch.tensor(0.9)\n",
    "        return {'val_loss': criterion, 'val_acc':valAcc}\n",
    "    \n",
    "    # def validation_step_end(self, *args, **kwargs) -> Dict[str, Tensor]:\n",
    "    #     pass\n",
    "    \n",
    "    # def validation_epoch_end(\n",
    "    #     self,\n",
    "    #     outputs: Union[List[Dict[str, Tensor]], List[List[Dict[str, Tensor]]]]\n",
    "    # ) -> Dict[str, Dict[str, Tensor]]:\n",
    "    #     pass\n",
    "    \n",
    "    ## Test\n",
    "    def test_step(self, *args, **kwargs) -> Dict[str, Tensor]:\n",
    "        pass\n",
    "    \n",
    "    def test_step_end(self, *args, **kwargs) -> Dict[str, Tensor]:\n",
    "        pass\n",
    "\n",
    "    def test_epoch_end(\n",
    "        self,\n",
    "        outputs: Union[List[Dict[str, Tensor]], List[List[Dict[str, Tensor]]]]\n",
    "    ) -> Dict[str, Dict[str, Tensor]]: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:42:02.896916Z",
     "start_time": "2020-07-22T16:42:01.403458Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11 M  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd92d425b564efda76eb91ce75be090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-a3cb4cc8c978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyaiClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no-cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinit_scheduler_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     def test(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# TRAINING_STEP + TRAINING_STEP_END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# only track outputs when user implements training_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    630\u001b[0m                     \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m                 )\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# format and reduce outputs accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mtraining_step_output_for_epoch_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# TODO: temporary part of structured results PR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/logging.py\u001b[0m in \u001b[0;36mprocess_output\u001b[0;34m(self, output, train)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# all keys not progress_bar or log are candidates for callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcallback_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'progress_bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hiddens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=100, gpus=1, logger=None)\n",
    "trainer.fit(EasyaiClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
