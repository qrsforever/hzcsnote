{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:04:16.987417Z",
     "start_time": "2020-07-28T12:04:14.854660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.23.1\n",
      "torch 1.6.0.dev20200609+cu101\n",
      "torchvision 0.7.0.dev20200609+cu101\n",
      "pytorch_lightning 0.8.5\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%watermark -v -p numpy,pandas,matplotlib,sklearn,torch,torchvision,pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:04:17.392585Z",
     "start_time": "2020-07-28T12:04:16.990057Z"
    }
   },
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_get_top_dir\n",
    "from k12libs.utils.nb_easy import K12AI_DATASETS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:04:17.444410Z",
     "start_time": "2020-07-28T12:04:17.396193Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Sequence\n",
    "import warnings\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from torchvision import transforms, models\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T15:04:41.959982Z",
     "start_time": "2020-07-28T15:04:41.859425Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyaiClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(EasyaiClassifier, self).__init__()\n",
    "        self.model = self.build_model()\n",
    "        self.criterion = None\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        pass\n",
    "    \n",
    "    def teardown(self, stage: str):\n",
    "        pass\n",
    "    \n",
    "    def load_presetting_dataset_(self, dataset_name) -> None:\n",
    "        class JsonfileDataset(Dataset):\n",
    "            def __init__(self, root, phase, info):\n",
    "                self.root = root\n",
    "                self.info = info\n",
    "                image_list = []\n",
    "                label_list = []\n",
    "                with open(os.path.join(self.root, f'{phase}.json')) as f:\n",
    "                    items = json.load(f)\n",
    "                    for item in items:\n",
    "                        image_list.append(os.path.join(self.root, item['image_path']))\n",
    "                        label_list.append(item['label'])\n",
    "                self.image_list, self.label_list = image_list, label_list\n",
    "                \n",
    "                self.augtrans = None\n",
    "                self.imgtrans = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=info['mean'], std=info['std'])\n",
    "                ])\n",
    "            def data_augment(self, augtrans):\n",
    "                self.augtrans = transforms.Compose(augtrans)\n",
    "            def __getitem__(self, index):\n",
    "                img = Image.open(self.image_list[index]).convert('RGB')\n",
    "                if self.augtrans:\n",
    "                    img = self.augtrans(img)\n",
    "                img = self.imgtrans(img)\n",
    "                return img, self.label_list[index]\n",
    "            def __len__(self):\n",
    "                return len(self.image_list)\n",
    "\n",
    "        root = os.path.join('/data/datasets/cv/', dataset_name)\n",
    "        with open(os.path.join(root, 'info.json')) as f:\n",
    "            info = json.load(f)\n",
    "        return {phase:JsonfileDataset(root, phase, info) for phase in ('train', 'val', 'test')}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.datasets = self.load_presetting_dataset_('rmnist')\n",
    "        # delattr(self.__class__, 'val_dataloader')\n",
    "        # delattr(self.__class__, 'validation_step')\n",
    "        # delattr(self.__class__, 'validation_epoch_end')\n",
    "    \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['train']\n",
    "        dataset.data_augment([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.RandomHorizontalFlip()                     \n",
    "        ])\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "        \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['val']\n",
    "        dataset.data_augment([\n",
    "            transforms.Resize((32, 32)),\n",
    "        ])\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        dataset = self.datasets['test']\n",
    "        return DataLoader(dataset, batch_size=64, num_workers=2)\n",
    "    \n",
    "    def load_pretrained_model_(self, model_name, num_classes=None, pretrained=True):\n",
    "        model = getattr(models, model_name)(pretrained)\n",
    "        if num_classes:\n",
    "            if model_name.startswith('vgg'):\n",
    "                model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "            elif model_name.startswith('resnet'):\n",
    "                model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "            elif model_name.startswith('alexnet'):\n",
    "                model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "            elif model_name.startswith('mobilenet_v2'):\n",
    "                model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "            elif model_name.startswith('squeezenet'):\n",
    "                model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "            elif model_name.startswith('shufflenet'):\n",
    "                model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "            elif model_name.startswith('densenet'):\n",
    "                in_features = {\n",
    "                    \"densenet121\": 1024,\n",
    "                    \"densenet161\": 2208,\n",
    "                    \"densenet169\": 1664,\n",
    "                    \"densenet201\": 1920,\n",
    "                }\n",
    "                model.classifier = nn.Linear(in_features[model_name], num_classes)\n",
    "            else:\n",
    "                raise NotImplemented(f'{backbon}')\n",
    "        return model\n",
    "    \n",
    "    def build_model(self):\n",
    "        return self.load_pretrained_model_('resnet18', 10)\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        if self.criterion is None:\n",
    "            self.criterion = self.configure_criterion()\n",
    "        return self.criterion\n",
    "    \n",
    "    def configure_criterion(self):\n",
    "        # default\n",
    "        loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizer(self):\n",
    "        # default\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def configure_scheduler(self, optimizer):\n",
    "        # default\n",
    "        scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "        return scheduler\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.configure_optimizer()\n",
    "        scheduler = self.configure_scheduler(optimizer)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    # def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
    "    #     pass\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def calculate_acc_(self, y_pred, y_true):\n",
    "        return (torch.argmax(y_pred, axis=1) == y_true).float().mean()\n",
    "    \n",
    "    def step_(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return x, y, y_hat, loss\n",
    "    \n",
    "    ## Train\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, y_hat, loss = self.step_(batch)\n",
    "        with torch.no_grad():\n",
    "            accuracy = self.calculate_acc_(y_hat, y)\n",
    "        log = {'train_loss': loss, 'train_acc': accuracy}\n",
    "        output = OrderedDict({\n",
    "            'loss': loss,  # M\n",
    "            'acc': accuracy,     # O\n",
    "            'progress_bar': log, # O\n",
    "            \"log\": log           # O\n",
    "        })\n",
    "        return output\n",
    "    \n",
    "    # def training_step_end(self, *args, **kwargs):\n",
    "    #     pass\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        log = {'train_loss': avg_loss, 'train_acc': avg_acc, 'step': self.current_epoch}\n",
    "        return {'progress_bar': log, 'log': log}\n",
    "    \n",
    "    ## Valid\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, y_hat, loss = self.step_(batch)\n",
    "        accuracy = self.calculate_acc_(y_hat, y)\n",
    "        return {'val_loss': loss, 'val_acc': accuracy}\n",
    "    \n",
    "    # def validation_step_end(self, outputs):\n",
    "    #     pass\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        log = {'val_loss': avg_loss, 'val_acc': avg_acc, 'step': self.current_epoch}\n",
    "        return {'progress_bar': log, 'log': log}\n",
    "    \n",
    "    ## Test\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return {}\n",
    "        # x, y, y_hat, loss = self.step_(batch)\n",
    "        # accuracy = self.calculate_acc_(y_hat, y)\n",
    "        # return {'test_loss': loss, 'test_acc': accuracy}\n",
    "    \n",
    "    # def test_step_end(self, *args, **kwargs):\n",
    "    #     pass\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        return {}\n",
    "        # avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        # avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        # log = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        # return {'progress_bar': log, 'log': log}\n",
    "    \n",
    "\n",
    "class EasyaiTrainer(pl.Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(EasyaiTrainer, self).__init__(*args, **kwargs, gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T15:04:55.982262Z",
     "start_time": "2020-07-28T15:04:43.550101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54b400db5024af2b943f9ef7d25c22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = EasyaiTrainer(max_epochs=2, logger=None)\n",
    "trainer.fit(EasyaiClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:07:04.053210Z",
     "start_time": "2020-07-28T12:07:02.691769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699748aaffd04631add63e96838a4572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
