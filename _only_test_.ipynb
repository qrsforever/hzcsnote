{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyhocon import ConfigFactory\n",
    "from pyhocon import ConfigTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = dict()\n",
    "\n",
    "\n",
    "config = dict(\n",
    "    agent=dict(),\n",
    "    algo=dict(\n",
    "        discount=0.99,\n",
    "        batch_size=128,\n",
    "        learning_rate=1e-4,  # Trying lower for adam.\n",
    "        clip_grad_norm=10.,\n",
    "        min_steps_learn=int(5e4),\n",
    "        double_dqn=False,\n",
    "        prioritized_replay=False,\n",
    "        n_step_return=1,\n",
    "        replay_size=int(1e6),\n",
    "    ),\n",
    "    env=dict(\n",
    "        game=\"pong\",\n",
    "        episodic_lives=True,\n",
    "    ),\n",
    "    eval_env=dict(\n",
    "        game=\"pong\",  # NOTE: update in train script!\n",
    "        episodic_lives=False,\n",
    "        horizon=int(27e3),\n",
    "    ),\n",
    "    model=dict(dueling=False),\n",
    "    optim=dict(),\n",
    "    runner=dict(\n",
    "        n_steps=50e6,\n",
    "        log_interval_steps=1e6,\n",
    "    ),\n",
    "    sampler=dict(\n",
    "        batch_T=2,\n",
    "        batch_B=16,\n",
    "        max_decorrelation_steps=1000,\n",
    "        eval_n_envs=4,\n",
    "        eval_max_steps=int(125e3),\n",
    "        eval_max_trajectories=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "configs[\"dqn\"] = config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"agent\": {},\n",
      "    \"algo\": {\n",
      "        \"discount\": 0.99,\n",
      "        \"batch_size\": 128,\n",
      "        \"learning_rate\": 0.0001,\n",
      "        \"clip_grad_norm\": 10.0,\n",
      "        \"min_steps_learn\": 50000,\n",
      "        \"double_dqn\": false,\n",
      "        \"prioritized_replay\": false,\n",
      "        \"n_step_return\": 1,\n",
      "        \"replay_size\": 1000000\n",
      "    },\n",
      "    \"env\": {\n",
      "        \"game\": \"pong\",\n",
      "        \"episodic_lives\": true\n",
      "    },\n",
      "    \"eval_env\": {\n",
      "        \"game\": \"pong\",\n",
      "        \"episodic_lives\": false,\n",
      "        \"horizon\": 27000\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"dueling\": false\n",
      "    },\n",
      "    \"optim\": {},\n",
      "    \"runner\": {\n",
      "        \"n_steps\": 50000000.0,\n",
      "        \"log_interval_steps\": 1000000.0\n",
      "    },\n",
      "    \"sampler\": {\n",
      "        \"batch_T\": 2,\n",
      "        \"batch_B\": 16,\n",
      "        \"max_decorrelation_steps\": 1000,\n",
      "        \"eval_n_envs\": 4,\n",
      "        \"eval_max_steps\": 125000,\n",
      "        \"eval_max_trajectories\": 100\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(configs['dqn'], indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
