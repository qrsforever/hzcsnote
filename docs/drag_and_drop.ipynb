{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:21:30.211953Z",
     "start_time": "2020-08-19T12:21:30.189830Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input层\n",
    "\n",
    "\n",
    "- 参数\n",
    "    \n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:----\n",
    "<img width=150/> | <img width=100/> | <img width=200/> | <img width=450/>\n",
    "in_features | [int, int, int] | [3, width, height] | 参数必须包含三个值; 非法时提示\"in_features参数错误\" <br>[0]: 通道数,一般固定位3; 非法时提示\"in_features参数错误\" <br> [1]: 用户设置的图片input_size的width; 非法时提示\"in_features参数错误\"<br> [2]: 用户设置的图片input_size的height; 非法时提示\"in_features参数错误\"\n",
    "\n",
    "**Input层in_features可以设置成只读, 其值为(3, input_size.width, input_size.height), 从而减少用户输入错误** \n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "shape = {channel: this.in_features[0], width: this.in_features[1], height: this.in_features[2]}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "![Input Node](/notebooks/assets/layers/input_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output层\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:----\n",
    "<img width=150/> | <img width=100/> | <img width=200/> | <img width=450/>\n",
    "out_features | int | > 0 | 值等于上一个层的out_features, 并且如果是分类任务其值应该等于分类的数目, 实际上这个层没有意义, 只用来作为显示\n",
    "\n",
    "- 实例\n",
    "\n",
    "![Output Node](/notebooks/assets/layers/output_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution层 (2D)\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "in_channels | int | > 0 | 非法时提示\"参数in_channels应为大于0的整数, 且值为上一层的shape输出中的out_channel\" <br> 为了防止用户输入错误,可以改为只读形式,值为前一层的shape中channel\n",
    "out_channels |  int | > 0 | 非法时提示\"参数out_channels应为大于0的整数\"\n",
    "kernel_size | int | > 0 | 非法时提示\"参数kernel_size应为大于0的整数 (推荐3,5,7等最大公约数为1的数)\"\n",
    "stride | int | > 0 | 非法时提示\"参数stride应为大于0的整数\"\n",
    "padding | int | >=0 | 非法时提示\"参数padding应为大于等于0的整数\"\n",
    "dilation | int | > 0 | 非法时提示\"参数dilation应为大于0的整数\"\n",
    "groups | int | > 0 | 非法时提示\"参数groups为大于0的整数\"\n",
    "bias | bool | |\n",
    "\n",
    "\n",
    "**padding非0值不应大于kernel_size的一半, 如果dilation非0, padding不应大于`kernel_size + (kernel_size - 1)*(dilation - 1)`的一半**\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "    let w = prelayer.shape.w; // 前一层shape输出的宽(width)\n",
    "    let h = prelayer.shape.h; // 前一层shape输出的高(height)\n",
    "    let k = eval(`${this.kernel_size} + (${this.kernel_size} - 1) * (${this.dilation} - 1)`);  // 考虑到dilation大于1的情况\n",
    "\n",
    "    wout = Math.floor(eval(`(${w} + 2 * ${this.padding} - ${k})/${this.stride}`)) + 1;\n",
    "    hout = Math.floor(eval(`(${h} + 2 * ${this.padding} - ${k})/${this.stride}`)) + 1;\n",
    "    \n",
    "    shape = {channel: this.out_channels, width: wout, height: hout}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "当dilation == 1时: `k = kernel_size`\n",
    "\n",
    "![Convoluation Node](/notebooks/assets/layers/convolution_layer.png)\n",
    "\n",
    "当dilation > 1时, `k = kernel_size + (kernel_size -1)*(dilation -1)`\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "shape.w &= (preinput.w + 2*padding - k) / stride + 1 \\\\\n",
    "shape.h &= (preinput.h + 2*padding - k) / stride + 1\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding层(只考虑中心对称)\n",
    "\n",
    "`零填充, 常数填充, 镜像填充, 重复填充`几种子类型方式可按一种方式处理, 只考虑对称方式的填充(top = bottom = left = right)\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "padding | int | >= 0 | 意义为(padding_left, padding_right, padding_top, padding_bottim)\n",
    "value | float | >= 0 | 常数填充时, 需要填充的值\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "    let w = prelayer.shape.w + 2*padding\n",
    "    let h = prelayer.shape.h + 2*padding\n",
    "    let c = prelayer.shape.c\n",
    "    \n",
    "    shape = {channel: c, width: w, height: h}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "![Padding Node](/notebooks/assets/layers/padding_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling层\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "kernel_size | int | > 0 | 非法时提示\"参数kernel_size应为大于0的整数 (推荐3,5,7等最大公约数为1的数)\"\n",
    "stride | int | > 0 | 非法时提示\"参数stride应为大于0的整数\"\n",
    "padding | int | >=0 | 非法时提示\"参数padding应为大于等于0的整数\"\n",
    "dilation | int | > 0 | 非法时提示\"参数dilation应为大于0的整数\"\n",
    "output_size | int | > 0 | (only AdaptiveXXXPool)自动适配池化的输出大小, 非法时提示\"参数output_size应为大于0的整数\"\n",
    "ceil_mode | bool | True/False | True: 向上取整; False: 向下取整\n",
    "~~return_indices~~ | bool | True/False | (only MaxPool)记录池化像素索引, 用来反池化, **可以先忽略/隐藏该参数**\n",
    "~~count_include_pad~~ | bool | True/False | (only AvgPool)填充值是否参与计算, **可以先忽略/隐藏该参数**\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "\n",
    "    let w = prelayer.shape.w;   // 前一层shape的宽度\n",
    "    let h = prelayer.shape.h;   // 前一层shape的高度\n",
    "    let c = prelayer.shape.c;   // 前一层shape的通道\n",
    " \n",
    "    // subtype: AdaptiveXXXPool2D \n",
    "    let W = output_size;\n",
    "    let H = output_size;\n",
    "\n",
    "    // subtype: 其他\n",
    "    if (ceil_mode == \"True\") {\n",
    "        func = Math.ceil;     // 上取整方法\n",
    "    } else { \n",
    "        func = Match.floor;   // 下取整方法\n",
    "    }\n",
    "    let K = eval(`${kernel_size} + (${kernel_size} - 1) * (${dilation} - 1)`);  // 考虑到dilation大于1的情况\n",
    "    let W = func(eval(`(${w} + 2 * ${padding} - ${K})/${stride}`)) + 1\n",
    "    let H = func(eval(`(${h} + 2 * ${padding} - ${K})/${stride}`)) + 1\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "XXXPool2D: `shape = {channel:prelayer.shape.c, w: func(w + 2*padding - k)/2) + 1, h: func(h + 2*padding - k)/2) + 1}`\n",
    "\n",
    "![Pooling Node](/notebooks/assets/layers/pooling_layer.png)\n",
    "\n",
    "AdaptiveXXXPool2D: `shape = {channel:prelayer.shape.c, w: output_size, h: output_size}`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation层\n",
    "\n",
    "- 形状\n",
    "\n",
    "该层不会对shape做变化\n",
    "\n",
    "```js    \n",
    "    let w = prelayer.shape.w;\n",
    "    let h = prelayer.shape.h;\n",
    "    let c = prelayer.shape.c;\n",
    "    \n",
    "    shape = {channel: c, width: w, height: h}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "\n",
    "![Activation Node](/notebooks/assets/layers/activation_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize层\n",
    "\n",
    "$$\n",
    "y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
    "$$\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "num_features | int | > 0 | 与上一层的shape.c相等, 若非法提示\"num_features特征数目不对\"; **推荐设置成只读**\n",
    "~~eps~~ | float | (0, 1) | 防止分母为0, 所以该属性**推荐隐藏** \n",
    "momentum | float | (0, 1) | 动态均值和动态方差所使用的动量因子(新batch和全局的取舍$\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t$)\n",
    "affine | bool | True/False | True: 对结果缩放($\\gamma$)和平移($\\beta$), 均可在反向传播中学习\n",
    "track_running_stats | bool | Ture/False | True: 启动全局batch统计特性\n",
    "\n",
    "**所有不在值域范围内的参数值均可提示参数非法**\n",
    "\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "    let w = prelayer.shape.w + 2*padding\n",
    "    let h = prelayer.shape.h + 2*padding\n",
    "    let c = prelayer.shape.c\n",
    "    \n",
    "    shape = {channel: c, width: w, height: h}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "![Normal Node](/notebooks/assets/layers/normalize_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T13:40:00.567533Z",
     "start_time": "2020-08-18T13:40:00.517121Z"
    }
   },
   "source": [
    "### Flatten层\n",
    "\n",
    "将多维数据\"压平\"为1维\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "~~start_dim~~ | int | >= 0 | **删除属性**\n",
    "~~end_dim~~ | int | >= -1 | **删除属性**\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "    let w = prelayer.shape.w;\n",
    "    let h = prelayer.shape.h;\n",
    "    let c = prelayer.shape.c;\n",
    "    \n",
    "    shape = {channel: null, width: null, height: w*h*c}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "\n",
    "![Flatten Node](/notebooks/assets/layers/flatten_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T14:14:56.733685Z",
     "start_time": "2020-08-18T14:14:56.682952Z"
    }
   },
   "source": [
    "### ~~Reshape层~~\n",
    "\n",
    "**使用flatten层取代**\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "target_shape | list(int) | len(list) <= 3 | list里所有元素的乘积应该等于上一层shape的w*h*c <br> 非法提示\"target_shape参数非法\" \n",
    "    \n",
    "\n",
    "- 形状\n",
    "    \n",
    "```js\n",
    "    let c = prelayer.shape.c;\n",
    "    let w = prelayer.shape.w;\n",
    "    let h = prelayer.shape.h;\n",
    "\n",
    "    let C = null;\n",
    "    let W = null;\n",
    "    let H = null;\n",
    "    switch(len(target_shape)) {\n",
    "        case 3:\n",
    "            C = target_shape[0];\n",
    "            W = target_shape[1];\n",
    "            H = target_shape[2];\n",
    "            break;\n",
    "        case 2:\n",
    "            W = target_shape[0];\n",
    "            H = target_shape[1];\n",
    "            break;\n",
    "        case 1:\n",
    "            H = target_shape[0];\n",
    "            break;\n",
    "        case *:\n",
    "            // error\n",
    "    }\n",
    "\n",
    "    shape = {channel: C, width: W, height: H}\n",
    "\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "\n",
    "![Reshape Node](/notebooks/assets/layers/reshape_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear层\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "in_features | int | > 0 | 值必须为上个层的shape.h, 非法提示\"in_features参数非法\"; **可以设置成只读**\n",
    "out_features | int | > 0 |\n",
    "bias | bool | True/False |\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "    shape = {channel: null, width:null, height:out_features}\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "\n",
    "![Linear Node](/notebooks/assets/layers/linear_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout层\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "p | float | (0, 1) | 伯努利(0-1)以p几率让神经元失效\n",
    "inplace | bool | True/False | True: 对输入tensor本地修改, 节省内容 **推荐为默认**\n",
    "\n",
    "- 形状\n",
    "\n",
    "输入: 任意\n",
    "\n",
    "输出: 输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add层\n",
    "\n",
    "- 形状\n",
    "\n",
    "输入: 任意(两个input层维度一致,大小一致)\n",
    "\n",
    "输出: 输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat层\n",
    "\n",
    "- 参数\n",
    "\n",
    "属性 | 类型 | 值域 | 描述\n",
    ":---:|:---:|:---:|:------\n",
    "<img width=150/> | <img width=100/> | <img width=100/> | <img width=450/>\n",
    "dim | int | > 0 | -1: 表示最后一维度, 输入的层要大于2个, 除了要合并的dim外, 其他维度必须一致, 否则提示\"dim参数错误\"\n",
    "\n",
    "- 形状\n",
    "\n",
    "```js\n",
    "   //            0  1   2   3\n",
    "   // dim= 1:  (32, 3, 64, 64), (32, 3, 64, 64) --> (32, 3+3, 64, 64)\n",
    "   // dim=-1:  (32, 3, 64, 64), (32, 3, 64, 64) --> (32, 3, 64, 64 + 64)\n",
    "\n",
    "```\n",
    "\n",
    "- 实例\n",
    "\n",
    "\n",
    "![Cat Node](/notebooks/assets/layers/cat_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~Loss层~~\n",
    "\n",
    "**删除或者隐藏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:21:31.181658Z",
     "start_time": "2020-08-19T12:21:30.545169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]]]),\n",
       " torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.ones(2, 3, 2)\n",
    "A, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:21:31.207450Z",
     "start_time": "2020-08-19T12:21:31.184784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2., 2.],\n",
       "          [2., 2.],\n",
       "          [2., 2.]],\n",
       " \n",
       "         [[2., 2.],\n",
       "          [2., 2.],\n",
       "          [2., 2.]]]),\n",
       " torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 2*torch.ones(2, 3, 2)\n",
    "B, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:21:31.233343Z",
     "start_time": "2020-08-19T12:21:31.210700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 2., 2.],\n",
       "          [1., 1., 2., 2.],\n",
       "          [1., 1., 2., 2.]],\n",
       " \n",
       "         [[1., 1., 2., 2.],\n",
       "          [1., 1., 2., 2.],\n",
       "          [1., 1., 2., 2.]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.cat((A,B), 2)\n",
    "C, C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 拖拽模型 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T12:21:32.368379Z",
     "start_time": "2020-08-19T12:21:31.235934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"k12libs.utils.nb_easy\" (lazy loading)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"780\"\n",
       "            src=\"http://116.85.5.40:9091/drawnet.html?jfile=simple&flask=http://116.85.5.40:8117/k12ai/notebook/message\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff1cef3ecf8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_start_html, W3URL\n",
    "k12ai_start_html(f'{W3URL}/drawnet.html?jfile=simple', height=780, flask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ActivityRegularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxoutDense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpatialDropout1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpatialDropout2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpatialDropout3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeDistributedDense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AtrousConvolution1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AtrousConvolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SeparableConvolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UpSampling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UpSampling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UpSampling3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeroPadding1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeroPadding2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeroPadding3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### AvgPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### AvgPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### AvgPooling3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### MaxPooling3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalAvgPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalAvgPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalAvgPooling3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T12:59:09.462292Z",
     "start_time": "2020-06-01T12:59:09.456412Z"
    }
   },
   "source": [
    "### GlobalMaxPooling3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocallyConnected1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocallyConnected2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvLSTM2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvRecurrent2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Activations Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParametricSoftplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThreasholdedReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WideResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### [deepcognition](https://app.deepcognition.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "829.612px",
    "left": "1214.15px",
    "top": "110.8px",
    "width": "321.85px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
