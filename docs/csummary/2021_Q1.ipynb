{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T09:58:04.397287Z",
     "start_time": "2021-01-15T09:58:04.388610Z"
    }
   },
   "source": [
    "## 1.11 - 1.15\n",
    "\n",
    "- 风格迁移图片形式集成到竞赛版本\n",
    "\n",
    "- 换脸fsgan对图片支持的研究, 修改测试, 尚未集成竞赛框架中\n",
    "\n",
    "- 参考教材,技术要求纲目\n",
    ">\n",
    ">   https://towardsdatascience.com/explaining-ai-to-children-c9b2ecab1ffc\n",
    ">   https://thestempedia.com/blog/teaching-ai-kids/\n",
    ">   https://experiments.withgoogle.com/thing-translator\n",
    ">   https://thestempedia.com/shop/online-courses/artificial-intelligence-for-kids/\n",
    ">   http://csrankings.org/#/fromyear/2018/toyear/2019/index?ai&vision&mlmining&nlp&ir&world\n",
    ">   https://www.programmersought.com/article/46374152058\n",
    ">   https://www.codingforkid.com/\n",
    ">   https://www.classcentral.com/subject/ai\n",
    ">   https://www.scribd.com/document/383775963/AI-Syllabus-Course\n",
    "\n",
    "- GAN通用框架调研"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 阶段1\n",
    "\n",
    "### 神经网络基本概念\n",
    "\n",
    "1. 发展史\n",
    "2. 基本结构 (神经元,网络层,激活函数等)\n",
    "3. 理论基础 (数据表示,张量运算,梯度优化等)\n",
    "\n",
    "### 神经网络的工具与方法\n",
    "\n",
    "1. 计算框架选型 (pytorch,tensorflow,keras等)\n",
    "2. 辅助计算工具 (numpy,matplotlib,pandas等)\n",
    "3. 计算方法/算法 (数据处理,模型,损失函数,优化算法等)\n",
    "4. 可视化方法 (tensorboard, 热力图, 卷积特征等)\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "1. <font color='Blue'><strong>数据标注 (分类,探测,分割等数据类型)</strong></font>\n",
    "2. 数据的划分 (训练集,验证集,测试集)\n",
    "3. 数据的处理 (标准化normalize,批量化batchsize,向量化等)\n",
    "\n",
    "### 技术调优\n",
    "\n",
    "1. 数据增强\n",
    "2. 预制权重\n",
    "3. 模型微调 (冻结部分网络层等方式)\n",
    "4. 解决过拟合 (权重正则化, 降低模型复杂度, Dropout等) \n",
    "5. 其他 (earlystop)\n",
    "\n",
    "## 阶段2\n",
    "\n",
    "### 模型构建\n",
    "\n",
    "### 模型训练\n",
    "\n",
    "1. 训练超参数\n",
    "2. 训练Metrics\n",
    "\n",
    "### 模型保存\n",
    "\n",
    "### 模型评估\n",
    "\n",
    "### 模型预测\n",
    "\n",
    "\n",
    "\n",
    "## 阶段3\n",
    "\n",
    "### 传统机器学习(ML)\n",
    "\n",
    "1. 监督学习 \n",
    "> 回归: LinearRegression,LogisticRegression,SVR等\n",
    ">\n",
    "> 分类: Naive Bayes, KNN, DecisionTree,SVM等\n",
    "\n",
    "2. 无监督学习\n",
    "> <font color='Blue'><strong>降维: PCA, LSA, SVD, LDA, t-SNE</strong></font>\n",
    ">\n",
    "> 聚类: K-Means, Fuzzy C-Means, DBSCAN, Mean Shift等\n",
    ">\n",
    "> <font color='Blue'><strong>关联规则: Apriori、FP-Growth、PrefixSpan、SPADE、AprioriAll、Apriori-Some等</strong></font>\n",
    "\n",
    "3. 集成学习\n",
    "\n",
    "> Stacking\n",
    ">\n",
    "> Bagging: Random Forest\n",
    ">\n",
    "> Boosting: AdaBoost, XGBoost, LightGBM\n",
    "\n",
    "4. 强化学习\n",
    "\n",
    "\n",
    "### 多层感知机(Perception)\n",
    "\n",
    "TODO\n",
    "\n",
    "\n",
    "### 计算机视觉(CV)\n",
    "\n",
    "1. 全连接层\n",
    "2. 卷积层 (原理,计算方法,滤波器,显著图等)\n",
    "3. 池化层 (作用,最大池化,平均池化,全局池化等)\n",
    "4. 分类任务 (AlexNet, VGGNet, GoogleNet, Inception,ResNet, MobileNet等)\n",
    "5. 探测任务 (R-CNN, YOLO, SSD等)\n",
    "6. <font color='green'><strong>分割任务</strong></font>\n",
    "\n",
    "\n",
    "### 自然语言处理(NLP)\n",
    "\n",
    "1. <font color='green'><strong>词法分析,句法分析,语义理解</strong></font>\n",
    "2. <font color='green'><strong>文本数据清洗,提取,分词与统计</strong></font>\n",
    "3. <font color='green'><strong>语言模型与计算</strong></font>\n",
    "4. <font color='green'><strong>其他模型(LDA主题模型(文档分类), 翻译模型(翻译应用), 隐马尔科夫模型(基因序列分析)等)</strong></font>\n",
    "5. <font color='green'><strong>循环神经网络 (RNN, LSTM, GRU等)</strong></font>\n",
    "6. <font color='green'><strong>条件随机场 (最大熵与词性标注)</strong></font>\n",
    "\n",
    "### 强化学习(RL)\n",
    "\n",
    "1. <font color='green'><strong>基本概念 (Agent, Environment, Action, State, Reward, Policy, Value Funtion等)</strong></font>\n",
    "2. <font color='green'><strong>探索开发</strong></font>\n",
    "3. <font color='green'><strong>策略梯度 (MDP, DFO:Derivative-Free Optimization无梯度优化; Policy Gradients等)</strong></font>\n",
    "4. <font color='green'><strong>动态规划 (策略评估, 时序差分学习, Q-Learning, DQN, A3C等)</strong></font>\n",
    "\n",
    "\n",
    "### GAN\n",
    "\n",
    "1. <font color='green'><strong>基本概念 (生成模型, 自编码器, 变分自编码器, 模式坍塌, 判别器等)</strong></font>\n",
    "2. <font color='green'><strong>GAN/DCGAN/WGAN/ConditionalGAN/GANs/CycleGAN</strong></font>\n",
    "3. <font color='green'><strong>换脸/风格迁移/图像降噪修复</strong></font>\n",
    "\n",
    "\n",
    "### 语音识别\n",
    "\n",
    "1. <font color='green'><strong>音频解码技术</strong></font>\n",
    "2. <font color='green'><strong>语音的信号处理及特征提取</strong></font>\n",
    "3. <font color='green'><strong>语音识别模型(GMM, HMM, 单音素/三音素模型等, DNN-HMM声学模型)</strong></font>\n",
    "4. <font color='green'><strong>seq2seq及注意力机制</strong></font>\n",
    "\n",
    "### CV3D\n",
    "\n",
    "TODO\n",
    "\n",
    "### 其他\n",
    "\n",
    "1. 大数据\n",
    "2. 数据挖掘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Networks and Deep Learning (Syllabus)\n",
    "The following is a list of topics, questions, subjects which are expected you to know at the end\n",
    "of the course on Artificial Neural Networks and Deep Learning. For this reason you can use it to\n",
    "double check your preparation before the exam.\n",
    "Please recall the exam is meant to verify what you have understood from the slides and lecture\n",
    "provided by the teachers, having said this, note:\n",
    "\n",
    "- This is NOT the list of questions and exercises you will find in the exam, but we will look\n",
    "at this list when preparing it, so the exam questions are going to check these points\n",
    "- If you know how to answer/face any of the following then you know how to face any\n",
    "possible question for the exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine vs Deep Learning\n",
    "\n",
    "- What is machine learning\n",
    "- What are the machine learning paradigms and their characteristics\n",
    "- What are the machine learning task and their characteristics\n",
    "- What is deep learning and how it differs from machine learning\n",
    "- Examples of successful deep learning applications\n",
    "- What is transfer learning and what it is used for\n",
    "- What is a feature and its role in machine and deep learning\n",
    "- What is cross-validation and what it is used for\n",
    "- What are hyperparameters and identify those for all the models presented in the course\n",
    "- What is Maximum likelihood estimation and how does it work in practice\n",
    "- What is Maximum a posteriori and how does it work in practice\n",
    "\n",
    "Feed Forward Neural Networks\n",
    "\n",
    "- The perceptron and its math\n",
    "- The Hebbian Learning paradigm, its maths, and it application\n",
    "- The feed forward neural architecture and its improvement wrt the Perceptron\n",
    "- The number of parameters of any model you can build\n",
    "- Activation functions, their math, their characteristics, and their practical use\n",
    "- What is backpropagation and how does it work\n",
    "- The relationship with non-linear optimization and gradient descent\n",
    "- Backpropagation computation for standard feedforward models\n",
    "- Online vs batch, vs mini-batch learning and their characteristics\n",
    "- Forward-backward algorithm for backpropagation\n",
    "- Derivatives chain rules\n",
    "- Error functions, their statistical rationale, their derivation, and their derivative\n",
    "- The issue of overfitting and its relationship with model complexity\n",
    "- Regularization techniques, their rationale and their implementation\n",
    "- Techniques for hyperparameters tuning and model selections\n",
    "- Techniques for weights initialization and their rationale\n",
    "- Batch-Normalization rationale and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks\n",
    "\n",
    "- Convolution and correlation, linear classifier for images\n",
    "- The layers of a CNN\n",
    "- Connections between CNN and Feedforward-NN, interpretations of CNN\n",
    "- How to compute the number of parameters of a CNN\n",
    "- Best practices to train CNN models: data augmentation, Transfer learning\n",
    "- Design criteria from the most successful architectures shown during classes (no need to\n",
    "know exactly the architectures)\n",
    "- Fully convolutional CNN and CNN for segmentation\n",
    "- The key principles of CNN used for object detection\n",
    "- Residual learning\n",
    "- GANs, what they are and how they are trained\n",
    "\n",
    "Recurrent Neural Networks\n",
    "- Models for sequence modeling\n",
    "- The architecture and math of a recurrent neural network\n",
    "- Backpropagation through time rationale and math\n",
    "- The limits of backpropagation through time and the vanishing/exploding gradient issue\n",
    "- The vanishing gradient math in a simple case\n",
    "- The Long Short-Term Memory model, rationale, ad math\n",
    "- The Gated Recurrent Unit\n",
    "- LSTM Networks, hierarchical and bidirectional.\n",
    "\n",
    "Sequence to Sequence Learning\n",
    "- Sequential Data Problems, with examples\n",
    "- The Seq2Seq model, training, and inference\n",
    "- Neural Turing Machine model and the attention mechanism\n",
    "- Attention mechanism in Seq2Seq models\n",
    "- Chatbot: core models and context handling\n",
    "- The Transformer model\n",
    "\n",
    "Word Embedding\n",
    "- Neural Autoencoder model, error function, and training\n",
    "- Language models and the N-grams model\n",
    "- Limits of the N-gram model\n",
    "- The concept of embedding and its benefits\n",
    "- The Neural Language Model and its use for word embedding\n",
    "- Google’s word2vec model (CBOW)\n",
    "- Possible uses of word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
