{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T10:06:01.444700Z",
     "start_time": "2020-04-08T10:06:01.276145Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T10:06:56.523974Z",
     "start_time": "2020-04-08T10:06:56.517552Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_STEPS = 20\n",
    "game = 'MountainCar-v0'\n",
    "path = f'/tmp/gym-{game}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T10:11:16.051759Z",
     "start_time": "2020-04-08T10:11:16.017449Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MountainCarEnv' object has no attribute 'get_action_meanings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a23b0c53ae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_meanings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MountainCarEnv' object has no attribute 'get_action_meanings'"
     ]
    }
   ],
   "source": [
    "env = gym.make(game)\n",
    "env = env.unwrapped\n",
    "\n",
    "print(env.action_space) \n",
    "print(env.observation_space)\n",
    "print(env.action_space.n)\n",
    "print(env.observation_space.shape[0])\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T10:08:03.773964Z",
     "start_time": "2020-04-08T10:08:03.229642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42125024 -0.00176824] 0 -1.0\n",
      "[-0.42277408 -0.00152385] 2 -1.0\n",
      "[-0.42404264 -0.00126856] 2 -1.0\n",
      "[-0.42504682 -0.00100418] 2 -1.0\n",
      "[-0.42677941 -0.00173259] 1 -1.0\n",
      "[-0.42922799 -0.00244857] 1 -1.0\n",
      "[-0.43237492 -0.00314694] 1 -1.0\n",
      "[-0.43519753 -0.00282261] 2 -1.0\n",
      "[-0.4396754  -0.00447787] 0 -1.0\n",
      "[-0.44377607 -0.00410067] 2 -1.0\n",
      "[-0.47306545  0.0006271 ] 2 -1.0\n",
      "[-4.72815903e-01  2.49550269e-04] 1 -1.0\n",
      "[-0.47394575 -0.00112985] 0 -1.0\n",
      "[-0.47544662 -0.00150087] 1 -1.0\n",
      "[-0.47730738 -0.00186076] 1 -1.0\n",
      "[-0.47951421 -0.00220683] 1 -1.0\n",
      "[-0.48205071 -0.0025365 ] 1 -1.0\n",
      "[-0.48489802 -0.0028473 ] 1 -1.0\n",
      "[-0.48703492 -0.00213691] 2 -1.0\n",
      "[-0.48844551 -0.00141059] 2 -1.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(game)\n",
    "for i_episode in range(2):\n",
    "    observation = env.reset()\n",
    "    for t in range(10):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(observation, action, reward)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:15:50.514112Z",
     "start_time": "2020-04-07T12:15:50.059648Z"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2edf88b63b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over."
     ]
    }
   ],
   "source": [
    "env = gym.make(game)\n",
    "env = wrappers.Monitor(env, path, force=True)\n",
    "env.reset()\n",
    "\n",
    "for i_episode in range(100):\n",
    "    observation = env.reset()\n",
    "    for t in range(MAX_STEPS):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:57:47.521802Z",
     "start_time": "2020-04-07T09:57:42.978842Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 15 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 18 timesteps\n",
      "Episode finished after 9 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 12 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 12 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "Episode finished after 9 timesteps\n",
      "Episode finished after 14 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 16 timesteps\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 15 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 12 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 17 timesteps\n",
      "Episode finished after 12 timesteps\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 15 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 15 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 19 timesteps\n",
      "Episode finished after 13 timesteps\n",
      "Episode finished after 17 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "Episode finished after 16 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 13 timesteps\n",
      "Episode finished after 16 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 20 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 18 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 11 timesteps\n",
      "Episode finished after 17 timesteps\n",
      "Episode finished after 11 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 11 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 17 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 20 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 17 timesteps\n",
      "Episode finished after 20 timesteps\n",
      "Episode finished after 12 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 17 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "Episode finished after 18 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 13 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 8 timesteps\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 18 timesteps\n",
      "Episode finished after 10 timesteps\n",
      "Episode finished after 16 timesteps\n",
      "MAX_STEPS: 20\n",
      "MAX_STEPS: 20\n",
      "Episode finished after 12 timesteps\n",
      "Episode finished after 19 timesteps\n",
      "Episode finished after 19 timesteps\n",
      "Episode finished after 18 timesteps\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(game)\n",
    "env = wrappers.Monitor(env, path, force=True)\n",
    "for i_episode in range(100):\n",
    "    observation = env.reset()\n",
    "    for t in range(MAX_STEPS):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    else:\n",
    "        print('MAX_STEPS: %d' % MAX_STEPS) \n",
    "        env.stats_recorder.save_complete()\n",
    "        env.stats_recorder.done = True\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
