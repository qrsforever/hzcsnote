{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T14:55:44.572781Z",
     "start_time": "2020-09-03T14:55:42.479470Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "! [ ! -L /datasets ] && ln -s /data/datasets/cv /datasets\n",
    "\n",
    "from k12libs.utils.nb_easy import k12ai_set_notebook\n",
    "\n",
    "k12ai_set_notebook(cellw=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需掌握知识点\n",
    "\n",
    "1. 激活函数层(Relu, Sigmoid)\n",
    "2. Dropout层\n",
    "3. Batchnorm层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-03T14:55:42.457Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['salviasplendens',\n",
      "                 'daffodil',\n",
      "                 'snowdrop',\n",
      "                 'lilyvalley',\n",
      "                 'bluebell',\n",
      "                 'crocus',\n",
      "                 'iris',\n",
      "                 'tigerlily',\n",
      "                 'tulip',\n",
      "                 'fritillary',\n",
      "                 'sunflower',\n",
      "                 'daisy',\n",
      "                 'coltsfoot',\n",
      "                 'dandelion',\n",
      "                 'cowslip',\n",
      "                 'buttercup',\n",
      "                 'windflower',\n",
      "                 'pansy',\n",
      "                 'coxcomb',\n",
      "                 'flamingo',\n",
      "                 'lily',\n",
      "                 'lotus'],\n",
      " 'mean': [0.4623, 0.4305, 0.295],\n",
      " 'num_classes': 22,\n",
      " 'num_records': 1760,\n",
      " 'std': [0.252, 0.2242, 0.2091]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   | Name               | Type              | Params | In sizes           | Out sizes         \n",
      "----------------------------------------------------------------------------------------------------\n",
      "0  | model              | NeuralNet         | 319 K  | [32, 3, 224, 224]  | [32, 22]          \n",
      "1  | model.features     | Sequential        | 112 K  | [32, 3, 224, 224]  | [32, 64, 55, 55]  \n",
      "2  | model.features.0   | BatchNorm2d       | 6      | [32, 3, 224, 224]  | [32, 3, 224, 224] \n",
      "3  | model.features.1   | Conv2d            | 9 K    | [32, 3, 224, 224]  | [32, 64, 110, 110]\n",
      "4  | model.features.2   | ReLU              | 0      | [32, 64, 110, 110] | [32, 64, 110, 110]\n",
      "5  | model.features.3   | BatchNorm2d       | 128    | [32, 64, 110, 110] | [32, 64, 110, 110]\n",
      "6  | model.features.4   | MaxPool2d         | 0      | [32, 64, 110, 110] | [32, 64, 110, 110]\n",
      "7  | model.features.5   | Dropout           | 0      | [32, 64, 110, 110] | [32, 64, 110, 110]\n",
      "8  | model.features.6   | Conv2d            | 102 K  | [32, 64, 110, 110] | [32, 64, 55, 55]  \n",
      "9  | model.features.7   | ReLU              | 0      | [32, 64, 55, 55]   | [32, 64, 55, 55]  \n",
      "10 | model.features.8   | BatchNorm2d       | 128    | [32, 64, 55, 55]   | [32, 64, 55, 55]  \n",
      "11 | model.features.9   | MaxPool2d         | 0      | [32, 64, 55, 55]   | [32, 64, 55, 55]  \n",
      "12 | model.features.10  | Dropout           | 0      | [32, 64, 55, 55]   | [32, 64, 55, 55]  \n",
      "13 | model.avgpool      | AdaptiveAvgPool2d | 0      | [32, 64, 55, 55]   | [32, 64, 5, 5]    \n",
      "14 | model.classifier   | Sequential        | 207 K  | [32, 64, 5, 5]     | [32, 22]          \n",
      "15 | model.classifier.0 | Flatten           | 0      | [32, 64, 5, 5]     | [32, 1600]        \n",
      "16 | model.classifier.1 | Linear            | 204 K  | [32, 1600]         | [32, 128]         \n",
      "17 | model.classifier.2 | Dropout           | 0      | [32, 128]          | [32, 128]         \n",
      "18 | model.classifier.3 | Linear            | 2 K    | [32, 128]          | [32, 22]          \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533b14fc94374ae1a8844dc601dc28a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_size = 224 # 输入模型的图片大小\n",
    "        self.batch_size = 32  # 输入模型的图片数量\n",
    "        \n",
    "        # 调试: 日志输出模型shape\n",
    "        self.example_input_array = torch.zeros(\n",
    "            self.batch_size, 3, self.input_size, self.input_size) \n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        flowers: 22个分类\n",
    "            0: 'salviasplendens' 鼠尾草\n",
    "            1: 'daffodil' 水仙花\n",
    "            2: 'snowdrop' 雪花莲\n",
    "            3: 'lilyvalley' 铃兰花\n",
    "            4: 'bluebell' 野风信子\n",
    "            5: 'crocus' 番红花\n",
    "            6: 'iris' 鸢尾花\n",
    "            7: 'tigerlily' 卷丹\n",
    "            8: 'tulip'  郁金香\n",
    "            9: 'fritillary' 豹纹蝶\n",
    "           10: 'sunflower' 向日葵\n",
    "           11: 'daisy' 雏菊\n",
    "           12: 'coltsfoot' 款冬\n",
    "           13: 'dandelion' 蒲公英\n",
    "           14: 'cowslip' 黄花九轮草\n",
    "           15: 'buttercup' 毛茛\n",
    "           16: 'windflower' 白头翁\n",
    "           17: 'pansy' 蝴蝶花\n",
    "           18: 'coxcomb'  鸡冠花\n",
    "           19: 'flamingo' 红鹤\n",
    "           20: 'lily'  百合花\n",
    "           21: 'lotus' 荷花\n",
    "        \"\"\"\n",
    "        return self.load_flowers()\n",
    "    \n",
    "    def build_model(self):\n",
    "        class NeuralNet(nn.Module):\n",
    "            def __init__(self, num_classes):\n",
    "                super().__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    nn.BatchNorm2d(num_features=3, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=1, dilation=1, groups=1, bias=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                    nn.MaxPool2d(kernel_size=7, stride=1, padding=3, ceil_mode=False),\n",
    "                    nn.Dropout(inplace=True, p=0.5),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=2, padding=2, dilation=1, groups=1, bias=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                    nn.MaxPool2d(kernel_size=5, stride=1, padding=2, ceil_mode=False),\n",
    "                    nn.Dropout(inplace=True, p=0.5)\n",
    "                )\n",
    "                self.avgpool = nn.AdaptiveAvgPool2d(output_size=(5, 5))\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Linear(in_features=1600, out_features=128, bias=True),\n",
    "                    nn.Dropout(inplace=True, p=0.5),\n",
    "                    nn.Linear(in_features=128, out_features=num_classes, bias=True),\n",
    "                  )\n",
    "                \n",
    "            def forward(self, x):     \n",
    "                x = self.avgpool(self.features(x))\n",
    "                return self.classifier(x)\n",
    "            \n",
    "        return NeuralNet(num_classes=22) # input shape: (32, 3, 224, 224)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader('train', self.batch_size, self.input_size, normalize=True)\n",
    "     \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean') # 损失方法\n",
    "        with torch.no_grad():\n",
    "            accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'loss': loss, 'progress_bar': {'acc': accuracy}}\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader('val', self.batch_size, self.input_size, normalize=True)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'loss': loss, 'acc': accuracy}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        return {'progress_bar': {'val_loss': avg_loss, 'val_acc': avg_acc}}\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader('test', self.batch_size, self.input_size)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, p = batch\n",
    "        y_hat = self(x)\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'acc': accuracy}\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        return {'test_acc': avg_acc}\n",
    "    \n",
    "    def configure_optimizer(self, model):\n",
    "        \"\"\"\n",
    "        优化器:\n",
    "            adam: 利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率\n",
    "            sgd:\n",
    "        \"\"\"\n",
    "        # 优化算法\n",
    "        # return self.adam(model.parameters(), base_lr=0.001, betas=(0.8, 0.88), weight_decay=0.001)\n",
    "        return self.sgd(model.parameters(), base_lr=0.01, momentum=0.88, nesterov=True, weight_decay=0.001)\n",
    "    \n",
    "    def configure_scheduler(self, optimizer):\n",
    "        \"\"\"\n",
    "        学习率策略:\n",
    "            step_lr: 每step_size个epoch，lr会自动乘以gamma(lr = lr*gamma)\n",
    "            multistep_lr: 按照milestones里的值,阶段地修改学习率(lr = lr*gamma)\n",
    "            reduceon_lr: 监控val_loss的值, 如果在容忍patience值指定的epoch次数内没有减少, 则修改学习率(lr = lr*factor)\n",
    "        \"\"\"\n",
    "        # return self.step_lr(optimizer, step_size=5, gamma=0.1)\n",
    "        # return self.multistep_lr(optimizer, milestones=[5, 10], gamma=0.1)\n",
    "        return self.reduceon_lr(optimizer, factor=0.1, patience=3)\n",
    "    \n",
    "    \n",
    "trainer = EasyaiTrainer(max_epochs=50, log_lr=True, model_summary='full', ckpt_path='9-1')\n",
    "\n",
    "model = CustomClassifier()\n",
    "\n",
    "# 训练\n",
    "trainer.fit(model)\n",
    "\n",
    "# 评估\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
