{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hello\" data-toc-modified-id=\"Hello-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hello</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T06:44:49.722745Z",
     "start_time": "2021-10-21T06:44:46.436894Z"
    }
   },
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_start_html, W3URL\n",
    "from urllib.parse import urlencode\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T06:27:18.760503Z",
     "start_time": "2021-08-11T06:27:18.666934Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T06:27:18.912193Z",
     "start_time": "2021-08-11T06:27:18.768240Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/cache/predict'):\n",
    "    os.makedirs('/cache/predict')\n",
    "    os.system('cp -arf /data/users/16601548608/123456/predict/* /cache/predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T06:27:19.002775Z",
     "start_time": "2021-08-11T06:27:18.915667Z"
    }
   },
   "outputs": [],
   "source": [
    "code='''\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer, EasyaiDataset\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "    ## Load\n",
    "    def prepare_dataset(self):\n",
    "        return self.load_presetting_dataset_('rmnist', '/data/datasets/cv')\n",
    "    \n",
    "    def build_model(self):\n",
    "        class SmallCNN(nn.Module):\n",
    "            def __init__(self, num_classes=10, hidden_size=100):\n",
    "                super(SmallCNN, self).__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, 3, padding=1),             # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride =1), # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride =1), # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride=2),  # 64: (128-3+2*1)//2 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 64, 3, padding=1),            # 64: (128-3+2*1)//1 + 1  \n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 64, 3, padding=1, stride=2),  # 32: (64-3+2*1)//2 + 1\n",
    "                    nn.ReLU(inplace=True))\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Flatten(),                               # 64*32*32\n",
    "                    nn.Linear(64*32*32, hidden_size), nn.ReLU(),\n",
    "                    nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = self.classifier(x)\n",
    "                return x\n",
    "        # return SmallCNN(num_classes=10)\n",
    "        return self.load_pretrained_model_('resnet18', num_classes=10)\n",
    "    \n",
    "    def configure_optimizer(self, model):\n",
    "        return self.adam(model.parameters(),\n",
    "            base_lr=0.001)\n",
    "\n",
    "    def configure_scheduler(self, optimizer):\n",
    "        return self.period_step(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    ## Train\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(\n",
    "            phase='train',\n",
    "            data_augment=[\n",
    "                self.random_resized_crop(size=(128, 128)),\n",
    "                self.random_brightness(factor=0.3),\n",
    "                self.random_rotation(degrees=30)\n",
    "            ],\n",
    "            random_order=False,\n",
    "            input_size=128,\n",
    "            normalize=True,\n",
    "            batch_size=32,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # REQUIRED\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        with torch.no_grad():\n",
    "            accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        log = {'train_loss': loss, 'train_acc': accuracy}\n",
    "        output = OrderedDict({\n",
    "            'loss': loss,        # M\n",
    "            'acc': accuracy,     # O\n",
    "            'progress_bar': log, # O\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        log = {'train_loss': avg_loss, 'train_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            'progress_loss': log,\n",
    "        })\n",
    "        return output\n",
    "        \n",
    "    ## Valid\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader('val',\n",
    "                input_size=128,\n",
    "                batch_size=32,\n",
    "                drop_last=False,\n",
    "                shuffle=False)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        output = OrderedDict({\n",
    "            'val_loss': loss,\n",
    "            'val_acc': accuracy,\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        log = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            **log,\n",
    "            'progress_loss': log,\n",
    "        })\n",
    "        print(log)\n",
    "        return output\n",
    "        \n",
    "    ## Test\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader('test',\n",
    "                input_size=128,\n",
    "                batch_size=32,\n",
    "                drop_last=False,\n",
    "                shuffle=False)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        output = OrderedDict({\n",
    "            'test_loss': loss,\n",
    "            'test_acc': accuracy\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        log = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            'progress_bar': log,\n",
    "            **log\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    \n",
    "trainer = EasyaiTrainer(\n",
    "    resume=False,\n",
    "    max_epochs=10, model_summary='full',\n",
    "    model_ckpt={'monitor': 'val_loss', 'period': 2, 'mode': 'min'},\n",
    "    early_stop={'monitor': 'val_acc', 'patience': 3, 'mode': 'max'}\n",
    ")\n",
    "\n",
    "model = CustomClassifier()\n",
    "model.example_input_array = torch.zeros(32, 3, 224, 224)\n",
    "trainer.fit(model)\n",
    "\n",
    "# url = 'oss://predict'\n",
    "# url = 'http://www.adwzw.com/uploadfile/2018/0612/20180612123356777.jpg'\n",
    "# url = 'ftp://talentai:123456@116.85.5.40:9021/predict/20180612123356777.jpg'\n",
    "# print(trainer.predict(model, image_path=url))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T07:46:14.968951Z",
     "start_time": "2020-08-25T07:46:14.907294Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T06:27:20.708154Z",
     "start_time": "2021-08-11T06:27:20.639107Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# params = {'default': code.replace('pyr.app.', '').replace('/data/datasets/cv', '/datasets')}\n",
    "# k12ai_start_html(f'{W3URL}/codemirror.html?{urlencode(params)}', width='100%', height='1200px')"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/414df638cb647ad82900add9e3212883"
  },
  "gist": {
   "data": {
    "description": "pyr/tasks/api_test.ipynb",
    "public": true
   },
   "id": "414df638cb647ad82900add9e3212883"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "213px",
    "left": "1328px",
    "top": "160px",
    "width": "332px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
