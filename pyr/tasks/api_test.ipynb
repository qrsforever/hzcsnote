{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T10:39:00.291954Z",
     "start_time": "2020-08-10T10:38:59.834856Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T14:36:07.137691Z",
     "start_time": "2020-08-10T14:36:06.495235Z"
    }
   },
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_start_html, W3URL\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T14:39:46.401150Z",
     "start_time": "2020-08-11T14:39:46.343030Z"
    }
   },
   "outputs": [],
   "source": [
    "code='''\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer, EasyaiDataset\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "    ## Load\n",
    "    def prepare_dataset(self):\n",
    "        return self.load_presetting_dataset_('rmnist', '/data/datasets/cv')\n",
    "    \n",
    "    def build_model(self):\n",
    "        # return self.load_pretrained_model_('resnet18', num_classes=10)\n",
    "        class SmallCNN(nn.Module):\n",
    "            def __init__(self, num_classes=10, hidden_size=100):\n",
    "                super(SmallCNN, self).__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, 3, padding=1),             # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride =1), # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride =1), # 128: (128-3+2*1)//1 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1, stride=2),  # 64: (128-3+2*1)//2 + 1\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 64, 3, padding=1),            # 64: (128-3+2*1)//1 + 1  \n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 64, 3, padding=1, stride=2),  # 32: (64-3+2*1)//2 + 1\n",
    "                    nn.ReLU(inplace=True))\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Flatten(),                               # 64*32*32\n",
    "                    nn.Linear(64*32*32, hidden_size), nn.ReLU(),\n",
    "                    nn.Linear(hidden_size, num_classes))\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                x = self.classifier(x)\n",
    "                return x\n",
    "        return SmallCNN(num_classes=10)\n",
    "    \n",
    "    def configure_optimizer(self, model):\n",
    "        return self.adam(model.parameters(),\n",
    "            base_lr=0.001)\n",
    "\n",
    "    def configure_scheduler(self, optimizer):\n",
    "        return self.period_step(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    ## Train\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(\n",
    "            phase='train',\n",
    "            data_augment=[\n",
    "                self.random_resized_crop(size=(128, 128)),\n",
    "                self.random_brightness(factor=0.3),\n",
    "                self.random_rotation(degrees=30)\n",
    "            ],\n",
    "            random_order=False,\n",
    "            input_size=128,\n",
    "            normalize=True,\n",
    "            batch_size=32,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # REQUIRED\n",
    "        x, y, _ = batch\n",
    "        y_hat = self.forward(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        with torch.no_grad():\n",
    "            accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        log = {'train_loss': loss, 'train_acc': accuracy}\n",
    "        output = OrderedDict({\n",
    "            'loss': loss,        # M\n",
    "            'acc': accuracy,     # O\n",
    "            'progress_bar': log, # O\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        log = {'train_loss': avg_loss, 'train_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            'progress_loss': log,\n",
    "        })\n",
    "        return output\n",
    "        \n",
    "    ## Valid\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader('val',\n",
    "                input_size=128,\n",
    "                batch_size=32,\n",
    "                drop_last=False,\n",
    "                shuffle=False)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self.forward(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        output = OrderedDict({\n",
    "            'val_loss': loss,\n",
    "            'val_acc': accuracy,\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        log = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            **log,\n",
    "            'progress_loss': log,\n",
    "        })\n",
    "        return output\n",
    "        \n",
    "    ## Test\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader('test',\n",
    "                input_size=128,\n",
    "                batch_size=32,\n",
    "                drop_last=False,\n",
    "                shuffle=False)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self.forward(x) # (32, 10)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        output = OrderedDict({\n",
    "            'test_loss': loss,\n",
    "            'test_acc': accuracy\n",
    "        })\n",
    "        return output\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        log = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
    "        output = OrderedDict({\n",
    "            'progress_bar': log,\n",
    "            **log\n",
    "        })\n",
    "        return output\n",
    "\n",
    "        \n",
    "trainer = EasyaiTrainer(max_epochs=1, model_summary=None, early_stop={'monitor': 'val_acc', 'patience': 3, 'mode': 'max'})\n",
    "trainer.fit(CustomClassifier())\n",
    "print(trainer.test())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T14:39:26.253808Z",
     "start_time": "2020-08-11T14:39:07.208084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37746edb8b2d4d3791e350ed436bba14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c718d4d05f4278b371a3a743caecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': tensor(0.1052, device='cuda:0'),\n",
      " 'test_loss': tensor(2.5602, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "{'test_loss': 2.560201406478882, 'test_acc': 0.1051587387919426}\n"
     ]
    }
   ],
   "source": [
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T14:39:51.037128Z",
     "start_time": "2020-08-11T14:39:50.981475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"900px\"\n",
       "            src=\"http://116.85.5.40:9091/codemirror.html?default=%0Afrom+k12ai+import+EasyaiClassifier%2C+EasyaiTrainer%2C+EasyaiDataset%0Afrom+collections+import+OrderedDict%0Aimport+torch%0Afrom+torch+import+nn%0A%0Aclass+CustomClassifier%28EasyaiClassifier%29%3A%0A++++%23%23+Load%0A++++def+prepare_dataset%28self%29%3A%0A++++++++return+self.load_presetting_dataset_%28%27rmnist%27%2C+%27%2Fdatasets%27%29%0A++++%0A++++def+build_model%28self%29%3A%0A++++++++%23+return+self.load_pretrained_model_%28%27resnet18%27%2C+num_classes%3D10%29%0A++++++++class+SmallCNN%28nn.Module%29%3A%0A++++++++++++def+__init__%28self%2C+num_classes%3D10%2C+hidden_size%3D100%29%3A%0A++++++++++++++++super%28SmallCNN%2C+self%29.__init__%28%29%0A++++++++++++++++self.features+%3D+nn.Sequential%28%0A++++++++++++++++++++nn.Conv2d%283%2C+32%2C+3%2C+padding%3D1%29%2C+nn.ReLU%28%29%2C+++++++++++++%23+128%3A+%28128-3%2B2%2A1%29%2F%2F1+%2B+1%0A++++++++++++++++++++nn.Conv2d%2832%2C+32%2C+3%2C+padding%3D1%2C+stride+%3D1%29%2C+nn.ReLU%28%29%2C+%23+128%3A+%28128-3%2B2%2A1%29%2F%2F1+%2B+1%0A++++++++++++++++++++nn.Conv2d%2832%2C+32%2C+3%2C+padding%3D1%2C+stride%3D2%29%2C+nn.ReLU%28%29%2C++%23+64%3A+%28128-3%2B2%2A1%29%2F%2F2+%2B+1%0A++++++++++++++++++++nn.Conv2d%2832%2C+64%2C+3%2C+padding%3D1%29%2C+nn.ReLU%28%29%2C++++++++++++%23+64%3A+%28128-3%2B2%2A1%29%2F%2F1+%2B+1++%0A++++++++++++++++++++nn.Conv2d%2864%2C+64%2C+3%2C+padding%3D1%2C+stride%3D2%29%2C+nn.ReLU%28%29%29++%23+32%3A+%2864-3%2B2%2A1%29%2F%2F2+%2B+1%0A++++++++++++++++self.classifier+%3D+nn.Sequential%28%0A++++++++++++++++++++nn.Flatten%28%29%2C++++++++++++++++++++++++++++++++++++++++++%23+64%2A32%2A32%0A++++++++++++++++++++nn.Linear%2864%2A32%2A32%2C+hidden_size%29%2C+nn.ReLU%28%29%2C%0A++++++++++++++++++++nn.Linear%28hidden_size%2C+num_classes%29%29%0A%0A++++++++++++def+forward%28self%2C+x%29%3A%0A++++++++++++++++x+%3D+self.features%28x%29%0A++++++++++++++++x+%3D+self.classifier%28x%29%0A++++++++++++++++return+x%0A++++++++return+SmallCNN%28num_classes%3D10%29%0A++++%0A++++def+configure_optimizer%28self%2C+model%29%3A%0A++++++++return+self.adam%28model.parameters%28%29%2C%0A++++++++++++base_lr%3D0.001%29%0A%0A++++def+configure_scheduler%28self%2C+optimizer%29%3A%0A++++++++return+self.period_step%28optimizer%2C+step_size%3D30%2C+gamma%3D0.1%29%0A++++%0A++++%23%23+Train%0A++++def+train_dataloader%28self%29%3A%0A++++++++return+self.get_dataloader%28%0A++++++++++++phase%3D%27train%27%2C%0A++++++++++++data_augment%3D%5B%0A++++++++++++++++self.random_resized_crop%28size%3D%28128%2C+128%29%29%2C%0A++++++++++++++++self.random_brightness%28factor%3D0.3%29%2C%0A++++++++++++++++self.random_rotation%28degrees%3D30%29%0A++++++++++++%5D%2C%0A++++++++++++random_order%3DFalse%2C%0A++++++++++++input_size%3D128%2C%0A++++++++++++normalize%3DTrue%2C%0A++++++++++++batch_size%3D32%2C%0A++++++++++++drop_last%3DFalse%2C%0A++++++++++++shuffle%3DFalse%29%0A%0A++++def+training_step%28self%2C+batch%2C+batch_idx%29%3A%0A++++++++%23+REQUIRED%0A++++++++x%2C+y%2C+_+%3D+batch%0A++++++++y_hat+%3D+self.forward%28x%29+%23+%2832%2C+10%29%0A++++++++loss+%3D+self.cross_entropy%28y_hat%2C+y%2C+reduction%3D%27mean%27%29%0A++++++++with+torch.no_grad%28%29%3A%0A++++++++++++accuracy+%3D+%28torch.argmax%28y_hat%2C+axis%3D1%29+%3D%3D+y%29.float%28%29.mean%28%29%0A++++++++log+%3D+%7B%27train_loss%27%3A+loss%2C+%27train_acc%27%3A+accuracy%7D%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%27loss%27%3A+loss%2C++++++++%23+M%0A++++++++++++%27acc%27%3A+accuracy%2C+++++%23+O%0A++++++++++++%27progress_bar%27%3A+log%2C+%23+O%0A++++++++%7D%29%0A++++++++return+output%0A%0A++++def+training_epoch_end%28self%2C+outputs%29%3A%0A++++++++avg_loss+%3D+torch.stack%28%5Bx%5B%27loss%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++avg_acc+%3D+torch.stack%28%5Bx%5B%27acc%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++log+%3D+%7B%27train_loss%27%3A+avg_loss%2C+%27train_acc%27%3A+avg_acc%7D%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%27progress_loss%27%3A+log%2C%0A++++++++%7D%29%0A++++++++return+output%0A++++++++%0A++++%23%23+Valid%0A++++def+val_dataloader%28self%29%3A%0A++++++++return+self.get_dataloader%28%27val%27%2C%0A++++++++++++++++input_size%3D128%2C%0A++++++++++++++++batch_size%3D32%2C%0A++++++++++++++++drop_last%3DFalse%2C%0A++++++++++++++++shuffle%3DFalse%29%0A%0A++++def+validation_step%28self%2C+batch%2C+batch_idx%29%3A%0A++++++++x%2C+y%2C+_+%3D+batch%0A++++++++y_hat+%3D+self.forward%28x%29+%23+%2832%2C+10%29%0A++++++++loss+%3D+self.cross_entropy%28y_hat%2C+y%2C+reduction%3D%27mean%27%29%0A++++++++accuracy+%3D+%28torch.argmax%28y_hat%2C+axis%3D1%29+%3D%3D+y%29.float%28%29.mean%28%29%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%27val_loss%27%3A+loss%2C%0A++++++++++++%27val_acc%27%3A+accuracy%2C%0A++++++++%7D%29%0A++++++++return+output%0A%0A++++def+validation_epoch_end%28self%2C+outputs%29%3A%0A++++++++avg_loss+%3D+torch.stack%28%5Bx%5B%27val_loss%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++avg_acc+%3D+torch.stack%28%5Bx%5B%27val_acc%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++log+%3D+%7B%27val_loss%27%3A+avg_loss%2C+%27val_acc%27%3A+avg_acc%7D%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%2A%2Alog%2C%0A++++++++++++%27progress_loss%27%3A+log%2C%0A++++++++%7D%29%0A++++++++return+output%0A++++++++%0A++++%23%23+Test%0A++++def+test_dataloader%28self%29%3A%0A++++++++return+self.get_dataloader%28%27test%27%2C%0A++++++++++++++++input_size%3D128%2C%0A++++++++++++++++batch_size%3D32%2C%0A++++++++++++++++drop_last%3DFalse%2C%0A++++++++++++++++shuffle%3DFalse%29%0A%0A++++def+test_step%28self%2C+batch%2C+batch_idx%29%3A%0A++++++++x%2C+y%2C+_+%3D+batch%0A++++++++y_hat+%3D+self.forward%28x%29+%23+%2832%2C+10%29%0A++++++++loss+%3D+self.cross_entropy%28y_hat%2C+y%2C+reduction%3D%27mean%27%29%0A++++++++accuracy+%3D+%28torch.argmax%28y_hat%2C+axis%3D1%29+%3D%3D+y%29.float%28%29.mean%28%29%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%27test_loss%27%3A+loss%2C%0A++++++++++++%27test_acc%27%3A+accuracy%0A++++++++%7D%29%0A++++++++return+output%0A%0A++++def+test_epoch_end%28self%2C+outputs%29%3A%0A++++++++avg_loss+%3D+torch.stack%28%5Bx%5B%27test_loss%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++avg_acc+%3D+torch.stack%28%5Bx%5B%27test_acc%27%5D+for+x+in+outputs%5D%29.mean%28%29%0A++++++++log+%3D+%7B%27test_loss%27%3A+avg_loss%2C+%27test_acc%27%3A+avg_acc%7D%0A++++++++output+%3D+OrderedDict%28%7B%0A++++++++++++%27progress_bar%27%3A+log%2C%0A++++++++++++%2A%2Alog%0A++++++++%7D%29%0A++++++++return+output%0A%0A++++++++%0Atrainer+%3D+EasyaiTrainer%28max_epochs%3D1%2C+model_summary%3DNone%2C+early_stop%3D%7B%27monitor%27%3A+%27val_acc%27%2C+%27patience%27%3A+3%2C+%27mode%27%3A+%27max%27%7D%29%0Atrainer.fit%28CustomClassifier%28%29%29%0Aprint%28trainer.test%28%29%29%0A\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4410d1e320>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'default': code.replace('pyr.app.', '').replace('/data/datasets/cv', '/datasets')}\n",
    "k12ai_start_html(f'{W3URL}/codemirror.html?{urlencode(params)}', width='100%', height='900px')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
