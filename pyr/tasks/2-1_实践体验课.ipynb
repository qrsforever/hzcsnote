{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T06:50:24.851054Z",
     "start_time": "2020-09-03T06:50:24.256553Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "! [ ! -L /datasets ] && ln -s /data/datasets /datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需掌握知识点\n",
    "\n",
    "1. 了解人工智能任务基本流程（训练与评估）\n",
    "- 了解数据与样本\n",
    "- 了解准确率与损失\n",
    "- 初步建立训练耗时概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T11:58:57.371617Z",
     "start_time": "2020-09-11T11:58:34.252544Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['dog', 'cat'],\n",
      " 'mean': [0.4861, 0.4499, 0.4115],\n",
      " 'num_classes': 2,\n",
      " 'num_records': 4000,\n",
      " 'std': [0.2251, 0.2206, 0.2198]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4716df9ae1724442bbb9bb5b7c0cfd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(fit)\tGPU-0 memory allocated: 86.66 MB\t max memory allocated: 352.73 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['dog', 'cat'],\n",
      " 'mean': [0.4861, 0.4499, 0.4115],\n",
      " 'num_classes': 2,\n",
      " 'num_records': 4000,\n",
      " 'std': [0.2251, 0.2206, 0.2198]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1037b89171bd458e8968c3419f18b3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[290 101]\n",
      " [ 11 398]]\n",
      "\n",
      "(fit)\tGPU-0 memory allocated: 129.35 MB\t max memory allocated: 352.73 MB\n",
      "(test)\tGPU-0 memory allocated: 129.35 MB\t max memory allocated: 352.73 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'acc': 0.86, 'cm': array([[290, 101],\n",
      "       [ 11, 398]])}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer\n",
    "\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Dataset ######\n",
    "    ##########################################################################\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        准备数据集, 从磁盘上加载数据集, 不同数据集的描述格式可能不一样, 一般有json/xml/csv等描述格式,\n",
    "        也可能直接是图片目录, 所有这些格式的处理可以在这个接口完成.\n",
    "        \n",
    "        预置数据集: mnist, cifar10, flowers, fruits, dogcat, chestxray\n",
    "            \n",
    "        返回:\n",
    "            以下几种方式任意一种:\n",
    "            1. EasyaiDataset实例, 表明只进行训练(只返回了训练数据集实例)\n",
    "            2. EasyaiDataset实例列表, 当列表长度为2时, 说明还要进行训练的校验, 当列表长度为3时, 说明还要进行测试评估.\n",
    "            3. EasyaiDataset实例字典, 如: {'train': EasyaiDataset, 'val': EasyaiDataset, 'test':EasyaiDataset}\n",
    "        \"\"\"\n",
    "        return self.load_dogcat()\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Model ######\n",
    "    ##########################################################################\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        构建模型\n",
    "        \n",
    "        返回:\n",
    "            模型实例\n",
    "        \"\"\"\n",
    "        return self.load_resnet18(num_classes=2)\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Hypes Parameters ######\n",
    "    ##########################################################################\n",
    "    def configure_optimizer(self, model):\n",
    "        \"\"\"\n",
    "        配置优化器\n",
    "        \n",
    "        返回:\n",
    "            optimizer\n",
    "        \"\"\"\n",
    "        return self.adam(model.parameters(), base_lr=0.001)\n",
    "\n",
    "    def configure_scheduler(self, optimizer):\n",
    "        \"\"\"\n",
    "        配置学习率衰减策略\n",
    "        \n",
    "        参数:\n",
    "            optimizer: 优化器(通过configure_optimizer配置得到的)\n",
    "        \n",
    "        返回:\n",
    "            scheduler: 学习率策略实例或list\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.step_lr(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: Train ######\n",
    "    ##########################################################################\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        训练数据集批量控制加载器, 可以设置批量的大小, 是否对数据进行洗牌(shuffle)等\n",
    "        \n",
    "        返回:\n",
    "            DataLoader: 数据加载器\n",
    "        \"\"\"\n",
    "        return self.get_dataloader(\n",
    "            phase='train',  # [M] 训练DataLoader\n",
    "            input_size=96,  # [O] 输入到模型的图片大小\n",
    "            batch_size=32,  # [O] 输入到模型的最大批量数\n",
    "            # data_augment=[\n",
    "            #     self.random_brightness(factor=0.3),\n",
    "            #     self.random_rotation(degrees=30)\n",
    "            # ], # [O] 数据增强\n",
    "            random_order=False, # [O] 数据增强变换方法顺序是否随机\n",
    "            normalize=True,     # [O] 是否对输入的数据进行归一化\n",
    "            drop_last=False,    # [O] 一次epoch中最后一次批量数可能不足, 是否丢弃\n",
    "            shuffle=False)      # [O] 加载的数据是否随机洗牌\n",
    "     \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        训练过程中, 迭代一次batch数据, 就会触发一次training_step的调用,训练,统计metrics\n",
    "        \n",
    "        参数:\n",
    "            batch: 一个batch的数据内容, 一般包括图片(image), 图片标签(labels), 图片路径(path).\n",
    "                具体batch中内容受prepare_dataset接口的实现会有所不同\n",
    "            batch_idx: 本轮epoch批量迭代次数\n",
    "            \n",
    "        返回:\n",
    "            metrics: 必须包含loss关键字, log(日志模块)和progress_bar(进度条显示)是可选的\n",
    "        \"\"\"\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean') # 损失方法\n",
    "        with torch.no_grad():\n",
    "            accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean() # 计算正确率\n",
    "        return {'loss': loss, 'acc': accuracy}\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Trainer: validation ######\n",
    "    ##########################################################################\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        同train_dataloader\n",
    "        \"\"\"\n",
    "        return self.get_dataloader(\n",
    "            phase='val',\n",
    "            input_size=96,\n",
    "            batch_size=32,\n",
    "            normalize=True,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        同train_step\n",
    "        \"\"\"\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'loss': loss, 'acc': accuracy}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        return {'progress_bar': {'val_loss': avg_loss, 'val_acc': avg_acc}}\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: test ######\n",
    "    ##########################################################################\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader(\n",
    "            phase='test',\n",
    "            input_size=96,\n",
    "            batch_size=32,\n",
    "            random_order=False,\n",
    "            normalize=True,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, p = batch\n",
    "        y_hat = torch.argmax(self(x), axis=1)\n",
    "        return {'y': y, 'y_hat': y_hat}\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_true = torch.cat([x['y'].cpu() for x in outputs])\n",
    "        y_pred = torch.cat([x['y_hat'].cpu() for x in outputs])\n",
    "        # 混淆矩阵\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(cm)\n",
    "        return {'acc': accuracy_score(y_true, y_pred), 'cm': cm}\n",
    "    \n",
    "    \n",
    "trainer = EasyaiTrainer(\n",
    "    max_epochs=1,  # 训练过程遍历完整数据集的总次数(epoch)\n",
    "    resume=False,  # True: 模型继续上次训练(模型必须没有改变)\n",
    "    log_rate=2,    # 日志打印的频率, 单位是迭代次数(iteration step) \n",
    "    model_summary='top', # 打印模型顶层Memory信息\n",
    "    model_ckpt={'monitor': 'val_loss', 'period': 2, 'mode': 'min'},\n",
    "    early_stop={'monitor': 'val_acc', 'patience': 3, 'mode': 'max'}\n",
    ")\n",
    "\n",
    "model = CustomClassifier()\n",
    "\n",
    "# 训练\n",
    "trainer.fit(model)\n",
    "\n",
    "# 评估\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
