{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T13:52:38.937488Z",
     "start_time": "2020-09-04T13:52:36.736703Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "! [ ! -L /datasets ] && ln -s /data/datasets/cv /datasets\n",
    "\n",
    "from k12libs.utils.nb_easy import k12ai_set_notebook\n",
    "\n",
    "k12ai_set_notebook(cellw=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需掌握知识点\n",
    "\n",
    "1. 激活函数层(Relu, Sigmoid)\n",
    "2. Dropout层\n",
    "3. Batchnorm层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T14:05:59.494860Z",
     "start_time": "2020-09-04T13:52:38.941352Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['rose', 'daisy', 'sunflower', 'dandelion', 'tulip'],\n",
      " 'mean': [0.4588, 0.4199, 0.3005],\n",
      " 'num_classes': 5,\n",
      " 'num_records': 4323,\n",
      " 'std': [0.2477, 0.2201, 0.2253]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   | Name               | Type       | Params | In sizes           | Out sizes         \n",
      "---------------------------------------------------------------------------------------------\n",
      "0  | model              | NeuralNet  | 2 M    | [32, 3, 224, 224]  | [32, 5]           \n",
      "1  | model.features     | Sequential | 388 K  | [32, 3, 224, 224]  | [32, 128, 5, 5]   \n",
      "2  | model.features.0   | Conv2d     | 896    | [32, 3, 224, 224]  | [32, 32, 222, 222]\n",
      "3  | model.features.1   | ReLU       | 0      | [32, 32, 222, 222] | [32, 32, 222, 222]\n",
      "4  | model.features.2   | MaxPool2d  | 0      | [32, 32, 222, 222] | [32, 32, 111, 111]\n",
      "5  | model.features.3   | Conv2d     | 18 K   | [32, 32, 111, 111] | [32, 64, 109, 109]\n",
      "6  | model.features.4   | ReLU       | 0      | [32, 64, 109, 109] | [32, 64, 109, 109]\n",
      "7  | model.features.5   | MaxPool2d  | 0      | [32, 64, 109, 109] | [32, 64, 54, 54]  \n",
      "8  | model.features.6   | Conv2d     | 73 K   | [32, 64, 54, 54]   | [32, 128, 52, 52] \n",
      "9  | model.features.7   | ReLU       | 0      | [32, 128, 52, 52]  | [32, 128, 52, 52] \n",
      "10 | model.features.8   | Dropout2d  | 0      | [32, 128, 52, 52]  | [32, 128, 52, 52] \n",
      "11 | model.features.9   | MaxPool2d  | 0      | [32, 128, 52, 52]  | [32, 128, 26, 26] \n",
      "12 | model.features.10  | Conv2d     | 147 K  | [32, 128, 26, 26]  | [32, 128, 24, 24] \n",
      "13 | model.features.11  | ReLU       | 0      | [32, 128, 24, 24]  | [32, 128, 24, 24] \n",
      "14 | model.features.12  | MaxPool2d  | 0      | [32, 128, 24, 24]  | [32, 128, 12, 12] \n",
      "15 | model.features.13  | Conv2d     | 147 K  | [32, 128, 12, 12]  | [32, 128, 10, 10] \n",
      "16 | model.features.14  | ReLU       | 0      | [32, 128, 10, 10]  | [32, 128, 10, 10] \n",
      "17 | model.features.15  | Dropout2d  | 0      | [32, 128, 10, 10]  | [32, 128, 10, 10] \n",
      "18 | model.features.16  | MaxPool2d  | 0      | [32, 128, 10, 10]  | [32, 128, 5, 5]   \n",
      "19 | model.classifier   | Sequential | 1 M    | [32, 128, 5, 5]    | [32, 5]           \n",
      "20 | model.classifier.0 | Flatten    | 0      | [32, 128, 5, 5]    | [32, 3200]        \n",
      "21 | model.classifier.1 | Dropout    | 0      | [32, 3200]         | [32, 3200]        \n",
      "22 | model.classifier.2 | Linear     | 1 M    | [32, 3200]         | [32, 512]         \n",
      "23 | model.classifier.3 | ReLU       | 0      | [32, 512]          | [32, 512]         \n",
      "24 | model.classifier.4 | Dropout    | 0      | [32, 512]          | [32, 512]         \n",
      "25 | model.classifier.5 | Linear     | 2 K    | [32, 512]          | [32, 5]           \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e670138b46e3430da92cfd46e0e0eefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "Epoch 00046: early stopping triggered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(fit)\tGPU-0 memory allocated: 16.49 MB\t max memory allocated: 833.08 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['rose', 'daisy', 'sunflower', 'dandelion', 'tulip'],\n",
      " 'mean': [0.4588, 0.4199, 0.3005],\n",
      " 'num_classes': 5,\n",
      " 'num_records': 4323,\n",
      " 'std': [0.2477, 0.2201, 0.2253]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0f5e99e93b4079a9aa22089ce0bcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(fit)\tGPU-0 memory allocated: 24.49 MB\t max memory allocated: 833.08 MB\n",
      "(test)\tGPU-0 memory allocated: 24.49 MB\t max memory allocated: 833.08 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'test_acc': 0.2366071492433548}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_size = 224 # 输入模型的图片大小\n",
    "        self.output_size = 5  # 模型输出大小(分类数)\n",
    "        self.batch_size = 32  # 输入模型的图片数量\n",
    "        \n",
    "        # 调试: 日志输出模型shape\n",
    "        self.example_input_array = torch.zeros(\n",
    "            self.batch_size, 3, self.input_size, self.input_size) \n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        flowers5: 5个分类\n",
    "            0: 'rose'        玫瑰\n",
    "            1: 'daisy'       雏菊\n",
    "            2: 'sunflower'   向日葵\n",
    "            3: 'dandelion'   蒲公英\n",
    "            4: 'tulip'       郁金香\n",
    "        \"\"\"\n",
    "\n",
    "        return self.load_flowers5()\n",
    "\n",
    "    def build_model(self):\n",
    "        class NeuralNet(nn.Module):\n",
    "            def __init__(self, num_classes):\n",
    "                super().__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(kernel_size=2),\n",
    "                    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(kernel_size=2),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout2d(),\n",
    "                    nn.MaxPool2d(kernel_size=2),\n",
    "                    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(kernel_size=2),\n",
    "                    nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout2d(0.6),\n",
    "                    nn.MaxPool2d(kernel_size=2),\n",
    "                )\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "                    nn.Dropout(p=0.4),\n",
    "                    nn.Linear(in_features=3200, out_features=512),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(p=0.4),\n",
    "                    nn.Linear(in_features=512, out_features=num_classes)\n",
    "                  )\n",
    "                \n",
    "            def forward(self, x):     \n",
    "                return self.classifier(self.features(x))\n",
    "            \n",
    "        return NeuralNet(num_classes=self.output_size) # input shape: (32, 3, 224, 224)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # data_augment = [\n",
    "        #     self.random_rotation(degrees=30),\n",
    "        #     self.random_horizontal_flip(),\n",
    "        #     self.random_vertical_flip()\n",
    "        # ]\n",
    "        return self.get_dataloader('train', self.batch_size, self.input_size, normalize=True, shuffle=False, data_augment=None)\n",
    "     \n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader('val', self.batch_size, self.input_size, normalize=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader('test', self.batch_size, self.input_size)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_true, _ = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.cross_entropy(y_pred, y_true)\n",
    "        # print(torch.argmax(y_pred, axis=1).flatten())\n",
    "        acc = (torch.argmax(y_pred, axis=1) == y_true).float().mean()\n",
    "        log = {'loss': loss, 'acc': acc}\n",
    "        return log\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_true, _ = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.cross_entropy(y_pred, y_true)\n",
    "        acc = (torch.argmax(y_pred, axis=1) == y_true).float().mean()\n",
    "        log = {'val_loss': loss, 'val_acc': acc}\n",
    "        return log\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        log = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        return {'progress_bar': log}\n",
    "    \n",
    "    def configure_optimizer(self, model):\n",
    "        \"\"\"\n",
    "        优化器:\n",
    "            adam: 利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率\n",
    "            sgd:\n",
    "        \"\"\"\n",
    "        # 优化算法\n",
    "        return self.adam(model.parameters(), base_lr=0.001, weight_decay=0.0001)\n",
    "        # return self.sgd(model.parameters(), base_lr=0.01, momentum=0.88, nesterov=False, weight_decay=0.001)\n",
    "    \n",
    "    def configure_scheduler(self, optimizer):\n",
    "        \"\"\"\n",
    "        学习率策略:\n",
    "            step_lr: 每step_size个epoch，lr会自动乘以gamma(lr = lr*gamma)\n",
    "            multistep_lr: 按照milestones里的值,阶段地修改学习率(lr = lr*gamma)\n",
    "            reduceon_lr: 监控val_loss的值, 如果在容忍patience值指定的epoch次数内没有减少, 则修改学习率(lr = lr*factor)\n",
    "        \"\"\"\n",
    "        # return self.step_lr(optimizer, step_size=30, gamma=0.1)\n",
    "        # return self.multistep_lr(optimizer, milestones=[5, 10], gamma=0.1)\n",
    "        return self.reduceon_lr(optimizer, factor=0.1, patience=4, min_lr=0.000001)\n",
    "    \n",
    "    \n",
    "trainer = EasyaiTrainer(\n",
    "    max_epochs=200,\n",
    "    log_lr=True,\n",
    "    model_summary='full',\n",
    "    early_stop={'monitor': 'val_acc', 'patience': 6, 'mode': 'max'},\n",
    "    # early_stop={'monitor': 'val_loss', 'patience': 6, 'mode': 'min'},\n",
    "    ckpt_path='9-2')\n",
    "\n",
    "model = CustomClassifier()\n",
    "\n",
    "# 训练\n",
    "trainer.fit(model)\n",
    "\n",
    "# 评估\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
