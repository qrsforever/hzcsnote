{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T10:32:10.979206Z",
     "start_time": "2020-09-11T10:32:10.384149Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "! [ ! -L /datasets ] && ln -s /data/datasets/ /datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T14:04:08.870675Z",
     "start_time": "2020-08-31T14:04:08.862741Z"
    }
   },
   "source": [
    "## 需掌握知识点\n",
    "\n",
    "1. 人工智能的应用与价值\n",
    "2. 人工智能作为一次科技浪潮的特点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T11:58:31.325039Z",
     "start_time": "2020-09-11T11:57:17.732571Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
      " 'mean': [0.1362, 0.1362, 0.1362],\n",
      " 'num_classes': 10,\n",
      " 'num_records': 10000,\n",
      " 'std': [0.2893, 0.2893, 0.2893]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   | Name                        | Type              | Params\n",
      "-------------------------------------------------------------------\n",
      "0  | model                       | ResNet            | 11 M  \n",
      "1  | model.conv1                 | Conv2d            | 9 K   \n",
      "2  | model.bn1                   | BatchNorm2d       | 128   \n",
      "3  | model.relu                  | ReLU              | 0     \n",
      "4  | model.maxpool               | MaxPool2d         | 0     \n",
      "5  | model.layer1                | Sequential        | 147 K \n",
      "6  | model.layer1.0              | BasicBlock        | 73 K  \n",
      "7  | model.layer1.0.conv1        | Conv2d            | 36 K  \n",
      "8  | model.layer1.0.bn1          | BatchNorm2d       | 128   \n",
      "9  | model.layer1.0.relu         | ReLU              | 0     \n",
      "10 | model.layer1.0.conv2        | Conv2d            | 36 K  \n",
      "11 | model.layer1.0.bn2          | BatchNorm2d       | 128   \n",
      "12 | model.layer1.1              | BasicBlock        | 73 K  \n",
      "13 | model.layer1.1.conv1        | Conv2d            | 36 K  \n",
      "14 | model.layer1.1.bn1          | BatchNorm2d       | 128   \n",
      "15 | model.layer1.1.relu         | ReLU              | 0     \n",
      "16 | model.layer1.1.conv2        | Conv2d            | 36 K  \n",
      "17 | model.layer1.1.bn2          | BatchNorm2d       | 128   \n",
      "18 | model.layer2                | Sequential        | 525 K \n",
      "19 | model.layer2.0              | BasicBlock        | 230 K \n",
      "20 | model.layer2.0.conv1        | Conv2d            | 73 K  \n",
      "21 | model.layer2.0.bn1          | BatchNorm2d       | 256   \n",
      "22 | model.layer2.0.relu         | ReLU              | 0     \n",
      "23 | model.layer2.0.conv2        | Conv2d            | 147 K \n",
      "24 | model.layer2.0.bn2          | BatchNorm2d       | 256   \n",
      "25 | model.layer2.0.downsample   | Sequential        | 8 K   \n",
      "26 | model.layer2.0.downsample.0 | Conv2d            | 8 K   \n",
      "27 | model.layer2.0.downsample.1 | BatchNorm2d       | 256   \n",
      "28 | model.layer2.1              | BasicBlock        | 295 K \n",
      "29 | model.layer2.1.conv1        | Conv2d            | 147 K \n",
      "30 | model.layer2.1.bn1          | BatchNorm2d       | 256   \n",
      "31 | model.layer2.1.relu         | ReLU              | 0     \n",
      "32 | model.layer2.1.conv2        | Conv2d            | 147 K \n",
      "33 | model.layer2.1.bn2          | BatchNorm2d       | 256   \n",
      "34 | model.layer3                | Sequential        | 2 M   \n",
      "35 | model.layer3.0              | BasicBlock        | 919 K \n",
      "36 | model.layer3.0.conv1        | Conv2d            | 294 K \n",
      "37 | model.layer3.0.bn1          | BatchNorm2d       | 512   \n",
      "38 | model.layer3.0.relu         | ReLU              | 0     \n",
      "39 | model.layer3.0.conv2        | Conv2d            | 589 K \n",
      "40 | model.layer3.0.bn2          | BatchNorm2d       | 512   \n",
      "41 | model.layer3.0.downsample   | Sequential        | 33 K  \n",
      "42 | model.layer3.0.downsample.0 | Conv2d            | 32 K  \n",
      "43 | model.layer3.0.downsample.1 | BatchNorm2d       | 512   \n",
      "44 | model.layer3.1              | BasicBlock        | 1 M   \n",
      "45 | model.layer3.1.conv1        | Conv2d            | 589 K \n",
      "46 | model.layer3.1.bn1          | BatchNorm2d       | 512   \n",
      "47 | model.layer3.1.relu         | ReLU              | 0     \n",
      "48 | model.layer3.1.conv2        | Conv2d            | 589 K \n",
      "49 | model.layer3.1.bn2          | BatchNorm2d       | 512   \n",
      "50 | model.layer4                | Sequential        | 8 M   \n",
      "51 | model.layer4.0              | BasicBlock        | 3 M   \n",
      "52 | model.layer4.0.conv1        | Conv2d            | 1 M   \n",
      "53 | model.layer4.0.bn1          | BatchNorm2d       | 1 K   \n",
      "54 | model.layer4.0.relu         | ReLU              | 0     \n",
      "55 | model.layer4.0.conv2        | Conv2d            | 2 M   \n",
      "56 | model.layer4.0.bn2          | BatchNorm2d       | 1 K   \n",
      "57 | model.layer4.0.downsample   | Sequential        | 132 K \n",
      "58 | model.layer4.0.downsample.0 | Conv2d            | 131 K \n",
      "59 | model.layer4.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "60 | model.layer4.1              | BasicBlock        | 4 M   \n",
      "61 | model.layer4.1.conv1        | Conv2d            | 2 M   \n",
      "62 | model.layer4.1.bn1          | BatchNorm2d       | 1 K   \n",
      "63 | model.layer4.1.relu         | ReLU              | 0     \n",
      "64 | model.layer4.1.conv2        | Conv2d            | 2 M   \n",
      "65 | model.layer4.1.bn2          | BatchNorm2d       | 1 K   \n",
      "66 | model.avgpool               | AdaptiveAvgPool2d | 0     \n",
      "67 | model.fc                    | Linear            | 5 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83620ed3986d47a2a664d50e224635ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "Epoch 00008: early stopping triggered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(fit)\tGPU-0 memory allocated: 259.2 MB\t max memory allocated: 1458.63 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'label_names': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
      " 'mean': [0.1362, 0.1362, 0.1362],\n",
      " 'num_classes': 10,\n",
      " 'num_records': 10000,\n",
      " 'std': [0.2893, 0.2893, 0.2893]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff3e7574db04f0eb12aa594b7fc9e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(fit)\tGPU-0 memory allocated: 302.28 MB\t max memory allocated: 1458.63 MB\n",
      "(test)\tGPU-0 memory allocated: 302.28 MB\t max memory allocated: 1458.63 MB\n",
      "--------------------------------------------------------------------------------\n",
      "{'test_acc': 0.9856151342391968}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "from pyr.app.k12ai import EasyaiClassifier, EasyaiTrainer\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomClassifier(EasyaiClassifier):\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Dataset ######\n",
    "    ##########################################################################\n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        准备数据集, 从磁盘上加载数据集, 不同数据集的描述格式可能不一样, 一般有json/xml/csv等描述格式,\n",
    "        也可能直接是图片目录, 所有这些格式的处理可以在这个接口完成.\n",
    "        \n",
    "        预置数据集: mnist, cifar10, flowers, fruits, dogcat, chestxray\n",
    "            \n",
    "        返回:\n",
    "            以下几种方式任意一种:\n",
    "            1. EasyaiDataset实例, 表明只进行训练(只返回了训练数据集实例)\n",
    "            2. EasyaiDataset实例列表, 当列表长度为2时, 说明还要进行训练的校验, 当列表长度为3时, 说明还要进行测试评估.\n",
    "            3. EasyaiDataset实例字典, 如: {'train': EasyaiDataset, 'val': EasyaiDataset, 'test':EasyaiDataset}\n",
    "        \"\"\"\n",
    "        return self.load_mnist()\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Model ######\n",
    "    ##########################################################################\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        构建模型\n",
    "        \n",
    "        返回:\n",
    "            模型实例\n",
    "        \"\"\"\n",
    "        return self.load_resnet18(num_classes=10)\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Hypes Parameters ######\n",
    "    ##########################################################################\n",
    "    def configure_optimizer(self, model):\n",
    "        \"\"\"\n",
    "        配置优化器\n",
    "        \n",
    "        返回:\n",
    "            optimizer\n",
    "        \"\"\"\n",
    "        return self.adam(model.parameters(), base_lr=0.001)\n",
    "\n",
    "    def configure_scheduler(self, optimizer):\n",
    "        \"\"\"\n",
    "        配置学习率衰减策略\n",
    "        \n",
    "        参数:\n",
    "            optimizer: 优化器(通过configure_optimizer配置得到的)\n",
    "        \n",
    "        返回:\n",
    "            scheduler: 学习率策略实例或list\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.step_lr(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: Train ######\n",
    "    ##########################################################################\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        训练数据集批量控制加载器, 可以设置批量的大小, 是否对数据进行洗牌(shuffle)等\n",
    "        \n",
    "        返回:\n",
    "            DataLoader: 数据加载器\n",
    "        \"\"\"\n",
    "        return self.get_dataloader(\n",
    "            phase='train',  # [M] 训练DataLoader\n",
    "            input_size=28,  # [O] 输入到模型的图片大小\n",
    "            batch_size=32,  # [O] 输入到模型的最大批量数\n",
    "            # data_augment=[\n",
    "            #     self.random_brightness(factor=0.3),\n",
    "            #     self.random_rotation(degrees=30)\n",
    "            # ], # [O] 数据增强\n",
    "            random_order=False, # [O] 数据增强变换方法顺序是否随机\n",
    "            normalize=True,     # [O] 是否对输入的数据进行归一化\n",
    "            drop_last=False,    # [O] 一次epoch中最后一次批量数可能不足, 是否丢弃\n",
    "            shuffle=False)      # [O] 加载的数据是否随机洗牌\n",
    "     \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        训练过程中, 迭代一次batch数据, 就会触发一次training_step的调用,训练,统计metrics\n",
    "        \n",
    "        参数:\n",
    "            batch: 一个batch的数据内容, 一般包括图片(image), 图片标签(labels), 图片路径(path).\n",
    "                具体batch中内容受prepare_dataset接口的实现会有所不同\n",
    "            batch_idx: 本轮epoch批量迭代次数\n",
    "            \n",
    "        返回:\n",
    "            metrics: 必须包含loss关键字, log(日志模块)和progress_bar(进度条显示)是可选的\n",
    "        \"\"\"\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean') # 损失方法\n",
    "        with torch.no_grad():\n",
    "            accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean() # 计算争取率\n",
    "        return {'loss': loss, 'acc': accuracy}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        log = {'train_loss': avg_loss, 'train_acc': avg_acc}\n",
    "        return {'progress_bar': log}\n",
    "\n",
    "    ##########################################################################\n",
    "    ####### Trainer: validation ######\n",
    "    ##########################################################################\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        同train_dataloader\n",
    "        \"\"\"\n",
    "        return self.get_dataloader(\n",
    "            phase='val',\n",
    "            input_size=28,\n",
    "            batch_size=32,\n",
    "            normalize=True,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        同train_step\n",
    "        \"\"\"\n",
    "        x, y, _ = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.cross_entropy(y_hat, y, reduction='mean')\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'loss': loss, 'acc': accuracy}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        return {'progress_bar': {'val_loss': avg_loss, 'val_acc': avg_acc}}\n",
    "    \n",
    "    ##########################################################################\n",
    "    ####### Trainer: test ######\n",
    "    ##########################################################################\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader(\n",
    "            phase='test',\n",
    "            input_size=28,\n",
    "            batch_size=32,\n",
    "            random_order=False,\n",
    "            normalize=True,\n",
    "            drop_last=False,\n",
    "            shuffle=False)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, p = batch\n",
    "        y_hat = self(x)\n",
    "        accuracy = (torch.argmax(y_hat, axis=1) == y).float().mean()\n",
    "        return {'acc': accuracy}\n",
    "        \n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_acc = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        return {'test_acc': avg_acc}\n",
    "    \n",
    "    \n",
    "trainer = EasyaiTrainer(\n",
    "    max_epochs=10, # 训练过程遍历完整数据集的总次数(epoch)\n",
    "    resume=False,  # True: 模型继续上次训练(模型必须没有改变)\n",
    "    log_rate=2,    # 日志打印的频率, 单位是迭代次数(iteration step) \n",
    "    model_summary='full', # 打印模型顶层Memory信息\n",
    "    model_ckpt={'monitor': 'val_loss', 'period': 2, 'mode': 'min'},\n",
    "    early_stop={'monitor': 'val_acc', 'patience': 3, 'mode': 'max'}\n",
    ")\n",
    "\n",
    "model = CustomClassifier()\n",
    "\n",
    "# 训练\n",
    "trainer.fit(model)\n",
    "\n",
    "# 评估\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
