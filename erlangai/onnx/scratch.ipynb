{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "insured-franchise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:22:23.995717Z",
     "start_time": "2021-08-26T13:22:19.569520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.19.5\n",
      "sklearn 0.24.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.1\n",
      "PIL 6.2.2\n",
      "matplotlib 3.3.3\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.0.dev20210103+cu101\n",
      "torchvision 0.9.0.dev20210103+cu101\n",
      "torchaudio not installed\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio\n",
    "%watermark -v -p tensorflow,tensorboard\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        segs = x.split(' ')\n",
    "        g = globals()\n",
    "        if 'github.com' in segs[1]:\n",
    "            uri = segs[1].replace('github.com', 'raw.githubusercontent.com')\n",
    "            mod = uri.split('/')\n",
    "            for s in ['main', 'master']:\n",
    "                uri = 'https://' + '/'.join(mod[:-1]) + '/main/' + mod[-1] + '.py'\n",
    "                x = requests.get(uri).text\n",
    "                if x.status == 200:\n",
    "                    break\n",
    "        elif 'gitee.com' in segs[1]:\n",
    "            mod = segs[1].split('/')\n",
    "            for s in ['/raw/main/', '/raw/master/']:\n",
    "                uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:]) + '.py'\n",
    "                x = requests.get(uri).text\n",
    "                if x.status == 200:\n",
    "                    break\n",
    "        elif segs[1][0] == '/':\n",
    "            with open(segs[1] + '.py') as fr:\n",
    "                x = fr.read()\n",
    "        exec(x, g)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chicken-allergy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:22:24.051559Z",
     "start_time": "2021-08-26T13:22:23.998821Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### Torch ###\n",
    "###\n",
    "\n",
    "_IMPORT_('import torch')\n",
    "_IMPORT_('import torch.nn as nn')\n",
    "_IMPORT_('import torch.nn.functional as F')\n",
    "_IMPORT_('import torch.optim as O')\n",
    "_IMPORT_('from torchvision import models as M')\n",
    "_IMPORT_('from torchvision import transforms as T')\n",
    "_IMPORT_('from torch.utils.data import Dataset, DataLoader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-reynolds",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:22:24.108000Z",
     "start_time": "2021-08-26T13:22:24.054227Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-carter",
   "metadata": {},
   "source": [
    "## Pytorch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intellectual-final",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:22:24.171107Z",
     "start_time": "2021-08-26T13:22:24.110357Z"
    }
   },
   "outputs": [],
   "source": [
    "class TorchModel(nn.ModuleList):\n",
    "    def __init__(self):\n",
    "        super(TorchModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(32, eps=1e-5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.avgpoll = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=(0, 0))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.avgpoll(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nutritional-geometry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:23:42.554320Z",
     "start_time": "2021-08-26T13:23:42.473324Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='/data/nb_data/datasets/', train=True, download=False,\n",
    "    transform=T.Compose([T.Lambda(lambda x: x.convert('RGB')), T.ToTensor(), T.Normalize((0.1307,), (0.3081,))]))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TorchModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = O.Adam(model.parameters(), lr=1e-4)\n",
    "# not learning, only for onnx\n",
    "for epoch in range(1):\n",
    "    for image, target in train_loader:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "silver-blowing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:30:09.098219Z",
     "start_time": "2021-08-26T13:30:08.994481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 28, 28, strides=[2352, 784, 28, 1], requires_grad=0, device=cpu),\n",
      "      %conv2.weight : Float(10, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %conv2.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n",
      "      %17 : Float(32, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %18 : Float(32, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %16 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.1, %17, %18)\n",
      "  %12 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%16) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1111:0\n",
      "  %13 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%12) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:911:0\n",
      "  %14 : Float(1, 10, 1, 1, strides=[10, 1, 1, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%13, %conv2.weight, %conv2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:391:0\n",
      "  %15 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%14) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/flatten.py:40:0\n",
      "  return (%15)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model, torch.randn((1, 3, 28, 28)),\n",
    "    '/data/nb_data/tmp/torch_model.onnx', \n",
    "    verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-avatar",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-merchandise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T07:12:57.958939Z",
     "start_time": "2021-08-26T07:12:57.953396Z"
    }
   },
   "source": [
    "- [Creating and Modifying ONNX Model Using ONNX Python API][1]\n",
    "\n",
    "[1]: https://leimao.github.io/blog/ONNX-Python-API/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-clinic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T13:22:25.320715Z",
     "start_time": "2021-08-26T13:22:19.533Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
