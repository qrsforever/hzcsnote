{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c309d978",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1><span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-&amp;-Tools\" data-toc-modified-id=\"Import-&amp;-Tools-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import &amp; Tools</a></span></li><li><span><a href=\"#Repnet-Model\" data-toc-modified-id=\"Repnet-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Repnet Model</a></span></li><li><span><a href=\"#Load-Model\" data-toc-modified-id=\"Load-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-Conv3D-Model\" data-toc-modified-id=\"Simple-Conv3D-Model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Simple Conv3D Model</a></span></li></ul></li><li><span><a href=\"#Frozen-Graph\" data-toc-modified-id=\"Frozen-Graph-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Frozen Graph</a></span></li><li><span><a href=\"#Saved-Model\" data-toc-modified-id=\"Saved-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Saved Model</a></span></li><li><span><a href=\"#TFlite\" data-toc-modified-id=\"TFlite-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TFlite</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b7e37",
   "metadata": {},
   "source": [
    "## Import & Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "piano-stereo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:00.362689Z",
     "start_time": "2021-08-31T10:44:55.869241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.24.2\n",
      "pandas 1.1.5\n",
      "cv2 4.5.3\n",
      "PIL 8.2.0\n",
      "matplotlib 3.3.4\n",
      "torch 1.9.0\n",
      "torchvision 0.10.0\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "onnx 1.10.1\n",
      "onnxruntime 1.8.1\n",
      "tf2onnx 1.9.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p cv2,PIL,matplotlib\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard\n",
    "%watermark -p onnx,onnxruntime,tf2onnx\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        segs = x.split(' ')\n",
    "        g = globals()\n",
    "        if 'github.com' in segs[1]:\n",
    "            uri = segs[1].replace('github.com', 'raw.githubusercontent.com')\n",
    "            mod = uri.split('/')\n",
    "            for s in ['main', 'master']:\n",
    "                uri = 'https://' + '/'.join(mod[:-1]) + '/main/' + mod[-1] + '.py'\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "                    break\n",
    "        elif 'gitee.com' in segs[1]:\n",
    "            mod = segs[1].split('/')\n",
    "            for s in ['/raw/main/', '/raw/master/']:\n",
    "                uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:]) + '.py'\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "                    break\n",
    "        elif segs[1][0] == '/':\n",
    "            with open(segs[1] + '.py') as fr:\n",
    "                x = fr.read()\n",
    "        exec(x, g)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unable-velvet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:00.426874Z",
     "start_time": "2021-08-31T10:45:00.366077Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'tensorboard-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_cell_magic\n",
    "def template_writefile(line, cell):\n",
    "    with open(line, 'w') as fw:\n",
    "        fw.write(cell.format(**globals()))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    args = line.split()\n",
    "    file, port, height = args[0], int(args[1]), 600\n",
    "    if len(args) == 3:\n",
    "        height = int(args[2])\n",
    "    # res = !lsof -i:$port | grep $port\n",
    "    # if len(res) == 1:\n",
    "    #     pid = int(res[0].split(' ')[1])\n",
    "    #     !kill -9 $pid\n",
    "    import netron\n",
    "    netron.start(file, address=('0.0.0.0', port), browse=False)\n",
    "    display_html(port, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfec991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:00.485773Z",
     "start_time": "2021-08-31T10:45:00.429188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.lite.python.util import run_graph_optimizations, get_grappler_config\n",
    "import onnx\n",
    "import onnx.helper as OH\n",
    "import onnxruntime as rt\n",
    "import copy\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38538d9c",
   "metadata": {},
   "source": [
    "## Repnet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360369b",
   "metadata": {},
   "source": [
    "Repnet模型转换为onnx进行推理时, 存在两个问题:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <li> 加法算子操作输入shape不一致问题(pos_encoding)</li>\n",
    "    <li> 3D卷积(5-D)后进行BatchNormlization时, 不支持5D</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0391c63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "younger-execution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:19:00.584468Z",
     "start_time": "2021-08-31T14:19:00.449511Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers\n",
    "\n",
    "\n",
    "def get_sims(embs, temperature):\n",
    "    \"\"\"Calculates self-similarity between batch of sequence of embeddings.\"\"\"\n",
    "    batch_size = tf.shape(embs)[0]\n",
    "    seq_len = tf.shape(embs)[1]\n",
    "    embs = tf.reshape(embs, [batch_size, seq_len, -1])\n",
    "\n",
    "    def _get_sims(embs):\n",
    "        \"\"\"Calculates self-similarity between sequence of embeddings.\"\"\"\n",
    "        dist = pairwise_l2_distance(embs, embs)\n",
    "        sims = -1.0 * dist\n",
    "        return sims\n",
    "\n",
    "    sims = tf.map_fn(_get_sims, embs)\n",
    "    sims /= temperature\n",
    "    sims = tf.nn.softmax(sims, axis=-1)\n",
    "    sims = tf.expand_dims(sims, -1)\n",
    "    return sims\n",
    "\n",
    "\n",
    "def flatten_sequential_feats(x, batch_size, seq_len):\n",
    "    \"\"\"Flattens sequential features with known batch size and seq_len.\"\"\"\n",
    "    x = tf.reshape(x, [batch_size, seq_len, -1])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Transformer from https://www.tensorflow.org/tutorials/text/transformer .\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead)\n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "      Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "      Returns:\n",
    "        outputs: shape == (..., seq_len_q, depth_v)\n",
    "        attention_weights: shape == (..., seq_len_q, seq_len_k)\n",
    "      \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk.\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    # (..., seq_len_q, seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    outputs = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return outputs, attention_weights\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"Multi-headed attention layer.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(\n",
    "            q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(\n",
    "            k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(\n",
    "            v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(\n",
    "            scaled_attention,\n",
    "            perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(\n",
    "            scaled_attention,\n",
    "            (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        outputs = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return outputs, attention_weights\n",
    "\n",
    "\n",
    "class TransformerLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Implements a single transformer layer (https://arxiv.org/abs/1706.03762).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, dff,\n",
    "                 dropout_rate=0.1,\n",
    "                 reorder_ln=False):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.reorder_ln = reorder_ln\n",
    "\n",
    "    def call(self, x):\n",
    "        inp_x = x\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            x = self.layernorm1(x)\n",
    "\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        attn_output, _ = self.mha(x, x, x, mask=None)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            out1 = inp_x + attn_output\n",
    "            x = out1\n",
    "        else:\n",
    "            # (batch_size, input_seq_len, d_model)\n",
    "            out1 = self.layernorm1(x + attn_output)\n",
    "            x = out1\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            x = self.layernorm2(x)\n",
    "\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(x)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "\n",
    "        if self.reorder_ln:\n",
    "            out2 = out1 + ffn_output\n",
    "        else:\n",
    "            # (batch_size, input_seq_len, d_model)\n",
    "            out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "def pairwise_l2_distance(a, b):\n",
    "    \"\"\"Computes pairwise distances between all rows of a and all rows of b.\"\"\"\n",
    "    norm_a = tf.reduce_sum(tf.square(a), 1)\n",
    "    norm_a = tf.reshape(norm_a, [-1, 1])\n",
    "    norm_b = tf.reduce_sum(tf.square(b), 1)\n",
    "    norm_b = tf.reshape(norm_b, [1, -1])\n",
    "    dist = tf.maximum(norm_a - 2.0 * tf.matmul(a, b, False, True) + norm_b, 0.0)\n",
    "    return dist\n",
    "\n",
    "\n",
    "class ResnetPeriodEstimator(tf.keras.models.Model):\n",
    "    \"\"\"RepNet model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_frames=64,\n",
    "        image_size=112,\n",
    "        base_model_layer_name='conv4_block3_out',\n",
    "        temperature=13.544,\n",
    "        dropout_rate=0.25,\n",
    "        l2_reg_weight=1e-6,\n",
    "        temporal_conv_channels=512,\n",
    "        temporal_conv_kernel_size=3,\n",
    "        temporal_conv_dilation_rate=3,\n",
    "        conv_channels=32,\n",
    "        conv_kernel_size=3,\n",
    "        transformer_layers_config=((512, 4, 512),),\n",
    "        transformer_dropout_rate=0.0,\n",
    "        transformer_reorder_ln=True,\n",
    "        period_fc_channels=(512, 512),\n",
    "        within_period_fc_channels=(512, 512)):\n",
    "        super(ResnetPeriodEstimator, self).__init__()\n",
    "\n",
    "        # Model params.\n",
    "        self.num_frames = num_frames\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.base_model_layer_name = base_model_layer_name\n",
    "\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_reg_weight = l2_reg_weight\n",
    "\n",
    "        self.temporal_conv_channels = temporal_conv_channels\n",
    "        self.temporal_conv_kernel_size = temporal_conv_kernel_size\n",
    "        self.temporal_conv_dilation_rate = temporal_conv_dilation_rate\n",
    "\n",
    "        self.conv_channels = conv_channels\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        # Transformer config in form of (channels, heads, bottleneck channels).\n",
    "        self.transformer_layers_config = transformer_layers_config\n",
    "        self.transformer_dropout_rate = transformer_dropout_rate\n",
    "        self.transformer_reorder_ln = transformer_reorder_ln\n",
    "\n",
    "        self.period_fc_channels = period_fc_channels\n",
    "        self.within_period_fc_channels = within_period_fc_channels\n",
    "\n",
    "        # Base ResNet50 Model.\n",
    "        base_model = tf.keras.applications.ResNet50V2(\n",
    "            include_top=False, weights=None, pooling='max')\n",
    "        self.base_model = tf.keras.models.Model(\n",
    "            inputs=base_model.input,\n",
    "            outputs=base_model.get_layer(self.base_model_layer_name).output)\n",
    "\n",
    "        # 3D Conv on k Frames\n",
    "        self.temporal_conv_layers = [\n",
    "            layers.Conv3D(self.temporal_conv_channels,\n",
    "                          self.temporal_conv_kernel_size,\n",
    "                          padding='same',\n",
    "                          dilation_rate=(self.temporal_conv_dilation_rate, 1, 1),\n",
    "                          kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                          kernel_initializer='he_normal')]\n",
    "        self.temporal_bn_layers = [layers.BatchNormalization(axis=4)\n",
    "                                   for _ in self.temporal_conv_layers]\n",
    "\n",
    "        # Counting Module (Self-sim > Conv > Transformer > Classifier)\n",
    "        self.conv_3x3_layer = layers.Conv2D(self.conv_channels,\n",
    "                                            self.conv_kernel_size,\n",
    "                                            padding='same',\n",
    "                                            activation=tf.nn.relu)\n",
    "\n",
    "        channels = self.transformer_layers_config[0][0]\n",
    "        self.input_projection = layers.Dense(\n",
    "            channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "            activation=None)\n",
    "\n",
    "        self.input_projection2 = layers.Dense(\n",
    "            channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "            activation=None)\n",
    "\n",
    "        length = self.num_frames\n",
    "        self.pos_encoding = tf.compat.v1.get_variable(\n",
    "            name='resnet_period_estimator/pos_encoding',\n",
    "            shape=[1, length, 1],\n",
    "            initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "        self.pos_encoding2 = tf.compat.v1.get_variable(\n",
    "            name='resnet_period_estimator/pos_encoding2',\n",
    "            shape=[1, length, 1],\n",
    "            initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "        self.transformer_layers = []\n",
    "        for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "            self.transformer_layers.append(\n",
    "                TransformerLayer(d_model, num_heads, dff,\n",
    "                                 self.transformer_dropout_rate,\n",
    "                                 self.transformer_reorder_ln))\n",
    "\n",
    "        self.transformer_layers2 = []\n",
    "        for d_model, num_heads, dff in self.transformer_layers_config:\n",
    "            self.transformer_layers2.append(\n",
    "                TransformerLayer(d_model, num_heads, dff,\n",
    "                                 self.transformer_dropout_rate,\n",
    "                                 self.transformer_reorder_ln))\n",
    "\n",
    "        # Period Prediction Module.\n",
    "        self.dropout_layer = layers.Dropout(self.dropout_rate)\n",
    "        num_preds = self.num_frames//2\n",
    "        self.fc_layers = []\n",
    "        for channels in self.period_fc_channels:\n",
    "            self.fc_layers.append(layers.Dense(\n",
    "                channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                activation=tf.nn.relu))\n",
    "        self.fc_layers.append(layers.Dense(\n",
    "            num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "        # Within Period Module\n",
    "        num_preds = 1\n",
    "        self.within_period_fc_layers = []\n",
    "        for channels in self.within_period_fc_channels:\n",
    "            self.within_period_fc_layers.append(layers.Dense(\n",
    "                channels, kernel_regularizer=regularizers.l2(self.l2_reg_weight),\n",
    "                activation=tf.nn.relu))\n",
    "        self.within_period_fc_layers.append(layers.Dense(\n",
    "            num_preds, kernel_regularizer=regularizers.l2(self.l2_reg_weight)))\n",
    "\n",
    "    def call(self, x):\n",
    "        # Ensures we are always using the right batch_size during train/eval.\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        # Conv Feature Extractor.\n",
    "        x = tf.reshape(x, [-1, self.image_size, self.image_size, 3])\n",
    "        x = self.base_model(x)\n",
    "        h = tf.shape(x)[1]\n",
    "        w = tf.shape(x)[2]\n",
    "        c = tf.shape(x)[3]\n",
    "        x = tf.reshape(x, [batch_size, -1, h, w, c])\n",
    "\n",
    "        # 3D Conv to give temporal context to per-frame embeddings. \n",
    "        for bn_layer, conv_layer in zip(self.temporal_bn_layers,\n",
    "                                        self.temporal_conv_layers):\n",
    "            x = conv_layer(x)\n",
    "            x = bn_layer(x)\n",
    "            x = tf.nn.relu(x)\n",
    "            \n",
    "        x = tf.reshape(x, (batch_size, self.num_frames, 7, 7, -1))\n",
    "    \n",
    "        x = tf.reduce_max(x, [2, 3])\n",
    "\n",
    "        # Reshape and prepare embs for output.\n",
    "        final_embs = x\n",
    "\n",
    "        # Get self-similarity matrix.\n",
    "        x = get_sims(x, self.temperature)\n",
    "\n",
    "        # 3x3 conv layer on self-similarity matrix.\n",
    "        x = self.conv_3x3_layer(x)\n",
    "        x = tf.reshape(x, [batch_size, self.num_frames, -1])\n",
    "        within_period_x = x\n",
    "\n",
    "        # Period prediction.\n",
    "        x = self.input_projection(x)\n",
    "        x += self.pos_encoding\n",
    "        for transformer_layer in self.transformer_layers:\n",
    "            x = transformer_layer(x)\n",
    "        x = flatten_sequential_feats(x, batch_size, self.num_frames)\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = self.dropout_layer(x)\n",
    "            x = fc_layer(x)\n",
    "\n",
    "        # Within period prediction.\n",
    "        within_period_x = self.input_projection2(within_period_x)\n",
    "        within_period_x += self.pos_encoding2\n",
    "        for transformer_layer in self.transformer_layers2:\n",
    "            within_period_x = transformer_layer(within_period_x)\n",
    "        within_period_x = flatten_sequential_feats(within_period_x,\n",
    "                                                   batch_size,\n",
    "                                                   self.num_frames)\n",
    "        for fc_layer in self.within_period_fc_layers:\n",
    "            within_period_x = self.dropout_layer(within_period_x)\n",
    "            within_period_x = fc_layer(within_period_x)\n",
    "\n",
    "        return x, within_period_x, final_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f2ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T07:04:02.633001Z",
     "start_time": "2021-08-31T07:04:02.349943Z"
    }
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rocky-investigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T02:08:23.538673Z",
     "start_time": "2021-09-01T02:08:19.611372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 1)\n",
      "tf.Tensor([0.01174744], shape=(1,), dtype=float32)\n",
      "--------------------\n",
      "(1, 64, 512)\n",
      "tf.Tensor(\n",
      "[0.02054866 0.02054866 0.02054866 0.02054866 0.02054866 0.02054866\n",
      " 0.02054866 0.02054866 0.02054866 0.02054866], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "print(model.pos_encoding.shape)\n",
    "print(model.pos_encoding[0][0][:10])\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt.restore('/data/pretrained/cv/repnet/ckpt-88').expect_partial()\n",
    "print('-'*20)\n",
    "model.pos_encoding = tf.tile(model.pos_encoding, multiples=[1, 1, 512])\n",
    "model.pos_encoding2 = tf.tile(model.pos_encoding2, multiples=[1, 1, 512])\n",
    "print(model.pos_encoding.shape)\n",
    "print(model.pos_encoding[0][0][:10])\n",
    "test_inputs = np.random.randn(2, 64, 112, 112, 3).astype(np.float32)\n",
    "test_inputs_tensor = tf.convert_to_tensor(test_inputs)\n",
    "test_outputs = model(test_inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5d3480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T02:08:26.022357Z",
     "start_time": "2021-09-01T02:08:25.960425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 64, 32]), TensorShape([2, 64, 1]), TensorShape([2, 64, 512]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs[0].shape, test_outputs[1].shape, test_outputs[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411d10f",
   "metadata": {},
   "source": [
    "### Simple Conv3D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e74e0c7",
   "metadata": {},
   "source": [
    "tool | version\n",
    "---: | :---:\n",
    "tensorflow | 2.6.0\n",
    "tensorboard | 2.6.0\n",
    "onnx | 1.10.1\n",
    "onnxruntime | 1.8.1\n",
    "tf2onnx | 1.9.2\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "针对上面版本, 转换onnx格式时, BatchNormalization会和Transpose操作融合为FusedBatchNormV3, Transpose的dim参数让人疑惑\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7950928d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:00:41.204434Z",
     "start_time": "2021-08-31T14:00:40.230917Z"
    }
   },
   "outputs": [],
   "source": [
    "model3d = tf.keras.models.Sequential([\n",
    "    layers.Conv3D(\n",
    "        512, 3, padding='same',\n",
    "        dilation_rate=(3, 1, 1),\n",
    "        kernel_regularizer=regularizers.l2(1e-6),\n",
    "        kernel_initializer='he_normal'),\n",
    "    layers.BatchNormalization(axis=1),\n",
    "    layers.ReLU()\n",
    "])\n",
    "\n",
    "inputs3d = np.random.randn(2, 64, 7, 7, 1024).astype(np.float32)\n",
    "outputs3d = model3d(inputs3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0245077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:00:43.416288Z",
     "start_time": "2021-08-31T14:00:42.301130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models3d/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model3d_path = '/data/nb_data/saved_models3d'\n",
    "model3d.save(saved_model3d_path, save_format='tf', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f65e8dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:01:03.945889Z",
     "start_time": "2021-08-31T14:00:44.382647Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-09-01 19:35:50,051 - INFO - Signatures found in model: [serving_default].\n",
      "2021-09-01 19:35:50,051 - INFO - Output names: ['re_lu']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:35:51,904 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:35:53,287 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-09-01 19:35:53,287 - INFO - Using opset <onnx, 14>\n",
      "2021-09-01 19:36:00,509 - INFO - Computed 0 values for constant folding\n",
      "2021-09-01 19:36:05,483 - INFO - Optimizing ONNX model\n",
      "2021-09-01 19:36:05,796 - INFO - After optimization: Const -2 (5->3), Identity -6 (6->0)\n",
      "2021-09-01 19:36:05,946 - INFO - \n",
      "2021-09-01 19:36:05,946 - INFO - Successfully converted TensorFlow model /data/nb_data/saved_models3d to ONNX\n",
      "2021-09-01 19:36:05,947 - INFO - Model inputs: ['conv3d_1_input']\n",
      "2021-09-01 19:36:05,947 - INFO - Model outputs: ['re_lu']\n",
      "2021-09-01 19:36:05,947 - INFO - ONNX model is saved at /data/nb_data/saved_models3d/saved_model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 14 \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {saved_model3d_path} --output {saved_model3d_path}/saved_model.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81907ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:01:09.203110Z",
     "start_time": "2021-08-31T14:01:08.879980Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/saved_models3d/saved_model.onnx' at http://0.0.0.0:8123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='tensorboard-frame-69e37acee960e4c6' width='100%' height='400' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-69e37acee960e4c6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8123;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {saved_model3d_path}/saved_model.onnx 8123 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c28bc36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T14:01:14.001751Z",
     "start_time": "2021-08-31T14:01:12.805542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 64, 7, 7, 512), TensorShape([64, 7, 7, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = rt.InferenceSession(f'{saved_model3d_path}/saved_model.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: inputs3d}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "predictions = sess.run(outputs, inputs)\n",
    "predictions[-1].shape, outputs3d[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739203af",
   "metadata": {},
   "source": [
    "## Frozen Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a963c7ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:30:50.980124Z",
     "start_time": "2021-08-31T10:30:46.937974Z"
    }
   },
   "outputs": [],
   "source": [
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(tf.TensorSpec(test_inputs.shape, test_inputs.dtype))\n",
    "frozen_func = convert_variables_to_constants_v2(full_model, lower_control_flow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e3e5f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T09:55:35.177872Z",
     "start_time": "2021-08-31T09:55:35.114636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['add_gradient_functions_to_graph',\n",
       "  'add_to_graph',\n",
       "  'captured_inputs',\n",
       "  'function_def',\n",
       "  'graph',\n",
       "  'inputs',\n",
       "  'name',\n",
       "  'output_dtypes',\n",
       "  'output_shapes',\n",
       "  'outputs',\n",
       "  'pretty_printed_signature',\n",
       "  'prune',\n",
       "  'structured_input_signature',\n",
       "  'structured_outputs',\n",
       "  'trainable_variables',\n",
       "  'variables'],\n",
       " '------------------------------------------------------------',\n",
       " [<tf.Tensor 'x:0' shape=(2, 64, 112, 112, 3) dtype=float32>],\n",
       " [<tf.Tensor 'Identity:0' shape=(2, 64, 32) dtype=float32>,\n",
       "  <tf.Tensor 'Identity_1:0' shape=(2, 64, 1) dtype=float32>,\n",
       "  <tf.Tensor 'Identity_2:0' shape=(None, 64, None) dtype=float32>])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ x for x in dir(frozen_func) if x[0] != '_'], '-' * 60, \\\n",
    "frozen_func.inputs, frozen_func.outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f2dda0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T09:55:35.244732Z",
     "start_time": "2021-08-31T09:55:35.180147Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['add_capture',\n",
       "  'add_to_collection',\n",
       "  'add_to_collections',\n",
       "  'as_default',\n",
       "  'as_graph_def',\n",
       "  'as_graph_element',\n",
       "  'building_function',\n",
       "  'capture',\n",
       "  'capture_by_value',\n",
       "  'capture_call_time_value',\n",
       "  'capture_distributed_variable',\n",
       "  'capture_eager_tensor',\n",
       "  'captured',\n",
       "  'captures',\n",
       "  'clear_captures',\n",
       "  'clear_collection',\n",
       "  'collections',\n",
       "  'colocate_with',\n",
       "  'container',\n",
       "  'control_captures',\n",
       "  'control_dependencies',\n",
       "  'control_outputs',\n",
       "  'create_op',\n",
       "  'deferred_external_captures',\n",
       "  'deferred_internal_captures',\n",
       "  'device',\n",
       "  'external_captures',\n",
       "  'finalize',\n",
       "  'finalized',\n",
       "  'get_all_collection_keys',\n",
       "  'get_collection',\n",
       "  'get_collection_ref',\n",
       "  'get_name_scope',\n",
       "  'get_operation_by_name',\n",
       "  'get_operations',\n",
       "  'get_tensor_by_name',\n",
       "  'gradient_override_map',\n",
       "  'graph_def_versions',\n",
       "  'inputs',\n",
       "  'internal_captures',\n",
       "  'is_control_flow_graph',\n",
       "  'is_feedable',\n",
       "  'is_fetchable',\n",
       "  'mark_as_unsaveable',\n",
       "  'name',\n",
       "  'name_scope',\n",
       "  'outer_graph',\n",
       "  'output_shapes',\n",
       "  'output_types',\n",
       "  'outputs',\n",
       "  'pop_capture',\n",
       "  'prevent_feeding',\n",
       "  'prevent_fetching',\n",
       "  'replace_capture',\n",
       "  'reset_captures',\n",
       "  'saveable',\n",
       "  'saving_errors',\n",
       "  'seed',\n",
       "  'structured_input_signature',\n",
       "  'structured_outputs',\n",
       "  'switch_to_thread_local',\n",
       "  'trainable_variables',\n",
       "  'unique_name',\n",
       "  'variable_captures',\n",
       "  'variables',\n",
       "  'version',\n",
       "  'watch_variable'],\n",
       " '------------------------------------------------------------',\n",
       " [<tf.Tensor 'x:0' shape=(2, 64, 112, 112, 3) dtype=float32>],\n",
       " [<tf.Tensor 'Identity:0' shape=(2, 64, 32) dtype=float32>,\n",
       "  <tf.Tensor 'Identity_1:0' shape=(2, 64, 1) dtype=float32>,\n",
       "  <tf.Tensor 'Identity_2:0' shape=(None, 64, None) dtype=float32>])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ x for x in dir(frozen_func.graph) if x[0] != '_'], '-' * 60, \\\n",
    "frozen_func.graph.inputs, frozen_func.graph.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ecc089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:07.271986Z",
     "start_time": "2021-08-31T10:29:06.867092Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ByteSize',\n",
       " 'Clear',\n",
       " 'ClearExtension',\n",
       " 'ClearField',\n",
       " 'CopyFrom',\n",
       " 'DESCRIPTOR',\n",
       " 'DiscardUnknownFields',\n",
       " 'Extensions',\n",
       " 'FindInitializationErrors',\n",
       " 'FromString',\n",
       " 'HasExtension',\n",
       " 'HasField',\n",
       " 'IsInitialized',\n",
       " 'ListFields',\n",
       " 'MergeFrom',\n",
       " 'MergeFromString',\n",
       " 'ParseFromString',\n",
       " 'RegisterExtension',\n",
       " 'SerializePartialToString',\n",
       " 'SerializeToString',\n",
       " 'SetInParent',\n",
       " 'UnknownFields',\n",
       " 'WhichOneof',\n",
       " 'library',\n",
       " 'node',\n",
       " 'version',\n",
       " 'versions']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_graph_def = frozen_func.graph.as_graph_def()\n",
    "[ x for x in dir(frozen_graph_def) if x[0] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91f9e30e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T09:55:35.699933Z",
     "start_time": "2021-08-31T09:55:35.635282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colocation_groups',\n",
       " 'control_inputs',\n",
       " 'device',\n",
       " 'get_attr',\n",
       " 'graph',\n",
       " 'inputs',\n",
       " 'name',\n",
       " 'node_def',\n",
       " 'op_def',\n",
       " 'outputs',\n",
       " 'run',\n",
       " 'traceback',\n",
       " 'type',\n",
       " 'values']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operations = frozen_func.graph.get_operations()\n",
    "[ x for x in dir(operations[590]) if x[0] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bc8f28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T09:55:36.088460Z",
     "start_time": "2021-08-31T09:55:36.016567Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  580 resnet_period_estimator/model/conv4_block2_preact_bn/FusedBatchNormV3/ReadVariableOp\n",
      "  581 resnet_period_estimator/model/conv4_block2_preact_bn/ReadVariableOp_1/resource\n",
      "  582 resnet_period_estimator/model/conv4_block2_preact_bn/ReadVariableOp_1\n",
      "  583 resnet_period_estimator/model/conv4_block2_preact_bn/ReadVariableOp/resource\n",
      "  584 resnet_period_estimator/model/conv4_block2_preact_bn/ReadVariableOp\n",
      "  585 resnet_period_estimator/model/conv4_block1_3_conv/BiasAdd/ReadVariableOp/resource\n",
      "  586 resnet_period_estimator/model/conv4_block1_3_conv/BiasAdd/ReadVariableOp\n",
      "  587 resnet_period_estimator/model/conv4_block1_3_conv/Conv2D/ReadVariableOp/resource\n",
      "  588 resnet_period_estimator/model/conv4_block1_3_conv/Conv2D/ReadVariableOp\n",
      "  589 resnet_period_estimator/model/conv4_block1_0_conv/BiasAdd/ReadVariableOp/resource\n",
      "  590 resnet_period_estimator/model/conv4_block1_0_conv/BiasAdd/ReadVariableOp\n",
      "  591 resnet_period_estimator/model/conv3_block4_preact_bn/ReadVariableOp_1/resource\n",
      "  592 resnet_period_estimator/model/conv3_block4_preact_bn/ReadVariableOp_1\n",
      "  593 resnet_period_estimator/model/conv3_block4_preact_bn/ReadVariableOp/resource\n",
      "  594 resnet_period_estimator/model/conv3_block4_preact_bn/ReadVariableOp\n"
     ]
    }
   ],
   "source": [
    "for i, op in enumerate(operations[580: 595], 580):\n",
    "    print('%5d' % i, op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da7223b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T09:55:36.159392Z",
     "start_time": "2021-08-31T09:55:36.091096Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"resnet_period_estimator/model/conv4_block1_0_conv/BiasAdd/ReadVariableOp\"\n",
      "op: \"Identity\"\n",
      "input: \"resnet_period_estimator/model/conv4_block1_0_conv/BiasAdd/ReadVariableOp/resource\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(operations[590])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cb7a8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:23:58.909599Z",
     "start_time": "2021-08-31T10:23:55.630784Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_tensors = [x for x in frozen_func.inputs if x.dtype != tf.resource]\n",
    "# output_tensors = frozen_func.outputs\n",
    "# \n",
    "# config = [\n",
    "#     'pruning', 'function', 'constfold', 'shape', 'remap', 'memory',\n",
    "#     'common_subgraph_elimination', 'arithmetic', 'loop', 'dependency', 'debug_stripper'\n",
    "# ]\n",
    "# \n",
    "# frozen_graph_def = run_graph_optimizations(\n",
    "#     frozen_graph_def,\n",
    "#     input_tensors,\n",
    "#     output_tensors,\n",
    "#     config=get_grappler_config(config),\n",
    "#     graph=frozen_func.graph\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1edf6f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:53.730937Z",
     "start_time": "2021-08-31T10:29:19.717963Z"
    }
   },
   "outputs": [],
   "source": [
    "as_text = False\n",
    "frozen_graph_proto_path = tf.io.write_graph(\n",
    "    graph_or_graph_def=frozen_graph_def,\n",
    "    logdir='/data/nb_data/frozen_models',\n",
    "    name='frozen_graph.pb%s' % ('txt' if as_text else ''),\n",
    "    as_text=as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6cf7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:53.730937Z",
     "start_time": "2021-08-31T10:29:19.717963Z"
    }
   },
   "outputs": [],
   "source": [
    "# %netron {frozen_graph_proto_path} 8121 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b199d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:53.730937Z",
     "start_time": "2021-08-31T10:29:19.717963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:305: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "2021-09-01 19:36:19,319 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:305: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:927: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:36:19,320 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:927: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:36:21,538 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-09-01 19:36:21,538 - INFO - Using opset <onnx, 14>\n",
      "2021-09-01 19:36:36,672 - INFO - Computed 0 values for constant folding\n",
      "2021-09-01 19:36:45,241 - INFO - Optimizing ONNX model\n",
      "2021-09-01 19:36:48,537 - INFO - After optimization: Add -2 (47->45), BatchNormalization -20 (31->11), Cast -63 (66->3), Const -133 (325->192), GlobalAveragePool +8 (0->8), Identity -45 (47->2), Less -1 (4->3), ReduceMean -8 (8->0), Reshape -11 (58->47), Transpose -137 (152->15)\n",
      "2021-09-01 19:36:48,939 - INFO - \n",
      "2021-09-01 19:36:48,940 - INFO - Successfully converted TensorFlow model /data/nb_data/frozen_models/frozen_graph.pb to ONNX\n",
      "2021-09-01 19:36:48,940 - INFO - Model inputs: ['x:0']\n",
      "2021-09-01 19:36:48,940 - INFO - Model outputs: ['Identity:0', 'Identity_1:0', 'Identity_2:0']\n",
      "2021-09-01 19:36:48,941 - INFO - ONNX model is saved at /data/nb_data/frozen_models/frozen_graph.pb.onnx\n"
     ]
    }
   ],
   "source": [
    "inputs = ','.join([x.name for x in frozen_func.inputs])\n",
    "outputs = ','.join([x.name for x in frozen_func.outputs])\n",
    "\n",
    "!python3 -m tf2onnx.convert --opset 14 --input {frozen_graph_proto_path} \\\n",
    "    --inputs {inputs} --outputs {outputs} --output {frozen_graph_proto_path}.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed96c133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:26:50.736798Z",
     "start_time": "2021-08-31T10:26:50.621633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/frozen_models/frozen_graph.pb.onnx' at http://0.0.0.0:8121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='tensorboard-frame-9c7b112d8947b388' width='100%' height='600' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9c7b112d8947b388\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8121;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {frozen_graph_proto_path}.onnx 8121 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04b81c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:30:00.867656Z",
     "start_time": "2021-08-31T10:30:00.332084Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Op registered for TensorListReserve with domain_version of 14\n",
      "\n",
      "==> Context: Bad node spec for node. Name: resnet_period_estimator/map/TensorArrayV2_1 OpType: TensorListReserve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['ByteSize',\n",
       "  'Clear',\n",
       "  'ClearExtension',\n",
       "  'ClearField',\n",
       "  'CopyFrom',\n",
       "  'DESCRIPTOR',\n",
       "  'DiscardUnknownFields',\n",
       "  'Extensions',\n",
       "  'FindInitializationErrors',\n",
       "  'FromString',\n",
       "  'HasExtension',\n",
       "  'HasField',\n",
       "  'IsInitialized',\n",
       "  'ListFields',\n",
       "  'MergeFrom',\n",
       "  'MergeFromString',\n",
       "  'ParseFromString',\n",
       "  'RegisterExtension',\n",
       "  'SerializePartialToString',\n",
       "  'SerializeToString',\n",
       "  'SetInParent',\n",
       "  'UnknownFields',\n",
       "  'WhichOneof',\n",
       "  'doc_string',\n",
       "  'initializer',\n",
       "  'input',\n",
       "  'name',\n",
       "  'node',\n",
       "  'output',\n",
       "  'quantization_annotation',\n",
       "  'sparse_initializer',\n",
       "  'value_info'],\n",
       " '------------------------------------------------------------',\n",
       " [name: \"x:0\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 2\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 112\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 3\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " '------------------------------------------------------------',\n",
       " [name: \"Identity:0\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 2\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 32\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " , name: \"Identity_1:0\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 2\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " , name: \"Identity_2:0\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 2\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model = onnx.load(f'{frozen_graph_proto_path}.onnx')\n",
    "try:\n",
    "    onnx.checker.check_model(onnx_model, full_check=True) \n",
    "except Exception as err:\n",
    "    print(err)\n",
    "graph_def = onnx_model.graph\n",
    "[x for x in dir(graph_def) if x[0] != '_'], '-'*60, graph_def.input, '-'*60, graph_def.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db0e2cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:29:53.730937Z",
     "start_time": "2021-08-31T10:29:19.717963Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 input: \"resnet_period_estimator/Reshape_1:0\"\n",
      "output: \"resnet_period_estimator/conv3d/Conv3D__174:0\"\n",
      "name: \"resnet_period_estimator/conv3d/Conv3D__174\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 4\n",
      "  ints: 1\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "   96 input: \"resnet_period_estimator/conv3d/Conv3D__174:0\"\n",
      "input: \"resnet_period_estimator/conv3d/Conv3D/ReadVariableOp:0\"\n",
      "input: \"resnet_period_estimator/conv3d/BiasAdd/ReadVariableOp:0\"\n",
      "output: \"Conv__281:0\"\n",
      "name: \"Conv__281\"\n",
      "op_type: \"Conv\"\n",
      "attribute {\n",
      "  name: \"dilations\"\n",
      "  ints: 3\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"strides\"\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"kernel_shape\"\n",
      "  ints: 3\n",
      "  ints: 3\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"pads\"\n",
      "  ints: 3\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  ints: 3\n",
      "  ints: 1\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "attribute {\n",
      "  name: \"group\"\n",
      "  i: 1\n",
      "  type: INT\n",
      "}\n",
      "domain: \"\"\n",
      "\n",
      "   97 input: \"Conv__281:0\"\n",
      "output: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3__176:0\"\n",
      "name: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3__176\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 4\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "   98 input: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3__176:0\"\n",
      "input: \"resnet_period_estimator/batch_normalization/ReadVariableOp:0\"\n",
      "input: \"resnet_period_estimator/batch_normalization/ReadVariableOp_1:0\"\n",
      "input: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3/ReadVariableOp:0\"\n",
      "input: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3/ReadVariableOp_1:0\"\n",
      "output: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3:0\"\n",
      "name: \"resnet_period_estimator/batch_normalization/FusedBatchNormV3\"\n",
      "op_type: \"BatchNormalization\"\n",
      "attribute {\n",
      "  name: \"epsilon\"\n",
      "  f: 0.0010000000474974513\n",
      "  type: FLOAT\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(graph_def.node[95:99], 95):\n",
    "    print('%5d' % i, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee708dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:17.739861Z",
     "start_time": "2021-09-01T07:34:16.979480Z"
    }
   },
   "source": [
    "## Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4a8766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:17.739861Z",
     "start_time": "2021-09-01T07:34:16.979480Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as multi_head_attention_layer_call_fn, multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn, layer_normalization_layer_call_and_return_conditional_losses, layer_normalization_1_layer_call_fn while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/saved_models/assets\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = '/data/nb_data/saved_models'\n",
    "model.save(saved_model_path, save_format='tf', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d691576b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:17.739861Z",
     "start_time": "2021-09-01T07:34:16.979480Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-09-01 19:37:37,344 - INFO - tf2onnx.tf_loader: Signatures found in model: [serving_default].\n",
      "2021-09-01 19:37:37,346 - INFO - tf2onnx.tf_loader: Output names: ['output_1', 'output_2', 'output_3']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:37:42,471 - WARNING - tensorflow: From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-09-01 19:37:44,949 - INFO - tf2onnx: inputs: ['input_1:0']\n",
      "2021-09-01 19:37:45,036 - INFO - tf2onnx: outputs: ['Identity:0', 'Identity_1:0', 'Identity_2:0']\n",
      "2021-09-01 19:37:45,620 - INFO - tf2onnx.tfonnx: Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
      "2021-09-01 19:37:45,620 - INFO - tf2onnx.tfonnx: Using opset <onnx, 14>\n",
      "2021-09-01 19:37:52,669 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding\n",
      "2021-09-01 19:37:52,681 - INFO - tf2onnx.tf_utils: Computed 0 values for constant folding\n",
      "2021-09-01 19:37:57,997 - INFO - tf2onnx.tf_utils: Computed 4 values for constant folding\n",
      "2021-09-01 19:38:05,282 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator/strided_slice_1\n",
      "2021-09-01 19:38:05,283 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator/strided_slice_2\n",
      "2021-09-01 19:38:05,283 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator/strided_slice_3\n",
      "2021-09-01 19:38:05,283 - INFO - tf2onnx.tfonnx: folding node using tf type=StridedSlice, name=StatefulPartitionedCall/resnet_period_estimator/strided_slice_5\n",
      "2021-09-01 19:38:05,309 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-09-01 19:38:05,316 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 10, 'Identity': 8, 'Placeholder': 6, 'AddV2': 3, 'Square': 2, 'Sum': 2, 'Mul': 2, 'Reshape': 2, 'TensorListGetItem': 1, 'MatMul': 1, 'Sub': 1, 'Maximum': 1, 'TensorListSetItem': 1})\n",
      "\ttensorflow attr: Counter({'dtype': 16, 'value': 10, 'shape': 6, 'element_dtype': 2, 'Tidx': 2, 'keep_dims': 2, 'transpose_a': 1, 'transpose_b': 1})\n",
      "\tonnx mapped: Counter({'Const': 10, 'Placeholder': 6, 'Identity': 4, 'AddV2': 3, 'Square': 2, 'Sum': 2, 'Reshape': 2, 'Mul': 2, 'TensorListGetItem': 1, 'MatMul': 1, 'Sub': 1, 'Maximum': 1, 'TensorListSetItem': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-09-01 19:38:05,321 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-09-01 19:38:05,323 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Placeholder': 6, 'Less': 2, 'Identity': 2, 'LogicalAnd': 1})\n",
      "\ttensorflow attr: Counter({'dtype': 6, 'shape': 5})\n",
      "\tonnx mapped: Counter({'Placeholder': 6, 'Less': 2, 'LogicalAnd': 1, 'Identity': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-09-01 19:38:05,839 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)\n",
      "2021-09-01 19:38:07,011 - VERBOSE - tf2onnx.tfonnx: Summay Stats:\n",
      "\ttensorflow ops: Counter({'Const': 582, 'Reshape': 55, 'Identity': 47, 'Pack': 43, 'GatherV2': 40, 'Prod': 40, 'Relu': 38, 'Conv2D': 35, 'BiasAdd': 34, 'Shape': 32, 'FusedBatchNormV3': 31, 'AddV2': 26, 'ConcatV2': 20, 'MatMul': 20, 'StridedSlice': 16, 'Mul': 13, 'Pad': 12, 'Mean': 8, 'Transpose': 8, 'Sub': 5, 'StopGradient': 4, 'SquaredDifference': 4, 'Rsqrt': 4, 'BatchMatMulV2': 4, 'NoOp': 3, 'MaxPool': 3, 'Softmax': 3, 'FloorMod': 2, 'Cast': 2, 'Sqrt': 2, 'RealDiv': 2, 'Placeholder': 1, 'SpaceToBatchND': 1, 'Conv3D': 1, 'BatchToSpaceND': 1, 'Max': 1, 'TensorListFromTensor': 1, 'TensorListReserve': 1, 'StatelessWhile': 1, 'TensorListStack': 1, 'ExpandDims': 1})\n",
      "\ttensorflow attr: Counter({'value': 582, 'dtype': 579, 'data_format': 104, 'Tidx': 69, 'N': 63, 'keep_dims': 49, 'axis': 43, 'batch_dims': 40, 'padding': 39, 'strides': 39, 'explicit_paddings': 38, 'dilations': 36, 'out_type': 32, 'epsilon': 31, 'exponential_avg_factor': 31, 'is_training': 31, 'transpose_a': 20, 'transpose_b': 20, 'begin_mask': 16, 'ellipsis_mask': 16, 'end_mask': 16, 'new_axis_mask': 16, 'shrink_axis_mask': 16, 'adj_x': 4, 'adj_y': 4, 'ksize': 3, 'element_dtype': 3, '_acd_function_control_output': 2, 'Truncate': 2, 'to': 2, 'shape': 1, '_read_only_resource_inputs': 1, '_stateful_parallelism': 1, 'body': 1, 'cond': 1, 'num_elements': 1})\n",
      "\tonnx mapped: Counter({'Const': 511, 'Reshape': 55, 'Identity': 44, 'Pack': 43, 'GatherV2': 40, 'Prod': 40, 'Relu': 38, 'FusedBatchNormV3': 31, 'Shape': 28, 'AddV2': 26, 'Conv2D': 24, 'BiasAdd': 20, 'ConcatV2': 20, 'MatMul': 20, 'StridedSlice': 16, 'Mul': 13, 'Mean': 8, 'Transpose': 8, 'Sub': 5, 'StopGradient': 4, 'SquaredDifference': 4, 'Rsqrt': 4, 'BatchMatMulV2': 4, 'MaxPool': 3, 'Softmax': 3, 'FloorMod': 2, 'Cast': 2, 'Sqrt': 2, 'RealDiv': 2, 'Placeholder': 1, 'Pad': 1, 'SpaceToBatchND': 1, 'Conv3D': 1, 'BatchToSpaceND': 1, 'Max': 1, 'TensorListFromTensor': 1, 'TensorListReserve': 1, 'StatelessWhile': 1, 'TensorListStack': 1, 'ExpandDims': 1})\n",
      "\tonnx unmapped: Counter()\n",
      "2021-09-01 19:38:07,011 - INFO - tf2onnx.optimizer: Optimizing ONNX model\n",
      "2021-09-01 19:38:07,020 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-09-01 19:38:07,635 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: Add -1 (48->47), Concat +1 (69->70), Const -167 (723->556), Gather +2 (42->44), Identity -1 (69->68), Placeholder -1 (6->5), Reshape +1 (70->71), Shape +1 (32->33), Split +1 (0->1), Transpose -133 (158->25)\n",
      "2021-09-01 19:38:07,635 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-09-01 19:38:07,824 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-09-01 19:38:07,824 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-09-01 19:38:08,070 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -7 (102->95), Concat -1 (70->69), Const -48 (556->508), Reshape -4 (71->67), Split -1 (1->0), Transpose -1 (25->24), Unsqueeze -44 (114->70)\n",
      "2021-09-01 19:38:08,070 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-09-01 19:38:09,103 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-09-01 19:38:09,104 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-09-01 19:38:09,288 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-09-01 19:38:09,289 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-09-01 19:38:10,252 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Cast -23 (95->72), Concat -16 (69->53), Const -235 (508->273), Gather -10 (44->34), ReduceProd -10 (40->30), Shape -7 (33->26), Unsqueeze -20 (70->50)\n",
      "2021-09-01 19:38:10,252 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-09-01 19:38:10,405 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: Const +1 (273->274), Gather -1 (34->33), Shape -1 (26->25), Unsqueeze +1 (50->51)\n",
      "2021-09-01 19:38:10,406 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-09-01 19:38:10,551 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: GlobalAveragePool +8 (0->8), ReduceMean -8 (8->0)\n",
      "2021-09-01 19:38:10,551 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-09-01 19:38:10,696 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-09-01 19:38:10,696 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-09-01 19:38:11,105 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Const -1 (274->273), Identity -68 (68->0)\n",
      "2021-09-01 19:38:11,105 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-09-01 19:38:11,287 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: BatchNormalization -20 (31->11), Const -60 (273->213), Squeeze -13 (18->5), Unsqueeze -13 (51->38)\n",
      "2021-09-01 19:38:11,287 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 19:38:11,407 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-09-01 19:38:11,407 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-09-01 19:38:11,552 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-09-01 19:38:11,552 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-09-01 19:38:11,667 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-09-01 19:38:11,667 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-09-01 19:38:11,795 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: Cast -2 (72->70), Const +2 (213->215)\n",
      "2021-09-01 19:38:11,795 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-09-01 19:38:11,916 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-09-01 19:38:11,916 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-09-01 19:38:12,033 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-09-01 19:38:12,033 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-09-01 19:38:12,427 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Cast -1 (70->69), Const -2 (215->213), Less -1 (4->3), Reshape -5 (67->62)\n",
      "2021-09-01 19:38:12,427 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-09-01 19:38:12,565 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: Cast -15 (69->54), Concat -15 (53->38), Const +17 (213->230), Gather -15 (33->18), ReduceProd -30 (30->0), Squeeze +3 (5->8), Unsqueeze -30 (38->8)\n",
      "2021-09-01 19:38:12,565 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-09-01 19:38:12,668 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-09-01 19:38:12,668 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-09-01 19:38:12,928 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-09-01 19:38:12,928 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-09-01 19:38:13,037 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-09-01 19:38:13,037 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-09-01 19:38:13,159 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-09-01 19:38:13,160 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-09-01 19:38:13,279 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-09-01 19:38:13,279 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-09-01 19:38:13,428 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-09-01 19:38:13,428 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-09-01 19:38:13,546 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-09-01 19:38:13,546 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-09-01 19:38:13,666 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2021-09-01 19:38:13,666 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-09-01 19:38:13,779 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-09-01 19:38:13,779 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-09-01 19:38:13,882 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-09-01 19:38:13,883 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-09-01 19:38:14,173 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Const -16 (230->214)\n",
      "2021-09-01 19:38:14,173 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-09-01 19:38:14,281 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2021-09-01 19:38:14,281 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-09-01 19:38:14,532 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-09-01 19:38:14,533 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-09-01 19:38:14,639 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-09-01 19:38:14,640 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-09-01 19:38:14,747 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-09-01 19:38:14,748 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-09-01 19:38:14,879 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-09-01 19:38:14,879 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-09-01 19:38:14,992 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-09-01 19:38:14,993 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose\n",
      "2021-09-01 19:38:15,121 - VERBOSE - tf2onnx.optimizer.TransposeOptimizer: no change\n",
      "2021-09-01 19:38:15,121 - VERBOSE - tf2onnx.optimizer: Apply remove_redundant_upsample\n",
      "2021-09-01 19:38:15,229 - VERBOSE - tf2onnx.optimizer.UpsampleOptimizer: no change\n",
      "2021-09-01 19:38:15,229 - VERBOSE - tf2onnx.optimizer: Apply fold_constants\n",
      "2021-09-01 19:38:15,333 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change\n",
      "2021-09-01 19:38:15,333 - VERBOSE - tf2onnx.optimizer: Apply const_dequantize_optimizer\n",
      "2021-09-01 19:38:15,434 - VERBOSE - tf2onnx.optimizer.ConstDequantizeOptimizer: no change\n",
      "2021-09-01 19:38:15,435 - VERBOSE - tf2onnx.optimizer: Apply loop_optimizer\n",
      "2021-09-01 19:38:15,537 - VERBOSE - tf2onnx.optimizer.LoopOptimizer: no change\n",
      "2021-09-01 19:38:15,537 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication\n",
      "2021-09-01 19:38:15,735 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: no change\n",
      "2021-09-01 19:38:15,736 - VERBOSE - tf2onnx.optimizer: Apply reshape_optimizer\n",
      "2021-09-01 19:38:15,839 - VERBOSE - tf2onnx.optimizer.ReshapeOptimizer: no change\n",
      "2021-09-01 19:38:15,839 - VERBOSE - tf2onnx.optimizer: Apply global_pool_optimizer\n",
      "2021-09-01 19:38:16,110 - VERBOSE - tf2onnx.optimizer.GlobalPoolOptimizer: no change\n",
      "2021-09-01 19:38:16,111 - VERBOSE - tf2onnx.optimizer: Apply q_dq_optimizer\n",
      "2021-09-01 19:38:16,231 - VERBOSE - tf2onnx.optimizer.QDQOptimizer: no change\n",
      "2021-09-01 19:38:16,232 - VERBOSE - tf2onnx.optimizer: Apply remove_identity\n",
      "2021-09-01 19:38:16,345 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: no change\n",
      "2021-09-01 19:38:16,345 - VERBOSE - tf2onnx.optimizer: Apply remove_back_to_back\n",
      "2021-09-01 19:38:16,470 - VERBOSE - tf2onnx.optimizer.BackToBackOptimizer: no change\n",
      "2021-09-01 19:38:16,470 - VERBOSE - tf2onnx.optimizer: Apply einsum_optimizer\n",
      "2021-09-01 19:38:16,587 - VERBOSE - tf2onnx.optimizer.EinsumOptimizer: no change\n",
      "2021-09-01 19:38:16,607 - INFO - tf2onnx.optimizer: After optimization: Add -1 (48->47), BatchNormalization -20 (31->11), Cast -48 (102->54), Concat -31 (69->38), Const -509 (723->214), Gather -24 (42->18), GlobalAveragePool +8 (0->8), Identity -69 (69->0), Less -1 (4->3), Placeholder -1 (6->5), ReduceMean -8 (8->0), ReduceProd -40 (40->0), Reshape -8 (70->62), Shape -7 (32->25), Squeeze -10 (18->8), Transpose -134 (158->24), Unsqueeze -106 (114->8)\n",
      "2021-09-01 19:38:17,021 - INFO - tf2onnx: \n",
      "2021-09-01 19:38:17,021 - INFO - tf2onnx: Successfully converted TensorFlow model /data/nb_data/saved_models to ONNX\n",
      "2021-09-01 19:38:17,021 - INFO - tf2onnx: Model inputs: ['input_1']\n",
      "2021-09-01 19:38:17,021 - INFO - tf2onnx: Model outputs: ['output_1', 'output_2', 'output_3']\n",
      "2021-09-01 19:38:17,021 - INFO - tf2onnx: ONNX model is saved at /data/nb_data/saved_models/saved_model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 14 --verbose --debug \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {saved_model_path} --output {saved_model_path}/saved_model.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10fb3fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T02:10:06.032829Z",
     "start_time": "2021-09-01T02:10:05.818239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8123\n",
      "Serving '/data/nb_data/saved_models/saved_model.onnx' at http://0.0.0.0:8123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='tensorboard-frame-1eaa5610cbe4c335' width='100%' height='600' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1eaa5610cbe4c335\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8123;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %netron {saved_model_path}/saved_model.onnx 8123 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0800e378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:17.739861Z",
     "start_time": "2021-09-01T07:34:16.979480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  180 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_transpose__549\n",
      "  181 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_reshape__550\n",
      "  182 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_concat__551\n",
      "  183 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_gather__553\n",
      "  184 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_reshape__554\n",
      "  185 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_transpose__559\n",
      "  186 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND_reshape__561\n",
      "  187 StatefulPartitionedCall/resnet_period_estimator/conv3d/Conv3D/BatchToSpaceND\n",
      "  188 StatefulPartitionedCall/resnet_period_estimator/conv3d/BiasAdd\n",
      "  189 StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576\n",
      "------------------------------------------------------------\n",
      "input: \"StatefulPartitionedCall/resnet_period_estimator/conv3d/BiasAdd:0\"\n",
      "output: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576:0\"\n",
      "name: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 4\n",
      "  ints: 1\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "  190 StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3\n",
      "  191 StatefulPartitionedCall/resnet_period_estimator/Relu\n",
      "  192 StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__581\n",
      "------------------------------------------------------------\n",
      "input: \"StatefulPartitionedCall/resnet_period_estimator/Relu:0\"\n",
      "output: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__581:0\"\n",
      "name: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__581\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  ints: 4\n",
      "  ints: 1\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "  193 StatefulPartitionedCall/resnet_period_estimator/Reshape_2\n",
      "  194 StatefulPartitionedCall/resnet_period_estimator/Max\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(f'{saved_model_path}/saved_model.onnx')\n",
    "onnx_model = onnx.shape_inference.infer_shapes(onnx_model, check_type=True) # for value_info\n",
    "onnx_graph_def = onnx_model.graph\n",
    "for i, node in enumerate(onnx_graph_def.node[180:195], 180):\n",
    "    print('%5d' % i, node.name)\n",
    "    if 'FusedBatchNormV3' in node.name and 'Transpose' == node.op_type:\n",
    "        attr = node.attribute.pop()\n",
    "        if attr.ints[1] == 3:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 4, 1, 2, 3]))\n",
    "        elif attr.ints[1] == 2:\n",
    "            node.attribute.append(OH.make_attribute('perm', [0, 2, 3, 4, 1]))\n",
    "        print('-'*60)\n",
    "        print(node)\n",
    "        print('-'*60)\n",
    "        \n",
    "onnx.save(onnx_model, f'{saved_model_path}/saved_model_mod.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f11b2ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:34:27.274057Z",
     "start_time": "2021-09-01T07:34:27.206510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 479, 206)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onnx_graph_def.node), len(onnx_graph_def.value_info), len(onnx_graph_def.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e17166bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:23.669329Z",
     "start_time": "2021-09-01T07:35:23.609303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(name: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576:0\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "   }\n",
       " },\n",
       " '--------------------------------------------------------------------------------',\n",
       " input: \"StatefulPartitionedCall/resnet_period_estimator/conv3d/BiasAdd:0\"\n",
       " output: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576:0\"\n",
       " name: \"StatefulPartitionedCall/resnet_period_estimator/batch_normalization/FusedBatchNormV3__576\"\n",
       " op_type: \"Transpose\"\n",
       " attribute {\n",
       "   name: \"perm\"\n",
       "   ints: 0\n",
       "   ints: 4\n",
       "   ints: 1\n",
       "   ints: 2\n",
       "   ints: 3\n",
       "   type: INTS\n",
       " })"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_idx = 189\n",
    "onnx_graph_def.value_info[target_idx], '-'*80, onnx_graph_def.node[target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8558fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:30.064157Z",
     "start_time": "2021-09-01T07:35:29.973956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512] StatefulPartitionedCall/resnet_period_estimator/conv3d/BiasAdd/ReadVariableOp:0\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(onnx_graph_def.initializer):\n",
    "    if onnx_graph_def.node[target_idx].input[0][:-2] in w.name:\n",
    "        print(w.dims, w.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8d43761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:42.850850Z",
     "start_time": "2021-09-01T07:35:42.733903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8123\n",
      "Serving '/data/nb_data/saved_models/saved_model_mod.onnx' at http://0.0.0.0:8123\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='tensorboard-frame-9f5b726828505b8' width='100%' height='600' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9f5b726828505b8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8123;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron {saved_model_path}/saved_model_mod.onnx 8123 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "417d9a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:35:59.862806Z",
     "start_time": "2021-09-01T07:35:57.531288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = rt.InferenceSession(f'{saved_model_path}/saved_model_mod.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: test_inputs}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "predictions = sess.run(outputs, inputs)\n",
    "predictions[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "169472b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:36:48.948098Z",
     "start_time": "2021-09-01T07:36:48.880296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[1.3301184],\n",
       "       [1.3351945],\n",
       "       [1.666209 ],\n",
       "       [1.94694  ],\n",
       "       [1.675955 ],\n",
       "       [1.2609154],\n",
       "       [1.6613737],\n",
       "       [1.8184739],\n",
       "       [2.199509 ],\n",
       "       [1.2911549]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs[1][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36922760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T07:38:52.918763Z",
     "start_time": "2021-09-01T07:38:52.854106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3301201],\n",
       "       [1.3352016],\n",
       "       [1.6662414],\n",
       "       [1.9469837],\n",
       "       [1.6759973],\n",
       "       [1.260942 ],\n",
       "       [1.6614059],\n",
       "       [1.8185081],\n",
       "       [2.1995409],\n",
       "       [1.2911682]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da38f2",
   "metadata": {},
   "source": [
    "## TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cdfc9c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:06.302285Z",
     "start_time": "2021-08-31T10:44:56.002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_period_estimator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, None, None, 1024)  5209600   \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              multiple                  14156288  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  2048      \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "transformer_layer (Transform multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "transformer_layer_1 (Transfo multiple                  1577984   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  262656    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  513       \n",
      "=================================================================\n",
      "Total params: 25,690,081\n",
      "Trainable params: 25,673,313\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(saved_model_path)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346f2afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:06.303367Z",
     "start_time": "2021-08-31T10:44:56.007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 145). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsnl0ylf1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpsnl0ylf1/assets\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS, # tflite: some op not support\n",
    "]\n",
    "litemodel = converter.convert()\n",
    "with open(f'{saved_model_path}/saved_model.tflite', 'wb') as f:\n",
    "    f.write(litemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9c56797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:06.304625Z",
     "start_time": "2021-08-31T10:44:56.012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'x',\n",
       "   'index': 0,\n",
       "   'shape': array([  1,  64, 112, 112,   3], dtype=int32),\n",
       "   'shape_signature': array([ -1,  64, 112, 112,   3], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}}],\n",
       " [{'name': 'Identity',\n",
       "   'index': 443,\n",
       "   'shape': array([ 1,  1, 32], dtype=int32),\n",
       "   'shape_signature': array([-1, -1, 32], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}},\n",
       "  {'name': 'Identity_1',\n",
       "   'index': 567,\n",
       "   'shape': array([1, 1, 1], dtype=int32),\n",
       "   'shape_signature': array([-1, -1,  1], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}},\n",
       "  {'name': 'Identity_2',\n",
       "   'index': 292,\n",
       "   'shape': array([ 1, 64,  1], dtype=int32),\n",
       "   'shape_signature': array([-1, 64, -1], dtype=int32),\n",
       "   'dtype': numpy.float32,\n",
       "   'quantization': (0.0, 0),\n",
       "   'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "    'zero_points': array([], dtype=int32),\n",
       "    'quantized_dimension': 0},\n",
       "   'sparsity_parameters': {}}])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=f'{saved_model_path}/saved_model.tflite')\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "interpreter.resize_tensor_input(input_details[0]['index'], test_inputs.shape) # modify input shape\n",
    "interpreter.allocate_tensors()\n",
    "input_details, output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5081b980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T10:45:06.306552Z",
     "start_time": "2021-08-31T10:44:56.016Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_inputs)\n",
    "interpreter.invoke()\n",
    "output_data1 = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data2 = interpreter.get_tensor(output_details[1]['index'])\n",
    "output_data3 = interpreter.get_tensor(output_details[2]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14ee9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3301675],\n",
       "       [1.3352613],\n",
       "       [1.6663213],\n",
       "       [1.9470959],\n",
       "       [1.6760602],\n",
       "       [1.2610333],\n",
       "       [1.6614742],\n",
       "       [1.8185761],\n",
       "       [2.1995866],\n",
       "       [1.2912288]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data2[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5f7c7",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da404e",
   "metadata": {},
   "source": [
    "- https://github.com/onnx/onnx/blob/master/docs/Operators.md\n",
    "- https://github.com/microsoft/onnxruntime/blob/master/docs/Versioning.md\n",
    "- https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md\n",
    "- https://segmentfault.com/a/1190000039936376\n",
    "- https://github.com/onnx/tensorflow-onnx/issues/1606\n",
    "- https://github.com/onnx/tensorflow-onnx/issues/1634"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108552f5",
   "metadata": {},
   "source": [
    "## FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d92bd",
   "metadata": {},
   "source": [
    "[TensorFlow Lite: TensorListFromTensor, TensorListReserve, TensorListStack, While][1]\n",
    "\n",
    "[1]: https://github.com/tensorflow/tensorflow/issues/33416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1d27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "262.997px",
    "width": "271.009px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "509.389px",
    "left": "1133.98px",
    "top": "245.278px",
    "width": "375.114px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
