{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-and-Define-Utils\" data-toc-modified-id=\"Load-and-Define-Utils-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load and Define Utils</a></span><ul class=\"toc-item\"><li><span><a href=\"#Magics\" data-toc-modified-id=\"Magics-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Magics</a></span></li><li><span><a href=\"#Easy-Widget\" data-toc-modified-id=\"Easy-Widget-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Easy Widget</a></span></li></ul></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Source\" data-toc-modified-id=\"Data-Source-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data Source</a></span></li><li><span><a href=\"#Data-Convert\" data-toc-modified-id=\"Data-Convert-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Convert</a></span></li><li><span><a href=\"#Data-Sink\" data-toc-modified-id=\"Data-Sink-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Data Sink</a></span></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Test</a></span></li></ul></li><li><span><a href=\"#JetRep\" data-toc-modified-id=\"JetRep-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>JetRep</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inference-Process\" data-toc-modified-id=\"Inference-Process-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Inference Process</a></span></li><li><span><a href=\"#Pre-Worker\" data-toc-modified-id=\"Pre-Worker-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pre Worker</a></span></li><li><span><a href=\"#Post-Worker\" data-toc-modified-id=\"Post-Worker-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Post Worker</a></span></li><li><span><a href=\"#Process-Class\" data-toc-modified-id=\"Process-Class-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Process Class</a></span></li><li><span><a href=\"#Control-Class\" data-toc-modified-id=\"Control-Class-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Control Class</a></span></li></ul></li><li><span><a href=\"#Repnet-Model\" data-toc-modified-id=\"Repnet-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Repnet Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pre-Process\" data-toc-modified-id=\"Pre-Process-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Pre Process</a></span></li><li><span><a href=\"#Model-Output\" data-toc-modified-id=\"Model-Output-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Model Output</a></span></li><li><span><a href=\"#Post-Process\" data-toc-modified-id=\"Post-Process-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Post Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calculate-Scores\" data-toc-modified-id=\"Calculate-Scores-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Calculate Scores</a></span></li><li><span><a href=\"#Calculate-Count\" data-toc-modified-id=\"Calculate-Count-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Calculate Count</a></span></li></ul></li></ul></li><li><span><a href=\"#Make-it-together\" data-toc-modified-id=\"Make-it-together-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Make it together</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<center>The Notebook Only Run On Jetson The Device</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notename = !uname -n\n",
    "if 'nano' != notename[0]:\n",
    "    raise RuntimeError('notebook server is not jetson device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.4\n",
      "sklearn not installed\n",
      "pandas 0.22.0\n",
      "ipywidgets 6.0.0\n",
      "cv2 4.1.1\n",
      "PIL 5.1.0\n",
      "matplotlib 2.1.1\n",
      "plotly not installed\n",
      "netron not installed\n",
      "torch not installed\n",
      "torchvision not installed\n",
      "torchaudio not installed\n",
      "tensorflow 2.5.0+nv21.8\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx not installed\n",
      "onnxruntime 1.8.1\n",
      "tensorrt 8.0.1.6\n",
      "tvm not installed\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "import threading, queue\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "    \n",
    "def get_logger(name, level=logging.DEBUG, filepath=None, console=True):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    #  %(filename)s\n",
    "    formatter = logging.Formatter('%(asctime)s - %(funcName)s:%(lineno)d - %(name)s - %(levelname)s - %(message)s')\n",
    "    if console:\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(level)\n",
    "        console.setFormatter(formatter)\n",
    "        logger.addHandler(console)\n",
    "    if filepath:\n",
    "        filelog = logging.FileHandler(filepath)\n",
    "        filelog.setLevel(level)\n",
    "        filelog.setFormatter(formatter)\n",
    "        logger.addHandler(filelog)\n",
    "    return logger\n",
    "\n",
    "import cv2\n",
    "\n",
    "SCRIPT_DIR = '/home/nano/omega/jetson/scripts'\n",
    "logger = get_logger('JetRep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_line_magic\n",
    "def killall(line):\n",
    "    pid_list=!ps -eo pid,command | grep $line  | grep -v 'grep' | cut -c1-6\n",
    "    for pid in pid_list:\n",
    "        pid = pid.strip()\n",
    "        !kill -9 $pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMPORT('https://gitee.com/qrsforever/nb_easy/easy_widget.py')\n",
    "\n",
    "def switch_play_video(context, btnwid, oldval, newval, framecntwid, gstwid, frameimgwid):\n",
    "    def _video_cap_loop():\n",
    "        context.logger(\"Open GStreamer ... %s\" % gstwid.value)\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(gstwid.value, cv2.CAP_GSTREAMER)\n",
    "            if cap.isOpened():\n",
    "                context.logger('GStreamer is Opened!')\n",
    "                count = 0\n",
    "                while btnwid.value and count < framecntwid.value:\n",
    "                    retval, frame = cap.read()\n",
    "                    if retval:\n",
    "                        frameimgwid.value = bytes(cv2.imencode(ext='.jpeg', img=frame)[1])\n",
    "                    count += 1\n",
    "                cap.release()\n",
    "            btnwid.value = False\n",
    "            context.logger('GStreamer is Stopped!')\n",
    "        except Exception as err:\n",
    "            context.logger('%s' % err)\n",
    "    if newval:\n",
    "        framecntwid.disabled = True\n",
    "        btnwid.icon = 'stop-circle'\n",
    "        btnwid.description = 'Stop'\n",
    "        context.logger('Start Thread... ')\n",
    "        threading.Thread(target=_video_cap_loop, args=()).start()\n",
    "    else:\n",
    "        framecntwid.disabled = False\n",
    "        btnwid.icon = 'play'\n",
    "        btnwid.description= 'Start'\n",
    "        \n",
    "\n",
    "def get_play_schema(gst):\n",
    "     return {\n",
    "        'type': 'page',\n",
    "        'objs': [\n",
    "            {\n",
    "                'type': 'H',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_togglebutton('switch_play', 'Start', icon='play'),\n",
    "                    nbeasy_widget_int('frame_count', 'Frame Count', default=300, min_=100, max_=900, width=150),\n",
    "                    nbeasy_widget_string('gst', 'GStreamer', gst, width='70%', readonly=True),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'type': 'V',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_image('frame_image', 'Image', '', format='jpeg')\n",
    "                ],\n",
    "                'align_items': 'center'\n",
    "            },\n",
    "            {\n",
    "                'type': 'observe',\n",
    "                'objs': [\n",
    "                    {\n",
    "                        'handler': switch_play_video,\n",
    "                        'params': {\n",
    "                            'source': 'switch_play',\n",
    "                            'targets': [\n",
    "                                'frame_count',\n",
    "                                'gst',\n",
    "                                'frame_image'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# easy = nbeasy_schema_parse(get_play_schema(gst), debug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import abc\n",
    "import uuid\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSCom(traitlets.HasTraits):\n",
    "    \n",
    "    teename = traitlets.Unicode('')\n",
    "\n",
    "    def __init__(self, parent, *args, **kwargs):\n",
    "        super(GSCom, self).__init__(*args, **kwargs)\n",
    "        if parent is not None:\n",
    "            parent.children[self.name] = self\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "            \n",
    "    def gst_pipe(self):\n",
    "        raise RuntimeError('abstract method called')\n",
    "        \n",
    "    def gst_str(self):\n",
    "        gst = ' %s. ! queue ! ' % self.parent.teename if self.parent else ''\n",
    "        gst += ' ! '.join(self.gst_pipe())\n",
    "        for _, child in self.children.items():\n",
    "            gst += child.gst_str()\n",
    "        return gst "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvarguscamerasrc name=csicam sensor-id=0 ! \"video/x-raw(memory:NVMM),width=640,height=480,format=(string)NV12,framerate=30/1\" ! nvvidconv flip-method=6 ! \"video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx\" ! textoverlay halignment=0 valignment=2 text=CSI:48b02d5bcfa5 ! clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\" ! tee name=tee_raw'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Camera(traitlets.HasTraits):\n",
    "    device = traitlets.Int(min=0, max=1, default_value=0)\n",
    "    uuid = traitlets.Unicode('')\n",
    "    \n",
    "    @traitlets.default('uuid')\n",
    "    def _default_uuid(self):\n",
    "        return uuid.UUID(int=uuid.getnode()).hex[-12:]\n",
    "\n",
    "\n",
    "class DataSource(GSCom):\n",
    "    teename = traitlets.Unicode('tee_raw')\n",
    "    name = traitlets.Unicode()\n",
    "    width = traitlets.Int(default_value=640)\n",
    "    height = traitlets.Int(default_value=480)\n",
    "    framerate = traitlets.Int(default_value=30)\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(DataSource, self).__init__(None, *args, **kwargs)\n",
    "   \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            'tee name=%s' % self.teename\n",
    "        ]\n",
    "    \n",
    "\n",
    "class USBCamera(Camera, DataSource):\n",
    "    name = traitlets.Unicode(default_value='usbcam')\n",
    "    device = traitlets.Int(default_value=1)\n",
    "    \n",
    "    def gst_pipe(self):\n",
    "        raise NotImplementedError('usb cammera')\n",
    "    \n",
    "\n",
    "class CSICamera(Camera, DataSource):\n",
    "    name = traitlets.Unicode(default_value='csicam')\n",
    "    device = traitlets.Int(default_value=0)\n",
    "    \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            f'nvarguscamerasrc name={self.name} sensor-id={self.device}',\n",
    "            f'\"video/x-raw(memory:NVMM),width={self.width},height={self.height},format=(string)NV12,framerate={self.framerate}/1\"',\n",
    "            f'nvvidconv flip-method=6',\n",
    "            f'\"video/x-raw, width=(int){self.width}, height=(int){self.height}, format=(string)BGRx\"',\n",
    "            f'textoverlay halignment=0 valignment=2 text=CSI:{self.uuid}',\n",
    "            f'clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\"',\n",
    "        ] + super().gst_pipe()\n",
    "    \n",
    "gst_source_csi = CSICamera(device=0)\n",
    "gst_source_csi.gst_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tee_raw. ! queue ! nvvidconv ! nvv4l2h264enc bitrate=4000000 ! h264parse !  tee name=tee_h264 '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataConvert(GSCom):\n",
    "    name = traitlets.Unicode(allow_none=False)\n",
    "\n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            ' tee name=%s ' % self.teename\n",
    "        ]\n",
    "\n",
    "    \n",
    "class H264CodecCvt(DataConvert):\n",
    "    teename = traitlets.Unicode('tee_h264')\n",
    "    name = traitlets.Unicode('h264', read_only=True)\n",
    "    bitrate = traitlets.Int(default_value=4000000)\n",
    "    \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            'nvvidconv',\n",
    "            'nvv4l2h264enc bitrate=%d' % self.bitrate,\n",
    "            'h264parse',\n",
    "        ] + super().gst_pipe()\n",
    "    \n",
    "gst_cvt_h264 = H264CodecCvt(gst_source_csi, bitrate=4000000)    \n",
    "gst_cvt_h264.gst_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' tee_raw. ! queue ! videoconvert ! \"video/x-raw, format=(string)BGR\" ! shmsink socket-path=\"/tmp/gst_repnet.shm\" shm-size=20000000 sync=true wait-for-connection=false',\n",
       " ' tee_h264. ! queue ! splitmuxsink muxer=qtmux max-size-time=300000000000 max-files=10 location=\"/home/nano/omega/gst/%03d.mp4\"',\n",
       " ' tee_h264. ! queue ! flvmux ! rtmpsink location=rtmp://172.16.0.35:1935/live/48b02d5bcfa5')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataSink(GSCom):\n",
    "    name = traitlets.Unicode(allow_none=False)\n",
    "   \n",
    "  \n",
    "class ShareMemorySink(DataSink):\n",
    "    name = traitlets.Unicode(default_value='shmsink')\n",
    "    path = traitlets.Unicode(default_value='/tmp/gst_socket.shm')\n",
    "    size = traitlets.Int(default_value=67108864, min=0, max=4294967295)\n",
    "    \n",
    "    def __init__(self, parent, *args, **kwargs):\n",
    "        super(ShareMemorySink, self).__init__(parent, *args, **kwargs)\n",
    "        if os.path.exists(self.path):\n",
    "            os.unlink(self.path)\n",
    "    \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            'videoconvert', \n",
    "            '\"video/x-raw, format=(string)BGR\"',\n",
    "            f'shmsink socket-path=\"{self.path}\" shm-size={self.size} sync=true wait-for-connection=false'\n",
    "        ]\n",
    "    \n",
    "\n",
    "class MultiFilesSink(DataSink):\n",
    "    name = traitlets.Unicode(default_value='multifilessink')\n",
    "    duration = traitlets.Int(default_value=600, min=1, max=3600)\n",
    "    maxfiles = traitlets.Int(default_value=200, min=1, max=1000)\n",
    "    location = traitlets.Unicode(default_value=f'/tmp/{datetime.datetime.now().strftime(\"%Y%m%d\")}')\n",
    "    \n",
    "    def __init__(self, parent, *args, **kwargs):\n",
    "        super(MultiFilesSink, self).__init__(parent, *args, **kwargs)\n",
    "        os.makedirs(self.location, exist_ok=True)\n",
    "    \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            f'splitmuxsink muxer=qtmux max-size-time={self.duration * 1000000000} max-files={self.maxfiles} location=\"{self.location}/%03d.mp4\"',\n",
    "        ]\n",
    "\n",
    "\n",
    "class SRSRtmpSink(DataSink):\n",
    "    name = traitlets.Unicode(default_value='rtmpsink')\n",
    "    server = traitlets.Unicode(default_value='127.0.0.1')\n",
    "    port = traitlets.Int(default_value=1935)\n",
    "    stream = traitlets.Unicode(allow_none=False)\n",
    "    \n",
    "    def __init__(self, parent, *args, **kwargs):\n",
    "        super(SRSRtmpSink, self).__init__(parent, *args, **kwargs)\n",
    "        \n",
    "    def gst_pipe(self):\n",
    "        return [\n",
    "            'flvmux',\n",
    "            f'rtmpsink location=rtmp://{self.server}:{self.port}/live/{self.stream}',\n",
    "        ]\n",
    "    \n",
    "gst_sink_shm = ShareMemorySink(parent=gst_source_csi, path='/tmp/gst_repnet.shm', size=20000000)\n",
    "gst_sink_files = MultiFilesSink(parent=gst_cvt_h264, duration=300, maxfiles=10, location='/home/nano/omega/gst')\n",
    "gst_sink_rtmp = SRSRtmpSink(parent=gst_cvt_h264, server='172.16.0.35', stream='48b02d5bcfa5')\n",
    "gst_sink_shm.gst_str(), gst_sink_files.gst_str(), gst_sink_rtmp.gst_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvarguscamerasrc name=csicam sensor-id=0 ! \"video/x-raw(memory:NVMM),width=640,height=480,format=(string)NV12,framerate=30/1\" ! nvvidconv flip-method=6 ! \"video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx\" ! textoverlay halignment=0 valignment=2 text=CSI:48b02d5bcfa5 ! clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\" ! tee name=tee_raw tee_raw. ! queue ! nvvidconv ! nvv4l2h264enc bitrate=4000000 ! h264parse !  tee name=tee_h264  tee_h264. ! queue ! splitmuxsink muxer=qtmux max-size-time=300000000000 max-files=10 location=\"/home/nano/omega/gst/%03d.mp4\" tee_h264. ! queue ! flvmux ! rtmpsink location=rtmp://172.16.0.35:1935/live/48b02d5bcfa5 tee_raw. ! queue ! videoconvert ! \"video/x-raw, format=(string)BGR\" ! shmsink socket-path=\"/tmp/gst_repnet.shm\" shm-size=20000000 sync=true wait-for-connection=false'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gst_source_csi.gst_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%killall gst-launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash --bg -s '{gst_source_csi.gst_str()}'\n",
    "\n",
    "sudo rm -rf /tmp/gst_repnet.shm\n",
    "\n",
    "bash -c \"gst-launch-1.0 -e ${1}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JetRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process\n",
    "from subprocess import Popen, PIPE, check_output, TimeoutExpired\n",
    "from threading import Thread\n",
    "import psutil\n",
    "import queue\n",
    "\n",
    "def get_pids(proname=None, cmdstr=None):\n",
    "    if proname:\n",
    "        try:\n",
    "            return list(map(int, check_output([\"pidof\", proname]).split()))\n",
    "        except:\n",
    "            return []\n",
    "    if keystr:\n",
    "        pids = []\n",
    "        for proc in psutil.process_iter():\n",
    "            if cmdstr in ' '.join(proc.cmdline()):\n",
    "                pids.append(proc.pid)\n",
    "        return pids\n",
    "    \n",
    "# get_pids('gst-launch-1.0')\n",
    "\n",
    "def kill_tree(pid, including_parent=True):    \n",
    "    parent = psutil.Process(pid)\n",
    "    children = parent.children(recursive=True)\n",
    "    for child in children:\n",
    "        child.kill()\n",
    "    gone, still_alive = psutil.wait_procs(children, timeout=5)\n",
    "    if including_parent:\n",
    "        parent.kill()\n",
    "        parent.wait(5)\n",
    " \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repnet_inference_process(model_path, batch_queue, result_queue, status_queue, timeout):\n",
    "    logger.debug('Start repnet_inference_process...')\n",
    "    import tensorrt as trt\n",
    "    import queue\n",
    "    sys.path.append('/usr/src/tensorrt/samples/python')\n",
    "    import common\n",
    "    \n",
    "    status_queue.put((100, 'starting'))\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as f, \\\n",
    "            trt.Runtime(trt.Logger()) as runtime, \\\n",
    "            runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "            engine.create_execution_context() as context:\n",
    "\n",
    "            inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "\n",
    "            status_queue.put((101, 'running'))\n",
    "            while True:\n",
    "                try:\n",
    "                    token, np_frames = batch_queue.get(timeout=timeout)\n",
    "                    if token < 0:\n",
    "                        status_queue.put((0, 'quit'))\n",
    "                        break\n",
    "                except queue.Empty:\n",
    "                    continue\n",
    "                except Exception as err:\n",
    "                    status_queue.put((-1, f'err: {err}'))\n",
    "                    break\n",
    "\n",
    "                np_frames = np_frames.astype(np.float32)\n",
    "                np_frames -= 127.5\n",
    "                np_frames /= 127.5\n",
    "                inputs[0].host = np.reshape(np_frames, (1, 64, 112, 112, 3))\n",
    "\n",
    "                trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "                trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, ((-1, 1), (-1, 32)))]\n",
    "\n",
    "                result_queue.put((token, trt_outputs[0].copy(), trt_outputs[1].copy()))\n",
    "    except Exception as err:\n",
    "        status_queue.put((-2, f'err: {err}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prerep_process_worker(app):\n",
    "    logger.debug(\"Start prerep_process_worker...\")\n",
    "    pre_frame = None\n",
    "    keep_flag = 1\n",
    "    while True:\n",
    "        try:\n",
    "            frame_bgr, fbat = app.read_put()\n",
    "        except Exception as err:\n",
    "            logger.error(f'Err: {err}')\n",
    "            break\n",
    "        fbat.raw_frames.append(frame_bgr)\n",
    "\n",
    "        if app._black_box:\n",
    "            black_x1, black_y1, black_x2, black_y2 = app._black_box\n",
    "            frame_bgr[black_y1:black_y2, black_x1:black_x2, :] = 0\n",
    "\n",
    "        if app._focus_box:\n",
    "            focus_x1, focus_y1, focus_x2, focus_y2 = app._focus_box\n",
    "            frame_bgr = frame_bgr[focus_y1:focus_y2, focus_x1:focus_x2, :]\n",
    "\n",
    "        if app._area_thresh > 0:\n",
    "            frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "            if pre_frame is not None:\n",
    "                frame_tmp = cv2.absdiff(frame_gray, pre_frame)\n",
    "                frame_tmp = cv2.threshold(frame_tmp, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "                frame_tmp = cv2.dilate(frame_tmp, None, iterations=2)\n",
    "                contours, _ = cv2.findContours(frame_tmp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                if len(contours) > 0:\n",
    "                    for contour in contours:\n",
    "                        if cv2.contourArea(contour) > app._area_thresh:\n",
    "                            keep_flag += 1\n",
    "                            break\n",
    "            pre_frame = frame_gray\n",
    "        else:\n",
    "            keep_flag += 1\n",
    "\n",
    "        if keep_flag % app._stride == 0 or len(fbat.raw_frames) > app._max_raw_frames:\n",
    "            frame_bgr = cv2.resize(frame_bgr, (112, 112))\n",
    "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            fbat.selected_indices.append(len(fbat.raw_frames) - 1)\n",
    "            fbat.bat_inputs.append(frame_rgb)\n",
    "            if len(fbat.raw_frames) > app._max_raw_frames:\n",
    "                diff = app.F - len(fbat.selected_indices) \n",
    "                for _ in range(diff):\n",
    "                    fbat.selected_indices.append(len(fbat.raw_frames) - 1)\n",
    "                    fbat.bat_inputs.append(frame_rgb)\n",
    "                logger.warn(f'May be still frames is to many, diff[{diff}].')\n",
    "            keep_flag = 1\n",
    "    logger.debug('PreRep process worker end!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postrep_process_worker(app):\n",
    "    logger.debug(\"Start postrep_process_worker...\")\n",
    "    while True:\n",
    "        try:\n",
    "            fbat, within_scores, period_scores = app.read_get()\n",
    "            if fbat is None:\n",
    "                continue\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "        except Exception as err:\n",
    "            logger.error(f'Err: {err}')\n",
    "            break\n",
    "            \n",
    "        per_frame_periods = np.argmax(period_scores, axis=-1) + 1\n",
    "        per_frame_counts = np.where(per_frame_periods < 3, 0.0, 1 / per_frame_periods)\n",
    "        logger.debug(sum(per_frame_counts))\n",
    "    \n",
    "    logger.debug('PostRep process worker end!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class FrameProcessApp(traitlets.HasTraits):\n",
    "    \n",
    "    frame_size = traitlets.Tuple(traitlets.Int(), traitlets.Int())\n",
    "    focus_box = traitlets.List(trait=traitlets.Float(min=0., max=1.), default_value=[0.0, 0.1, 1.0, 1.0], minlen=4, maxlen=4)\n",
    "    black_box = traitlets.List(trait=traitlets.Float(min=0., max=1.), default_value=[0.0, 0.0, 1.0, 1.0], minlen=4, maxlen=4)\n",
    "    area_rate = traitlets.Float(default_value=0.002, min=0.0, max=0.05)\n",
    "    strides = traitlets.List(trait=traitlets.Int(), default_value=[4], minlen=1, maxlen=3)\n",
    "    \n",
    "    F = 64\n",
    "    K = F * 100\n",
    "    \n",
    "    def __init__(self, logger, read_gst, send_gst, mdata_in, mdata_out, *args, **kwargs):\n",
    "        super(FrameProcessApp, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.logger = logger\n",
    "        self._focus_box = None\n",
    "        self._black_box = None\n",
    "        self._stride = 4\n",
    "        self._max_raw_frames = self._stride * self.K\n",
    "        self._area_thresh = 0\n",
    "        self.frame_size = (640, 480)\n",
    "        self.frame_rate = 30\n",
    "        \n",
    "        self._currbat = None\n",
    "        self._batches = {}\n",
    "        self.read_cap, self.read_gst = None, read_gst\n",
    "        self.send_cap, self.send_gst = None, send_gst\n",
    "        \n",
    "        self.mdata_in = mdata_in\n",
    "        self.mdata_out = mdata_out\n",
    "\n",
    "        \n",
    "    class FBatch(object):\n",
    "        def __init__(self):\n",
    "            self.token = int(time.time() * 1000)\n",
    "            self.raw_frames = []\n",
    "            self.bat_inputs = []\n",
    "            self.selected_indices = []\n",
    "        \n",
    "    def make_fbatch(self):\n",
    "        return self.FBatch()\n",
    "        \n",
    "    def open_reader(self):\n",
    "        try:\n",
    "            read_cap = cv2.VideoCapture(self.read_gst, cv2.CAP_GSTREAMER)\n",
    "            if not read_cap.isOpened():\n",
    "                raise RuntimeError('Could not open camera.')\n",
    "            retval, _ = read_cap.read()\n",
    "            if not retval:\n",
    "                raise RuntimeError('Could not read image from camera.')\n",
    "            \n",
    "            self.frame_size = (\n",
    "                int(read_cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                int(read_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            )\n",
    "            self.frame_rate = int(read_cap.get(cv2.CAP_PROP_FPS))\n",
    "                \n",
    "        except:\n",
    "            raise RuntimeError('Could not initialize camera.  Please see error trace.')\n",
    "        self.read_cap = read_cap\n",
    "        \n",
    "    def close_reader(self):\n",
    "        if self.read_cap:\n",
    "            self.logger.debug(\"Exec cap release.\")\n",
    "            self.read_cap.release()\n",
    "        self._currbat = None \n",
    "            \n",
    "    def read_put(self):\n",
    "        retval, frame = self.read_cap.read()\n",
    "        if not retval:\n",
    "            raise RuntimeError('Camera read error, maybe camera is released.')\n",
    "        if self._currbat is None:\n",
    "            self._currbat = self.make_fbatch()    \n",
    "        if len(self._currbat.selected_indices) == self.F:\n",
    "            self.mdata_in.put((self._currbat.token, np.asarray(self._currbat.bat_inputs)))\n",
    "            self._batches[self._currbat.token] = self._currbat\n",
    "            self._currbat = self.make_fbatch()\n",
    "        return frame, self._currbat\n",
    "        \n",
    "        \n",
    "    def read_get(self):\n",
    "        token, within_scores, period_scores = self.mdata_out.get(timeout=1)\n",
    "        jbat = None\n",
    "        if token in self._batches:\n",
    "            jbat = self._batches.pop(token)\n",
    "        return jbat, within_scores, period_scores\n",
    "    \n",
    "\n",
    "    def open_sender(self):\n",
    "        pass\n",
    "    \n",
    "    def close_sender(self):\n",
    "        pass\n",
    "    \n",
    "    def write(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    @staticmethod\n",
    "    def calc_rect_box(w, h, box):\n",
    "        return [int(w * box[0]), int(h * box[1]), int(w * box[2]), int(h * box[3])]\n",
    "        \n",
    "    @traitlets.observe('frame_size')\n",
    "    def _on_frame_size(self, change):   \n",
    "        if self._focus_box:\n",
    "            self._focus_box = self.calc_rect_box(change['new'][0], change['new'][1], self.focus_box)\n",
    "        if self._black_box:\n",
    "            self._black_box = self.calc_rect_box(change['new'][0], change['new'][1], self.black_box)\n",
    "        if self._focus_box:\n",
    "            x1, y1, x2, y2 = self._focus_box \n",
    "            self._area_thresh = int((x2 - x1) * (y2 - y1) * self.area_rate)\n",
    "        else:\n",
    "            self._area_thresh = int(change['new'][0] * change['new'][1] * self.area_rate)\n",
    "        \n",
    "    @traitlets.observe('focus_box')\n",
    "    def _on_focus_box(self, change):\n",
    "        if change['new'] == [0., 0., 1., 1.]:\n",
    "            self._focus_box = None\n",
    "            return\n",
    "        self._focus_box = self.calc_rect_box(self.frame_size[0], self.frame_size[1], change['new'])\n",
    "        \n",
    "    @traitlets.observe('black_box')\n",
    "    def _on_black_box(self, change):\n",
    "        if change['new'] == [0., 0., 0., 0.] or change['new'] == [1., 1., 1., 1.]:\n",
    "            self._black_box = None\n",
    "            return\n",
    "        self._black_box = self.calc_rect_box(self.frame_size[0], self.frame_size[1], change['new'])\n",
    "        \n",
    "    @traitlets.observe('area_rate')\n",
    "    def _on_area_rate(self, change):\n",
    "        if self._focus_box:\n",
    "            x1, y1, x2, y2 = self._focus_box \n",
    "            self._area_thresh = (x2 - x1) * (y2 - y1) * change['new']\n",
    "            return\n",
    "        self._area_thresh = int(self.frame_size[0] * self.frame_size[1] * change['new'])\n",
    "        \n",
    "    @traitlets.observe('strides')\n",
    "    def _on_strides(self, change):\n",
    "        # TODO only support one stride\n",
    "        self._stride = change['new'][0]\n",
    "        self._max_raw_frames = self._stride * sefl.K\n",
    "        \n",
    "    @traitlets.validate('focus_box')\n",
    "    def _check_focus_box(self, proposal):\n",
    "        value = proposal['value']\n",
    "        if value[0] >= value[2] or value[1] >= value[3]: \n",
    "            raise traitlets.TraitError(f'focus_box invalid: {value}')\n",
    "        return value\n",
    "                         \n",
    "    @traitlets.validate('black_box')\n",
    "    def _check_black_box(self, proposal):\n",
    "        value = proposal['value']\n",
    "        if value[0] > value[2] or value[1] > value[3]: \n",
    "            raise traitlets.TraitError(f'Parameter focus_box is invalid: {value}')\n",
    "        return value\n",
    "    \n",
    "    def __str__(self):\n",
    "        str_ = f'_area_thresh: {self._area_thresh} _focus_box: {self._focus_box} _black_box: {self._black_box} '\n",
    "        str_ += f'_stride: {self._stride}'\n",
    "        return str_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class JetRep(traitlets.HasTraits):\n",
    "    gst_cmd = traitlets.Unicode('gst-launch-1.0', read_only=True)\n",
    "    shm_path = traitlets.Unicode('/tmp/gst_repnet.shm', read_only=True)\n",
    "    \n",
    "    trt_weigth = traitlets.Unicode('/home/nano/models/repnet_b1.trt') \n",
    "    trt_msg_timeout = traitlets.Int(5)\n",
    "    trycheck_count = traitlets.Int(6)\n",
    "    \n",
    "    def __init__(self, logger, *args, **kwargs):\n",
    "        super(JetRep, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.logger = logger\n",
    "        self.gst_process = None\n",
    "        self.engine_process = None\n",
    "        self.pre_worker = None \n",
    "        self.post_worker = None\n",
    "        self.msg_in = None\n",
    "        self.msg_out = None\n",
    "        self.msg_status = None\n",
    "        \n",
    "    def start_gst_launch(self):\n",
    "        # TODO read config, make gst string\n",
    "        gst_data_src = CSICamera(device=0, framerate=25)\n",
    "        gst_h264_cvt = H264CodecCvt(gst_data_src, bitrate=4000000)    \n",
    "        \n",
    "        _ = ShareMemorySink(parent=gst_data_src, path=self.shm_path, size=20000000)\n",
    "        _ = SRSRtmpSink(parent=gst_h264_cvt, server='172.16.0.35', stream='48b02d5bcfa5')\n",
    "        _ = MultiFilesSink(parent=gst_h264_cvt, duration=300, maxfiles=10, location='/home/nano/omega/gst')\n",
    "        \n",
    "        # start\n",
    "        # sudo systemctl restart nvargus-daemon\n",
    "        self.gst_process = Popen(f'{self.gst_cmd} -e {gst_data_src.gst_str()}', stderr=PIPE, universal_newlines=True, shell=True, start_new_session=True)\n",
    "        try:\n",
    "            _, stderr = self.gst_process.communicate(timeout=3)\n",
    "            raise RuntimeError('error: gst command line')\n",
    "        except TimeoutExpired:\n",
    "            pass\n",
    "        \n",
    "        self.logger.debug('Gst-launch started.')\n",
    "\n",
    "\n",
    "    def stop_gst_launch(self):\n",
    "        for pid in get_pids(self.gst_cmd):\n",
    "            # os.killpg(os.getpgid(pid), signal.SIGINT) # start_new_session must be True\n",
    "            kill_tree(os.getpgid(pid))\n",
    "        self.gst_process = None\n",
    "\n",
    "\n",
    "    def start_infer_engine(self):\n",
    "        if not os.path.exists(self.trt_weigth):\n",
    "            raise FileNotFoundError(f'error: {self.trt_weigth} is not found')\n",
    "        self.engine_process = Process(target=repnet_inference_process, args=(\n",
    "                self.trt_weigth, self.msg_in, self.msg_out, self.msg_status, self.trt_msg_timeout))\n",
    "        self.engine_process.start()\n",
    "        for i in range(1, self.trycheck_count + 1):\n",
    "            try:\n",
    "                errcode, msg = self.msg_status.get(timeout=self.trt_msg_timeout)\n",
    "                self.logger.debug(f'start infer engine: {errcode}: {msg}')\n",
    "                if errcode == 101:\n",
    "                    break\n",
    "            except queue.Empty:\n",
    "                self.logger.debug(f'warning[{i}]: cannot start infer engine !!!')\n",
    "\n",
    "    \n",
    "    def stop_infer_engine(self):\n",
    "        if self.engine_process:\n",
    "            for i in range(1, self.trycheck_count + 1):\n",
    "                self.msg_in.put((-1, None))\n",
    "                try:\n",
    "                    errcode, msg = self.msg_status.get(timeout=self.trt_msg_timeout)\n",
    "                    self.logger.debug(f'stop infer engine: {errcode}: {msg}')\n",
    "                    break\n",
    "                except queue.Empty:\n",
    "                    self.logger.debug(f'warning[{i}]: cannot stop infer engine !!!')\n",
    "        self.engine_process = None\n",
    "\n",
    " \n",
    "    def start_prerep_worker(self):\n",
    "        self.app.open_reader()\n",
    "        self.pre_worker = threading.Thread(target=prerep_process_worker, args=(self.app,), )\n",
    "        self.pre_worker.start()\n",
    "\n",
    " \n",
    "    def stop_prerep_worker(self):\n",
    "        if self.pre_worker:\n",
    "            self.app.close_reader()\n",
    "            for i in range(1, self.trycheck_count + 1):\n",
    "                if not self.pre_worker.is_alive():\n",
    "                    self.pre_worker.join()\n",
    "                    break\n",
    "                time.sleep(0.01)\n",
    "        self.pre_worker = None\n",
    "\n",
    "\n",
    "    def start_postrep_worker(self):\n",
    "        self.app.open_sender()\n",
    "        self.post_worker = threading.Thread(target=postrep_process_worker, args=(self.app,))\n",
    "        self.post_worker.start()\n",
    "\n",
    "        \n",
    "    def stop_postrep_worker(self):\n",
    "        if self.post_worker:\n",
    "            self.app.close_sender()\n",
    "            for i in range(1, self.trycheck_count + 1):\n",
    "                if not self.post_worker.is_alive():\n",
    "                    self.post_worker.join()\n",
    "                    break\n",
    "                time.sleep(0.01)\n",
    "        self.post_worker = None\n",
    "\n",
    "        \n",
    "    def start(self):\n",
    "        self.stop()\n",
    "        \n",
    "        self.msg_in = Queue()\n",
    "        self.msg_out = Queue()\n",
    "        self.msg_status = Queue()\n",
    "        \n",
    "        self.start_gst_launch()\n",
    "        self.start_infer_engine()\n",
    "        \n",
    "        read_gst_str = ' ! '.join([\n",
    "            f'shmsrc socket-path={self.shm_path}',\n",
    "            'video/x-raw, format=BGR, width=640, height=480',\n",
    "            'appsink'\n",
    "        ])\n",
    "        send_gst_str = ''\n",
    "        self.app = FrameProcessApp(self.logger, read_gst_str, send_gst_str, self.msg_in, self.msg_out)\n",
    "        \n",
    "        self.start_prerep_worker()\n",
    "        self.start_postrep_worker()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_prerep_worker()\n",
    "        self.stop_postrep_worker()\n",
    "        self.stop_infer_engine()\n",
    "        self.stop_gst_launch()\n",
    "        \n",
    "        if self.msg_in: self.msg_in.close()\n",
    "        if self.msg_out: self.msg_out.close()\n",
    "        if self.msg_status: self.msg_status.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jr = JetRep(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 22:04:10,967 - start_gst_launch:39 - JetRep - DEBUG - Gst-launch started.\n",
      "2021-11-05 22:04:11,103 - repnet_inference_process:2 - JetRep - DEBUG - Start repnet_inference_process...\n",
      "2021-11-05 22:04:14,769 - start_infer_engine:58 - JetRep - DEBUG - start infer engine: 100: starting\n",
      "2021-11-05 22:04:19,775 - start_infer_engine:62 - JetRep - DEBUG - warning[2]: cannot start infer engine !!!\n",
      "2021-11-05 22:04:24,781 - start_infer_engine:62 - JetRep - DEBUG - warning[3]: cannot start infer engine !!!\n",
      "2021-11-05 22:04:24,852 - start_infer_engine:58 - JetRep - DEBUG - start infer engine: 101: running\n",
      "2021-11-05 22:04:24,948 - prerep_process_worker:2 - JetRep - DEBUG - Start prerep_process_worker...\n",
      "2021-11-05 22:04:24,949 - postrep_process_worker:2 - JetRep - DEBUG - Start postrep_process_worker...\n"
     ]
    }
   ],
   "source": [
    "jr.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_area_thresh: 614 _focus_box: None _black_box: None _stride: 4\n"
     ]
    }
   ],
   "source": [
    "print(jr.app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jr.app._batches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 22:05:15,047 - postrep_process_worker:16 - JetRep - DEBUG - 1.8770833333333334\n"
     ]
    }
   ],
   "source": [
    "len(jr.app._currbat.raw_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 22:03:28,930 - postrep_process_worker:11 - JetRep - ERROR - Err: handle is closed\n",
      "2021-11-05 22:03:28,967 - postrep_process_worker:18 - JetRep - DEBUG - PostRep process worker end!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'is_alive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b5c21d4152a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mjr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_alive'"
     ]
    }
   ],
   "source": [
    "jr.pre_worker.is_alive(),  jr.post_worker.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pstree -p {jr.gst_process.pid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jr.app._currbat.selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pstree -p {jr.engine_process.pid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"80%\"\n",
       "            height=\"680\"\n",
       "            src=\"http://ossrs.net/players/rtc_player.html?vhost=__defaultVhost__&app=live&stream=48b02d5bcfa5&server=172.16.0.35&port=8181&autostart=true&schema=http\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f31424400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\n",
    "    src='http://ossrs.net/players/rtc_player.html?vhost=__defaultVhost__&app=live&stream=48b02d5bcfa5&server=172.16.0.35&port=8181&autostart=true&schema=http',\n",
    "    width='80%', height=680\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Repnet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Pre Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "sys.path.append('/usr/src/tensorrt/samples/python')\n",
    "\n",
    "import common\n",
    "\n",
    "TRT_LOGGER = trt.Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "np_frames = np_frames.astype(np.float32)\n",
    "np_frames -= 127.5\n",
    "np_frames /= 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/nano/models/repnet_b1.trt'\n",
    "\n",
    "stride = STRIDES[0]\n",
    "\n",
    "\n",
    "frames_seq_len = len(np_frames)\n",
    "print(\"num_frames:\", frames_seq_len)\n",
    "\n",
    "num_batches = int(np.ceil(frames_seq_len / NUM_FRAMES / stride / BATCH_SIZE))\n",
    "print(\"num_batches:\", num_batches)\n",
    "\n",
    "K = NUM_FRAMES * stride * BATCH_SIZE\n",
    "\n",
    "output_shapes = [(-1, 1), (-1, NUM_FRAMES // 2)]\n",
    "within_period_scores = []\n",
    "period_scores = []\n",
    "with open(MODEL_PATH, \"rb\") as f, \\\n",
    "    trt.Runtime(TRT_LOGGER) as runtime, \\\n",
    "    runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "    engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        \n",
    "    start = time.time()\n",
    "    for batch_idx in range(num_batches):\n",
    "        idxes = range(batch_idx * K, (batch_idx + 1) * K, stride)\n",
    "        idxes = np.clip(idxes, 0, frames_seq_len - 1)\n",
    "        np_inputs = np.reshape(np.take(np_frames, idxes, axis=0), (BATCH_SIZE, NUM_FRAMES, INPUT_SIZE, INPUT_SIZE, 3))\n",
    "        inputs[0].host = np_inputs\n",
    "        trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "        trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "        within_period_scores.append(trt_outputs[0].copy())\n",
    "        period_scores.append(trt_outputs[1].copy())\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    np_within_period_scores = np.concatenate(within_period_scores, axis=0)\n",
    "    np_period_scores = np.concatenate(period_scores, axis=0)\n",
    "    \n",
    "np_within_period_scores.shape, np_period_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "  e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "  return e_x / np.sum(e_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "within_period_scores = sigmoid(np_within_period_scores)[:, 0]\n",
    "within_period_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "per_frame_periods = np.argmax(np_period_scores, axis=-1) + 1\n",
    "conf_pred_periods = np.max(softmax(np_period_scores, axis=-1), axis=-1)\n",
    "per_frame_periods[:20], conf_pred_periods[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "conf_pred_periods = np.where(per_frame_periods < 3, 0.0, conf_pred_periods)\n",
    "conf_pred_periods[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "within_period_scores = np.sqrt(within_period_scores * conf_pred_periods)\n",
    "within_period_scores[:10], 'pred socre (%d): %.6f' % (stride, np.mean(within_period_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "per_frame_counts = np.where(per_frame_periods < 3, 0.0, 1 / per_frame_periods)\n",
    "per_frame_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "all_within_period_scores = np.repeat(within_period_scores, stride, axis=0)[:frames_seq_len]\n",
    "all_period_scores = np.repeat(np_period_scores, stride, axis=0)[:frames_seq_len]\n",
    "all_period_counts = (1 / stride) * np.repeat(per_frame_counts, stride, axis=0)[:frames_seq_len]\n",
    "all_within_period_scores.shape, all_period_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(all_period_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_within_period_binary = np.asarray(all_within_period_scores > 0.5)\n",
    "all_within_period_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(all_period_counts * np.asarray(all_within_period_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Calculate Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "all_per_frame_periods = np.argmax(all_period_scores, axis=-1) + 1\n",
    "\n",
    "per_frame_counts = np.where(np.less(all_per_frame_periods, 3), 0.0, np.divide(1.0,  stride * all_per_frame_periods))\n",
    "per_frame_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Make it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import threading, queue\n",
    "import cv2, os, sys\n",
    "import tensorrt as trt\n",
    "from scipy.signal import medfilt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "sys.path.append('/usr/src/tensorrt/samples/python')\n",
    "\n",
    "import common\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "  e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "  return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_FRAMES = 64\n",
    "INPUT_SIZE = 112\n",
    "STRIDES = [4, 6]\n",
    "\n",
    "TRT_LOGGER = trt.Logger()\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "usb_pipelines = [\n",
    "    'v4l2src device=/dev/video1',\n",
    "    'video/x-raw, width=(int)640, height=(int)480, framerate=(fraction)30/1',\n",
    "    'videoconvert',\n",
    "    'video/x-raw, format=(string)BGR',\n",
    "    'videoflip video-direction=4',\n",
    "    'textoverlay halignment=0 valignment=2 text=TalentAI',\n",
    "    'clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\"',\n",
    "    'appsink'\n",
    "]\n",
    "\n",
    "frames_queue = queue.Queue()\n",
    "\n",
    "usb_gst = \" ! \".join(usb_pipelines)\n",
    "usb_gst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def cal_rect_points(w, h, box):\n",
    "    if box[0] < 1.0 and box[1] < 1.0 and box[2] <= 1.0 and box[3] <= 1.0:\n",
    "        x1, y1 = int(w * box[0]), int(h * box[1])\n",
    "        x2, y2 = int(w * box[2]), int(h * box[3])\n",
    "    else:\n",
    "        x1, y1 = box[0], box[1]\n",
    "        x2, y2 = box[2], box[3]\n",
    "    return x1, y1, x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def repnet_grab_worker(gst, wid, frames_queue):\n",
    "    cap = cv2.VideoCapture(gst, cv2.CAP_GSTREAMER)\n",
    "    duration=500\n",
    "    width=112\n",
    "    height=112\n",
    "    stride=4\n",
    "    focus_box=[0.2, 0.2, 0.8, 0.8]\n",
    "    black_box=[0.35, 0.0, 0.65,0.35]\n",
    "    rm_still=True\n",
    "    area_rate_thres=0.003\n",
    "    \n",
    "    f = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if rm_still:\n",
    "        pre_frame = None\n",
    "        area_thres = area_rate_thres * w * h\n",
    "        \n",
    "    if black_box is not None:\n",
    "        black_x1, black_y1, black_x2, black_y2 = cal_rect_points(w, h, black_box)\n",
    "    if focus_box is not None:\n",
    "        focus_x1, focus_y1, focus_x2, focus_y2 = cal_rect_points(w, h, focus_box)\n",
    "        w = focus_x2 - focus_x1\n",
    "        h = focus_y2 - focus_y1\n",
    "    \n",
    "    frames = []\n",
    "    count = 0\n",
    "    n_frames = f * duration\n",
    "    keep_flag = 0\n",
    "    try:\n",
    "        while n_frames > 0:\n",
    "            retval, frame_bgr = cap.read()\n",
    "            n_frames -= 1\n",
    "            if not retval:\n",
    "                continue\n",
    "\n",
    "            if black_box is not None:\n",
    "                frame_bgr[black_y1:black_y2, black_x1:black_x2, :] = 0\n",
    "\n",
    "            if wid:\n",
    "                if focus_box is not None:\n",
    "                    cv2.rectangle(frame_bgr, (focus_x1, focus_y1), (focus_x2, focus_y2), (0, 255, 0), 2)\n",
    "\n",
    "                wid.value = bytes(cv2.imencode(ext='.jpeg', img=frame_bgr)[1])\n",
    "\n",
    "            if focus_box is not None:\n",
    "                frame_bgr = frame_bgr[focus_y1:focus_y2, focus_x1:focus_x2, :]\n",
    "\n",
    "\n",
    "            if rm_still:\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if pre_frame is not None:\n",
    "                    frame_tmp = cv2.absdiff(frame_gray, pre_frame)\n",
    "                    frame_tmp = cv2.threshold(frame_tmp, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "                    frame_tmp = cv2.dilate(frame_tmp, None, iterations=2)\n",
    "                    contours, _ = cv2.findContours(frame_tmp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                    if len(contours) > 0:\n",
    "                        for contour in contours:\n",
    "                            if cv2.contourArea(contour) > area_thres:\n",
    "                                keep_flag += 1\n",
    "                                break\n",
    "                pre_frame = frame_gray\n",
    "\n",
    "            frame_bgr = cv2.resize(frame_bgr, (width, height))\n",
    "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            if not rm_still or keep_flag % stride == 0:\n",
    "                keep_flag = 0\n",
    "                frames.append(frame_rgb)\n",
    "                if len(frames) == 64 and frames_queue:\n",
    "                    frames_queue.put(frames)\n",
    "                    frames = []\n",
    "    finally:\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def repnet_model(wid, frames_queue):\n",
    "    count = 0\n",
    "    wid.value = \"Count: 0\"\n",
    "    output_shapes = [(-1, 1), (-1, NUM_FRAMES // 2)]\n",
    "    MODEL_PATH = '/home/nano/models/repnet_b1.trt'\n",
    "    i = 0\n",
    "    with open(MODEL_PATH, \"rb\") as f, \\\n",
    "        trt.Runtime(TRT_LOGGER) as runtime, \\\n",
    "        runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "        engine.create_execution_context() as context:\n",
    "            \n",
    "        inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        \n",
    "        while True:\n",
    "            np_frames = np.asarray(frames_queue.get(), dtype=np.float32) \n",
    "            np_frames = np_frames.astype(np.float32)\n",
    "            np_frames -= 127.5\n",
    "            np_frames /= 127.5\n",
    "            \n",
    "            np_inputs = np.reshape(np_frames, (1, NUM_FRAMES, INPUT_SIZE, INPUT_SIZE, 3))\n",
    "\n",
    "            within_period_scores = []\n",
    "            period_scores = []\n",
    "            inputs[0].host = np_inputs\n",
    "            trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "            trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "            np_within_period_scores = trt_outputs[0].copy()\n",
    "            np_period_scores = trt_outputs[1].copy()\n",
    "            \n",
    "            \n",
    "            per_frame_periods = np.argmax(np_period_scores, axis=-1) + 1\n",
    "            conf_pred_periods = np.max(softmax(np_period_scores, axis=-1), axis=-1)\n",
    "            conf_pred_periods = np.where(per_frame_periods < 3, 0.0, conf_pred_periods)\n",
    "            \n",
    "            within_period_scores = sigmoid(np_within_period_scores)[:, 0]\n",
    "            within_period_scores = np.sqrt(within_period_scores * conf_pred_periods)\n",
    "            within_period_binary = np.asarray(within_period_scores > 0.5)\n",
    "\n",
    "            per_frame_counts = np.where(per_frame_periods < 3, 0.0, 1 / per_frame_periods)\n",
    "            count += sum(per_frame_counts)\n",
    "            i += 1\n",
    "            \n",
    "            wid.value = \"Count: %d\" % count\n",
    "            if i > 20:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_vid = widgets.Text(value=\"Count: 0\")\n",
    "grap_wid = widgets.Image(format='jpeg')\n",
    "display(widgets.VBox([count_vid, grap_wid]))\n",
    "\n",
    "repnet_grap_worker = threading.Thread(target=repnet_grab_worker, args=(usb_gst, grap_wid, frames_queue))\n",
    "repnet_grap_worker.start()\n",
    "repnet_model(count_vid, frames_queue)\n",
    "repnet_grap_worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [multiprocessing fork() vs spawn()][1] \n",
    "<div class=\"alert alert-info\"><code>\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "mp.set_start_method('fork', force=True)\n",
    "</code></div>\n",
    "\n",
    "[1]: https://stackoverflow.com/questions/64095876/multiprocessing-fork-vs-spawn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Failed to create CaptureSession][1]\n",
    "<div class=\"alert alert-warning\">\n",
    "This may happen if there is another session using this same camera (hung or alive) and try to use same camera again; if this issue is happening sometimes. You can close all sessions and reset the nvargus-daemon to reset the argus framework and try nvgstcapture-1.0 again. \n",
    "<code>\n",
    "sudo systemctl restart nvargus-daemon\n",
    "</code></div>\n",
    "\n",
    "[1]: https://forums.developer.nvidia.com/t/error-generated-gstnvarguscamerasrc-cpp-execute-543-failed-to-create-capturesession/112431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "292.969px",
    "left": "1457px",
    "top": "66px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
