{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-and-Define-Utils\" data-toc-modified-id=\"Load-and-Define-Utils-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load and Define Utils</a></span><ul class=\"toc-item\"><li><span><a href=\"#JsonEncoder\" data-toc-modified-id=\"JsonEncoder-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>JsonEncoder</a></span></li><li><span><a href=\"#Display\" data-toc-modified-id=\"Display-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Display</a></span></li><li><span><a href=\"#Easy-Widget\" data-toc-modified-id=\"Easy-Widget-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Easy Widget</a></span></li></ul></li><li><span><a href=\"#System-Tools-and-Info\" data-toc-modified-id=\"System-Tools-and-Info-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>System Tools and Info</a></span><ul class=\"toc-item\"><li><span><a href=\"#jtop\" data-toc-modified-id=\"jtop-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>jtop</a></span></li><li><span><a href=\"#v4l-utils\" data-toc-modified-id=\"v4l-utils-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>v4l-utils</a></span></li><li><span><a href=\"#opencv\" data-toc-modified-id=\"opencv-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>opencv</a></span></li><li><span><a href=\"#Others\" data-toc-modified-id=\"Others-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Others</a></span><ul class=\"toc-item\"><li><span><a href=\"#nvpmodel:-set-nvidia-power-mode\" data-toc-modified-id=\"nvpmodel:-set-nvidia-power-mode-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>nvpmodel: set nvidia power mode</a></span></li><li><span><a href=\"#power-fan\" data-toc-modified-id=\"power-fan-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>power fan</a></span></li><li><span><a href=\"#desktop-(not-required)\" data-toc-modified-id=\"desktop-(not-required)-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>desktop (not required)</a></span></li><li><span><a href=\"#nvargus-daemon\" data-toc-modified-id=\"nvargus-daemon-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>nvargus-daemon</a></span></li><li><span><a href=\"#docker-dli\" data-toc-modified-id=\"docker-dli-2.4.5\"><span class=\"toc-item-num\">2.4.5&nbsp;&nbsp;</span>docker dli</a></span></li><li><span><a href=\"#Install-Jetcam\" data-toc-modified-id=\"Install-Jetcam-2.4.6\"><span class=\"toc-item-num\">2.4.6&nbsp;&nbsp;</span>Install Jetcam</a></span></li></ul></li></ul></li><li><span><a href=\"#CPU-VS-GPU-(opencv)\" data-toc-modified-id=\"CPU-VS-GPU-(opencv)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CPU VS GPU (opencv)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Camera-Test\" data-toc-modified-id=\"Camera-Test-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Camera Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#CSI-Camera(video0)\" data-toc-modified-id=\"CSI-Camera(video0)-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>CSI Camera(video0)</a></span></li><li><span><a href=\"#USB-Camera-(video1)\" data-toc-modified-id=\"USB-Camera-(video1)-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>USB Camera (video1)</a></span></li></ul></li></ul></li><li><span><a href=\"#GStreamer-Test\" data-toc-modified-id=\"GStreamer-Test-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>GStreamer Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#GStreamer-1.0\" data-toc-modified-id=\"GStreamer-1.0-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>GStreamer-1.0</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shm-Source\" data-toc-modified-id=\"Shm-Source-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Shm Source</a></span></li></ul></li><li><span><a href=\"#UDPSink\" data-toc-modified-id=\"UDPSink-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>UDPSink</a></span></li><li><span><a href=\"#SHMSink\" data-toc-modified-id=\"SHMSink-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>SHMSink</a></span></li></ul></li><li><span><a href=\"#Repnet-Model\" data-toc-modified-id=\"Repnet-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Repnet Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pre-Process\" data-toc-modified-id=\"Pre-Process-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Pre Process</a></span></li><li><span><a href=\"#Model-Output\" data-toc-modified-id=\"Model-Output-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Model Output</a></span></li><li><span><a href=\"#Post-Process\" data-toc-modified-id=\"Post-Process-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Post Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calculate-Scores\" data-toc-modified-id=\"Calculate-Scores-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Calculate Scores</a></span></li><li><span><a href=\"#Calculate-Count\" data-toc-modified-id=\"Calculate-Count-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Calculate Count</a></span></li></ul></li></ul></li><li><span><a href=\"#Make-it-together\" data-toc-modified-id=\"Make-it-together-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Make it together</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<center>The Notebook Only Run On Jetson The Device</center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notename = !uname -n\n",
    "if 'nano' != notename[0]:\n",
    "    raise RuntimeError('notebook server is not jetson device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.4\n",
      "sklearn not installed\n",
      "pandas 0.22.0\n",
      "ipywidgets 6.0.0\n",
      "cv2 4.5.1\n",
      "PIL 5.1.0\n",
      "matplotlib 2.1.1\n",
      "plotly not installed\n",
      "netron not installed\n",
      "torch not installed\n",
      "torchvision not installed\n",
      "torchaudio not installed\n",
      "tensorflow 2.5.0+nv21.8\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx not installed\n",
      "onnxruntime 1.8.1\n",
      "tensorrt 8.0.1.6\n",
      "tvm 0.8.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:11: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "import threading, queue\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "\n",
    "SCRIPT_DIR = '/home/nano/omega/jetson/scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### JsonEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json, functools, datetime\n",
    "class __JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.datetime, datetime.timedelta)):\n",
    "            return '{}'.format(obj)\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps = functools.partial(json.dumps, cls=__JsonEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT('import pandas as pd')\n",
    "_IMPORT('import cv2')\n",
    "_IMPORT('from PIL import Image')\n",
    "_IMPORT('import matplotlib.pyplot as plt')\n",
    "_IMPORT('import plotly')\n",
    "_IMPORT('import plotly.graph_objects as go')\n",
    "_IMPORT('import ipywidgets as widgets')\n",
    "_IMPORT('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_read(url, rgb=True, size=None):\n",
    "    if url.startswith('http'):\n",
    "        response = requests.get(url)\n",
    "        if response:\n",
    "            imgmat = np.frombuffer(response.content, dtype=np.uint8)\n",
    "            img = cv2.imdecode(imgmat, cv2.IMREAD_COLOR)\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        img = cv2.imread(url)\n",
    "        \n",
    "    if rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if size:\n",
    "        if isinstance(size, int):\n",
    "            size = (size, size)\n",
    "        img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMPORT('/home/nano/nb_easy/easy_widget.py')\n",
    "\n",
    "def switch_play_video(context, btnwid, oldval, newval, framecntwid, gstwid, frameimgwid):\n",
    "    def _video_cap_loop():\n",
    "        context.logger(\"Open GStreamer ... %s\" % gstwid.value)\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(gstwid.value, cv2.CAP_GSTREAMER)\n",
    "            if cap.isOpened():\n",
    "                context.logger('GStreamer is Opened!')\n",
    "                count = 0\n",
    "                while btnwid.value and count < framecntwid.value:\n",
    "                    retval, frame = cap.read()\n",
    "                    if retval:\n",
    "                        frameimgwid.value = bytes(cv2.imencode(ext='.jpeg', img=frame)[1])\n",
    "                    count += 1\n",
    "                cap.release()\n",
    "            btnwid.value = False\n",
    "            context.logger('GStreamer is Stopped!')\n",
    "        except Exception as err:\n",
    "            context.logger('%s' % err)\n",
    "    if newval:\n",
    "        framecntwid.disabled = True\n",
    "        btnwid.icon = 'stop-circle'\n",
    "        btnwid.description = 'Stop'\n",
    "        context.logger('Start Thread... ')\n",
    "        threading.Thread(target=_video_cap_loop, args=()).start()\n",
    "    else:\n",
    "        framecntwid.disabled = False\n",
    "        btnwid.icon = 'play'\n",
    "        btnwid.description= 'Start'\n",
    "        \n",
    "\n",
    "def get_play_schema(gst):\n",
    "     return {\n",
    "        'type': 'page',\n",
    "        'objs': [\n",
    "            {\n",
    "                'type': 'H',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_togglebutton('switch_play', 'Start', icon='play'),\n",
    "                    nbeasy_widget_int('frame_count', 'Frame Count', default=300, min_=100, max_=900, width=150),\n",
    "                    nbeasy_widget_string('gst', 'GStreamer', gst, width='70%', readonly=True),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'type': 'V',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_image('frame_image', 'Image', '', format='jpeg')\n",
    "                ],\n",
    "                'align_items': 'center'\n",
    "            },\n",
    "            {\n",
    "                'type': 'observe',\n",
    "                'objs': [\n",
    "                    {\n",
    "                        'handler': switch_play_video,\n",
    "                        'params': {\n",
    "                            'source': 'switch_play',\n",
    "                            'targets': [\n",
    "                                'frame_count',\n",
    "                                'gst',\n",
    "                                'frame_image'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# easy = nbeasy_schema_parse(get_play_schema(gst), debug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Tools and Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jtop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./nano_jtop_6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo -H pip3 install -U jetson-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from jtop import jtop\n",
    "with jtop() as jetson:\n",
    "    if jetson.ok():\n",
    "        print(json.dumps(jetson.stats, indent=4))\n",
    "jetson.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_ARCH_BIN = jetson.board.hardware.get('CUDA_ARCH_BIN')\n",
    "CUDA_ARCH_BIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v4l-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt install v4l-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! v4l2-ctl --help-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! v4l2-ctl --list-devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! v4l2-ctl -d /dev/video0 --list-formats-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! v4l2-ctl -d /dev/video1 --list-formats-ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%writefile $SCRIPT_DIR/install_opencv_cuda.sh\n",
    "\n",
    "OPENCV_VER=4.1.1\n",
    "CUDA_ARCH_BIN=5.3\n",
    "OPENCV_ROOT=/home/nano/omega/jetson/opencv/\n",
    "\n",
    "sudo apt-get install -y build-essential cmake git unzip pkg-config\n",
    "sudo apt-get install -y libjpeg-dev libpng-dev libtiff-dev\n",
    "sudo apt-get install -y libavcodec-dev libavformat-dev libswscale-dev\n",
    "sudo apt-get install -y libgtk2.0-dev libcanberra-gtk*\n",
    "sudo apt-get install -y python3-dev python3-numpy python3-pip\n",
    "sudo apt-get install -y libxvidcore-dev libx264-dev libgtk-3-dev\n",
    "sudo apt-get install -y libtbb2 libtbb-dev libdc1394-22-dev\n",
    "sudo apt-get install -y libv4l-dev v4l-utils\n",
    "sudo apt-get install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev\n",
    "sudo apt-get install -y libavresample-dev libvorbis-dev libxine2-dev\n",
    "sudo apt-get install -y libfaac-dev libmp3lame-dev libtheora-dev\n",
    "sudo apt-get install -y libopencore-amrnb-dev libopencore-amrwb-dev\n",
    "sudo apt-get install -y libopenblas-dev libatlas-base-dev libblas-dev\n",
    "sudo apt-get install -y liblapack-dev libeigen3-dev gfortran\n",
    "sudo apt-get install -y libhdf5-dev protobuf-compiler\n",
    "sudo apt-get install -y libprotobuf-dev libgoogle-glog-dev libgflags-dev\n",
    "\n",
    "\n",
    "cd $OPENCV_ROOT\n",
    "\n",
    "wget -O opencv.zip https://github.91chifun.workers.dev/https://github.com//opencv/opencv/archive/refs/tags/$OPENCV_VER.zip\n",
    "wget -O opencv_contrib.zip  https://github.91chifun.workers.dev/https://github.com//opencv/opencv_contrib/archive/refs/tags/$OPENCV_VER.zip\n",
    "        \n",
    "unzip opencv.zip\n",
    "unzip opencv_contrib.zip\n",
    "\n",
    "rm -f opencv.zip opencv_contrib.zip\n",
    "\n",
    "cd opencv-$OPENCV_VER\n",
    "mkdir build\n",
    "cd build\n",
    "cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
    "    -D CMAKE_INSTALL_PREFIX=/usr \\\n",
    "    -D OPENCV_EXTRA_MODULES_PATH=$OPENCV_ROOT/opencv_contrib-$OPENCV_VER/modules \\\n",
    "    -D EIGEN_INCLUDE_PATH=/usr/include/eigen3 \\\n",
    "    -D WITH_OPENCL=OFF \\\n",
    "    -D WITH_CUDA=ON \\\n",
    "    -D CUDA_ARCH_BIN=$CUDA_ARCH_BIN \\\n",
    "    -D CUDA_ARCH_PTX=\"\" \\\n",
    "    -D WITH_CUDNN=ON \\\n",
    "    -D WITH_CUBLAS=ON \\\n",
    "    -D ENABLE_FAST_MATH=ON \\\n",
    "    -D CUDA_FAST_MATH=ON \\\n",
    "    -D OPENCV_DNN_CUDA=ON \\\n",
    "    -D ENABLE_NEON=ON \\\n",
    "    -D WITH_QT=OFF \\\n",
    "    -D WITH_OPENMP=ON \\\n",
    "    -D WITH_OPENGL=ON \\\n",
    "    -D BUILD_TIFF=ON \\\n",
    "    -D WITH_FFMPEG=ON \\\n",
    "    -D WITH_GSTREAMER=ON \\\n",
    "    -D WITH_TBB=ON \\\n",
    "    -D BUILD_TBB=ON \\\n",
    "    -D BUILD_TESTS=OFF \\\n",
    "    -D WITH_EIGEN=ON \\\n",
    "    -D WITH_V4L=ON \\\n",
    "    -D WITH_LIBV4L=ON \\\n",
    "    -D OPENCV_ENABLE_NONFREE=ON \\\n",
    "    -D INSTALL_C_EXAMPLES=OFF \\\n",
    "    -D INSTALL_PYTHON_EXAMPLES=OFF \\\n",
    "    -D BUILD_NEW_PYTHON_SUPPORT=ON \\\n",
    "    -D BUILD_opencv_python3=TRUE \\\n",
    "    -D OPENCV_GENERATE_PKGCONFIG=ON \\\n",
    "    -D BUILD_EXAMPLES=OFF ..\n",
    "    \n",
    "make -j$(nproc) && sudo make install && sudo ldconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!dpkg -l | grep -i libopencv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nvpmodel: set nvidia power mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo nvpmodel -m 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo nvpmodel -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### power fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $SCRIPT_DIR/local.rc\n",
    "\n",
    "sudo /usr/bin/jetson_clocks\n",
    "\n",
    "# start\n",
    "sudo sh -c 'echo 255 > /sys/devices/pwm-fan/target_pwm'\n",
    "# stop\n",
    "# sudo sh -c 'echo 0 >/sys/devices/pwm-fan/target_pwm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### desktop (not required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "\n",
    "# 安装桌面\n",
    "sudo apt install xubuntu-desktop\n",
    "sudo dpkg-reconfigure lightdm\n",
    "\n",
    "# 关闭图形用户界面\n",
    "sudo systemctl set-default multi-user.target\n",
    "sudo reboot\n",
    " \n",
    "# 启用图形用户界面\n",
    "sudo systemctl set-default graphical.target\n",
    "sudo reboot\n",
    "\n",
    "sudo init 3 # 临时关闭桌面\n",
    "sudo init 5 # 临时重启桌面\n",
    "\n",
    "```\n",
    "\n",
    "```sh\n",
    "# 删除桌面\n",
    "sudo apt autoremove --purge $( dpkg-query -l *xubuntu* | grep ii | tr -s \" \" | cut -d\" \" -f2; dpkg-query -l *xfce* | grep 'ii' | tr -s \" \" | cut -d\" \" -f2 )\n",
    "sudo apt autoremove --purge lightdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nvargus-daemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "sudo systemctl stop nvargus-daemon\n",
    "export enableCamScfLogs=5\n",
    "sudo /usr/sbin/nvargus-daemon\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docker dli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $SCRIPT_DIR/docker_dli_run.sh\n",
    "\n",
    "VERSION=v2.0.1-r32.6.1\n",
    "\n",
    "ARGS=\n",
    "\n",
    "if [[ -e /dev/video0 ]] \n",
    "then\n",
    "    ARGS=\"$ARGS --device /dev/video0\"\n",
    "fi\n",
    "\n",
    "if [[ -e /dev/video1 ]] \n",
    "then\n",
    "    ARGS=\"$ARGS --device /dev/video1\"\n",
    "fi\n",
    "\n",
    "sudo docker run --runtime nvidia -it --rm --network host \\\n",
    "    --volume ~/nvdli-data:/nvdli-nano/data \\\n",
    "    --volume /tmp/argus_socket:/tmp/argus_socket \\\n",
    "    $ARGS \\\n",
    "    nvcr.io/nvidia/dli/dli-nano-ai:$VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Jetcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh \n",
    "git clone https://github.com/NVIDIA-AI-IOT/jetcam\n",
    "cd jetcam\n",
    "sudo python3 setup.py install\n",
    "```\n",
    "<div style=\"margin-top:30px; width: 100%;\">\n",
    "    <div style=\"float:left;\">\n",
    "        <a\n",
    "           title=\"JetCam GITHUB\"\n",
    "           href=\"https://github.com/NVIDIA-AI-IOT/jetcam\"\n",
    "           style=\"color:blue;font-size:28px;text-decoration:none;\">\n",
    "                &#128279;\n",
    "        </a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU VS GPU (opencv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /home/nano/opencv_cpu_vs_gpu.py\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "### VALUES\n",
    "NUM_REPEAT = 10000\n",
    "\n",
    "if cv2.cuda.getCudaEnabledDeviceCount() == 0:\n",
    "    raise RuntimeError('opencv not enable cuda')\n",
    "\n",
    "### Read source image\n",
    "img_src = im_read(\"https://raceai.s3.didiyunapi.com/data/datasets/cv/Dinner_plate/blue/blue1.jpg\")\n",
    "\n",
    "### Run with CPU\n",
    "time_start = time.time()\n",
    "for i in range (NUM_REPEAT):\n",
    "    img_dst = cv2.resize(img_src, (300, 300))\n",
    "time_end = time.time()\n",
    "print(\"CPU = {0}\".format((time_end - time_start) * 1000 / NUM_REPEAT) + \"[msec]\")\n",
    "\n",
    "### Run with GPU\n",
    "img_gpu_src = cv2.cuda_GpuMat() # Allocate device memory only once, as memory allocation seems to take time...\n",
    "img_gpu_dst = cv2.cuda_GpuMat()\n",
    "time_start = time.time()\n",
    "for i in range (NUM_REPEAT):\n",
    "    img_gpu_src.upload(img_src)\n",
    "    img_gpu_dst = cv2.cuda.resize(img_gpu_src, (300, 300))\n",
    "    img_dst = img_gpu_dst.download()\n",
    "time_end = time.time()\n",
    "print(\"GPU = {0}\".format((time_end - time_start) * 1000 / NUM_REPEAT) + \"[msec]\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSI Camera(video0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_pipelines = [\n",
    "    \"nvarguscamerasrc sensor-id=0\",\n",
    "    \"video/x-raw(memory:NVMM), width=640, height=480, format=(string)NV12, framerate=(fraction)30/1\",\n",
    "    \"nvvidconv\",\n",
    "    \"video/x-raw, width=(int)224, height=(int)224, format=(string)BGRx\",\n",
    "    \"videoconvert\",\n",
    "    \"appsink\"\n",
    "]\n",
    "\n",
    "csi_gst = \" ! \".join(csi_pipelines)\n",
    "csi_gst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_cap = cv2.VideoCapture(csi_gst, cv2.CAP_GSTREAMER)\n",
    "if csi_cap.isOpened():\n",
    "    retval, image = csi_cap.read()\n",
    "    if retval:\n",
    "        print(image.shape)\n",
    "csi_cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USB Camera (video1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usb_pipelines = [\n",
    "    'v4l2src device=/dev/video1',\n",
    "    'video/x-raw, width=(int)640, height=(int)480, framerate=(fraction)30/1',\n",
    "    'videoconvert',\n",
    "    'video/x-raw, format=(string)BGR',\n",
    "    'videoflip video-direction=4',\n",
    "    'textoverlay halignment=0 valignment=2 text=TalentAI',\n",
    "    'clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\"',\n",
    "    'appsink'\n",
    "]\n",
    "\n",
    "usb_gst = \" ! \".join(usb_pipelines)\n",
    "usb_gst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg')\n",
    "display(image_widget)\n",
    "usb_cap = cv2.VideoCapture(usb_gst, cv2.CAP_GSTREAMER)\n",
    "count = 0\n",
    "if usb_cap.isOpened():\n",
    "    retval, image = usb_cap.read()\n",
    "    if retval:\n",
    "        print('image shape:', image.shape, 'image format type:', image.dtype)\n",
    "    start = time.time()\n",
    "    while count < 100:\n",
    "        retval, image = usb_cap.read()\n",
    "        if retval:\n",
    "            image_widget.value = bytes(cv2.imencode(ext='.jpeg', img=image)[1])\n",
    "        count += 1\n",
    "    print(300 / (time.time() - start), 'vs', 'fps: 30')\n",
    "usb_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usb_cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GStreamer Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GStreamer-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top:30px; width: 100%;\">\n",
    "    <div style=\"float:left;\">\n",
    "        <a\n",
    "           title=\"Install\"\n",
    "           href=\"https://docs.nvidia.com/jetson/l4t/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/accelerated_gstreamer.html#wwpID0E0R40HA\"\n",
    "           style=\"color:blue;font-size:28px;text-decoration:none;\">\n",
    "                &#128279; nvidia gstreamer\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float:left;\">\n",
    "        <a\n",
    "           title=\"gst inspect\"\n",
    "           href=\"https://gstreamer.freedesktop.org/documentation/tools/gst-inspect.html?gi-language=python\"\n",
    "           style=\"color:blue;font-size:28px;text-decoration:none;\">\n",
    "                &#128279; gst-inspect-1.0\n",
    "        </a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gst-inspect-1.0 --help-all\n",
    "# ! gst-inspect-1.0  | grep 'nvdec\\|nvenc'\n",
    "# ! gst-inspect-1.0 v4l2src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gst-launch-1.0 -v nvarguscamerasrc ! nvv4l2h264enc ! h264parse ! flvmux name=mux ! queue ! rtmpsink location='rtmp://116.85.58.226:1935/live/nano?vhost=seg.600s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/nano/omega/jetson/scripts/gst_cmd_demo.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_DIR/gst_cmd_demo.txt\n",
    "\n",
    "gst-launch-1.0 -vvv nvarguscamerasrc sensor-id=0 \\\n",
    "    ! video/x-raw(memory:NVMM), width=640, height=480, format=(string)NV12, framerate=(fraction)30/1 \\\n",
    "    ! nvvidconv \\\n",
    "    ! video/x-raw, width=(int)224, height=(int)224, format=(string)BGRx \\\n",
    "    ! videoconvert ! appsink\n",
    "    \n",
    "gst-launch-1.0 -vvv nvarguscamerasrc sensor-id=0 \\\n",
    "    ! video/x-raw(memory:NVMM), width=640, height=480, format=(string)NV12, framerate=(fraction)30/1 \\\n",
    "    ! nvvidconv \\\n",
    "    ! video/x-raw, width=(int)224, height=(int)224, format=(string)BGRx \\\n",
    "    ! videoconvert \\\n",
    "    ! shmsink socket-path=/tmp/gst_shm_socket_0 shm-size=2000000\n",
    "    \n",
    "gst-launch-1.0 v4l2src device=/dev/video1 \\\n",
    "    ! \"video/x-raw, width=(int)640, height=(int)480, framerate=(fraction)30/1\" \\\n",
    "    ! videoconvert \\\n",
    "    ! \"video/x-raw, format=(string)BGR\" \\\n",
    "    ! videoflip video-direction=4 \\\n",
    "    ! textoverlay halignment=0 valignment=2 text=TalentAI \\\n",
    "    ! clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\" \\\n",
    "    ! shmsink socket-path=/tmp/gst_shm_socket_1 shm-size=2000000\n",
    "    \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! gst-inspect-1.0 timeoverlay\n",
    "# ! gst-inspect-1.0 clockoverlay\n",
    "# ! gst-inspect-1.0 videoflip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shm Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDPSink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 3 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%bash --bg --proc bg_gst_udpsink\n",
    "\n",
    "pid=`ps -eo pid,command | grep \"gst-launch\"  | grep -v \"grep\" | cut -c1-6`\n",
    "if [[ x$pid != x ]]\n",
    "then\n",
    "    kill -9 $pid\n",
    "fi\n",
    "\n",
    "gst-launch-1.0 -e nvarguscamerasrc sensor-id=0 \\\n",
    "    ! 'video/x-raw(memory:NVMM), width=640, height=480, framerate=30/1' \\\n",
    "    ! nvv4l2h264enc bitrate=8000000 insert-sps-pps=true \\\n",
    "    ! rtph264pay mtu=1400 \\\n",
    "    ! udpsink host=127.0.0.1 port=5000 sync=false async=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subprocess.Popen: [\"args\", \"communicate\", \"encoding\", \"errors\", \"kill\", \"pid\", \"poll\", \"returncode\", \"send_signal\", \"stderr\", \"stdin\", \"stdout\", \"terminate\", \"universal_newlines\", \"wait\"]'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_DIR(bg_gst_udpsink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f677f5f16f584634942b19d98bf11f40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "udp_pipelines = [\n",
    "    'udpsrc port=5000 caps = \"application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264\"',\n",
    "    'rtph264depay',\n",
    "    'avdec_h264',\n",
    "    'videoconvert',\n",
    "    'appsink'\n",
    "]\n",
    "\n",
    "nbeasy_schema_parse(get_play_schema(' ! '.join(udp_pipelines)), debug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_gst_udpsink.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHMSink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 20 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%bash --bg --proc bg_gst_shmsink\n",
    "\n",
    "pid=`ps -eo pid,command | grep \"gst-launch\"  | grep -v \"grep\" | cut -c1-6`\n",
    "if [[ x$pid != x ]]\n",
    "then\n",
    "    kill -9 $pid\n",
    "fi\n",
    "\n",
    "sudo rm -rf /tmp/gst_shm_socket*\n",
    "\n",
    "gst-launch-1.0 -e nvarguscamerasrc sensor-id=0 sensor-mode=4 do-timestamp=true \\\n",
    "    ! 'video/x-raw(memory:NVMM), width=1280, height=720, framerate=30/1' \\\n",
    "    ! nvvidconv flip-method=1 \\\n",
    "    ! 'video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx' \\\n",
    "    ! videoconvert \\\n",
    "    ! shmsink socket-path=/tmp/gst_shm_socket_0 sync=true wait-for-connection=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3101aeb0271488b9c9bfad2d48217c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shm_pipelines = [\n",
    "    'shmsrc socket-path=/tmp/gst_shm_socket_0',\n",
    "    'video/x-raw, format=BGR, width=640, height=480, framerate=30/1',\n",
    "    'decodebin',\n",
    "    'videoconvert',\n",
    "    'appsink'\n",
    "]\n",
    "\n",
    "nbeasy_schema_parse(get_play_schema(' ! '.join(shm_pipelines)), debug=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_FRAMES = 64\n",
    "INPUT_SIZE = 112\n",
    "STRIDES = [4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cal_rect_points(w, h, box):\n",
    "    if box[0] < 1.0 and box[1] < 1.0 and box[2] <= 1.0 and box[3] <= 1.0:\n",
    "        x1, y1 = int(w * box[0]), int(h * box[1])\n",
    "        x2, y2 = int(w * box[2]), int(h * box[3])\n",
    "    else:\n",
    "        x1, y1 = box[0], box[1]\n",
    "        x2, y2 = box[2], box[3]\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def repnet_grab_video(\n",
    "    cap, duration=30, width=112, height=112,\n",
    "    black_box=None, focus_box=None,\n",
    "    rm_still=False, area_rate_thres=0.003,\n",
    "    wid = None):\n",
    "    \n",
    "    f = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if rm_still:\n",
    "        pre_frame = None\n",
    "        area_thres = area_rate_thres * w * h\n",
    "        \n",
    "    if black_box is not None:\n",
    "        black_x1, black_y1, black_x2, black_y2 = cal_rect_points(w, h, black_box)\n",
    "    if focus_box is not None:\n",
    "        focus_x1, focus_y1, focus_x2, focus_y2 = cal_rect_points(w, h, focus_box)\n",
    "        w = focus_x2 - focus_x1\n",
    "        h = focus_y2 - focus_y1\n",
    "        \n",
    "    wr_file = os.path.join('/home/nano/omega/', 'video_rec.mp4')\n",
    "    wr_vid = cv2.VideoWriter(wr_file, cv2.VideoWriter_fourcc(*'mp4v'), f, (w, h))\n",
    "    \n",
    "    frames = []\n",
    "    count = 0\n",
    "    n_frames = f * duration\n",
    "    while n_frames > 0:\n",
    "        retval, frame_bgr = cap.read()\n",
    "        n_frames -= 1\n",
    "        if not retval:\n",
    "            continue\n",
    "        keep_flag = False\n",
    "        \n",
    "        if black_box is not None:\n",
    "            frame_bgr[black_y1:black_y2, black_x1:black_x2, :] = 0\n",
    "            \n",
    "        if wid:\n",
    "            if focus_box is not None:\n",
    "                cv2.rectangle(frame_bgr, (focus_x1, focus_y1), (focus_x2, focus_y2), (0, 255, 0), 2)\n",
    "            # if black_box is not None:\n",
    "            #     cv2.rectangle(frame_bgr, (black_x1, black_y1), (black_x2, black_y2), (0, 0, 0), 2)\n",
    "                \n",
    "            wid.value = bytes(cv2.imencode(ext='.jpeg', img=frame_bgr)[1])\n",
    "            wr_vid.write(frame_bgr)\n",
    "            \n",
    "        if focus_box is not None:\n",
    "            frame_bgr = frame_bgr[focus_y1:focus_y2, focus_x1:focus_x2, :]\n",
    "\n",
    "            \n",
    "        if rm_still:\n",
    "            frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "            if pre_frame is not None:\n",
    "                frame_tmp = cv2.absdiff(frame_gray, pre_frame)\n",
    "                frame_tmp = cv2.threshold(frame_tmp, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "                frame_tmp = cv2.dilate(frame_tmp, None, iterations=2)\n",
    "                contours, _ = cv2.findContours(frame_tmp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                if len(contours) > 0:\n",
    "                    for contour in contours:\n",
    "                        if cv2.contourArea(contour) > area_thres:\n",
    "                            keep_flag = True\n",
    "                            break\n",
    "            pre_frame = frame_gray\n",
    "\n",
    "        frame_bgr = cv2.resize(frame_bgr, (width, height))\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        if not rm_still or keep_flag:\n",
    "            frames.append(frame_rgb)\n",
    "    wr_vid.release()\n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b11dbbb915345e998479b32c945cf8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15.175778150558472, 312)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gst = usb_gst\n",
    "cap = cv2.VideoCapture(gst, cv2.CAP_GSTREAMER)\n",
    "\n",
    "grap_wid = widgets.Image(format='jpeg')\n",
    "display(grap_wid)\n",
    "s = time.time()\n",
    "try:\n",
    "    np_frames = repnet_grab_video(\n",
    "        cap, duration=15,\n",
    "        focus_box=[0.2, 0.2, 0.8, 0.8],\n",
    "        black_box=[0.35, 0.0, 0.65,0.35],\n",
    "        rm_still=True,\n",
    "        wid=grap_wid\n",
    "    )\n",
    "finally:\n",
    "    cap.release()\n",
    "time.time() - s, len(np_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "sys.path.append('/usr/src/tensorrt/samples/python')\n",
    "\n",
    "import common\n",
    "\n",
    "TRT_LOGGER = trt.Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_frames = np_frames.astype(np.float32)\n",
    "np_frames -= 127.5\n",
    "np_frames /= 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames: 312\n",
      "num_batches: 2\n",
      "7.124357223510742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((128, 1), (128, 32))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = '/home/nano/models/repnet_b1.trt'\n",
    "\n",
    "stride = STRIDES[0]\n",
    "\n",
    "\n",
    "frames_seq_len = len(np_frames)\n",
    "print(\"num_frames:\", frames_seq_len)\n",
    "\n",
    "num_batches = int(np.ceil(frames_seq_len / NUM_FRAMES / stride / BATCH_SIZE))\n",
    "print(\"num_batches:\", num_batches)\n",
    "\n",
    "K = NUM_FRAMES * stride * BATCH_SIZE\n",
    "\n",
    "output_shapes = [(-1, 1), (-1, NUM_FRAMES // 2)]\n",
    "within_period_scores = []\n",
    "period_scores = []\n",
    "with open(MODEL_PATH, \"rb\") as f, \\\n",
    "    trt.Runtime(TRT_LOGGER) as runtime, \\\n",
    "    runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "    engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        \n",
    "    start = time.time()\n",
    "    for batch_idx in range(num_batches):\n",
    "        idxes = range(batch_idx * K, (batch_idx + 1) * K, stride)\n",
    "        idxes = np.clip(idxes, 0, frames_seq_len - 1)\n",
    "        np_inputs = np.reshape(np.take(np_frames, idxes, axis=0), (BATCH_SIZE, NUM_FRAMES, INPUT_SIZE, INPUT_SIZE, 3))\n",
    "        inputs[0].host = np_inputs\n",
    "        trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "        trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "        within_period_scores.append(trt_outputs[0].copy())\n",
    "        period_scores.append(trt_outputs[1].copy())\n",
    "    print(time.time() - start)\n",
    "    \n",
    "    np_within_period_scores = np.concatenate(within_period_scores, axis=0)\n",
    "    np_period_scores = np.concatenate(period_scores, axis=0)\n",
    "    \n",
    "np_within_period_scores.shape, np_period_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "  e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "  return e_x / np.sum(e_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7220123 , 0.7463001 , 0.87977093, 0.91712135, 0.8924475 ,\n",
       "       0.85733384, 0.80690604, 0.8692044 , 0.8772147 , 0.82718176],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_period_scores = sigmoid(np_within_period_scores)[:, 0]\n",
    "within_period_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 29, 16, 16, 16, 11, 29, 29,\n",
       "        29, 29, 29]),\n",
       " array([0.15444997, 0.19517766, 0.15174979, 0.12972385, 0.14001933,\n",
       "        0.14640234, 0.13848084, 0.13389178, 0.15653203, 0.17029709,\n",
       "        0.14815323, 0.16268641, 0.17944562, 0.1493676 , 0.1430226 ,\n",
       "        0.14058772, 0.1320132 , 0.1926608 , 0.18879111, 0.2944325 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_frame_periods = np.argmax(np_period_scores, axis=-1) + 1\n",
    "conf_pred_periods = np.max(softmax(np_period_scores, axis=-1), axis=-1)\n",
    "per_frame_periods[:20], conf_pred_periods[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15444997, 0.19517766, 0.15174979, 0.12972385, 0.14001933,\n",
       "       0.14640234, 0.13848084, 0.13389178, 0.15653203, 0.17029709],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_pred_periods = np.where(per_frame_periods < 3, 0.0, conf_pred_periods)\n",
    "conf_pred_periods[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.33393827, 0.38165572, 0.36538345, 0.3449239 , 0.35349667,\n",
       "        0.35428193, 0.33427688, 0.34114414, 0.37055662, 0.37532204],\n",
       "       dtype=float32), 'pred socre (4): 0.184144')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_period_scores = np.sqrt(within_period_scores * conf_pred_periods)\n",
    "within_period_scores[:10], 'pred socre (%d): %.6f' % (stride, np.mean(within_period_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
       "       0.0625, 0.0625])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_frame_counts = np.where(per_frame_periods < 3, 0.0, 1 / per_frame_periods)\n",
    "per_frame_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312,), (312, 32))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_within_period_scores = np.repeat(within_period_scores, stride, axis=0)[:frames_seq_len]\n",
    "all_period_scores = np.repeat(np_period_scores, stride, axis=0)[:frames_seq_len]\n",
    "all_period_counts = (1 / stride) * np.repeat(per_frame_counts, stride, axis=0)[:frames_seq_len]\n",
    "all_within_period_scores.shape, all_period_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9184337214509624"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_period_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_within_period_binary = np.asarray(all_within_period_scores > 0.5)\n",
    "all_within_period_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46896551724137925"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_period_counts * np.asarray(all_within_period_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.015625  , 0.015625  , 0.015625  , 0.015625  ,\n",
       "       0.015625  , 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00892857,\n",
       "       0.00892857, 0.00892857, 0.00892857, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05      , 0.05      , 0.05      ,\n",
       "       0.05      , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05      , 0.05      ,\n",
       "       0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "       0.05      , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_per_frame_periods = np.argmax(all_period_scores, axis=-1) + 1\n",
    "\n",
    "per_frame_counts = np.where(np.less(all_per_frame_periods, 3), 0.0, np.divide(1.0,  stride * all_per_frame_periods))\n",
    "per_frame_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'v4l2src device=/dev/video1 ! video/x-raw, width=(int)640, height=(int)480, framerate=(fraction)30/1 ! videoconvert ! video/x-raw, format=(string)BGR ! videoflip video-direction=4 ! textoverlay halignment=0 valignment=2 text=TalentAI ! clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\" ! appsink'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading, queue\n",
    "import cv2, os, sys\n",
    "import tensorrt as trt\n",
    "from scipy.signal import medfilt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "sys.path.append('/usr/src/tensorrt/samples/python')\n",
    "\n",
    "import common\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "  e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "  return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_FRAMES = 64\n",
    "INPUT_SIZE = 112\n",
    "STRIDES = [4, 6]\n",
    "\n",
    "TRT_LOGGER = trt.Logger()\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "usb_pipelines = [\n",
    "    'v4l2src device=/dev/video1',\n",
    "    'video/x-raw, width=(int)640, height=(int)480, framerate=(fraction)30/1',\n",
    "    'videoconvert',\n",
    "    'video/x-raw, format=(string)BGR',\n",
    "    'videoflip video-direction=4',\n",
    "    'textoverlay halignment=0 valignment=2 text=TalentAI',\n",
    "    'clockoverlay halignment=2 time-format=\"%Y/%m/%d %H:%M:%S\"',\n",
    "    'appsink'\n",
    "]\n",
    "\n",
    "frames_queue = queue.Queue()\n",
    "\n",
    "usb_gst = \" ! \".join(usb_pipelines)\n",
    "usb_gst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_rect_points(w, h, box):\n",
    "    if box[0] < 1.0 and box[1] < 1.0 and box[2] <= 1.0 and box[3] <= 1.0:\n",
    "        x1, y1 = int(w * box[0]), int(h * box[1])\n",
    "        x2, y2 = int(w * box[2]), int(h * box[3])\n",
    "    else:\n",
    "        x1, y1 = box[0], box[1]\n",
    "        x2, y2 = box[2], box[3]\n",
    "    return x1, y1, x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repnet_grab_worker(gst, wid, frames_queue):\n",
    "    cap = cv2.VideoCapture(gst, cv2.CAP_GSTREAMER)\n",
    "    duration=500\n",
    "    width=112\n",
    "    height=112\n",
    "    stride=4\n",
    "    focus_box=[0.2, 0.2, 0.8, 0.8]\n",
    "    black_box=[0.35, 0.0, 0.65,0.35]\n",
    "    rm_still=True\n",
    "    area_rate_thres=0.003\n",
    "    \n",
    "    f = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    if rm_still:\n",
    "        pre_frame = None\n",
    "        area_thres = area_rate_thres * w * h\n",
    "        \n",
    "    if black_box is not None:\n",
    "        black_x1, black_y1, black_x2, black_y2 = cal_rect_points(w, h, black_box)\n",
    "    if focus_box is not None:\n",
    "        focus_x1, focus_y1, focus_x2, focus_y2 = cal_rect_points(w, h, focus_box)\n",
    "        w = focus_x2 - focus_x1\n",
    "        h = focus_y2 - focus_y1\n",
    "    \n",
    "    frames = []\n",
    "    count = 0\n",
    "    n_frames = f * duration\n",
    "    keep_flag = 0\n",
    "    try:\n",
    "        while n_frames > 0:\n",
    "            retval, frame_bgr = cap.read()\n",
    "            n_frames -= 1\n",
    "            if not retval:\n",
    "                continue\n",
    "\n",
    "            if black_box is not None:\n",
    "                frame_bgr[black_y1:black_y2, black_x1:black_x2, :] = 0\n",
    "\n",
    "            if wid:\n",
    "                if focus_box is not None:\n",
    "                    cv2.rectangle(frame_bgr, (focus_x1, focus_y1), (focus_x2, focus_y2), (0, 255, 0), 2)\n",
    "\n",
    "                wid.value = bytes(cv2.imencode(ext='.jpeg', img=frame_bgr)[1])\n",
    "\n",
    "            if focus_box is not None:\n",
    "                frame_bgr = frame_bgr[focus_y1:focus_y2, focus_x1:focus_x2, :]\n",
    "\n",
    "\n",
    "            if rm_still:\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if pre_frame is not None:\n",
    "                    frame_tmp = cv2.absdiff(frame_gray, pre_frame)\n",
    "                    frame_tmp = cv2.threshold(frame_tmp, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "                    frame_tmp = cv2.dilate(frame_tmp, None, iterations=2)\n",
    "                    contours, _ = cv2.findContours(frame_tmp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                    if len(contours) > 0:\n",
    "                        for contour in contours:\n",
    "                            if cv2.contourArea(contour) > area_thres:\n",
    "                                keep_flag += 1\n",
    "                                break\n",
    "                pre_frame = frame_gray\n",
    "\n",
    "            frame_bgr = cv2.resize(frame_bgr, (width, height))\n",
    "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            if not rm_still or keep_flag % stride == 0:\n",
    "                keep_flag = 0\n",
    "                frames.append(frame_rgb)\n",
    "                if len(frames) == 64 and frames_queue:\n",
    "                    frames_queue.put(frames)\n",
    "                    frames = []\n",
    "    finally:\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repnet_model(wid, frames_queue):\n",
    "    count = 0\n",
    "    wid.value = \"Count: 0\"\n",
    "    output_shapes = [(-1, 1), (-1, NUM_FRAMES // 2)]\n",
    "    MODEL_PATH = '/home/nano/models/repnet_b1.trt'\n",
    "    i = 0\n",
    "    with open(MODEL_PATH, \"rb\") as f, \\\n",
    "        trt.Runtime(TRT_LOGGER) as runtime, \\\n",
    "        runtime.deserialize_cuda_engine(f.read()) as engine, \\\n",
    "        engine.create_execution_context() as context:\n",
    "            \n",
    "        inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        \n",
    "        while True:\n",
    "            np_frames = np.asarray(frames_queue.get(), dtype=np.float32) \n",
    "            np_frames = np_frames.astype(np.float32)\n",
    "            np_frames -= 127.5\n",
    "            np_frames /= 127.5\n",
    "            \n",
    "            np_inputs = np.reshape(np_frames, (1, NUM_FRAMES, INPUT_SIZE, INPUT_SIZE, 3))\n",
    "\n",
    "            within_period_scores = []\n",
    "            period_scores = []\n",
    "            inputs[0].host = np_inputs\n",
    "            trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "            trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "            np_within_period_scores = trt_outputs[0].copy()\n",
    "            np_period_scores = trt_outputs[1].copy()\n",
    "            \n",
    "            \n",
    "            per_frame_periods = np.argmax(np_period_scores, axis=-1) + 1\n",
    "            conf_pred_periods = np.max(softmax(np_period_scores, axis=-1), axis=-1)\n",
    "            conf_pred_periods = np.where(per_frame_periods < 3, 0.0, conf_pred_periods)\n",
    "            \n",
    "            within_period_scores = sigmoid(np_within_period_scores)[:, 0]\n",
    "            within_period_scores = np.sqrt(within_period_scores * conf_pred_periods)\n",
    "            within_period_binary = np.asarray(within_period_scores > 0.5)\n",
    "\n",
    "            per_frame_counts = np.where(per_frame_periods < 3, 0.0, 1 / per_frame_periods)\n",
    "            count += sum(per_frame_counts)\n",
    "            i += 1\n",
    "            \n",
    "            wid.value = \"Count: %d\" % count\n",
    "            if i > 20:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e35ab59864e43f59242f6102acfbbe9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-3fef9ffcbc11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrepnet_grap_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepnet_grab_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musb_gst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrap_wid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrepnet_grap_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrepnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_vid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrepnet_grap_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-fa1df42453c2>\u001b[0m in \u001b[0;36mrepnet_model\u001b[0;34m(wid, frames_queue)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mnp_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mnp_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mnp_frames\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_vid = widgets.Text(value=\"Count: 0\")\n",
    "grap_wid = widgets.Image(format='jpeg')\n",
    "display(widgets.VBox([count_vid, grap_wid]))\n",
    "\n",
    "repnet_grap_worker = threading.Thread(target=repnet_grab_worker, args=(usb_gst, grap_wid, frames_queue))\n",
    "repnet_grap_worker.start()\n",
    "repnet_model(count_vid, frames_queue)\n",
    "repnet_grap_worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Nvidia Accelerated GStreamer][5]\n",
    "- **[How to Install OpenCV 4.5 on NVIDIA Jetson Nano (CSI Camera)][2]**\n",
    "- [OpenCV 4 + CUDA on Jetson Nano][1]\n",
    "- [To speed up the image processing OpenCV with GPU (CUDA)][3]\n",
    "- [Embedded Diaries: Jetson gstreamer Video Encoding & Decoding][4]\n",
    "- [GStreamer provides different commands for capture images were two is nvarguscamerasrc and v4l2src.][6]\n",
    "- [nvidia jetson xavier NX GStreamer 推流操作][7]\n",
    "- [git: gst rtsp server][8]\n",
    "- [git: gst examples][9]\n",
    "\n",
    "[9]: https://github.com/mad4ms/python-opencv-gstreamer-examples\n",
    "[8]: https://github.com/GStreamer/gst-rtsp-server\n",
    "[7]: http://m.blog.chinaunix.net/uid-21501855-id-5846723.html\n",
    "[6]: https://developer.ridgerun.com/wiki/index.php?title=Xavier/Video_Capture_and_Display/Software_Support/GStreamer\n",
    "[5]: https://docs.nvidia.com/jetson/l4t/index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/accelerated_gstreamer.html\n",
    "[4]: https://www.hackster.io/SaadTiwana/embedded-diaries-jetson-gstreamer-video-encoding-decoding-585ba7\n",
    "[3]: https://titanwolf.org/Network/Articles/Article?AID=fb3facac-d5d2-42c5-96b2-3c25d2201736\n",
    "[2]: https://automaticaddison.com/how-to-install-opencv-4-5-on-nvidia-jetson-nano/\n",
    "[1]: https://www.jetsonhacks.com/2019/11/22/opencv-4-cuda-on-jetson-nano/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Jetson Nano Cuda,cuDNN,Opencv][1]\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <code>\n",
    "        wget http://dragon.studio/2021/02/opencv_2021-02-27-1_all.deb\n",
    "        sudo apt remove libopencv opencv-licenses libopencv-python libtbb-dev libopencv-dev\n",
    "        sudo apt install ./opencv_2021-02-27-1_all.deb\n",
    "    </code>\n",
    "</div>\n",
    "\n",
    "- [fatal error: boostdesc_bgm.i: No such file or directory][2]\n",
    "\n",
    "[2]: https://github.com/opencv/opencv_contrib/issues/1301\n",
    "[1]: https://forums.developer.nvidia.com/t/jetson-nano-cuda-cudnn-opencv/169731/2"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "292.969px",
    "left": "1536px",
    "top": "66px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
