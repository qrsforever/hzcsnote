{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Global-Import\" data-toc-modified-id=\"Global-Import-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Global Import</a></span></li><li><span><a href=\"#Jstson-Device\" data-toc-modified-id=\"Jstson-Device-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Jstson Device</a></span><ul class=\"toc-item\"><li><span><a href=\"#Target-System-Info\" data-toc-modified-id=\"Target-System-Info-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://github.com/jetsonhacks/jetsonUtilities\" rel=\"nofollow\" target=\"_blank\">Target System Info</a></a></span></li><li><span><a href=\"#Setup-Software-Environment\" data-toc-modified-id=\"Setup-Software-Environment-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Setup Software Environment</a></span></li></ul></li><li><span><a href=\"#X86-Host-(TODO)\" data-toc-modified-id=\"X86-Host-(TODO)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>X86 Host (TODO)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Host-System-Info\" data-toc-modified-id=\"Host-System-Info-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Host System Info</a></span></li><li><span><a href=\"#Install-QEMU\" data-toc-modified-id=\"Install-QEMU-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><a href=\"https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson#building-jetson-containers-on-an-x86-workstation-using-qemu\" rel=\"nofollow\" target=\"_blank\">Install QEMU</a></a></span></li><li><span><a href=\"#Install-Nvidia-SDK-Manager-(Docker)\" data-toc-modified-id=\"Install-Nvidia-SDK-Manager-(Docker)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span><a href=\"https://developer.nvidia.com/nvidia-sdk-manager\" rel=\"nofollow\" target=\"_blank\">Install Nvidia SDK Manager (Docker)</a></a></span></li><li><span><a href=\"#Cross-Compile-Tensort\" data-toc-modified-id=\"Cross-Compile-Tensort-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><a href=\"https://github.com/NVIDIA/TensorRT/tree/release/8.0#setting-up-the-build-environment\" rel=\"nofollow\" target=\"_blank\">Cross-Compile Tensort</a></a></span></li><li><span><a href=\"#Jetson-Containers-ðŸ”—\" data-toc-modified-id=\"Jetson-Containers-ðŸ”—-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Jetson Containers <a href=\"https://ngc.nvidia.com/catalog/Containers?orderBy=scoreDESC&amp;pageNumber=0&amp;query=jetson&amp;quickFilter=&amp;filters=\" rel=\"nofollow\" target=\"_blank\">ðŸ”—</a></a></span></li></ul></li><li><span><a href=\"#Global-Configure\" data-toc-modified-id=\"Global-Configure-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Global Configure</a></span></li><li><span><a href=\"#Onnx-to-Tensorrt\" data-toc-modified-id=\"Onnx-to-Tensorrt-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Onnx to Tensorrt</a></span><ul class=\"toc-item\"><li><span><a href=\"#Builder\" data-toc-modified-id=\"Builder-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Builder</a></span></li><li><span><a href=\"#BuildConfig\" data-toc-modified-id=\"BuildConfig-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>BuildConfig</a></span></li><li><span><a href=\"#Network-&amp;-OnnxParser\" data-toc-modified-id=\"Network-&amp;-OnnxParser-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Network &amp; OnnxParser</a></span></li><li><span><a href=\"#Runtime\" data-toc-modified-id=\"Runtime-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Runtime</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:49:47.101219Z",
     "start_time": "2021-10-14T06:49:45.868796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 95))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "\n",
    "@register_line_cell_magic\n",
    "def template_writefile(line, cell):\n",
    "    path = os.path.dirname(line)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    with open(line, 'w') as fw:\n",
    "        fw.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.078000Z",
     "start_time": "2021-10-13T09:57:14.004126Z"
    }
   },
   "outputs": [],
   "source": [
    "SCRIPT_ROOT = '/data/nb_data/jetson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jstson Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Target System Info][1]\n",
    "\n",
    "[1]: https://github.com/jetsonhacks/jetsonUtilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.154826Z",
     "start_time": "2021-10-13T09:57:14.080782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/nb_data/jetson/jetson_device_versions.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_ROOT/jetson_device_versions.sh\n",
    "\n",
    "git clone --depth 1 https://github.com/jetsonhacks/jetsonUtilities.git\n",
    "cd jetsonUtilities\n",
    "python3 jetsonInfo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NVIDIA Jetson Nano (Developer Kit Version)\n",
    " L4T 32.6.1 [ JetPack 4.6 ]\n",
    "   Ubuntu 18.04.5 LTS\n",
    "   Kernel Version: 4.9.253-tegra\n",
    " CUDA 10.2.300\n",
    "   CUDA Architecture: 5.3\n",
    " OpenCV version: 4.1.1\n",
    "   OpenCV Cuda: NO\n",
    " CUDNN: 8.2.1.32\n",
    " TensorRT: 8.0.1.6\n",
    " Vision Works: 1.6.0.501\n",
    " VPI: ii libnvvpi1 1.1.11 arm64 NVIDIA Vision Programming Interface library\n",
    " Vulcan: 1.2.70\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T11:30:29.286670Z",
     "start_time": "2021-10-14T11:30:29.002768Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform-release-notes/tf-jetson-rel.html#tf-jetson-rel\n",
    "JP_VERSION = '46'\n",
    "TF_VERSION = '2.5.0'\n",
    "NV_VERSION = '21.08'\n",
    "\n",
    "TRT_VERSION = 'release/8.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Software Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.317439Z",
     "start_time": "2021-10-13T09:57:14.234818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/nb_data/jetson/software_setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_ROOT/software_setup.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "USER_HOME=/home/$USER\n",
    "CUDA_HOME=/usr/local/cuda\n",
    "\n",
    "JP_VERSION=46\n",
    "TF_VERSION=2.5.0\n",
    "NV_VERSION=21.08\n",
    "\n",
    "SUDO=''\n",
    "\n",
    "PIP_INSTALL=\"$SUDO pip3 install --retries 10 --timeout 120\"\n",
    "APT_INSTALL=\"$SUDO apt install -y --no-install-recommends\"\n",
    "BOOTRC_FILE=\"$USER_HOME/.bootrc'\n",
    "HOST_ADDR=`who | grep \"pts/0\" | awk -F\" \" '{match($NF, /[^(].*[^)]/); print substr($NF, RSTART,RLENGTH)}'`\n",
    "\n",
    "echo_bootrc() {\n",
    "    echo \"$*\" | tee -a $BOOTRC_FILE\n",
    "}\n",
    "\n",
    "echo_bashrc() {\n",
    "    echo \"$*\" | tee -a $USER_HOME/.bashrc\n",
    "}\n",
    "\n",
    "# on boot script\n",
    "__setup_bootrc() {\n",
    "    echo -e \"#!/bin/bash\\nsleep 10\" > $BOOTRC_FILE\n",
    "    chmod 777 $BOOTRC_FILE\n",
    "    sudo bash -c \"echo '@reboot  root  test -x $BOOTRC_FILE && $BOOTRC_FILE' >> /etc/crontab\"\n",
    "}\n",
    "\n",
    "# environment\n",
    "__setup_bashrc() {\n",
    "    echo_bashrc \"alias pip='pip3'\"\n",
    "    echo_bashrc \"alias python='python3'\"\n",
    "    echo_bashrc \"export PIP_INSTALL='$PIP_INSTALL'\"\n",
    "    echo_bashrc \"export APT_INSTALL='$APT_INSTALL'\"\n",
    "    echo_bashrc \"export CUDA_HOME=$CUDA_HOME\"\n",
    "}\n",
    "\n",
    "# mount.nfs host\n",
    "__setup_mntnfs(){\n",
    "    mkdir -p $USER_HOME/omega\n",
    "    $APT_INSTALL nfs-common\n",
    "    echo_bootrc \"mount.nfs $HOST_ADDR:/blog/public $USER_HOME/omega\"\n",
    "}\n",
    "\n",
    "# notebook\n",
    "__setup_notebook() {\n",
    "    $PIP_INSTALL autopep8\n",
    "    $PIP_INSTALL jupyter jupyter_contrib_nbextensions jupyter_nbextensions_configurator\n",
    "    $SUDO jupyter contrib nbextension install --sys-prefix\n",
    "    $SUDO jupyter nbextensions_configurator enable\n",
    "    git clone --depth 1 https://github.com.cnpmjs.org/qrsforever/jupyter_config.git\n",
    "    $SUDO ./jupyter_config/install.sh\n",
    "    echo_bootrc \"su - $USER -c 'umask 0000; jupyter notebook --no-browser --notebook-dir=$USER_HOME/omega --allow-root --ip=0.0.0.0 --port=8118 &'\"\n",
    "}\n",
    "\n",
    "# cmake\n",
    "__setup_cmake() {\n",
    "    wget https://github.com/Kitware/CMake/releases/download/v3.21.2/cmake-3.21.2-linux-aarch64.tar.gz\n",
    "    tar zxf cmake-3.21.2-linux-aarch64.tar.gz\n",
    "    cp -aprf cmake-3.21.2-linux-aarch64.tar/* /usr/\n",
    "}\n",
    "\n",
    "# machine learning\n",
    "__setup_ml() {\n",
    "    # tensorflow: https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html#upgrading_tensorflow\n",
    "    $APT_INSTALL libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran\n",
    "    $PIP_INSTALL -U pip testresources setuptools==49.6.0\n",
    "    $PIP_INSTALL -U numpy==1.19.4 future==0.18.2 mock==3.0.5 keras_preprocessing==1.1.2 keras_applications==1.0.8 gast==0.4.0 futures protobuf pybind11 cython pkgconfig\n",
    "    $SUDO env H5PY_SETUP_REQUIRES=0 && $PIP_INSTALL -U h5py==3.1.0\n",
    "    $PIP_INSTALL -U --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v${JP_VERSION} tensorflow==${TF_VERSION}+nv${NV_VERSION}\n",
    "    \n",
    "    # onnx2tensor\n",
    "    $APT_INSTALL libprotobuf-dev protobuf-compiler\n",
    "    git clone --depth 1 --recursive https://github.com.cnpmjs.org/onnx/onnx-tensorrt.git\n",
    "    cd onnx-tensorrt && mkdir build && cd build && cmake ../ && make -j && sudo make install\n",
    "    \n",
    "    # pycuda, onnx_helper, graph\n",
    "    $PIP_INSTALL --global-option=build_ext --global-option=\"-I$CUDA_HOME/include/\" --global-option=\"-L$CUDA_HOME/lib\" pycuda\n",
    "    $PIP_INSTALL onnx_graphsurgeon --index-url https://pypi.ngc.nvidia.com\n",
    "    $PIP_INSTALL polygraphy --index-url https://pypi.ngc.nvidia.com\n",
    "    # git clone --depth 1 https://github.com.cnpmjs.org/NVIDIA/TensorRT.git\n",
    "}\n",
    "\n",
    "__setup_bootrc\n",
    "__setup_bashrc\n",
    "__setup_mntnfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## X86 Host (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Host System Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P40           Off  | 00000000:00:06.0 Off |                    0 |\n",
    "| N/A   28C    P0    46W / 250W |      0MiB / 22919MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID   Type   Process name                             Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### [Install QEMU][1]\n",
    "\n",
    "[1]: https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson#building-jetson-containers-on-an-x86-workstation-using-qemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.394383Z",
     "start_time": "2021-10-13T09:57:14.319756Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/nb_data/jetson/qemu.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_ROOT/qemu.sh\n",
    "\n",
    "sudo apt-get install -y qemu binfmt-support qemu-user-static\n",
    "\n",
    "# TODO FAQs: write error: Invalid argument\n",
    "# copy multiarch/qemu-user-static:x86_64-aarch64:/usr/bin/qemu-aarch64-static ${pwd}\n",
    "# run when reboot\n",
    "docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n",
    "\n",
    "# Test\n",
    "# docker run --rm -v ${pwd}/qemu-aarch64-static:/usr/bin/qemu-aarch64-static -t arm64v8/ubuntu uname -m\n",
    "docker run --rm -t arm64v8/ubuntu uname -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### [Install Nvidia SDK Manager (Docker)](https://developer.nvidia.com/nvidia-sdk-manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.472104Z",
     "start_time": "2021-10-13T09:57:14.398339Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /data/nb_data/jetson/sdkmanager_docker.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_ROOT/sdkmanager_docker.sh\n",
    "\n",
    "version=1.6.1\n",
    "build=18175\n",
    "\n",
    "docker load -i ./sdkmanager_$version.$build_docker.tar.gz\n",
    "docker tag sdkmanager:$version.$build sdkmanager:latest\n",
    "    \n",
    "docker run -it --rm sdkmanager --help\n",
    "\n",
    "docker run -itd --net host --name nvidia_sdkmanger --volume /data/:/data --entrypoint=/bin/bash sdkmanager \n",
    "\n",
    "# in container\n",
    "# --host: Install Host Components\n",
    "# sdkmanager --exitonfinish --cli downloadonly --logintype devzone --product Jetson --version 4.6 --targetos Linux \\\n",
    "#   --host --flash all --target JETSON_NANO_TARGETS--license accept --downloadfolder /data/docker/jetpack_files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### [Cross-Compile Tensort](https://github.com/NVIDIA/TensorRT/tree/release/8.0#setting-up-the-build-environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T11:33:50.331118Z",
     "start_time": "2021-10-14T11:33:50.012551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%template_writefile $SCRIPT_ROOT/cross_compile_tensort.sh\n",
    "\n",
    "# Download and Update\n",
    "git clone -b {TRT_VERSION} --depth 1 https://github.com/NVIDIA/TensorRT.git /data/TensorRT8.0\n",
    "cd /data/TensorRT8.0\n",
    "git submodule update --init --recursive\n",
    "\n",
    "# Copy JetPack Files to docker\n",
    "if [ ! -d docker/jetpack_files ]\n",
    "then\n",
    "    cp -aprf /data/docker/jetpack_files docker/\n",
    "fi\n",
    "\n",
    "./docker/build.sh --file docker/ubuntu-cross-aarch64.Dockerfile --tag tensorrt-jetpack-cuda10.2 --cuda 10.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Jetson Containers [ðŸ”—](https://ngc.nvidia.com/catalog/Containers?orderBy=scoreDESC&pageNumber=0&query=jetson&quickFilter=&filters=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:14.552881Z",
     "start_time": "2021-10-13T09:57:14.475169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%template_writefile $SCRIPT_ROOT/Dockerfile.l4t-tensorrt-tf2.5\n",
    "\n",
    "FROM nvcr.io/nvidia/\n",
    "    \n",
    "ENV TZ=Asia/Shanghai \\\n",
    "    H5PY_SETUP_REQUIRES=0 \\\n",
    "    LANG=C.UTF-8 \\\n",
    "    PYTHONIOENCODING=utf-8 \\\n",
    "    DEBIAN_FRONTEND=noninteractive \\\n",
    "    APT_INSTALL=\"apt install -y --no-install-recommends\" \\\n",
    "    PIP_INSTALL=\"python3 -m pip install --no-cache-dir --retries 20 --timeout 120\" \\\n",
    "    PIP_INSTALL_FAST=\"python3 -m pip install --trusted-host mirrors.aliyun.com --extra-index-url http://mirrors.aliyun.com\"\n",
    "\n",
    "RUN rm -rf /usr/bin/python /usr/bin/python3\n",
    "\n",
    "RUN apt update --fix-missing && rm -rf /usr/bin/python /usr/bin/python3 && \\\n",
    "    apt remove --purge python3.8 python3.8-dev && ln -s /usr/bin/python3.6 /usr/bin/python3 \\\n",
    "    $APT_INSTALL net-tools locate libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip \\\n",
    "        libjpeg8-dev liblapack-dev libblas-dev gfortran python3.6 && \\\n",
    "    python3 -m pip uninstall tensorflow tensorflow-estimator tensorboard && \\\n",
    "    $PIP_INSTALL -U pip testresources setuptools==49.6.0 && \\\n",
    "    $PIP_INSTALL -U numpy==1.19.4 future==0.18.2 mock==3.0.5 grpcio==1.34.1 keras_preprocessing==1.1.2 \\\n",
    "        keras_applications==1.0.8 gast==0.4.0 futures protobuf pybind11 cython pkgconfig h5py==2.10.0 \\\n",
    "    $PIP_INSTALL -U --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v{JP_VERSION} tensorflow=={TF_VERSION}+nv{NV_VERSION}\n",
    "\n",
    "RUN cp /etc/apt/sources.list /etc/apt/sources.list.save && \\\n",
    "    sed -i s@http://ports.ubuntu.com@http://mirrors.aliyun.com@g /etc/apt/sources.list && \\\n",
    "    apt update && \\\n",
    "    $PIP_INSTALL_FAST onnx onnxruntime\n",
    "        \n",
    "# Error: $PIP_INSTALL -U h5py==3.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Global Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:58.240023Z",
     "start_time": "2021-10-13T09:57:58.131725Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c4f0aa16f6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTRT_LOGGER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEXPLICIT_BATCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkDefinitionCreationFlag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPLICIT_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)\n",
    "EXPLICIT_BATCH = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "onnx_file_path = '../onnx/repnet/saved_model.onnx'\n",
    "engine_file_path = './saved_model.trt'\n",
    "\n",
    "_DIR_(trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.209086Z",
     "start_time": "2021-10-13T09:57:07.997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_DIR_(trt.BuilderFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.210487Z",
     "start_time": "2021-10-13T09:57:08.000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for attr in _DIR_(trt.BuilderFlag, False):\n",
    "    obj = eval('trt.BuilderFlag.%s' % attr)\n",
    "    if isinstance(obj, trt.BuilderFlag):\n",
    "        print('%50s:\\t%d' % (attr, int(obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Onnx to Tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.211681Z",
     "start_time": "2021-10-13T09:57:08.140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "builder = trt.Builder(TRT_LOGGER)\n",
    "_DIR_(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.213088Z",
     "start_time": "2021-10-13T09:57:08.143Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "builder.max_batch_size, builder.platform_has_fast_fp16, builder.platform_has_fast_int8, builder.platform_has_tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### BuildConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.214386Z",
     "start_time": "2021-10-13T09:57:08.209Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = builder.create_builder_config()\n",
    "_DIR_(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.215510Z",
     "start_time": "2021-10-13T09:57:08.212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config.max_workspace_size, config.flags, config.default_device_type, config.engine_capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.216813Z",
     "start_time": "2021-10-13T09:57:08.214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config.max_workspace_size = 1 << 28\n",
    "config.set_flag(trt.BuilderFlag.FP16)\n",
    "config.set_flag(trt.BuilderFlag.STRICT_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Network & OnnxParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.218055Z",
     "start_time": "2021-10-13T09:57:08.285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "network = builder.create_network(EXPLICIT_BATCH)\n",
    "_DIR_(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.219144Z",
     "start_time": "2021-10-13T09:57:08.288Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "_DIR_(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.220320Z",
     "start_time": "2021-10-13T09:57:08.291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(onnx_file_path, 'rb') as model:\n",
    "    if not parser.parse(model.read()):\n",
    "        for e in range(parser.num_errors):\n",
    "            print(parser.get_error(e))\n",
    "        raise TypeError(\"Parser parse failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.221600Z",
     "start_time": "2021-10-13T09:57:08.294Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_graphsurgeon as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.222743Z",
     "start_time": "2021-10-13T09:57:08.296Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_DIR_(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.223824Z",
     "start_time": "2021-10-13T09:57:08.299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "graph = gs.import_onnx(onnx.load(onnx_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.225050Z",
     "start_time": "2021-10-13T09:57:08.301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "node0 = graph.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.226123Z",
     "start_time": "2021-10-13T09:57:08.305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "node0, node0.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.227165Z",
     "start_time": "2021-10-13T09:57:08.307Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "node8 = graph.nodes[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.228228Z",
     "start_time": "2021-10-13T09:57:08.310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'to' in list(node8.attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.229372Z",
     "start_time": "2021-10-13T09:57:08.312Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for node in graph.nodes:\n",
    "    if 'allowzero' in list(node.attrs.keys()):\n",
    "        print(node.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.230481Z",
     "start_time": "2021-10-13T09:57:08.315Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_DIR_(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.231504Z",
     "start_time": "2021-10-13T09:57:08.318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "node2 = graph.nodes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.232709Z",
     "start_time": "2021-10-13T09:57:08.321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_DIR_(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.233819Z",
     "start_time": "2021-10-13T09:57:08.323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_DIR_(gs.Graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:57:15.234937Z",
     "start_time": "2021-10-13T09:57:08.401Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "_DIR_(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Running and Building ARM Docker Containers on x86][1]\n",
    "- [NVIDIA L4T is a Linux based software distribution for the NVIDIA Jetson embedded computing platform][2]\n",
    "- [Jetson Docker build][3]\n",
    "- [This guide provides instructions for installing TensorFlow for Jetson Platform][4]\n",
    "- [Jetson Docker Containers][5]\n",
    "- [NVIDIA Container Runtime on Jetson][6]\n",
    "- [Install Tensorrt][7]\n",
    "- [Tensorrt Guide][11]\n",
    "- [The following development platforms are supported with NVIDIA SDK Manager: Target Devices][8]\n",
    "- [JetPack SDK in Docker for simple and clean flashing of a Jetson TX2][9]\n",
    "- [Creating a Cross-Compilation like process for Jetson TX2 (aarch64) using QEMU with Docker][10]\n",
    "\n",
    "[11]: https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html\n",
    "[10]: https://trn84.medium.com/creating-a-cross-compilation-like-process-for-jetson-tx2-aarch64-using-qemu-with-docker-5cb38f6a65bc\n",
    "[9]: https://trn84.medium.com/jetpack-sdk-in-docker-for-simple-and-clean-flashing-of-a-jetson-tx2-32b4db6c8d65\n",
    "[8]: https://docs.nvidia.com/sdk-manager/system-requirements/index.html\n",
    "[7]: https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html\n",
    "[6]: https://github.com/NVIDIA/nvidia-docker/wiki/NVIDIA-Container-Runtime-on-Jetson#building-jetson-containers-on-an-x86-workstation-using-qemu\n",
    "[5]: https://ngc.nvidia.com/catalog/Containers\n",
    "[4]: https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html\n",
    "[3]: https://github.com/dusty-nv/jetson-containers\n",
    "[2]: https://ngc.nvidia.com/catalog/containers/nvidia:l4t-base\n",
    "[1]: https://www.stereolabs.com/docs/docker/building-arm-container-on-x86/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Attribute not found: allowzero][1]\n",
    "- [Assertion failed: inputs.at(1).is_weights() && \"The input pads is required to be an initializer.\"][2]\n",
    "- [Stand-alone pad operation fails with: Assertion failed: inputs.at(1).is_weights()][3]\n",
    "- [Assertion failed: convertOnnxPadding(onnxPadding, &begPadding, &endPadding) && \"This version of TensorRT only supports padding on the outer two dimensions!\"][4]\n",
    "- [ONNX to TRT Error: Myelin Error in addNodeToMyelinGraph: 0 gather operation not supported within a loop body. ][5]\n",
    "- [Build Tensorrt: cub/cub.cuh: No such file or directory #8][6]\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<code>\n",
    "    if(NOT CUB_ROOT_DIR)\n",
    "      if (CUDA_VERSION VERSION_LESS 11.0)\n",
    "        set(CUB_ROOT_DIR ${CMAKE_CURRENT_SOURCE_DIR}/third_party/cub CACHE STRING \"directory of CUB installation\")\n",
    "      endif()\n",
    "    endif()\n",
    "    /* fixit -DTRT_PLATFORM_ID=aarch64 -DCUDA_VERSION=10.2 */\n",
    "</code>\n",
    "</div>\n",
    "   \n",
    "[6]: https://githubmemory.com/repo/grimoire/amirstan_plugin/issues/8\n",
    "[5]: https://github.com/NVIDIA/TensorRT/issues/1081\n",
    "[4]: https://github.com/onnx/onnx-tensorrt/issues/533\n",
    "[3]: https://github.com/onnx/onnx-tensorrt/issues/411\n",
    "[2]: https://github.com/NVIDIA/TensorRT/issues/439\n",
    "[1]: https://github.com/onnx/onnx/issues/3225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "351px",
    "width": "196px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
