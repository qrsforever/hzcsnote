{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8349f7b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Repnet-Model\" data-toc-modified-id=\"Load-Repnet-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Repnet Model</a></span></li><li><span><a href=\"#Define-a-Simple-Conv3D\" data-toc-modified-id=\"Define-a-Simple-Conv3D-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define a Simple Conv3D</a></span></li><li><span><a href=\"#Repnet-Model-Part2-(Conv3D-+-BN)\" data-toc-modified-id=\"Repnet-Model-Part2-(Conv3D-+-BN)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Repnet Model Part2 (Conv3D + BN)</a></span></li><li><span><a href=\"#Convert-to-Onnx\" data-toc-modified-id=\"Convert-to-Onnx-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Convert to Onnx</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf2onnx:-from_keras\" data-toc-modified-id=\"tf2onnx:-from_keras-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>tf2onnx: from_keras</a></span></li><li><span><a href=\"#tf2onnx:-from_function\" data-toc-modified-id=\"tf2onnx:-from_function-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>tf2onnx: from_function</a></span></li><li><span><a href=\"#tf2onnx:-load-saved_models\" data-toc-modified-id=\"tf2onnx:-load-saved_models-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>tf2onnx: load saved_models</a></span></li></ul></li><li><span><a href=\"#FAQs\" data-toc-modified-id=\"FAQs-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>FAQs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e31947",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "ipywidgets 7.6.3\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "plotly 5.3.0\n",
      "netron 5.1.6\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n",
      "tensorflow 2.6.0\n",
      "tensorboard 2.6.0\n",
      "tflite not installed\n",
      "onnx 1.10.1\n",
      "tf2onnx 1.10.0\n",
      "onnxruntime 1.8.1\n",
      "tensorrt not installed\n",
      "tvm not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "%watermark -p tensorflow,tensorboard,tflite\n",
    "%watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image, Javascript\n",
    "from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import argparse, shlex, signal\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x.startswith('https://'):\n",
    "            x = x[8:]\n",
    "        if not x.endswith('.py'):\n",
    "            x = x + '.py'\n",
    "        if x[0] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        else:\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                uri = 'https://' + x\n",
    "                x = requests.get(uri)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                uri = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = uri.split('/')\n",
    "                for s in ['main', 'master']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    uri = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    x = requests.get(uri)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697cb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_html(port, height=600):\n",
    "    from IPython import display\n",
    "    from html import escape as html_escape\n",
    "    frame_id = 'erlangai-frame-{:08x}'.format(random.getrandbits(64))\n",
    "    shell = '''\n",
    "      <iframe id='%HTML_ID%' width='100%' height='%HEIGHT%' frameborder='0'>\n",
    "      </iframe>\n",
    "      <script>\n",
    "        (function() {\n",
    "          const frame = document.getElementById(%JSON_ID%);\n",
    "          const url = new URL(%URL%, window.location);\n",
    "          const port = %PORT%;\n",
    "          if (port) {\n",
    "            url.port = port;\n",
    "          }\n",
    "          frame.src = url;\n",
    "        })();\n",
    "      </script>\n",
    "    '''\n",
    "    replacements = [\n",
    "        ('%HTML_ID%', html_escape(frame_id, quote=True)),\n",
    "        ('%JSON_ID%', json.dumps(frame_id)),\n",
    "        ('%HEIGHT%', '%d' % height),\n",
    "        ('%PORT%', '%d' % port),\n",
    "        ('%URL%', json.dumps('/')),\n",
    "    ]\n",
    "    for (k, v) in replacements:\n",
    "        shell = shell.replace(k, v)\n",
    "    display.display(display.HTML(shell))\n",
    "\n",
    "@register_line_magic\n",
    "def netron(line):\n",
    "    parser = argparse.ArgumentParser(prog='netron')\n",
    "    parser.add_argument('--file', '-f', type=str, required=True, help='netron model file')\n",
    "    parser.add_argument('--port', '-p', type=int, default=0, help='netron server port')\n",
    "    parser.add_argument('--height', type=int, default=500, help='display netron html window hight')\n",
    "    import netron\n",
    "    try:\n",
    "        args = parser.parse_args(shlex.split(line))\n",
    "        address = netron.start(args.file, address=('0.0.0.0', args.port), browse=False)\n",
    "        display_html(address[1], args.height)\n",
    "    except:\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2ce59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install git+https://github.com/onnx/tensorflow-onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8964ab1",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Tensorflow ###\n",
    "###\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "layers = tf.keras.layers\n",
    "regularizers = tf.keras.regularizers\n",
    "\n",
    "DATA_OUTPUT = '/data/nb_data/test_conv3d'\n",
    "os.makedirs(DATA_OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e6411",
   "metadata": {},
   "source": [
    "## Load Repnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58e9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMPORT('gitee.com/qrsforever/blog_source_codes/AI/tensorflow/misc/ResnetPeriodEstimator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112231ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "IMAGE_W = 112\n",
    "IMAGE_H = 112\n",
    "NUM_FRAMES = 64\n",
    "\n",
    "PATH_TO_CKPT='/data/pretrained/cv/repnet/'\n",
    "SAVED_MODEL_ROOT = '/data/nb_data/test_conv3d'\n",
    "MODEL_PART1_OUTFILE = f'{SAVED_MODEL_ROOT}/model_part1_outputs.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d38f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_PART1_OUTFILE):\n",
    "    !test ! -d $PATH_TO_CKPT && mkdir -p $PATH_TO_CKPT && \\\n",
    "        wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/checkpoint && \\\n",
    "        wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00000-of-00002 && \\\n",
    "        wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.data-00001-of-00002 && \\\n",
    "        wget -P $PATH_TO_CKPT https://storage.googleapis.com/repnet_ckpt/ckpt-88.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5524deea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 64, 32]), TensorShape([1, 64, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResnetPeriodEstimator()\n",
    "model.call = tf.function(model.call)\n",
    "tf.train.Checkpoint(model=model).restore(f'{PATH_TO_CKPT}/ckpt-88').expect_partial()\n",
    "test_inputs = np.random.randn(BATCH_SIZE, NUM_FRAMES, IMAGE_H, IMAGE_W, 3).astype(np.float32)\n",
    "test_inputs_tensor = tf.convert_to_tensor(test_inputs)\n",
    "test_outputs = model(test_inputs_tensor)\n",
    "test_outputs[0].shape, test_outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642d73cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 7, 7, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResnetPart1(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart1')\n",
    "        self.base_model = tf.keras.models.Model(\n",
    "            name='base_model', inputs=model.base_model.input,\n",
    "            outputs=model.base_model.get_layer('conv4_block3_out').output)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (-1, IMAGE_H, IMAGE_W, 3))\n",
    "        return self.base_model(x)\n",
    "    \n",
    "if not os.path.exists(MODEL_PART1_OUTFILE):\n",
    "    model1 = ResnetPart1(model)\n",
    "    model_part1_outputs = model1(test_inputs_tensor)\n",
    "    np.save(MODEL_PART1_OUTFILE, model_part1_outputs)\n",
    "    print(tf.reshape(model_part1_outputs, (-1,))[:3], '-'*90, model_part1_outputs.shape)\n",
    "else:\n",
    "    model_part1_outputs = np.load(f'{SAVED_MODEL_ROOT}/model_part1_outputs.npy')\n",
    "    \n",
    "model_part1_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c137b",
   "metadata": {},
   "source": [
    "## Define a Simple Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ed4341",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "Serving '/data/nb_data/test_conv3d/testmodel.onnx' at http://0.0.0.0:37718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-dc2f7d018fe8d904' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-dc2f7d018fe8d904\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 37718;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from tf2onnx import logging, utils\n",
    "# \n",
    "# logging.basicConfig(level=5)\n",
    "# utils.set_debug_mode(True)\n",
    "# \n",
    "class ModelCNN3D(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='ModelCNN3D')\n",
    "        self.temporal_conv_layer = layers.Conv3D(\n",
    "            3, 3, padding='same', name='temporal_conv_layer',\n",
    "            dilation_rate=(1, 1, 1),\n",
    "            kernel_regularizer=regularizers.l2(1e-6),\n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "        self.temporal_bn_layers = layers.BatchNormalization(name='temporal_bn_layers')                  \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.temporal_conv_layer(x)\n",
    "        x = self.temporal_bn_layers(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "    \n",
    "testmodel = ModelCNN3D()\n",
    "inputs = np.random.randn(1, 10, 28, 28, 3)\n",
    "outputs = testmodel(inputs)\n",
    "tf2onnx.convert.from_keras(\n",
    "    testmodel,\n",
    "    input_signature=(tf.TensorSpec(shape=inputs.shape, name=\"x\"),),\n",
    "    opset=11, output_path=f'{SAVED_MODEL_ROOT}/testmodel.onnx')[0];\n",
    "\n",
    "%netron -f {SAVED_MODEL_ROOT}/testmodel.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf62f3",
   "metadata": {},
   "source": [
    "## Repnet Model Part2 (Conv3D + BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0834ea7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.        , 1.0429665 , 0.54142964], dtype=float32)>,\n",
       " '------------------------------------------------------------------------------------------',\n",
       " TensorShape([1, 64, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResnetPart2_0(tf.keras.models.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(name='ResnetPart2_0')\n",
    "        self.temporal_conv_layer = layers.Conv3D(\n",
    "            512, 3, padding='same', name='temporal_conv_layer',\n",
    "            dilation_rate=(3, 1, 1), weights=model.temporal_conv_layers[0].get_weights())\n",
    "        self.temporal_bn_layers = layers.BatchNormalization(axis=-1, # default\n",
    "            name='temporal_bn_layers', weights=model.temporal_bn_layers[0].get_weights())                  \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, [1, -1] + x.shape.as_list()[1:])\n",
    "        x = self.temporal_conv_layer(x)\n",
    "        x = self.temporal_bn_layers(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return tf.reduce_max(x, [2, 3])\n",
    "\n",
    "model2_0 = ResnetPart2_0(model)\n",
    "model_part2_outputs = model2_0(model_part1_outputs)\n",
    "tf.reshape(model_part2_outputs, (-1,))[:3], '-'*90, model_part2_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3419b",
   "metadata": {},
   "source": [
    "## Convert to Onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e91016",
   "metadata": {},
   "source": [
    "### tf2onnx: from_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7906aebb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2_proto_0 = tf2onnx.convert.from_keras(\n",
    "    model2_0,\n",
    "    input_signature=(tf.TensorSpec(shape=model_part1_outputs.shape, name=\"x\"),),\n",
    "    opset=11, output_path=f'{SAVED_MODEL_ROOT}/model2_0.onnx')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af92b788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResnetPart2_0/Reshape\n",
      "ResnetPart2_0/temporal_conv_layer/Conv3D__14\n",
      "Conv__18\n",
      "ResnetPart2_0/temporal_bn_layers/FusedBatchNormV3\n",
      "ResnetPart2_0/Relu\n",
      "ResnetPart2_0/Max\n",
      "ResnetPart2_0/temporal_bn_layers/FusedBatchNormV3__17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([name: \"x\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 7\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 1024\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ],\n",
       " [name: \"output_1\"\n",
       " type {\n",
       "   tensor_type {\n",
       "     elem_type: 1\n",
       "     shape {\n",
       "       dim {\n",
       "         dim_value: 1\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 64\n",
       "       }\n",
       "       dim {\n",
       "         dim_value: 512\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }\n",
       " ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for node in model2_proto_0.graph.node:\n",
    "    print(node.name)\n",
    "model2_proto_0.graph.input, model2_proto_0.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550c18ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/test_conv3d/model2_0.onnx' at http://0.0.0.0:36869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-e9a5289ddfd5b1f7' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-e9a5289ddfd5b1f7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 36869;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/model2_0.onnx --height 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c25dcfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = ort.InferenceSession(f'{SAVED_MODEL_ROOT}/model2_0.onnx')  \n",
    "inputs = {sess.get_inputs()[0].name: model_part1_outputs}\n",
    "outputs = [o.name for o in sess.get_outputs()]\n",
    "predictions = sess.run(outputs, inputs)\n",
    "predictions[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae5848",
   "metadata": {},
   "source": [
    "### tf2onnx: from_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed2587a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "func2_0 = tf.function(lambda x: model2_0(x))\n",
    "func2_proto_0 = tf2onnx.convert.from_function(\n",
    "    function=func2_0,\n",
    "    input_signature=(tf.TensorSpec(model_part1_outputs.shape, model_part1_outputs.dtype),),\n",
    "    opset=11, output_path=f'{SAVED_MODEL_ROOT}/func2_0.onnx')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9aa46b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/test_conv3d/func2_0.onnx' at http://0.0.0.0:45676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-4d262e6ff8db1fb0' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-4d262e6ff8db1fb0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 45676;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/func2_0.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a395fd",
   "metadata": {},
   "source": [
    "### tf2onnx: load saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e81b705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/nb_data/test_conv3d/model2_0/assets\n"
     ]
    }
   ],
   "source": [
    "model2_0.save(f'{SAVED_MODEL_ROOT}/model2_0', save_format='tf', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4f51d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-22 11:24:23,764 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-22 11:24:23,764 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-22 11:24:25,832 - WARNING - From /usr/local/lib/python3.6/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-22 11:24:27,349 - INFO - Using tensorflow=2.6.0, onnx=1.10.1, tf2onnx=1.10.0/42e800\n",
      "2021-10-22 11:24:27,349 - INFO - Using opset <onnx, 11>\n",
      "2021-10-22 11:24:35,148 - INFO - Computed 2 values for constant folding\n",
      "2021-10-22 11:24:39,391 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2_0/temporal_conv_layer/Conv3D/strided_slice_1\n",
      "2021-10-22 11:24:39,391 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/ResnetPart2_0/temporal_conv_layer/Conv3D/strided_slice_2\n",
      "2021-10-22 11:24:40,113 - INFO - Optimizing ONNX model\n",
      "2021-10-22 11:24:40,839 - INFO - After optimization: Cast -1 (4->3), Const -53 (84->31), Gather +1 (1->2), Identity -9 (9->0), Squeeze -7 (9->2), Unsqueeze -15 (21->6)\n",
      "2021-10-22 11:24:40,953 - INFO - \n",
      "2021-10-22 11:24:40,953 - INFO - Successfully converted TensorFlow model /data/nb_data/test_conv3d/model2_0 to ONNX\n",
      "2021-10-22 11:24:40,954 - INFO - Model inputs: ['input_1']\n",
      "2021-10-22 11:24:40,954 - INFO - Model outputs: ['output_1']\n",
      "2021-10-22 11:24:40,954 - INFO - ONNX model is saved at /data/nb_data/test_conv3d/model2_0/model2.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --opset 11 \\\n",
    "    --tag serve --signature_def serving_default \\\n",
    "    --saved-model {SAVED_MODEL_ROOT}/model2_0 --output {SAVED_MODEL_ROOT}/model2_0/model2.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11115362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/data/nb_data/test_conv3d/model2_0/model2.onnx' at http://0.0.0.0:38034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id='erlangai-frame-e175f80bb78778e6' width='100%' height='360' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"erlangai-frame-e175f80bb78778e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 38034;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%netron -f {SAVED_MODEL_ROOT}/model2_0/model2.onnx --height 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429fd5a",
   "metadata": {},
   "source": [
    "## FAQs\n",
    "\n",
    "- [Conversion of tranpose into reshape goes wrong after 3D NDHWC convolution (FusedBatchNormV3) ][1]\n",
    "\n",
    "[1]:https://github.com/onnx/tensorflow-onnx/issues/1749"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "209px",
    "left": "1433px",
    "top": "96px",
    "width": "273.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
