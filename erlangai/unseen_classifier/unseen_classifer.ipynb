{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behavioral-choir",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:00:05.855328Z",
     "start_time": "2021-07-07T11:00:00.778689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.19.4\n",
      "sklearn 0.24.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.1\n",
      "PIL 6.2.2\n",
      "matplotlib 3.3.3\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.0.dev20210103+cu101\n",
      "torchvision 0.9.0.dev20210103+cu101\n",
      "torchaudio not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-rating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:00:25.284982Z",
     "start_time": "2021-07-07T11:00:23.750631Z"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Common ###\n",
    "###\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "\n",
    "_IMPORT_('import numpy as np')\n",
    "_IMPORT_('import pandas as pd')\n",
    "_IMPORT_('from tqdm.notebook import tqdm')\n",
    "\n",
    "def print_progress_bar(x):\n",
    "    print('\\r', end='')\n",
    "    print('Progress: {}%:'.format(x), '%s%s' % ('▋'*(x//2), '.'*((100-x)//2)), end='')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "###\n",
    "### Torch ###\n",
    "###\n",
    "\n",
    "_IMPORT_('import torch')\n",
    "_IMPORT_('import torch.nn as nn')\n",
    "_IMPORT_('import torch.nn.functional as F')\n",
    "_IMPORT_('import torch.optim as O')\n",
    "_IMPORT_('from torchvision import models as M')\n",
    "_IMPORT_('from torchvision import transforms as T')\n",
    "_IMPORT_('from torch.utils.data import Dataset, DataLoader')\n",
    "\n",
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT_('import cv2')\n",
    "_IMPORT_('from PIL import Image')\n",
    "_IMPORT_('from torchvision.utils import make_grid')\n",
    "_IMPORT_('import matplotlib.pyplot as plt')\n",
    "_IMPORT_('import plotly')\n",
    "_IMPORT_('import plotly.graph_objects as go')\n",
    "_IMPORT_('import ipywidgets as widgets')\n",
    "_IMPORT_('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_table(headers, data, width=900):\n",
    "    ncols = len(headers)\n",
    "    width = int(width / ncols)\n",
    "    lralign = []\n",
    "    caption = []\n",
    "    for item in headers:\n",
    "        astr = ''\n",
    "        if item[0] == ':':\n",
    "            astr = ':'\n",
    "            item = item[1:]\n",
    "        astr += '---'\n",
    "        if item[-1] == ':':\n",
    "            astr += ':'\n",
    "            item = item[:-1]\n",
    "        lralign.append(astr)\n",
    "        caption.append(item)\n",
    "    captionstr = '|'.join(caption) + chr(10)\n",
    "    lralignstr = '|'.join(lralign) + chr(10)\n",
    "    imgholdstr = '|'.join(['<img width=%d/>' % width] * ncols) + chr(10)\n",
    "    table = captionstr + lralignstr + imgholdstr\n",
    "    is_dict = isinstance(data[0], dict)\n",
    "    for row in data:\n",
    "        if is_dict:\n",
    "            table += '|'.join([f'{row[c]}' for c in caption]) + chr(10)\n",
    "        else:\n",
    "            table += '|'.join([f'{col}' for col in row]) + chr(10)\n",
    "    return Markdown(table)\n",
    "\n",
    "def show_video(vidsrc, width=None, height=None):\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if vidsrc.startswith('http'):\n",
    "        data_url = vidsrc\n",
    "    else:\n",
    "        mp4 = open(vidsrc, 'rb').read()\n",
    "        data_url = 'data:video/mp4;base64,' + base64.b64encode(mp4).decode()\n",
    "    return HTML('<video %s %s controls src=\"%s\" type=\"video/mp4\"/>' % (W, H, data_url))\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<img %s %s src=\"%s\"/>' % (W, H, data_url))\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if image_path.startswith('http'):\n",
    "        data_url = image_path\n",
    "    else:\n",
    "        img = open(image_path, 'rb').read()\n",
    "        data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<img %s %s src=\"%s\"/>' % (W, H, data_url))\n",
    "\n",
    "def im_read(url, rgb=True, size=None):\n",
    "    response = requests.get(url)\n",
    "    if response:\n",
    "        imgmat = np.frombuffer(response.content, dtype=np.uint8)\n",
    "        img = cv2.imdecode(imgmat, cv2.IMREAD_COLOR)\n",
    "        if rgb:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if size:\n",
    "           if isinstance(size, int):\n",
    "               size = (size, size)\n",
    "           img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "        return img\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-segment",
   "metadata": {},
   "source": [
    "## OpenMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "textile-diesel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:00:37.099269Z",
     "start_time": "2021-07-07T11:00:36.910833Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as spd\n",
    "import torch\n",
    "\n",
    "import libmr\n",
    "\n",
    "\n",
    "def calc_distance(query_score, mcv, eu_weight, distance_type='eucos'):\n",
    "    if distance_type == 'eucos':\n",
    "        query_distance = spd.euclidean(mcv, query_score) * eu_weight + \\\n",
    "            spd.cosine(mcv, query_score)\n",
    "    elif distance_type == 'euclidean':\n",
    "        query_distance = spd.euclidean(mcv, query_score)\n",
    "    elif distance_type == 'cosine':\n",
    "        query_distance = spd.cosine(mcv, query_score)\n",
    "    else:\n",
    "        print(\"distance type not known: enter either of eucos, euclidean or cosine\")\n",
    "    return query_distance\n",
    "\n",
    "\n",
    "def fit_weibull(means, dists, categories, tailsize=20, distance_type='eucos'):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        means (C, channel, C)\n",
    "        dists (N_c, channel, C) * C\n",
    "    Output:\n",
    "        weibull_model : Perform EVT based analysis using tails of distances and save\n",
    "                        weibull model parameters for re-adjusting softmax scores\n",
    "    \"\"\"\n",
    "    weibull_model = {}\n",
    "    for mean, dist, category_name in zip(means, dists, categories):\n",
    "        weibull_model[category_name] = {}\n",
    "        weibull_model[category_name]['distances_{}'.format(distance_type)] = dist[distance_type]\n",
    "        weibull_model[category_name]['mean_vec'] = mean\n",
    "        weibull_model[category_name]['weibull_model'] = []\n",
    "        for channel in range(mean.shape[0]):\n",
    "            mr = libmr.MR()\n",
    "            tailtofit = np.sort(dist[distance_type][channel, :])[-tailsize:]\n",
    "            mr.fit_high(tailtofit, len(tailtofit))\n",
    "            weibull_model[category_name]['weibull_model'].append(mr)\n",
    "\n",
    "    return weibull_model\n",
    "\n",
    "\n",
    "def query_weibull(category_name, weibull_model, distance_type='eucos'):\n",
    "    return [weibull_model[category_name]['mean_vec'],\n",
    "            weibull_model[category_name]['distances_{}'.format(distance_type)],\n",
    "            weibull_model[category_name]['weibull_model']]\n",
    "\n",
    "\n",
    "def compute_openmax_prob(scores, scores_u):\n",
    "    prob_scores, prob_unknowns = [], []\n",
    "    for s, su in zip(scores, scores_u):\n",
    "        channel_scores = np.exp(s)\n",
    "        channel_unknown = np.exp(np.sum(su))\n",
    "\n",
    "        total_denom = np.sum(channel_scores) + channel_unknown\n",
    "        prob_scores.append(channel_scores / total_denom)\n",
    "        prob_unknowns.append(channel_unknown / total_denom)\n",
    "\n",
    "    # Take channel mean\n",
    "    scores = np.mean(prob_scores, axis=0)\n",
    "    unknowns = np.mean(prob_unknowns, axis=0)\n",
    "    modified_scores = scores.tolist() + [unknowns]\n",
    "    return modified_scores\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def openmax(weibull_model, categories, input_score, eu_weight, alpha=10, distance_type='eucos'):\n",
    "    \"\"\"Re-calibrate scores via OpenMax layer\n",
    "    Output:\n",
    "        openmax probability and softmax probability\n",
    "    \"\"\"\n",
    "    nb_classes = len(categories)\n",
    "\n",
    "    ranked_list = input_score.argsort().ravel()[::-1][:alpha]\n",
    "    alpha_weights = [((alpha + 1) - i) / float(alpha) for i in range(1, alpha + 1)]\n",
    "    omega = np.zeros(nb_classes)\n",
    "    omega[ranked_list] = alpha_weights\n",
    "\n",
    "    scores, scores_u = [], []\n",
    "    for channel, input_score_channel in enumerate(input_score):\n",
    "        score_channel, score_channel_u = [], []\n",
    "        for c, category_name in enumerate(categories):\n",
    "            mav, dist, model = query_weibull(category_name, weibull_model, distance_type)\n",
    "            channel_dist = calc_distance(input_score_channel, mav[channel], eu_weight, distance_type)\n",
    "            wscore = model[channel].w_score(channel_dist)\n",
    "            modified_score = input_score_channel[c] * (1 - wscore * omega[c])\n",
    "            score_channel.append(modified_score)\n",
    "            score_channel_u.append(input_score_channel[c] - modified_score)\n",
    "\n",
    "        scores.append(score_channel)\n",
    "        scores_u.append(score_channel_u)\n",
    "\n",
    "    scores = np.asarray(scores)\n",
    "    scores_u = np.asarray(scores_u)\n",
    "\n",
    "    openmax_prob = np.array(compute_openmax_prob(scores, scores_u))\n",
    "    softmax_prob = softmax(np.array(input_score.ravel()))\n",
    "    return openmax_prob, softmax_prob\n",
    "\n",
    "\n",
    "def compute_channel_distances(mavs, features, eu_weight=0.5):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        mavs (channel, C)\n",
    "        features: (N, channel, C)\n",
    "    Output:\n",
    "        channel_distances: dict of distance distribution from MAV for each channel.\n",
    "    \"\"\"\n",
    "    eucos_dists, eu_dists, cos_dists = [], [], []\n",
    "    for channel, mcv in enumerate(mavs):  # Compute channel specific distances\n",
    "        eu_dists.append([spd.euclidean(mcv, feat[channel]) for feat in features])\n",
    "        cos_dists.append([spd.cosine(mcv, feat[channel]) for feat in features])\n",
    "        eucos_dists.append([spd.euclidean(mcv, feat[channel]) * eu_weight +\n",
    "                            spd.cosine(mcv, feat[channel]) for feat in features])\n",
    "\n",
    "    return {'eucos': np.array(eucos_dists), 'cosine': np.array(cos_dists), 'euclidean': np.array(eu_dists)}\n",
    "\n",
    "\n",
    "def compute_train_score_and_mavs_and_dists(train_class_num,trainloader,device,net):\n",
    "    scores = [[] for _ in range(train_class_num)]\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # this must cause error for cifar\n",
    "            _, outputs = net(inputs)\n",
    "            for score, t in zip(outputs, targets):\n",
    "                # print(f\"torch.argmax(score) is {torch.argmax(score)}, t is {t}\")\n",
    "                if torch.argmax(score) == t:\n",
    "                    scores[t].append(score.unsqueeze(dim=0).unsqueeze(dim=0))\n",
    "    scores = [torch.cat(x).cpu().numpy() for x in scores]  # (N_c, 1, C) * C\n",
    "    mavs = np.array([np.mean(x, axis=0) for x in scores])  # (C, 1, C)\n",
    "    dists = [compute_channel_distances(mcv, score) for mcv, score in zip(mavs, scores)]\n",
    "    return scores, mavs, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wicked-singles",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T12:01:29.043544Z",
     "start_time": "2021-07-07T12:01:28.286427Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASETS_ROOT = '/data/datasets/cv/rflowers'\n",
    "MODEL_CKPT_PATH = '/data/pretrained/cv/k12lite/model_resnet18_flower.pth'\n",
    "mean, std = (0.4623, 0.4305, 0.295), (0.252, 0.2242, 0.2091)\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std) # 对数据归一化处理\n",
    "])\n",
    "predict_model = M.resnet18(pretrained=False)\n",
    "predict_model.fc = nn.Linear(predict_model.fc.in_features, 22)\n",
    "predict_model.load_state_dict(torch.load(MODEL_CKPT_PATH))\n",
    "predict_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alert-picture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T12:08:13.023793Z",
     "start_time": "2021-07-07T12:08:12.857272Z"
    }
   },
   "outputs": [],
   "source": [
    "class JsonfileDataset(Dataset):\n",
    "    def __init__(self, data_root, json_file, resize=None, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.json_file = json_file\n",
    "        self.resize = resize\n",
    "        self.image_list, self.label_list = self.__read_jsonfile(json_file)\n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_list[index]).convert('RGB')\n",
    "        if self.resize:\n",
    "            img = img.resize(self.resize)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.label_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __read_jsonfile(self, jsonfile):\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(os.path.join(self.data_root, self.json_file)) as f:\n",
    "            items = json.load(f)\n",
    "            for item in items:\n",
    "                image_list.append(os.path.join(self.data_root, item['image_path']))\n",
    "                label_list.append(item['label'])\n",
    "        return image_list, label_list\n",
    "    \n",
    "train_data = JsonfileDataset(DATASETS_ROOT, 'all.json', transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "concerned-smart",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T12:02:27.374223Z",
     "start_time": "2021-07-07T12:02:27.212302Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = '/data/datasets/cv/rflowers/imgs/1/image_0001.jpg'\n",
    "# img_path = '/data/datasets/cv/rflowers/labels_hist.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "\n",
    "inputs = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equivalent-crossing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T12:02:28.814381Z",
     "start_time": "2021-07-07T12:02:27.864652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.7257,  13.0367,  -9.4243,  -9.5839,  -8.6934,  -6.1066,  -3.4276,\n",
       "          -9.8430,  -3.2183,  -4.6251,  -6.6655,  -8.8507,  -5.1508,  -3.9305,\n",
       "          -2.2419,  -3.2049,  -6.4950, -10.7448,  -7.8508, -13.4011,  -6.4250,\n",
       "          -8.7064]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-millennium",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-junior",
   "metadata": {},
   "source": [
    "- https://zhuanlan.zhihu.com/p/66192159\n",
    "\n",
    "- https://github.com/13952522076/Open-Set-Recognition\n",
    "\n",
    "- https://github.com/mattolson93/CGDL-for-Open-Set-Recognition\n",
    "\n",
    "- https://github.com/MrtnMndt/Deep_Openset_Recognition_through_Uncertainty\n",
    "\n",
    "- https://yanqi-chen.github.io/2019/06/24/openset-0/\n",
    "\n",
    "- https://recodbr.files.wordpress.com/2016/09/2016-icip-tutorial-open-set-light.pdf\n",
    "\n",
    "- https://www.cnblogs.com/bonelee/p/14482628.html"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
