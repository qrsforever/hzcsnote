{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> CV Api Test </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_print\n",
    "from k12libs.utils.nb_easy import k12ai_get_app_dir\n",
    "from k12libs.utils.nb_easy import k12ai_get_top_dir\n",
    "from k12libs.utils.nb_easy import k12ai_run_project\n",
    "from k12libs.utils.nb_widget import k12ai_schema_parse\n",
    "\n",
    "import os\n",
    "import json\n",
    "import _jsonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26226f7d351840c298831c431cf12689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Text(value='16601548608', continuous_update=False, description='Use…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_file = os.path.join(k12ai_get_top_dir(), 'k12libs/templates', 'projects.jsonnet')\n",
    "schema_json = _jsonnet.evaluate_file(schema_file)\n",
    "\n",
    "generator = k12ai_schema_parse(json.loads(schema_json), lan='cn', debug=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dir = os.path.join(k12ai_get_top_dir(), 'cv/app', 'templates', 'schema')\n",
    "# !ls $schema_dir \n",
    "\n",
    "basic_file = os.path.join(schema_dir, 'k12ai_cv.jsonnet')\n",
    "# !cat $basic_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e322a82265446e6ae88b9d319e15558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='cls', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_json = _jsonnet.evaluate_file(basic_file, ext_vars={\n",
    "    'task': 'cls',\n",
    "    'dataset_name': 'mnist'})\n",
    "# k12ai_print(basic_json, indent=2)\n",
    "\n",
    "generator = k12ai_schema_parse(json.loads(basic_json), lan='cn', debug=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf01d055e824cd78a0f65f8b5c309f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='det', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_json = _jsonnet.evaluate_file(basic_file, ext_vars={\n",
    "    'task': 'det',\n",
    "    'dataset_name': 'voc'})\n",
    "# k12ai_print(basic_json, indent=2)\n",
    "\n",
    "generator = k12ai_schema_parse(json.loads(basic_json), lan='cn', debug=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k12ai_print(generator.get_all_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "context = k12ai_run_project(lan='cn', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d7cb60eb440ba953a95848b75f848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='cls', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"request\": {\n",
      "        \"op\": \"train.start\",\n",
      "        \"user\": \"15801310416\",\n",
      "        \"service_name\": \"k12cv\",\n",
      "        \"service_uuid\": \"cifar10\",\n",
      "        \"service_params\": {\n",
      "            \"task\": \"cls\",\n",
      "            \"method\": \"image_classifier\",\n",
      "            \"data.include_val\": false,\n",
      "            \"dataset\": \"default\",\n",
      "            \"data.workers\": 4,\n",
      "            \"data.drop_last\": false,\n",
      "            \"data.image_tool\": \"pil\",\n",
      "            \"data.input_mode\": \"RGB\",\n",
      "            \"solver.display_iter\": 20,\n",
      "            \"solver.save_iters\": 2000,\n",
      "            \"solver.test_interval\": 100,\n",
      "            \"train.batch_size\": 32,\n",
      "            \"val.batch_size\": 32,\n",
      "            \"test.batch_size\": 32,\n",
      "            \"train.data_transformer.fit_stride\": 1,\n",
      "            \"train.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"train.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"train.data_transformer.align_method\": \"only_pad\",\n",
      "            \"train.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.train.random_border.bool\": false,\n",
      "            \"_k12.train.random_brightness.bool\": false,\n",
      "            \"_k12.train.random_contrast.bool\": false,\n",
      "            \"_k12.train.random_crop.bool\": false,\n",
      "            \"_k12.train.random_det_crop.bool\": false,\n",
      "            \"_k12.train.random_gauss_blur.bool\": false,\n",
      "            \"_k12.train.random_hsv.bool\": false,\n",
      "            \"_k12.train.random_hue.bool\": false,\n",
      "            \"_k12.train.random_pad.bool\": false,\n",
      "            \"_k12.train.random_perm.bool\": false,\n",
      "            \"_k12.train.random_resize.bool\": false,\n",
      "            \"_k12.train.random_resized_crop.bool\": false,\n",
      "            \"_k12.train.random_rotate.bool\": false,\n",
      "            \"_k12.train.random_saturation.bool\": false,\n",
      "            \"val.data_transformer.fit_stride\": 1,\n",
      "            \"val.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"val.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"val.data_transformer.align_method\": \"only_pad\",\n",
      "            \"val.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.val.random_border.bool\": false,\n",
      "            \"_k12.val.random_brightness.bool\": false,\n",
      "            \"_k12.val.random_contrast.bool\": false,\n",
      "            \"_k12.val.random_crop.bool\": false,\n",
      "            \"_k12.val.random_det_crop.bool\": false,\n",
      "            \"_k12.val.random_gauss_blur.bool\": false,\n",
      "            \"_k12.val.random_hsv.bool\": false,\n",
      "            \"_k12.val.random_hue.bool\": false,\n",
      "            \"_k12.val.random_pad.bool\": false,\n",
      "            \"_k12.val.random_perm.bool\": false,\n",
      "            \"_k12.val.random_resize.bool\": false,\n",
      "            \"_k12.val.random_resized_crop.bool\": false,\n",
      "            \"_k12.val.random_rotate.bool\": false,\n",
      "            \"_k12.val.random_saturation.bool\": false,\n",
      "            \"test.data_transformer.fit_stride\": 1,\n",
      "            \"test.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"test.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"test.data_transformer.align_method\": \"only_pad\",\n",
      "            \"test.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.data.dataset_name\": \"cifar10\",\n",
      "            \"data.data_dir\": \"/datasets/cifar10\",\n",
      "            \"data.num_records\": 60000,\n",
      "            \"data.num_classes\": 10,\n",
      "            \"data.normalize.mean\": [\n",
      "                0.485,\n",
      "                0.456,\n",
      "                0.406\n",
      "            ],\n",
      "            \"data.normalize.std\": [\n",
      "                0.229,\n",
      "                0.224,\n",
      "                0.225\n",
      "            ],\n",
      "            \"data.normalize.div_value\": 255,\n",
      "            \"_k12.network.backbone.enum\": \"vgg\",\n",
      "            \"network.backbone\": \"vgg16\",\n",
      "            \"network.model_name\": \"base_model\",\n",
      "            \"network.norm_type\": \"batchnorm\",\n",
      "            \"network.pretrained\": false,\n",
      "            \"network.syncbn\": false,\n",
      "            \"network.distributed\": true,\n",
      "            \"network.gather\": true,\n",
      "            \"network.resume_continue\": false,\n",
      "            \"network.resume_strict\": false,\n",
      "            \"network.resume_val\": false,\n",
      "            \"network.checkpoints_root\": \"/cache\",\n",
      "            \"network.checkpoints_dir\": \"ckpts\",\n",
      "            \"_k12.network.pretrained_path\": \"/pretrained\",\n",
      "            \"anchor.num_anchor_list\": [],\n",
      "            \"anchor.cur_anchor_sizes\": [],\n",
      "            \"anchor.feature_maps_wh\": [],\n",
      "            \"anchor.aspect_ratio_list\": [],\n",
      "            \"network.num_feature_list\": [],\n",
      "            \"network.stride_list\": [],\n",
      "            \"network.head_index_list\": [],\n",
      "            \"solver.lr.metric\": \"epoch\",\n",
      "            \"solver.max_epoch\": 360,\n",
      "            \"solver.lr.base_lr\": 0.001,\n",
      "            \"solver.lr.lr_policy\": \"multistep\",\n",
      "            \"solver.lr.multistep.gamma\": 0.1,\n",
      "            \"solver.lr.multistep.stepvalue\": [\n",
      "                90,\n",
      "                120\n",
      "            ],\n",
      "            \"solver.lr.is_warm\": false,\n",
      "            \"loss.loss_type\": \"ce_loss\",\n",
      "            \"loss.loss_weights.ce_loss.ce_loss\": 1.0,\n",
      "            \"loss.params.ce_loss.reduction\": \"mean\",\n",
      "            \"loss.params.ce_loss.ignore_index\": -1,\n",
      "            \"solver.optim.optim_method\": \"adam\",\n",
      "            \"solver.optim.adam.weight_decay\": 0.001,\n",
      "            \"solver.optim.adam.betas\": [\n",
      "                0.5,\n",
      "                0.999\n",
      "            ],\n",
      "            \"solver.optim.adam.eps\": 1e-08\n",
      "        }\n",
      "    },\n",
      "    \"response\": {\n",
      "        \"code\": 100000,\n",
      "        \"message\": \"success\",\n",
      "        \"data\": {\n",
      "            \"task\": \"cls\",\n",
      "            \"method\": \"image_classifier\",\n",
      "            \"data\": {\n",
      "                \"include_val\": false,\n",
      "                \"workers\": 4,\n",
      "                \"drop_last\": false,\n",
      "                \"image_tool\": \"pil\",\n",
      "                \"input_mode\": \"RGB\",\n",
      "                \"data_dir\": \"/datasets/cifar10\",\n",
      "                \"num_records\": 60000,\n",
      "                \"num_classes\": 10,\n",
      "                \"normalize\": {\n",
      "                    \"mean\": [\n",
      "                        0.485,\n",
      "                        0.456,\n",
      "                        0.406\n",
      "                    ],\n",
      "                    \"std\": [\n",
      "                        0.229,\n",
      "                        0.224,\n",
      "                        0.225\n",
      "                    ],\n",
      "                    \"div_value\": 255\n",
      "                }\n",
      "            },\n",
      "            \"dataset\": \"default\",\n",
      "            \"solver\": {\n",
      "                \"display_iter\": 20,\n",
      "                \"save_iters\": 2000,\n",
      "                \"test_interval\": 100,\n",
      "                \"lr\": {\n",
      "                    \"metric\": \"epoch\",\n",
      "                    \"base_lr\": 0.001,\n",
      "                    \"lr_policy\": \"multistep\",\n",
      "                    \"multistep\": {\n",
      "                        \"gamma\": 0.1,\n",
      "                        \"stepvalue\": [\n",
      "                            90,\n",
      "                            120\n",
      "                        ]\n",
      "                    },\n",
      "                    \"is_warm\": false\n",
      "                },\n",
      "                \"max_epoch\": 360,\n",
      "                \"optim\": {\n",
      "                    \"optim_method\": \"adam\",\n",
      "                    \"adam\": {\n",
      "                        \"weight_decay\": 0.001,\n",
      "                        \"betas\": [\n",
      "                            0.5,\n",
      "                            0.999\n",
      "                        ],\n",
      "                        \"eps\": 1e-08\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"batch_size\": 32,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                },\n",
      "                \"aug_trans\": {\n",
      "                    \"trans_seq\": []\n",
      "                }\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"batch_size\": 32,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                },\n",
      "                \"aug_trans\": {\n",
      "                    \"trans_seq\": []\n",
      "                }\n",
      "            },\n",
      "            \"test\": {\n",
      "                \"batch_size\": 32,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                }\n",
      "            },\n",
      "            \"network\": {\n",
      "                \"backbone\": \"vgg16\",\n",
      "                \"model_name\": \"base_model\",\n",
      "                \"norm_type\": \"batchnorm\",\n",
      "                \"syncbn\": false,\n",
      "                \"distributed\": true,\n",
      "                \"gather\": true,\n",
      "                \"resume_continue\": false,\n",
      "                \"resume_strict\": false,\n",
      "                \"resume_val\": false,\n",
      "                \"checkpoints_root\": \"/cache\",\n",
      "                \"checkpoints_dir\": \"ckpts\",\n",
      "                \"num_feature_list\": [],\n",
      "                \"stride_list\": [],\n",
      "                \"head_index_list\": [],\n",
      "                \"checkpoints_name\": \"base_model_vgg16\"\n",
      "            },\n",
      "            \"anchor\": {\n",
      "                \"num_anchor_list\": [],\n",
      "                \"cur_anchor_sizes\": [],\n",
      "                \"feature_maps_wh\": [],\n",
      "                \"aspect_ratio_list\": []\n",
      "            },\n",
      "            \"loss\": {\n",
      "                \"loss_type\": \"ce_loss\",\n",
      "                \"loss_weights\": {\n",
      "                    \"ce_loss\": {\n",
      "                        \"ce_loss\": 1.0\n",
      "                    }\n",
      "                },\n",
      "                \"params\": {\n",
      "                    \"ce_loss\": {\n",
      "                        \"reduction\": \"mean\",\n",
      "                        \"ignore_index\": -1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"key\": \"framework/15801310416/cifar10/train.start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "context = k12ai_run_project(lan='cn', debug=False, framework='k12cv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
