{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba752fc5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %watermark -p numpy,sklearn,pandas\n",
    "# %watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "# %watermark -p torch,torchvision,torchaudio\n",
    "# %watermark -p tensorflow,tensorboard,tflite\n",
    "# %watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "# from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "# from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import argparse, shlex, signal, traceback\n",
    "import numpy as np\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x, debug=False):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/' or x[1] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                x = 'https://' + x\n",
    "                x = requests.get(x)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                x = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = x.split('/')\n",
    "                for s in ['/main/', '/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    if debug:\n",
    "                        print(x)\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        if debug:\n",
    "            return x\n",
    "        else:\n",
    "            exec(x, globals())\n",
    "    except Exception as err:\n",
    "        # sys.stderr.write(f'request {x} : {err}')\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89569e73",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT('import pandas as pd')\n",
    "_IMPORT('import cv2')\n",
    "_IMPORT('from PIL import Image')\n",
    "_IMPORT('import matplotlib.pyplot as plt')\n",
    "_IMPORT('import plotly')\n",
    "_IMPORT('import plotly.graph_objects as go')\n",
    "_IMPORT('import ipywidgets as widgets')\n",
    "_IMPORT('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n",
    "\n",
    "def nbeasy_widget_display(images, img_wid=None):\n",
    "    if isinstance(images, np.ndarray):\n",
    "        images = {'_': images}\n",
    "    elif isinstance(images, tuple) or isinstance(images, list):\n",
    "        images = {f'_{i}': img for i, img in enumerate(images)}\n",
    "    C = len(images)\n",
    "    if C == 0:\n",
    "        return None\n",
    "    show_ncol, show_nrow = 1, 1\n",
    "    if C > 1:\n",
    "        if img_wid:\n",
    "            show_ncol = 2 if int(img_wid.width) <= 720 else 1\n",
    "        for i in range(C % show_ncol):\n",
    "            images[f'placehold-{i}'] = images[list(images.keys())[-1]].copy()\n",
    "        show_nrow = len(images) // show_ncol\n",
    "        row_images = []\n",
    "        col_images = []\n",
    "        for key, img in images.items():\n",
    "            if not key.startswith('_'):\n",
    "                cv2.putText(img, key, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 9,2), 1)\n",
    "            col_images.append(img)\n",
    "            if len(col_images) == show_ncol:\n",
    "                row_images.append(np.hstack(col_images))\n",
    "                col_images = []\n",
    "\n",
    "        display_image = np.vstack(row_images)\n",
    "    else:\n",
    "        display_image = images.popitem()[1]\n",
    "    \n",
    "    imgbytes = io.BytesIO(cv2.imencode('.png', display_image)[1]).getvalue()\n",
    "    if img_wid:\n",
    "        img_wid.layout.width = f'{display_image.shape[1]}px'\n",
    "        img_wid.layout.height = f'{display_image.shape[0]}px'\n",
    "        img_wid.value = imgbytes\n",
    "    else:\n",
    "        return imgbytes\n",
    "\n",
    "# https://www.webucator.com/article/python-color-constants-module/\n",
    "class COLORS(object):\n",
    "    # BGR\n",
    "    BLUE       = (255 , 0   , 0)\n",
    "    GREEN      = (0   , 255 , 0)\n",
    "    RED        = (0   , 0   , 255)\n",
    "    BLACK      = (0   , 0   , 0)\n",
    "    YELLOW     = (0   , 255 , 255)\n",
    "    WHITE      = (255 , 255 , 255)\n",
    "    CYAN       = (255 , 255 , 0)\n",
    "    MAGENTA    = (255 , 0   , 242)\n",
    "    GOLDEN     = (32  , 218 , 165)\n",
    "    LIGHTBLUE  = (255 , 9   , 2)\n",
    "    PURPLE     = (128 , 0   , 128)\n",
    "    CHOCOLATE  = (30  , 105 , 210)\n",
    "    PINK       = (147 , 20  , 255)\n",
    "    ORANGE     = (0   , 69  , 255)\n",
    "    GRAY       = (125 , 125 , 125)\n",
    "    DARKGRAY   = (50  , 50  , 50)\n",
    "    DARKGREEN  = (0   , 100 , 0)\n",
    "    OLIVE      = (0   , 128 , 0)\n",
    "    SILVER     = (192 , 192 , 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5d76a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import json, functools, datetime\n",
    "\n",
    "class __JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.datetime, datetime.timedelta)):\n",
    "            return '{}'.format(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps = functools.partial(json.dumps, cls=__JsonEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9c9826",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import skimage.filters as filters\n",
    "import threading\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "from enum import IntEnum\n",
    "\n",
    "_IMPORT('gitee.com/qrsforever/nb_easy/easy_widget')\n",
    "\n",
    "g_ctx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1bf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMPORT('./easy_widget.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef665d7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Grid Aurco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1243849",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A4_width_mm, A4_height_mm, printer_dpi = 210, 297, 600\n",
    "printer_dpi = 600\n",
    "printer_dpmm = printer_dpi / 25.4\n",
    "marker_size_mm, gap_size_mm = 25, 3\n",
    "aurco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)\n",
    "\n",
    "landscape = True # portrait\n",
    "\n",
    "if landscape:\n",
    "    A4_width_mm, A4_height_mm, printer_dpi = 280, 210, 600\n",
    "else:\n",
    "    A4_width_mm, A4_height_mm, printer_dpi = 210, 280, 600\n",
    "    \n",
    "markersX = (A4_width_mm - gap_size_mm) // (marker_size_mm + gap_size_mm)\n",
    "markersY = (A4_height_mm - gap_size_mm) // (marker_size_mm + gap_size_mm)\n",
    "\n",
    "aruco_gridboard = cv2.aruco.GridBoard_create(markersX, markersY, marker_size_mm, gap_size_mm, aurco_dict)\n",
    "\n",
    "width = markersX * marker_size_mm  + (markersX - 1) * gap_size_mm\n",
    "height =  markersY * marker_size_mm + (markersY - 1) * gap_size_mm\n",
    "\n",
    "cv2.imwrite(\"aruco_gridboard.png\", aruco_gridboard.draw((int(printer_dpmm * width), int(printer_dpmm * height))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e82a7",
   "metadata": {},
   "source": [
    "## Monocular: Single Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e0aa5c",
   "metadata": {
    "code_folding": [
     0,
     6,
     17,
     23,
     95,
     99,
     116,
     154,
     163,
     172,
     283,
     306,
     315,
     346
    ]
   },
   "outputs": [],
   "source": [
    "class CalibrateState(IntEnum):\n",
    "    COLLECT = 1\n",
    "    READIMAGE = 2\n",
    "    CALIBRATE = 3\n",
    "    COMPLETED = 4\n",
    "\n",
    "def stop_camera_calibrate(ctx, w_btn_source=None):\n",
    "    ctx.logger('stop_camera_calibrate()')\n",
    "    if hasattr(ctx, 'camera') and ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()\n",
    "\n",
    "def save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir):\n",
    "    cv_file = cv2.FileStorage(f'{out_dir}/intrinsics.yaml', cv2.FILE_STORAGE_WRITE)\n",
    "    cv_file.write('camera_matrix', camera_matrix)\n",
    "    cv_file.write('dist_coeffs', dist_coeffs)\n",
    "    cv_file.release()\n",
    "\n",
    "def load_calibration_intrinsics(out_dir):\n",
    "    yaml_file = f'{out_dir}/intrinsics.yaml'\n",
    "    assert os.path.exists(yaml_file), 'Not found intrinsics.yaml'\n",
    "    cv_file = cv2.FileStorage(yaml_file, cv2.FILE_STORAGE_READ)\n",
    "    camera_matrix = cv_file.getNode('camera_matrix').mat()\n",
    "    dist_coeffs = cv_file.getNode('dist_coeffs').mat()\n",
    "    return camera_matrix, dist_coeffs\n",
    " \n",
    "def start_calibrate_camera_with_good_flags(ctx, calibrate, img_size):\n",
    "    flags = 0\n",
    "    K = np.array([[max(img_size), 0, img_size[1]/2],[0, max(img_size), img_size[0]/2], [0, 0, 1]])\n",
    "    D = np.zeros((5, 1))\n",
    "    \n",
    "    retval, mat, dist, rvecs, tvecs, \\\n",
    "    std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "\n",
    "    ctx.logger(json.dumps({\n",
    "        're-project-error': retval, \n",
    "        'mat': str(mat.round(3).tolist()),\n",
    "        'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    aspect_ratio = mat[0][0] / mat[1][1]\n",
    "    if 1.0 - min(aspect_ratio, 1.0/aspect_ratio) < 0.01:\n",
    "        flags += cv2.CALIB_FIX_ASPECT_RATIO\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    center_point_reldiff = max(abs(np.array(mat[0, 2], mat[1][2]) - np.array(img_size)/2) / np.array(img_size))\n",
    "    if center_point_reldiff < 0.05:\n",
    "        flags += cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'center_point_reldiff': center_point_reldiff,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    error_threshold = 1.25 * retval\n",
    "    camera_matrix = mat\n",
    "    dist_coeffs = dist\n",
    "    error = retval\n",
    "\n",
    "    ignore_flags = {\n",
    "        'ignore_tangential_distortion': cv2.CALIB_ZERO_TANGENT_DIST,\n",
    "        'ignore_k3': cv2.CALIB_FIX_K3,\n",
    "        'ignore_k2': cv2.CALIB_FIX_K2,\n",
    "        'ignore_k1': cv2.CALIB_FIX_K1\n",
    "    }\n",
    "\n",
    "    for k, v in ignore_flags.items():\n",
    "        flags += v\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'ignore_type': k,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "        if retval > error_threshold:\n",
    "            break\n",
    "        camera_matrix = mat\n",
    "        dist_coeffs = dist\n",
    "        error = retval\n",
    "    \n",
    "    return error, camera_matrix, dist_coeffs\n",
    "\n",
    "def is_rotation_matrix(R):\n",
    "    shouldBeIdentity = np.dot(np.transpose(R), R)\n",
    "    return np.linalg.norm(np.identity(3, dtype=R.dtype) - shouldBeIdentity) < 1e-6\n",
    "\n",
    "def rotation_matrix2euler_angles(R):\n",
    "    assert(is_rotation_matrix(R))\n",
    "    # pitch = np.arctan2(R[2, 1], R[2, 2])\n",
    "    # raw = np.arctan2(-R[2, 0], np.hypot(R[2, 1], R[2, 2]))\n",
    "    # roll = np.arctan2(R[1, 0], R[0, 0])\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        pitch = math.atan2(R[2, 1], R[2, 2])\n",
    "        yaw = math.atan2(-R[2, 0], sy)\n",
    "        roll = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        pitch = math.atan2(-R[1, 2], R[1, 1])\n",
    "        yaw = math.atan2(-R[2, 0], sy)\n",
    "        roll = 0\n",
    "    return np.array([pitch, yaw, roll])\n",
    "\n",
    "def euler_angles2rotation_matrix(angles):\n",
    "    # cos, sin = np.cos(angles), np.sin(angles)\n",
    "    # X = np.array([\n",
    "    #     [1,      0,       0],\n",
    "    #     [0, cos[0], -sin[0]],\n",
    "    #     [0, sin[0], cos[0]]])\n",
    "    # Y = np.array([\n",
    "    #     [cos[1],  0, sin[1]],\n",
    "    #     [0,       1,      0],\n",
    "    #     [-sin[0], 0, cos[0]]])\n",
    "    # Z = np.array([\n",
    "    #     [cos[2], -sin[2], 0],\n",
    "    #     [sin[2],  cos[2], 0],\n",
    "    #     [0,            0, 1]])\n",
    "    # return Z @ Y @ X\n",
    "    \n",
    "    # Rotation on x-axis (pitch)\n",
    "    X = np.array([\n",
    "        [1, 0,                  0],\n",
    "        [0, math.cos(angles[0]), -math.sin(angles[0])],\n",
    "        [0, math.sin(angles[0]), math.cos(angles[0])]\n",
    "    ])\n",
    "\n",
    "    # Rotation on y-axis (raw)\n",
    "    Y = np.array([\n",
    "        [math.cos(angles[1]),  0, math.sin(angles[1])],\n",
    "        [0,                    1, 0],\n",
    "        [-math.sin(angles[1]), 0, math.cos(angles[1])]\n",
    "    ])\n",
    "\n",
    "    # Rotation on z-axis (roll)\n",
    "    Z = np.array([\n",
    "        [math.cos(angles[2]), -math.sin(angles[2]), 0],\n",
    "        [math.sin(angles[2]), math.cos(angles[2]),  0],\n",
    "        [0,                  0,                   1]\n",
    "    ])\n",
    "    return np.dot(Z, np.dot(Y, X))\n",
    "\n",
    "def pixel_to_world(intrinsics_matrix, extrinsics_matrix, x, y):\n",
    "    pseudo_inv_extrinsics = np.linalg.pinv(extrinsics_matrix)\n",
    "    intrinsics_inv = np.linalg.inv(intrinsics_matrix)\n",
    "    pixels_matrix = np.array((x, y, 1))\n",
    "    ans = np.matmul(intrinsics_inv, pixels_matrix)\n",
    "    ans = np.matmul(pseudo_inv_extrinsics, ans)\n",
    "    ans /= ans[-1] \n",
    "    return ans\n",
    "\n",
    "def measure_by_corners(camera_matrix, extrinsics_matrix, points):\n",
    "    p1 = pixel_to_world(camera_matrix, extrinsics_matrix, points[0][0], points[0][1])\n",
    "    p2 = pixel_to_world(camera_matrix, extrinsics_matrix, points[1][0], points[1][1])\n",
    "    p3 = pixel_to_world(camera_matrix, extrinsics_matrix, points[2][0], points[2][1])\n",
    "    W, H = p1 - p2, p2 - p3\n",
    "    width = np.sqrt(W[0]**2 + W[1]**2)\n",
    "    height = np.sqrt(H[0]**2 + H[1]**2)   \n",
    "    return width, height\n",
    "\n",
    "def single_aruco_estimate_pose(ctx, image, aruco_dict, camera_matrix, dist_coeffs, cross_line_p, marker_length=-1):\n",
    "    marker_corners, marker_ids, _ = cv2.aruco.detectMarkers(image, aruco_dict)\n",
    "    if marker_ids is None or len(marker_ids) > 5:\n",
    "        return {'det_marker_image': image}\n",
    "    det_marker_image = image\n",
    "    measure_image = image.copy()\n",
    "    tolerance_low, tolerance_high = cross_line_p - 3, cross_line_p + 3\n",
    "    if np.all(marker_ids is not None):\n",
    "        for (marker_corner, marker_id) in zip(marker_corners, marker_ids):\n",
    "            # corner: [[[306. 237.]\n",
    "            #          [440. 218.]\n",
    "            #          [477. 359.]\n",
    "            #          [344. 389.]]]\n",
    "            if marker_length < 0:\n",
    "                marker_length = 10.0 * (marker_id[0] - 60) # unit: mm\n",
    "                if marker_length < 0:\n",
    "                    continue\n",
    "                    \n",
    "            # another simple triangle method, as comparison with other methods\n",
    "            pixel_cm_ratio = cv2.arcLength(marker_corner[0], True) / (4 * marker_length)\n",
    "            min_rect = cv2.minAreaRect(marker_corner[0])\n",
    "            (c_x, c_y), (m_w, m_h), angle = min_rect\n",
    "            box = np.int0(cv2.boxPoints(min_rect))\n",
    "            \n",
    "            tri_width = m_w / pixel_cm_ratio\n",
    "            tri_height = m_h / pixel_cm_ratio\n",
    "            m_x, m_y, m_w, m_h, c_x, c_y = int(c_x - 0.5 * m_w), int(c_y - 0.5 * m_h), int(m_w), int(m_h), int(c_x), int(c_y)\n",
    "            \n",
    "            det_marker_image[m_y: m_y + m_h, m_x: m_x + m_w] = 127\n",
    "            cv2.circle(det_marker_image, (int(c_x), int(c_y)), 2, COLORS.OLIVE, -1)\n",
    "            cv2.polylines(det_marker_image, [box], True, COLORS.DARKGRAY, 2)\n",
    "\n",
    "            cv2.aruco.drawDetectedMarkers(det_marker_image, marker_corners, marker_ids, borderColor=COLORS.CYAN)\n",
    "            rvecs, tvecs, marker_points = cv2.aruco.estimatePoseSingleMarkers(marker_corner, marker_length, camera_matrix, dist_coeffs)\n",
    "\n",
    "            # calculate the height/width (2D to 3D)\n",
    "            (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "\n",
    "            # X (red color), Y (green color), Z (blue color)\n",
    "            cv2.drawFrameAxes(det_marker_image, camera_matrix, dist_coeffs, rvecs, tvecs, int(.8 * marker_length))  # Draw Axis\n",
    "            \n",
    "            bx1, by1, bw, bh = cv2.boundingRect(marker_corner[0])\n",
    "            if tolerance_low <= (by1 + bh) < tolerance_high:\n",
    "                cv2.rectangle(det_marker_image, (bx1, by1), (bx1 + bw, by1 + bh), COLORS.GREEN, 3)\n",
    "                \n",
    "            # rvecs: [[[ 0.18987504  2.79373027 -0.9026566 ]]]\n",
    "            # tvecs: [[[ 8.25180397  2.28427923 39.30899197]]]\n",
    "            # rotation_matrix: [[-0.97191346,  0.18216257,  0.14900011],\n",
    "            #                   [ 0.06054155,  0.80535491, -0.5896933 ],\n",
    "            #                   [-0.22741802, -0.56411016, -0.79376368]]\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rvecs[0])\n",
    "            extrinsics_matrix = np.concatenate([rotation_matrix, tvecs[0].T], axis=1) \n",
    "            width, height = measure_by_corners(camera_matrix, extrinsics_matrix, marker_corner[0])\n",
    "            distance = np.linalg.norm(tvecs[0])\n",
    "            # ctx.logger('width: {}, height: {}, distance: {}'.format(width, height, distance))\n",
    "            # angles = cv2.decomposeProjectionMatrix(extrinsics_matrix)[6].flatten()\n",
    "            angles = rotation_matrix2euler_angles(rotation_matrix)\n",
    "            pitch, yaw, roll = [math.degrees(angle) for angle in angles]\n",
    "            cv2.putText(det_marker_image,\n",
    "                        'size {} x {} D:{}'.format(round(width, 1), round(height, 1), round(distance, 1)),\n",
    "                        (tl[0], tl[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)\n",
    "            cv2.putText(det_marker_image,\n",
    "                        'pitch:{} yaw:{} roll:{}'.format(round(pitch, 1), round(yaw, 1), round(roll, 1)),\n",
    "                        (bl[0], bl[1] + 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)\n",
    "            \n",
    "            # extrinsics_matrix = euler_angles2rotation_matrix((-1.0 * pitch, yaw, roll))\n",
    "            # width, height = measure_by_corners(camera_matrix, extrinsics_matrix, marker_corner[0])\n",
    "            # cv2.putText(det_marker_image,\n",
    "            #             'size {} x {}'.format(round(width, 1), round(height, 1)),\n",
    "            #             (bl[0], bl[1] + 10),\n",
    "            #             cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)\n",
    "            \n",
    "            if ctx._aruco_tags_info:\n",
    "                measure_image[m_y: m_y + m_h, m_x: m_x + m_w] = 127\n",
    "                cv2.circle(measure_image, (int(c_x), int(c_y)), 2, COLORS.OLIVE, -1)\n",
    "                cv2.polylines(measure_image, [box], True, COLORS.DARKGRAY, 2)\n",
    "            \n",
    "                grid_extrinsics_matrix = ctx._aruco_tags_info.get_grid_extrinsics()\n",
    "                gr_width, gr_height = measure_by_corners(camera_matrix, grid_extrinsics_matrix, marker_corner[0])\n",
    "                \n",
    "                # get different extrinsics for each coner point (big err, due to big diff tvec)\n",
    "                # aruco_tag_info = ctx._aruco_tags_info.get_nearest_arucotag(tl[0], tl[1])\n",
    "                # p1 = pixel_to_world(camera_matrix, aruco_tag_info._e, tl[0], tl[1])\n",
    "                # aruco_tag_info = ctx._aruco_tags_info.get_nearest_arucotag(tr[0], tr[1])\n",
    "                # p2 = pixel_to_world(camera_matrix, aruco_tag_info._e, tr[0], tr[1])\n",
    "                # aruco_tag_info = ctx._aruco_tags_info.get_nearest_arucotag(br[0], br[1])\n",
    "                # p3 = pixel_to_world(camera_matrix, aruco_tag_info._e, br[0], br[1])\n",
    "                # W, H = p1 - p2, p2 - p3\n",
    "                # width = round(np.sqrt(W[0]**2 + W[1]**2), 1)\n",
    "                # height = round(np.sqrt(H[0]**2 + H[1]**2), 1)\n",
    "                \n",
    "                center_point = np.mean(marker_corner[0], axis=0, dtype=np.int32)\n",
    "                aruco_tag_info = ctx._aruco_tags_info.get_nearest_arucotag(center_point[0], center_point[1])\n",
    "                if aruco_tag_info:\n",
    "                    width, height = measure_by_corners(camera_matrix, aruco_tag_info._e, marker_corner[0])\n",
    "                    cv2.putText(measure_image,\n",
    "                                'grid global: {},{}'.format(round(gr_width, 1), round(gr_height, 1)),\n",
    "                                (tl[0], tl[1] - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)                \n",
    "                    cv2.putText(measure_image,\n",
    "                                'nearest{}: {},{}'.format(aruco_tag_info._t, round(width, 1), round(height, 1)),\n",
    "                                (bl[0], c_y),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)                \n",
    "                    cv2.putText(measure_image,\n",
    "                                'triangle: {},{} {},{}'.format(round(tri_width, 1), round(tri_height, 1), m_w, m_h),\n",
    "                                (bl[0], bl[1] + 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.BLUE, 1)                \n",
    "    return {'det_marker_image': det_marker_image, 'measure_image': measure_image}\n",
    "\n",
    "def girdaruco_estimate_poses(ctx, image, board, aruco_dict, camera_matrix, dist_coeffs):\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    marker_corners, marker_ids, rejected_points = cv2.aruco.detectMarkers(img_gray, aruco_dict)\n",
    "    # Refine detected markers\n",
    "    # Eliminates markers not part of our board, adds missing markers to the board\n",
    "    marker_corners, marker_ids, rejectedImgPoints, recoveredIds = cv2.aruco.refineDetectedMarkers(\n",
    "            image = img_gray,\n",
    "            board = board,\n",
    "            detectedCorners = marker_corners,\n",
    "            detectedIds = marker_ids,\n",
    "            rejectedCorners = rejected_points,\n",
    "            cameraMatrix = camera_matrix,\n",
    "            distCoeffs = dist_coeffs)\n",
    "    image = cv2.aruco.drawDetectedMarkers(image, marker_corners, borderColor=COLORS.CHOCOLATE)\n",
    "    if marker_ids is None or len(marker_ids) < 20:\n",
    "        raise RuntimeError('Not found any markers!')\n",
    "    # Estimate the posture of the gridboard, which is a construction of 3D space\n",
    "    pose, rvec, tvec = cv2.aruco.estimatePoseBoard(marker_corners, marker_ids, board, camera_matrix, dist_coeffs, None, None)\n",
    "    if pose:\n",
    "        # Draw the camera posture calculated from the gridboard\n",
    "        image = cv2.drawFrameAxes(image, camera_matrix, dist_coeffs, rvec, tvec, 20)\n",
    "    return image, marker_corners, marker_ids, rvec, tvec\n",
    "\n",
    "class _Ball(object):\n",
    "    def __init__(self, x, y, e, t):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._e = e\n",
    "        self._t = t\n",
    "    def __str__(self):\n",
    "        return f'{self._t}: ({self._x}, {self._y}), {np.round(self._e, 2).tolist()}'\n",
    "\n",
    "class ArucoTagsInfo(object):\n",
    "            \n",
    "    def __init__(self, grid_extrinsics_matrix, xy_map, gap):\n",
    "        self._grid_extrinsics_matrix = grid_extrinsics_matrix\n",
    "        self._gap = gap\n",
    "        self._cx_map_ordered =  collections.OrderedDict(sorted(xy_map.items(), key=lambda kv: kv[0][0]))\n",
    "        self._cy_map_ordered =  collections.OrderedDict(sorted(xy_map.items(), key=lambda kv: kv[0][1]))\n",
    "\n",
    "    def get_grid_extrinsics(self):\n",
    "        return self._grid_extrinsics_matrix \n",
    "    \n",
    "    def get_nearest_arucotag(self, x, y):\n",
    "        x_min, x_max = x - self._gap, x + self._gap\n",
    "        y_min, y_max = y - self._gap, y + self._gap\n",
    "        setx, sety = set(), set()\n",
    "        for point, ball in self._cx_map_ordered.items():\n",
    "            if point[0] > x_min and point[0] < x_max:\n",
    "                setx.add(ball)\n",
    "        for point, ball in self._cy_map_ordered.items():\n",
    "            if point[1] > y_min and point[1] < y_max:\n",
    "                sety.add(ball) \n",
    "        balls = list(setx.intersection(sety))\n",
    "        if len(balls) == 0:\n",
    "            return None\n",
    "        k, b = 2 * self._gap, balls[0]\n",
    "        for ball in balls:\n",
    "            d = abs(ball._x - x) + abs(ball._y - y)\n",
    "            if d < k:\n",
    "                k, b = d, ball\n",
    "        return b\n",
    "                 \n",
    "def detect_object_and_measure(ctx, image, dettype, camera_matrix, dist_coeffs, cross_line_p, cross_line_w):\n",
    "    result = {}\n",
    "    cross_line_p = int(cross_line_p * image.shape[0])\n",
    "    image[cross_line_p: cross_line_p + cross_line_w, :] = 127\n",
    "    if dettype == 'aruco-6x6': # Detect 6x6 ArUco Marker, [marker size] = [marker id] - 60 (mm)\n",
    "        dict_id = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_1000)\n",
    "        result = single_aruco_estimate_pose(ctx, image, dict_id, camera_matrix, dist_coeffs, cross_line_p)\n",
    "    elif dettype == 'aruco-4x4-26mm':\n",
    "        dict_id = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)\n",
    "        result = single_aruco_estimate_pose(ctx, image, dict_id, camera_matrix, dist_coeffs, cross_line_p, marker_length=26)\n",
    "    elif dettype == 'grid-26mm-3mm-9x7-4x4':\n",
    "        markersX, markersY, marker_size_mm, gap_size_mm = 9, 7, 26, 3\n",
    "        axis_length = int(0.5 * marker_size_mm)\n",
    "        dict_id = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)\n",
    "        board = cv2.aruco.GridBoard_create(\n",
    "            markersX=markersX,\n",
    "            markersY=markersY,\n",
    "            markerLength=marker_size_mm,\n",
    "            markerSeparation=gap_size_mm,\n",
    "            dictionary=dict_id)\n",
    "        try:\n",
    "            img_gird_pose, marker_corners, marker_ids, grid_rvec, grid_tvec = girdaruco_estimate_poses(ctx, image.copy(), board, dict_id, camera_matrix, dist_coeffs)\n",
    "            result['grid_pose'] = img_gird_pose\n",
    "            if len(marker_corners) == markersX * markersY:\n",
    "                rvecs, tvecs, marker_points = cv2.aruco.estimatePoseSingleMarkers(marker_corners, marker_size_mm, camera_matrix, dist_coeffs)\n",
    "                xy_map, length = {}, -1\n",
    "                for mc, mid, rvec, tvec in zip(marker_corners, marker_ids, rvecs, tvecs):\n",
    "                    extrinsics_matrix = np.concatenate([cv2.Rodrigues(rvec)[0], tvec.T], axis=1) \n",
    "                    if length < 0:\n",
    "                        length = max(abs(mc[0][0][0] - mc[0][2][0]), abs(mc[0][0][1] - mc[0][2][1]))\n",
    "                    center = tuple(np.mean(mc[0], axis=0, dtype=np.int32).tolist())\n",
    "                    width, hight = measure_by_corners(camera_matrix, extrinsics_matrix, mc[0])\n",
    "                    \n",
    "                    (cx, cy), (w, h), angle = cv2.minAreaRect(mc[0])\n",
    "                    tl_x, tl_y, w, h = int(cx - 0.5 * w), int(cy - 0.5 * h), int(w), int(h)\n",
    "                    image[tl_y:tl_y + h, tl_x:tl_x + w] = 255\n",
    "                    \n",
    "                    cv2.drawFrameAxes(image, camera_matrix, dist_coeffs, rvec, tvec, axis_length)\n",
    "                    cv2.putText(image, f'{round(width, 1)}', (center[0] - 12, center[1] - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.3, COLORS.BLACK, 1)\n",
    "                    cv2.putText(image, f'{round(hight, 1)}', (center[0] - 12, center[1] + 8), cv2.FONT_HERSHEY_SIMPLEX, 0.3, COLORS.BLACK, 1)\n",
    "                    if ctx._aruco_tags_info is None:\n",
    "                        xy_map[center] = _Ball(center[0], center[1], extrinsics_matrix, mid[0])\n",
    "                if ctx._aruco_tags_info is None:\n",
    "                    grid_extrinsics_matrix = np.concatenate([cv2.Rodrigues(grid_rvec)[0], grid_tvec], axis=1) \n",
    "                    ctx._aruco_tags_info = ArucoTagsInfo(grid_extrinsics_matrix, xy_map, length)\n",
    "            result['markers'] = image\n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}', clear=1)\n",
    "            time.sleep(0.3)\n",
    "            # raise\n",
    "        \n",
    "    elif dettype == 'black_edge_carton':\n",
    "        if ctx._aruco_tags_info is None:\n",
    "            cv2.putText(image, 'no extrinsics matrix', (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.LIGHT_BLUE, 1)\n",
    "        \n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "        img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "        img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "        img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "        contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # cv2.drawContours(image, contours, -1, color=(0, 0, 255), thickness=4)\n",
    "        # for cnt in contours:\n",
    "        #     area = cv2.contourArea(cnt)\n",
    "        #     if area > 1000 and area < 20000:\n",
    "        #         rect = cv2.minAreaRect(cnt)\n",
    "        #         (x, y), (w, h), angle = rect\n",
    "        #         box = cv2.boxPoints(rect)\n",
    "        #         box = np.int0(box)\n",
    "        #         cv2.circle(image, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "        #         cv2.polylines(image, [box], True, (100, 10, 0), 2)\n",
    "    elif dettype == 'tagboard':\n",
    "        if ctx._aruco_tags_info is None:\n",
    "            cv2.putText(image, 'no extrinsics matrix', (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.LIGHTBLUE, 1)\n",
    "            \n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "        img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "        # img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "        # img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "        contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        cv2.drawContours(image, contours, -1, color=(0, 0, 255), thickness=4)\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < 600 and area > 200:\n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                (x, y), (w, h), angle = rect\n",
    "                if w > h:\n",
    "                    rate = w / h\n",
    "                else:\n",
    "                    rate = h / w\n",
    "                if rate < 2:\n",
    "                    continue\n",
    "                box = np.int0(cv2.boxPoints(rect))\n",
    "                cv2.circle(image, (int(x), int(y)), 2, COLORS.RED, -1)\n",
    "                cv2.polylines(image, [box], True, COLORS.BLUE, 1)                \n",
    "                try:\n",
    "                    aruco_tag_info = ctx._aruco_tags_info.get_nearest_arucotag(x, y)\n",
    "                    if aruco_tag_info:\n",
    "                        width, height = measure_by_corners(camera_matrix, aruco_tag_info._e, box)\n",
    "                        cv2.putText(image, '%.2f, %.2f' % (width, height), box[0], cv2.FONT_HERSHEY_SIMPLEX, 0.4, COLORS.LIGHTBLUE, 1)\n",
    "                        result['image'] = image\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    return result\n",
    "\n",
    "# def foreach_read_frame(source):\n",
    "#     camera = cv2.VideoCapture(source)\n",
    "#     if not camera.isOpened():\n",
    "#         raise RuntimeError(f'Cannot open video: {camera_source}')\n",
    "#     frame_idx = 0\n",
    "#     while True:\n",
    "#         ret, frame_bgr = camera.read()\n",
    "#         if not ret:\n",
    "#             raise RuntimeError('Camera read error!')\n",
    "#         frame_idx += 1\n",
    "#         yield frame_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bbd10",
   "metadata": {},
   "source": [
    "### Calibration By ChessBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b642cdad",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def start_calibrate_by_chessboard(\n",
    "    ctx, w_btn_source, camera_source, squares_x, squares_y, square_size, win_size, term_iters, term_eps,\n",
    "    display_items, sample_size, use_file, w_resolution, w_cross_line_p, w_cross_line_w, \n",
    "    w_det_objtype, w_sample_list,  w_cam_frame):\n",
    "    \n",
    "    ctx.logger(f'start: {squares_x}, {squares_y}, {square_size}mm, {sample_size}', clear=1)\n",
    "    \n",
    "    # Object points for a chessboard\n",
    "    pattern_size = (squares_x - 1, squares_y - 1)\n",
    "    objp = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "    objp = objp * square_size\n",
    "        \n",
    "    win_size, zero_zone = (win_size, win_size), (-1, -1)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "    \n",
    "    def _init_load_images(img_dir, online=False):\n",
    "        obj_points, img_points = [], []\n",
    "        samples = []\n",
    "        options = [('Camera', 0)]\n",
    "        state = CalibrateState.COLLECT\n",
    "        if not online and os.path.exists(img_dir):\n",
    "            image_list = glob.glob(f'{img_dir}/*.png')\n",
    "            assert len(image_list) > 3, 'Not enough chess board images'\n",
    "            display_images = {}\n",
    "            for path in image_list:\n",
    "                name = os.path.basename(path)\n",
    "                img = cv2.imread(path)\n",
    "                # img = cv2.flip(img, 1)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                found, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "                better_chess_corners = cv2.cornerSubPix(gray, corners, win_size, zero_zone, criteria)\n",
    "                obj_points.append(objp)\n",
    "                img_points.append(better_chess_corners)\n",
    "                display_images['orig_corners'] = cv2.drawChessboardCorners(img.copy(), pattern_size, corners, found)\n",
    "                display_images['best_corners'] = cv2.drawChessboardCorners(img.copy(), pattern_size, better_chess_corners, found)\n",
    "                options.append((name, int(name.split('.')[0])))\n",
    "                samples.append(nbeasy_widget_display(display_images))\n",
    "            w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "            state = CalibrateState.CALIBRATE\n",
    "        else:\n",
    "            shutil.rmtree(img_dir, ignore_errors=True)\n",
    "            ctx.logger(f'rm {img_dir}')\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        ctx._out_dir = img_dir\n",
    "        return state, obj_points, img_points, samples, options\n",
    "        \n",
    "    def _video_capture():\n",
    "        w_btn_source.disabled = True\n",
    "        out_dir = f'out/chessboard/{squares_x}x{squares_y}_{square_size}_{w_resolution.value[0]}'\n",
    "        try:\n",
    "            state, obj_points, img_points, samples, options = _init_load_images(out_dir, sample_size is not None)\n",
    "                \n",
    "            camera = cv2.VideoCapture(camera_source)\n",
    "            if not camera.isOpened():\n",
    "                raise RuntimeError(f'Cannot open video: {camera_source}')\n",
    "                \n",
    "            # frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            # frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            frame_irate = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "            \n",
    "            frame_width, frame_height = w_resolution.value\n",
    "            camera.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "            camera.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "            w_cam_frame.width, w_cam_frame.height = str(frame_width), str(frame_height)\n",
    "            \n",
    "            ctx.logger(f'width:{frame_width} height:{frame_height} display: {w_cam_frame.width} resoluton: {w_resolution.value}')\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = camera.isOpened()\n",
    "\n",
    "            ctx._aruco_tags_info = None\n",
    "            camera_matrix, dist_coeffs = None, None\n",
    "\n",
    "            frame_idx, iter_idx = 0, 0\n",
    "            \n",
    "            show_raw, show_undist = 'raw' in display_items, 'undist' in display_items\n",
    "            while ctx.camera_is_running:\n",
    "                if w_sample_list.value != 0:\n",
    "                    w_cam_frame.value = samples[w_sample_list.value - 1]\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                if frame_width != w_resolution.value[0]:\n",
    "                    frame_width, frame_height = w_resolution.value\n",
    "                    camera.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "                    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "                    w_cam_frame.width, w_cam_frame.height = str(frame_width), str(frame_height)\n",
    "                    out_dir = f'out/chessboard/{squares_x}x{squares_y}_{square_size}_{w_resolution.value[0]}'\n",
    "                    state, obj_points, img_points, samples, options = _init_load_images(out_dir, False)\n",
    "                    frame_idx, iter_idx = 0, 0\n",
    "                    ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "                    \n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # frame_bgr = cv2.flip(frame_bgr, 1)\n",
    "                display_frames = {'raw': frame_bgr}  if show_raw else {}\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if state == CalibrateState.COLLECT:\n",
    "                    found, corners = cv2.findChessboardCorners(frame_gray, pattern_size)\n",
    "                    if found:\n",
    "                        # Find better sub pix position for the corners in the roof corners neighbourhood\n",
    "                        better_chess_corners = cv2.cornerSubPix(frame_gray, corners, win_size, zero_zone, criteria)\n",
    "                        display_frames['orig_corners'] = cv2.drawChessboardCorners(frame_bgr.copy(), pattern_size, corners, found)\n",
    "                        display_frames['best_corners'] = cv2.drawChessboardCorners(frame_bgr.copy(), pattern_size, better_chess_corners, found)\n",
    "\n",
    "                        if frame_idx % frame_irate == 0:\n",
    "                            obj_points.append(objp)\n",
    "                            img_points.append(better_chess_corners)\n",
    "                            iter_idx += 1\n",
    "\n",
    "                            box = cv2.boxPoints(cv2.minAreaRect(better_chess_corners.reshape(-1, 2)))\n",
    "                            cv2.drawContours(display_frames['best_corners'], [np.int0(box)], 0, COLORS.ORANGE, 2)\n",
    "\n",
    "                            # Draw and display the corners\n",
    "                            options.append((str(iter_idx) + '.png', iter_idx))\n",
    "                            samples.append(io.BytesIO(cv2.imencode('.png', display_frames['best_corners'])[1]).getvalue())\n",
    "                            if iter_idx == sample_size:\n",
    "                                state = CalibrateState.CALIBRATE\n",
    "                                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                            cv2.imwrite(f'{out_dir}/{iter_idx}.png', frame_bgr)\n",
    "                            print(f'{out_dir}/{iter_idx}.png')\n",
    "                        cv2.putText(display_frames['best_corners'], f'Count: {iter_idx}', (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, COLORS.LIGHTBLUE, 2)\n",
    "                elif state == CalibrateState.CALIBRATE and not use_file:\n",
    "                    error, camera_matrix, dist_coeffs = start_calibrate_camera_with_good_flags(\n",
    "                        ctx, functools.partial(\n",
    "                            cv2.calibrateCameraExtended, objectPoints=obj_points, imagePoints=img_points),\n",
    "                        img_size=frame_gray.shape[::-1],\n",
    "                    )\n",
    "\n",
    "                    save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir)\n",
    "                    \n",
    "                    # obj_points, img_points = obj_points[-1], img_points[-1]\n",
    "                    # # Calculating extrinsics by last imgage (rotation vector)\n",
    "                    # retval, rvec, tvec = cv2.solvePnP(obj_points, img_points, camera_matrix, dist_coeffs)                    \n",
    "                    # # rvec, tvec = np.mean(np.array(rvecs), axis=0), np.mean(np.array(tvecs), axis=0)\n",
    "                    # # transform rotation vector to ratation matrix\n",
    "                    # rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "                    # extrinsics_matrix = np.concatenate([rotation_matrix, tvec], 1) \n",
    "                    \n",
    "                    # calculate the re-project points error.  == reval\n",
    "                    # mean_error = 0\n",
    "                    # for obj_point, img_point, rvec, tvec in zip(obj_points, img_points, rvecs, tvecs):\n",
    "                    #     img_point_proj, _ = cv2.projectPoints(obj_point, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "                    #     error = cv2.norm(img_point, img_point_proj, cv2.NORM_L2) / len(img_point_proj)\n",
    "                    #     mean_error += error\n",
    "                    # ctx.logger('total error: {}'.format(mean_error / len(obj_points)))\n",
    "             \n",
    "                    state = CalibrateState.COMPLETED\n",
    "                else: \n",
    "                    # load from file\n",
    "                    if camera_matrix is None and use_file:\n",
    "                        camera_matrix, dist_coeffs = load_calibration_intrinsics(out_dir)\n",
    "                        \n",
    "                    if show_undist:\n",
    "                        display_frames['undist'] = cv2.undistort(frame_bgr.copy(), camera_matrix, dist_coeffs)\n",
    "                        \n",
    "                    result = detect_object_and_measure(ctx, frame_bgr.copy(), w_det_objtype.value, camera_matrix, dist_coeffs, w_cross_line_p.value, w_cross_line_w.value)\n",
    "                    for title, image in result.items():\n",
    "                        display_frames[title] = image\n",
    "\n",
    "                # display image\n",
    "                nbeasy_widget_display(display_frames, w_cam_frame)\n",
    "                frame_idx += 1\n",
    "\n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        finally:\n",
    "            w_btn_source.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "\n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "stop_calibrate_by_chessboard = stop_camera_calibrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84906ba",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Calibration By CharucoBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbd7df2",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def start_calibrate_by_charucoboard(\n",
    "    ctx, w_btn_source, camera_source, squares_x, squares_y, square_size, win_size, marker_size, \n",
    "    aruco_id, term_iters, term_eps, display_items, sample_size, use_file, w_resolution,\n",
    "    w_cross_line_p, w_cross_line_w, w_det_objtype, w_sample_list, w_cam_frame):\n",
    "    \n",
    "    ctx.logger(f'start: {squares_x}, {squares_y}, {square_size}mm, {marker_size}mm, {aruco_id}, {sample_size}, {use_file}', clear=1)\n",
    "    \n",
    "    charuco_dict = cv2.aruco.getPredefinedDictionary(aruco_id)\n",
    "    charuco_board = cv2.aruco.CharucoBoard_create(squares_x, squares_y, square_size, marker_size, charuco_dict)\n",
    "    \n",
    "    pattern_size = (squares_x, squares_y)\n",
    "    win_size, zero_zone = (win_size, win_size), (-1, -1)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, term_iters, term_eps)\n",
    "        \n",
    "    def _detect_charuco_corners(frame_gray, charuco_board, charuco_dict, win_size, zero_zone, criteria, lowlimit):\n",
    "        # corner detection\n",
    "        marker_corners, marker_ids, rejected_points = cv2.aruco.detectMarkers(frame_gray, charuco_dict)\n",
    "        if marker_corners is not None and len(marker_corners) > 0:\n",
    "            # corner refine \n",
    "            # marker_corners, marker_ids, refusd, recoverd = cv2.aruco.refineDetectedMarkers(\n",
    "            #     frame_gray, charuco_board, marker_corners, marker_ids, rejectedCorners=rejected_points) \n",
    "            # corner interpolation (get charuco corners and ids from detected aruco markers)\n",
    "            retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(marker_corners, marker_ids, frame_gray, charuco_board)\n",
    "            if charuco_corners is not None and len(charuco_corners) > lowlimit:\n",
    "                if win_size:\n",
    "                    better_charuco_corners = cv2.cornerSubPix(frame_gray, charuco_corners, win_size, zero_zone, criteria)\n",
    "                else:\n",
    "                    better_charuco_corners  = charuco_corners\n",
    "                return retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids \n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    def _init_load_images(img_dir, online=False):\n",
    "        samples = []\n",
    "        options = [('Camera', 0)]\n",
    "        state = CalibrateState.COLLECT\n",
    "        if not online and os.path.exists(img_dir):\n",
    "            image_list = glob.glob(f'{img_dir}/*.png')\n",
    "            assert len(image_list) > 10, 'Not enough chessaruco board images'\n",
    "            for path in image_list:\n",
    "                name = os.path.basename(path)\n",
    "                img = cv2.imread(path)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids = _detect_charuco_corners(\n",
    "                        gray, charuco_board, charuco_dict, win_size, zero_zone, criteria)\n",
    "                if retval:\n",
    "                    all_charuco_corners.append(better_charuco_corners)\n",
    "                    all_charuco_ids.append(charuco_ids)\n",
    "                    cv2.aruco.drawDetectedCornersCharuco(img, better_charuco_corners, charuco_ids)\n",
    "                    options.append((name, int(name.split('.')[0])))\n",
    "                    samples.append(io.BytesIO(cv2.imencode('.png', img)[1]).getvalue())\n",
    "            w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "            state = CalibrateState.CALIBRATE\n",
    "        else:\n",
    "            shutil.rmtree(img_dir, ignore_errors=True)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        ctx._out_dir = img_dir\n",
    "        return state, all_charuco_corners, all_charuco_ids, samples, options\n",
    "    \n",
    "    def _video_capture():\n",
    "        w_btn_source.disabled = True\n",
    "        result = {}\n",
    "        all_charuco_corners, all_charuco_ids = [], []\n",
    "        out_dir = f'out/chessaruco/{squares_x}x{squares_y}_{square_size}_{marker_size}_{w_resolution.value[0]}'\n",
    "            \n",
    "        try:\n",
    "            state, all_charuco_corners, all_charuco_ids, samples, options = _init_load_images(out_dir, sample_size is not None)\n",
    "                \n",
    "            camera = cv2.VideoCapture(camera_source)\n",
    "            if not camera.isOpened():\n",
    "                raise RuntimeError(f'Cannot open video: {camera_source}')\n",
    "                \n",
    "            # frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            # frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "            frame_irate = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "            frame_width, frame_height = w_resolution.value\n",
    "            camera.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "            camera.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "            w_cam_frame.width, w_cam_frame.height = str(frame_width), str(frame_height)\n",
    "            \n",
    "            ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = camera.isOpened()\n",
    "            \n",
    "            ctx._aruco_tags_info = None\n",
    "            camera_matrix, dist_coeffs = None, None,\n",
    "            \n",
    "            lowlimit = int(0.5 * squares_x * squares_y)\n",
    "            frame_idx, iter_idx = 0, 0\n",
    "            \n",
    "            show_raw, show_undist = 'raw' in display_items, 'undist' in display_items\n",
    "            while ctx.camera_is_running:\n",
    "                if w_sample_list.value != 0:\n",
    "                    if w_cam_frame.layout.width != frame_width:\n",
    "                        w_cam_frame.layout.width = f'{frame_width}px'\n",
    "                        w_cam_frame.layout.height = f'{frame_height}px'\n",
    "                    w_cam_frame.value = samples[w_sample_list.value]\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                if frame_width != w_resolution.value[0]:\n",
    "                    frame_width, frame_height = w_resolution.value\n",
    "                    camera.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "                    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "                    w_cam_frame.width, w_cam_frame.height = str(frame_width), str(frame_height)\n",
    "                    out_dir = f'out/chessaruco/{squares_x}x{squares_y}_{square_size}_{marker_size}_{w_resolution.value[0]}'\n",
    "                    state, all_charuco_corners, all_charuco_ids, samples, options = _init_load_images(out_dir, False)\n",
    "                    frame_idx, iter_idx = 0, 0\n",
    "                    ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # frame_bgr = cv2.flip(frame_bgr, 1)\n",
    "                display_frames = {'raw': frame_bgr}  if show_raw else {}\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if state == CalibrateState.COLLECT:\n",
    "                    retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids = _detect_charuco_corners(\n",
    "                        frame_gray, charuco_board, charuco_dict, win_size, zero_zone, criteria, lowlimit)\n",
    "                    \n",
    "                    if retval:\n",
    "                        display_frames['markers'] = cv2.aruco.drawDetectedMarkers(frame_bgr.copy(), marker_corners, marker_ids)                        \n",
    "                        display_frames['orig_corners'] = cv2.aruco.drawDetectedCornersCharuco(frame_bgr.copy(), charuco_corners, charuco_ids)\n",
    "                        display_frames['best_corners'] = cv2.aruco.drawDetectedCornersCharuco(frame_bgr.copy(), better_charuco_corners, charuco_ids)\n",
    "\n",
    "                        if frame_idx % frame_irate == 0:\n",
    "                            # Draw and Display markers and corners\n",
    "                            # objp = charuco_board.chessboardCorners[all_charuco_ids.flatten()]\n",
    "                            all_charuco_corners.append(better_charuco_corners)\n",
    "                            all_charuco_ids.append(charuco_ids)\n",
    "                            iter_idx += 1\n",
    "\n",
    "                            box = cv2.boxPoints(cv2.minAreaRect(better_charuco_corners.reshape(-1, 2)))\n",
    "                            cv2.drawContours(display_frames['best_corners'], [np.int0(box)], 0, COLORS.ORANGE, 2)\n",
    "\n",
    "                            options.append((str(iter_idx) + '.png', iter_idx))\n",
    "                            samples.append(io.BytesIO(cv2.imencode('.png', display_frames['best_corners'])[1]).getvalue())\n",
    "                            if iter_idx == sample_size:\n",
    "                                sample_size = None\n",
    "                                state = CalibrateState.CALIBRATE\n",
    "                                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                            cv2.imwrite(f'{out_dir}/{iter_idx}.png', frame_bgr)\n",
    "                        cv2.putText(display_frames['best_corners'], f'Count: {iter_idx}', (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, COLORS.GOLDEN, 2)\n",
    "                elif state == CalibrateState.CALIBRATE and not use_file:\n",
    "                    error, camera_matrix, dist_coeffs = start_calibrate_camera_with_good_flags(\n",
    "                        ctx, functools.partial(\n",
    "                            cv2.aruco.calibrateCameraCharucoExtended,\n",
    "                            charucoCorners=all_charuco_corners, charucoIds=all_charuco_ids,\n",
    "                            board=charuco_board),\n",
    "                        img_size=frame_gray.shape[::-1]\n",
    "                    )\n",
    "                        \n",
    "                    save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir)\n",
    "                    \n",
    "                    # total_error = 0.0\n",
    "                    # for k, (charuco_corners, c_ids, rvec, tvec) in enumerate(zip(all_charuco_corners, all_charuco_ids, rvecs, tvecs)):\n",
    "                    #     obj_points, img_points = cv2.aruco.getBoardObjectAndImagePoints(charuco_board, charuco_corners, c_ids)\n",
    "                    #     prj_points, _ = cv2.projectPoints(obj_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "                    #     error = cv2.norm(img_points, prj_points, cv2.NORM_L2) / len(obj_points)\n",
    "                    #     total_error += error\n",
    "                    # ctx.logger(f'mean total error: {total_error / len(all_charuco_corners)}')\n",
    "                    state = CalibrateState.COMPLETED\n",
    "                else: \n",
    "                    # load from file\n",
    "                    if camera_matrix is None and use_file:\n",
    "                        camera_matrix, dist_coeffs = load_calibration_intrinsics(out_dir)\n",
    "                     \n",
    "                    if show_undist:\n",
    "                        display_frames['undist'] = cv2.undistort(frame_bgr.copy(), camera_matrix, dist_coeffs)\n",
    "                        \n",
    "                    result = detect_object_and_measure(ctx, frame_bgr.copy(), w_det_objtype.value, camera_matrix, dist_coeffs, w_cross_line_p.value, w_cross_line_w.value)\n",
    "                    for title, image in result.items():\n",
    "                        display_frames[title] = image\n",
    "                    \n",
    "                # display image\n",
    "                nbeasy_widget_display(display_frames, w_cam_frame)\n",
    "                frame_idx += 1\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        finally:\n",
    "            w_btn_source.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "stop_calibrate_by_charucoboard = stop_camera_calibrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311d7e7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Other Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f2badb1",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reset_grid_aurco_tag(ctx, w_btn_source):\n",
    "    ctx.logger('reset_grid_aurco_tag', clear=1)\n",
    "    if getattr(ctx, '_aruco_tags_info'):\n",
    "        ctx._aruco_tags_info = None\n",
    "        \n",
    "def save_grid_aurco_tag(ctx, w_btn_source):\n",
    "    ctx.logger('save_grid_aurco_tag', clear=1)\n",
    "    if getattr(ctx, '_aruco_tags_info'):\n",
    "        with open(f'{ctx._out_dir}/grid_aruco_tags_info.pkl', 'wb') as f:\n",
    "            pickle.dump(ctx._aruco_tags_info, f)\n",
    "        \n",
    "def load_grid_aurco_tag(ctx, w_btn_source):\n",
    "    ctx.logger('load_grid_aurco_tag', clear=1)\n",
    "    with open(f'{ctx._out_dir}/grid_aruco_tags_info.pkl', 'rb') as f:\n",
    "        ctx._aruco_tags_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e52d1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Template Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75985614",
   "metadata": {
    "code_folding": [
     0,
     10
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09abd9328e470fa54902e11c11c89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(HTML(value=\"<b><font color='black'>Common :</b>\"), HBox(children=(D…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nbeasy_chessboard_choice_objs(nrow, ncol, square_size, width=300, ro=True):\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': [\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_x', 'Squares X', nrow, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_y', 'Squares Y', ncol, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_square_size', 'Square Size(mm)', square_size, width=width, readonly=ro)        \n",
    "        ]\n",
    "    }\n",
    "\n",
    "def nbeasy_charucoboard_choice_objs(nrow, ncol, square_size, marker_size, aruco_dict_id, width=300, ro=True):\n",
    "    enums = [\n",
    "        ('4x4', cv2.aruco.DICT_4X4_1000),\n",
    "        ('5x5', cv2.aruco.DICT_5X5_1000),\n",
    "    ]\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': [\n",
    "            nbeasy_widget_int('cfg.charucoboard_squares_x', 'Squares X', nrow, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.charucoboard_squares_y', 'Squares Y', ncol, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.charucoboard_square_size', 'Square Size(mm)', square_size, width=width, readonly=ro),\n",
    "            nbeasy_widget_float('cfg.charucoboard_marker_size', 'Marker Size CM', marker_size, width=width, readonly=ro),\n",
    "            nbeasy_widget_stringenum(\n",
    "                'cfg.charucoboard_aruco_dict', 'ArUco Dict', default=aruco_dict_id,\n",
    "                enums=enums,\n",
    "                width=width,\n",
    "                readonly=ro\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def nbeasy_common_shared_by_tagtype(tag):\n",
    "    return {\n",
    "        'type': 'V',\n",
    "        'objs': [\n",
    "            {\n",
    "                'type': 'H',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_int(f'cfg.{tag}_win_size', 'Win Size', default=5),\n",
    "                    nbeasy_widget_int(f'cfg.{tag}_term_iters', 'Term Iters', default=500),\n",
    "                    nbeasy_widget_float(f'cfg.{tag}_term_eps', 'Term EPS', default=0.0001),\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'type': 'V',\n",
    "                'name': 'Camera',\n",
    "                'objs': [\n",
    "                    {\n",
    "                        'type': 'H',\n",
    "                        'objs': [\n",
    "                            nbeasy_widget_togglebuttons(\n",
    "                                f'cfg.{tag}_resolution', ' ',  default=0,\n",
    "                                enums=[('SD ', [640, 480]), ('HD ', [1080, 720])],\n",
    "                                style='info', icons=['camera', 'camera']),\n",
    "                            nbeasy_widget_button(f'cfg.__btn_{tag}_start_camera', 'Start', width=200, style='success'),\n",
    "                            nbeasy_widget_button(f'cfg.__btn_{tag}_stop_camera', 'Stop', width=200, style='success'),\n",
    "                        ],\n",
    "                        'justify_content': 'center'\n",
    "                    },\n",
    "                ],\n",
    "                'align_items': 'center'\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def nbeasy_start_stop_camera(tag):\n",
    "    if tag == \"chessboard\":\n",
    "        start_handler = start_calibrate_by_chessboard\n",
    "        stop_handler = stop_calibrate_by_chessboard\n",
    "    elif tag == \"charucoboard\":\n",
    "        start_handler = start_calibrate_by_charucoboard\n",
    "        stop_handler = stop_calibrate_by_charucoboard\n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "    return [{\n",
    "        'handler': start_handler,\n",
    "        'params': {\n",
    "            'sources': [f'cfg.__btn_{tag}_start_camera'],\n",
    "            'targets': [\n",
    "                'cfg.camera_source:value',\n",
    "                f'cfg.{tag}_squares_x:value',\n",
    "                f'cfg.{tag}_squares_y:value',\n",
    "                f'cfg.{tag}_square_size:value',\n",
    "                f'cfg.{tag}_win_size:value',\n",
    "            ] + (\n",
    "                [\n",
    "                    'cfg.charucoboard_marker_size:value',\n",
    "                    'cfg.charucoboard_aruco_dict:value',\n",
    "                ] if tag == \"charucoboard\" else []\n",
    "            ) + [\n",
    "                f'cfg.{tag}_term_iters:value',\n",
    "                f'cfg.{tag}_term_eps:value',\n",
    "                'cfg.display_items:value',\n",
    "                'cfg.sample_size:value',\n",
    "                'cfg.use_file:value',\n",
    "                f'cfg.{tag}_resolution',\n",
    "                'cfg.cross_line_p',\n",
    "                'cfg.cross_line_w',\n",
    "                'cfg.det_object_type',\n",
    "                'cfg.sample_list',\n",
    "                '__cfg.video_frame'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'handler': stop_handler,\n",
    "        'params': {\n",
    "            'sources': [f'cfg.__btn_{tag}_stop_camera'],\n",
    "            'targets': [\n",
    "            ]\n",
    "        }\n",
    "    }]\n",
    "\n",
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'H',\n",
    "            'name': 'Common',\n",
    "            'objs': [\n",
    "                    nbeasy_widget_stringenum(\n",
    "                        'cfg.camera_source', 'Camera Source', default=1,\n",
    "                        enums=[('usb video 0', 0), ('usb video 1', 1), ('office stream 0', 'rtmp://101.42.139.3:31935/live/48b02d5bd01d?vhost=seg.300s')],\n",
    "                        width=300),\n",
    "                    nbeasy_widget_booltrigger(f'_cfg.is_online', 'Online', default=False, triggers=[\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_bool(f'cfg.use_file', 'Use File', default=True)\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_int(f'cfg.sample_size', 'Sample Size', 32, width=333)\n",
    "                            ]\n",
    "                        }\n",
    "                    ], width=200),\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'H',\n",
    "            'name': 'Display',\n",
    "            'objs': [\n",
    "                nbeasy_widget_multiselect(f'cfg.display_items', 'Select',  enums=[\n",
    "                    ('Camera Raw Frame', 'raw'),\n",
    "                    ('Compensate Distortion', 'undist')\n",
    "                ], width=300)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'type': 'V',\n",
    "                    'name': 'ChessBoard',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenumtrigger(\n",
    "                            '_cfg.chessboard_choice', 'Board Choise', default=1,\n",
    "                            enums = ['A4-15mm-11x8', 'A4-30mm-9x7', 'A3-25mm-16x11'],\n",
    "                            triggers = [\n",
    "                                nbeasy_chessboard_choice_objs(11, 8, 15),\n",
    "                                nbeasy_chessboard_choice_objs(9, 7, 30),\n",
    "                                nbeasy_chessboard_choice_objs(16, 11, 25),\n",
    "                            ],\n",
    "                            width=333),\n",
    "                        nbeasy_common_shared_by_tagtype('chessboard'),\n",
    "                    ],\n",
    "                }, # end chessboard\n",
    "                {\n",
    "                    'type': 'V',\n",
    "                    'name': 'CharucoBoard',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenumtrigger(\n",
    "                            '_cfg.charucoboard_choice', 'Board Choise', default=2,\n",
    "                            enums = ['A3-20mm-16mm-19x13-4x4', 'A4-30mm-23mm-9x6-4x4', 'A4-25mm-19mm-11x8-5x5', 'A4-15mm-12mm-11x8-5x5'],\n",
    "                            triggers = [\n",
    "                                nbeasy_charucoboard_choice_objs(19, 13, 20, 16, 0),\n",
    "                                nbeasy_charucoboard_choice_objs(9, 6, 30, 23, 0),\n",
    "                                nbeasy_charucoboard_choice_objs(11, 8, 25, 19, 1),\n",
    "                                nbeasy_charucoboard_choice_objs(11, 8, 15, 12, 1),\n",
    "                            ],\n",
    "                            width=333),\n",
    "                        nbeasy_common_shared_by_tagtype('charucoboard'),\n",
    "                    ],\n",
    "                }, # end charucoboard\n",
    "            ], # end tab objs\n",
    "        },\n",
    "        {\n",
    "            'type': 'V',\n",
    "            'objs': [\n",
    "                nbeasy_widget_image('__cfg.video_frame', 'Frame', '', width=640, height=480),\n",
    "                {\n",
    "                    'type': 'H',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenumtrigger(\n",
    "                            'cfg.det_object_type', 'Detect Object', default=0,\n",
    "                            enums=['aruco-6x6', 'grid-26mm-3mm-9x7-4x4', 'aruco-4x4-26mm', 'black_edge_carton', 'tagboard'],\n",
    "                            triggers = [\n",
    "                                {\n",
    "                                },\n",
    "                                {\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('cfg.__btn_reset_tags', 'Reset Tags', width=200, style='success'),\n",
    "                                                nbeasy_widget_button('cfg.__btn_save_tags', 'Save Tags', width=200, style='success'),\n",
    "                                            ]\n",
    "                                        }\n",
    "                                    ],\n",
    "                                },\n",
    "                                {\n",
    "                                },\n",
    "                                {\n",
    "                                },\n",
    "                                {\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('cfg.__btn_load_tags', 'Load Tags', width=200, style='success'),\n",
    "                                    ]\n",
    "                                }\n",
    "                            ],\n",
    "                            width=333),\n",
    "                        nbeasy_widget_float('cfg.cross_line_p', 'Line Position', default=0.99),\n",
    "                        nbeasy_widget_int('cfg.cross_line_w', 'Line Width', default=3),\n",
    "                        nbeasy_widget_stringenum(\n",
    "                            'cfg.sample_list', 'Sample List', default=0,\n",
    "                            enums=[('Camera', 0)],\n",
    "                            width=320)\n",
    "                    ],\n",
    "                    'justify_content': 'center'\n",
    "                }\n",
    "            ],\n",
    "            'align_items': 'center'\n",
    "        }, # end video\n",
    "    ], # end page objs\n",
    "    'evts': [\n",
    "        {\n",
    "            'type': 'jsdlink',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'source': 'cfg.__btn_chessboard_start_camera:disabled',\n",
    "                    'target': 'cfg.__btn_charucoboard_start_camera:disabled'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                *nbeasy_start_stop_camera('chessboard'),\n",
    "                *nbeasy_start_stop_camera('charucoboard'),\n",
    "                {\n",
    "                    'handler': reset_grid_aurco_tag,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_reset_tags'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': save_grid_aurco_tag,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_save_tags'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': load_grid_aurco_tag,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_load_tags'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "           \n",
    "        }\n",
    "    ], # end event\n",
    "}\n",
    "\n",
    "if g_ctx:\n",
    "    stop_camera_calibrate(g_ctx)\n",
    "g_ctx = nbeasy_schema_parse(schema, debug=True, border=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c0db5",
   "metadata": {},
   "source": [
    "## Binocular: Stereo Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ade0a",
   "metadata": {},
   "source": [
    "### Utils  Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52ec155f",
   "metadata": {
    "code_folding": [
     0,
     15,
     16,
     94
    ]
   },
   "outputs": [],
   "source": [
    "def _get_cameras():\n",
    "    prefix = '/sys/class/video4linux/'\n",
    "    cameras = []\n",
    "    for dev in os.listdir(prefix):\n",
    "        with open(f'{prefix}/{dev}/name', 'r') as f:\n",
    "            name = f.readline().strip().split(':')[0]\n",
    "            ty = 'monocular'\n",
    "            if '3D' in name:\n",
    "                ty = 'binocular'\n",
    "            cameras.append((name, (f'/dev/{dev}', ty)))\n",
    "    return cameras\n",
    "        \n",
    "    \n",
    "VIDEO_MAX_SIZE = 10000\n",
    "\n",
    "class StereoCamera(object):\n",
    "    def __init__(self, source, is_3d = False):\n",
    "        self.video_source = source\n",
    "        self.video_capture = None\n",
    "        self.is_running = False\n",
    "        self._is_3d = is_3d\n",
    "        # self.grabbed, self.frame = False, None\n",
    "        # self.read_lock, self.read_thread = threading.Lock(), None\n",
    "        \n",
    "    def is_3d(self):\n",
    "        return self._is_3d\n",
    "        \n",
    "    # def start(self):\n",
    "    #     if self.is_running:\n",
    "    #         return\n",
    "    #     self.grabbed, self.frame = self.video_capture.read()\n",
    "    #     if self.grabbed:\n",
    "    #         self.is_running = True\n",
    "    #         self.read_thread = threading.Thread(target=self._update_frame)\n",
    "    #         self.read_thread.start()\n",
    "    #         \n",
    "    # def stop(self):\n",
    "    #     if self.is_running:\n",
    "    #         self.is_running = False \n",
    "    #         if self.video_capture:\n",
    "    #             self.video_capture.release()\n",
    "    #         if self.read_thread:\n",
    "    #             self.read_thread.join()\n",
    "    #     self.video_capture, self.read_thread = None, None\n",
    "    #     \n",
    "    # def _update_frame(self):\n",
    "    #     try:\n",
    "    #         while self.is_running:\n",
    "    #             grabbed, frame = self.video_capture.read()\n",
    "    #             with self.read_lock:\n",
    "    #                 self.grabbed = grabbed\n",
    "    #                 self.frame = frame\n",
    "    #     finally:\n",
    "    #         self.stop()\n",
    "    #         \n",
    "    # def read(self):\n",
    "    #     with self.read_lock:\n",
    "    #         grabbed = self.grabbed\n",
    "    #         frame = self.frame.copy()\n",
    "    #     return grabbed, frame\n",
    "    # \n",
    "    # def read_left_right(self):\n",
    "    #     with self.read_lock:\n",
    "    #         frame = self.frame.copy()\n",
    "    #         grabbed = self.grabbed\n",
    "    #         frameL = frame[:, :int(self.width / 2), :]\n",
    "    #         frameR = frame[:, int(self.width / 2):, :]\n",
    "    #     return grabbed, frameL, frameL\n",
    "    \n",
    "    def open(self):\n",
    "        video_capture = cv2.VideoCapture(self.video_source)\n",
    "        if not video_capture.isOpened():\n",
    "            raise RuntimeError(f'Cannot open {self.video_source}')\n",
    "            \n",
    "        if self._is_3d:\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, VIDEO_MAX_SIZE) # 2560\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, VIDEO_MAX_SIZE) # 960\n",
    "            width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            if width != 2560:\n",
    "                video_capture.release()\n",
    "                raise RuntimeError(f'{self.video_source} is not stereo camera!')\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        else:\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "            \n",
    "        self.width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        self.video_capture = video_capture\n",
    "        self.is_running = True\n",
    "        return self.video_capture.read()[1].shape\n",
    "        \n",
    "    def close(self):\n",
    "        self.is_running = False\n",
    "        for _ in range(10):\n",
    "            if self.video_capture is None:\n",
    "                break\n",
    "            time.sleep(0.3)\n",
    "    \n",
    "    def read(self, flip=None):\n",
    "        try:\n",
    "            idx = 0\n",
    "            while self.is_running:\n",
    "                grabbed, frame = self.video_capture.read()\n",
    "                if not grabbed:\n",
    "                    raise RuntimeError('Video read error!')\n",
    "                idx += 1\n",
    "                \n",
    "                if flip > -2:\n",
    "                    frame = cv2.flip(frame, flip)\n",
    "                if self._is_3d:\n",
    "                    # 分离左右摄像头\n",
    "                    frameL = frame[:, :int(self.width / 2), :]\n",
    "                    frameR = frame[:, int(self.width / 2):, :]\n",
    "                    yield idx, [frameL, frameR]\n",
    "                else:\n",
    "                    yield idx, [frame]\n",
    "        finally:\n",
    "            self.video_capture.release()\n",
    "            self.video_capture = None\n",
    "            \n",
    "        raise StopIteration\n",
    "\n",
    "            \n",
    "def detect_chessboard(image, pattern_size, criteria, win_size, draw=False):\n",
    "    # 检测棋盘格\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    better_corners = None\n",
    "    found, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "    if found:\n",
    "        # 角点精检测 (亚像素)\n",
    "        better_corners = cv2.cornerSubPix(gray, corners, win_size, (-1, -1), criteria)\n",
    "        if draw:\n",
    "            cv2.drawChessboardCorners(image, pattern_size, better_corners, found)\n",
    "    return better_corners\n",
    "\n",
    "\n",
    "def calibrate_monocular_camera(ctx, imgfiles, world_point, pattern_size, criteria, win_size):        \n",
    "    image_size = None\n",
    "    world_points, pixel_points = [], []\n",
    "    for ifile in imgfiles:\n",
    "        image = cv2.imread(ifile)\n",
    "        if image_size is None:\n",
    "            image_size = image.shape[::-1][1:]\n",
    "        pixel_point = detect_chessboard(image, pattern_size, criteria, win_size)\n",
    "        if pixel_point is not None: \n",
    "            world_points.append(world_point)\n",
    "            pixel_points.append(pixel_point)\n",
    " \n",
    "    error, mtx, dist = start_calibrate_camera_with_good_flags(ctx,\n",
    "        functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points),\n",
    "        img_size=image_size)\n",
    "    \n",
    "    return image_size, error, mtx, dist\n",
    "\n",
    "\n",
    "def calibrate_binocular_camera(ctx, img_l_files, img_r_files, world_point, pattern_size, criteria, win_size):\n",
    "    image_size = None\n",
    "    world_points, pixel_points_L, pixel_points_R = [], [], []\n",
    "    for lfile, rfile in zip(img_l_files, img_r_files):\n",
    "        image_L = cv2.imread(lfile)\n",
    "        image_R = cv2.imread(rfile)\n",
    "        if image_size is None:\n",
    "            image_size = image_L.shape[::-1][1:]\n",
    "            ctx.logger(f'{lfile}, {rfile}, {image_size}')\n",
    "        pixel_point_L = detect_chessboard(image_L, pattern_size, criteria, win_size)\n",
    "        pixel_point_R = detect_chessboard(image_R, pattern_size, criteria, win_size)\n",
    "        if pixel_point_L is not None and pixel_point_R is not None: \n",
    "            world_points.append(world_point)\n",
    "            pixel_points_L.append(pixel_point_L)\n",
    "            pixel_points_R.append(pixel_point_R)\n",
    " \n",
    "    error_L, mtx_L, dist_L = start_calibrate_camera_with_good_flags(ctx,\n",
    "        functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points_L),\n",
    "        img_size=image_size)\n",
    "    \n",
    "    error_R, mtx_R, dist_R = start_calibrate_camera_with_good_flags(ctx,\n",
    "        functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points_R),\n",
    "        img_size=image_size)\n",
    "    \n",
    "    error, K1, D1, K2, D2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        world_points, pixel_points_L, pixel_points_R,\n",
    "        mtx_L, dist_L, mtx_R, dist_R, image_size,\n",
    "        R=None, # 第一和第二个摄像机之间的旋转矩阵\n",
    "        T=None, # 第一和第二个摄像机之间的平移矩阵\n",
    "        E=None, # essential matrix本质矩阵\n",
    "        F=None, # fundamental matrix基本矩阵\n",
    "        flags=None, criteria=None)\n",
    "        # flags=cv2.CALIB_FIX_INTRINSIC, criteria=criteria)\n",
    "    \n",
    "    # D1 = np.zeros((5, 1))\n",
    "    # D2 = np.zeros((5, 1))\n",
    "\n",
    "    return image_size, error, K1, D1, K2, D2, R, T, E, F\n",
    "\n",
    "\n",
    "def rectify_binocular_camera(ctx, K1, D1, K2, D2, image_size, R, T):\n",
    "    R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(\n",
    "        K1, D1, K2, D2, image_size, R, T,\n",
    "        R1=None, # 第一个摄像机的校正变换矩阵\n",
    "        R2=None, # 第二个摄像机的校正变换矩阵\n",
    "        P1=None, # 第一个摄像机在新坐标系下的投影矩阵\n",
    "        P2=None, # 第二个摄像机在新坐标系下的投影矩阵\n",
    "        Q=None,  # 4*4的视差图到深度图的映射矩阵\n",
    "        alpha=0, newImageSize=None)\n",
    "        # flags=cv2.CALIB_ZERO_DISPARITY, alpha=0.9, newImageSize=None)\n",
    "    \n",
    "    # 畸变校正和立体校正的映射矩阵, 计算像素空间坐标的重投影矩阵\n",
    "    l_map_x, l_map_y = cv2.initUndistortRectifyMap(K1, D1, R1, P1, image_size, cv2.CV_32FC1)\n",
    "    print(l_map_x)\n",
    "    r_map_x, r_map_y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, image_size, cv2.CV_32FC1)\n",
    "    return l_map_x, l_map_y, r_map_x, r_map_y, R1, R2, P1, P2, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb5cd5",
   "metadata": {},
   "source": [
    "### Callback Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdd3c247",
   "metadata": {
    "code_folding": [
     0,
     64,
     70,
     157,
     210,
     231,
     246,
     251,
     256,
     267,
     288,
     300,
     307,
     321,
     367,
     374,
     381,
     385
    ]
   },
   "outputs": [],
   "source": [
    "def on_start_collect_samples(ctx, w_btn, camera_source, sample_size, flip, rm_out, save_dir, w_video):\n",
    "    segs = os.path.basename(save_dir).split('_')\n",
    "    squares_x, squares_y, square_size, win_size, term_iters, term_eps = *list(map(int, segs[:-1])), float(segs[-1])\n",
    "    ctx.logger('on_start_collect_samples(%s, %d, %d, %d, %d, %d, %d, %f, %d)' % (\n",
    "        ':'.join(camera_source), sample_size, squares_x, squares_y, square_size, win_size, term_iters, term_eps,\n",
    "    flip), clear=1)\n",
    "    \n",
    "    pattern_size = (squares_x - 1, squares_y - 1)\n",
    "    win_size = (win_size, win_size)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "    \n",
    "    if rm_out:\n",
    "        shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            count = 0\n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                if idx % camera.fps == 0:\n",
    "                    if len(frames) == 2:\n",
    "                        frameL_copied, frameR_copied = frames[0].copy(), frames[1].copy()\n",
    "                        cornersL = detect_chessboard(frameL_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        cornersR = detect_chessboard(frameR_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        if cornersL is not None and cornersR is not None:\n",
    "                            count += 1\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"left_orig_{:0=3d}.png\".format(count)), frames[0])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"left_copy_{:0=3d}.png\".format(count)), frameL_copied)\n",
    "\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"right_orig_{:0=3d}.png\".format(count)), frames[1])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"right_copy_{:0=3d}.png\".format(count)), frameR_copied)\n",
    "\n",
    "                            cv2.putText(frameL_copied, f'Count: {count}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                            nbeasy_widget_display({'L': frameL_copied, 'R': frameR_copied}, w_video)\n",
    "\n",
    "                            if count == sample_size:\n",
    "                                break\n",
    "                    else:\n",
    "                        frame_copied = frames[0]\n",
    "                        corners = detect_chessboard(frame_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        if corners is not None:\n",
    "                            count += 1\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"orig_{:0=3d}.png\".format(count)), frames[0])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"chess_{:0=3d}.png\".format(count)), frame_copied)\n",
    "                            cv2.putText(frame_copied, f'Count: {count}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                            nbeasy_widget_display(frame_copied, w_video)\n",
    "\n",
    "                            if count == sample_size:\n",
    "                                break\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    camera = StereoCamera(camera_source[0], camera_source[1] == 'binocular')\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "\n",
    "\n",
    "def on_stop_collect_samples(ctx, w_btn = None):\n",
    "    ctx.logger(\"on_stop_collect_samples\")\n",
    "    if hasattr(ctx, 'stereo_camera'):\n",
    "        ctx.stereo_camera.close() \n",
    "\n",
    "        \n",
    "def on_start_calibrition_test(ctx, w_btn, camera_source, flip, save_dir, calibration_result, w_video):\n",
    "    ctx.logger('on_start_calibrition_test(%s, %s)' % (':'.join(camera_source), save_dir), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(calibration_result)\n",
    "\n",
    "            K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "            K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "            \n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_frames = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    display_frames['L'] = imgL\n",
    "                    display_frames['R'] = imgR\n",
    "                    display_frames['undist L'] = cv2.undistort(imgL.copy(), K1, D1)\n",
    "                    display_frames['undist R'] = cv2.undistort(imgR.copy(), K2, D2)\n",
    "                    nbeasy_widget_display(display_frames, w_video)\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    camera = StereoCamera(camera_source[0], is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "    \n",
    "    \n",
    "on_stop_test = on_stop_collect_samples\n",
    "\n",
    "\n",
    "def on_start_rectification_test(ctx, w_btn, camera_source, flip, save_dir, rectification_result, w_video):\n",
    "    ctx.logger('on_start_rectification_test(%s, %s)' % (':'.join(camera_source), save_dir), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(rectification_result)\n",
    "\n",
    "            K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "            K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "            \n",
    "            l_map, r_map = np.load(params['l_map_npz']), np.load(params['r_map_npz'])\n",
    "            l_map_x, l_map_y = l_map['l_map_x'], l_map['l_map_y']\n",
    "            r_map_x, r_map_y = r_map['r_map_x'], r_map['r_map_y']\n",
    "            \n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_frames = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    display_frames['undist L'] = cv2.undistort(imgL.copy(), K1, D1)\n",
    "                    display_frames['undist R'] = cv2.undistort(imgR.copy(), K2, D2)\n",
    "                    display_frames['rectified L'] = cv2.remap(imgL, l_map_x, l_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    display_frames['rectified R'] = cv2.remap(imgR, r_map_x, r_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    nbeasy_widget_display(display_frames, w_video)\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    camera = StereoCamera(camera_source[0], is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "    \n",
    "    \n",
    "def on_start_matcher(ctx, w_btn, camera_source, flip, save_dir, rectification_result, w_video):\n",
    "    ctx.logger('on_start_matcher(%s, %s)' % (':'.join(camera_source), save_dir), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(rectification_result)\n",
    "            l_map, r_map = np.load(params['l_map_npz']), np.load(params['r_map_npz'])\n",
    "            l_map_x, l_map_y = l_map['l_map_x'], l_map['l_map_y']\n",
    "            r_map_x, r_map_y = r_map['r_map_x'], r_map['r_map_y']\n",
    "            \n",
    "            Q = np.asarray(params['Q'])\n",
    "            \n",
    "            matcherL = cv2.StereoSGBM_create(\n",
    "                minDisparity=0,\n",
    "                numDisparities=128,\n",
    "                blockSize=3,\n",
    "                P1=8 * 1 * 3 ** 2,\n",
    "                P2=32 * 1 * 3 ** 2,\n",
    "                disp12MaxDiff=1,\n",
    "                preFilterCap=64,\n",
    "                uniquenessRatio=15,\n",
    "                speckleWindowSize=100,\n",
    "                speckleRange=1,\n",
    "                mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "            matcherR = cv2.ximgproc.createRightMatcher(matcherL)\n",
    "            \n",
    "            lmbda = 80000\n",
    "            sigma = 1.3\n",
    "            filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=matcherL)\n",
    "            filter.setLambda(lmbda)\n",
    "            filter.setSigmaColor(sigma)\n",
    "            \n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_images = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    rectifiedL = cv2.remap(imgL, l_map_x, l_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    rectifiedR = cv2.remap(imgR, r_map_x, r_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    display_images['rectifiedL'] = rectifiedL\n",
    "                    display_images['rectifiedR'] = rectifiedR\n",
    "                    H = max(rectifiedL.shape[0], rectifiedR.shape[0])\n",
    "                    W = rectifiedL.shape[1] + rectifiedR.shape[1]\n",
    "                    rectify_image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "                    rectify_image[0:rectifiedL.shape[0], 0:rectifiedL.shape[1]] = rectifiedL\n",
    "                    rectify_image[0:rectifiedR.shape[0],  rectifiedL.shape[1]:] = rectifiedR\n",
    "                    \n",
    "                    interval = 50\n",
    "                    # 绘制等间距平行线\n",
    "                    for k in range(H // interval):\n",
    "                        cv2.line(rectify_image, (0, interval * (k + 1)), (2 * W, interval * (k + 1)), COLORS.RED, 2, lineType=cv2.LINE_AA)\n",
    "                        \n",
    "                    grayL = cv2.cvtColor(rectifiedL, cv2.COLOR_BGR2GRAY)\n",
    "                    grayR = cv2.cvtColor(rectifiedR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    dispL = np.uint16(matcherL.compute(grayL, grayR))\n",
    "                    dispR = np.uint16(matcherR.compute(grayR, grayL))\n",
    "\n",
    "                    dispL = np.uint16(filter.filter(dispL, grayL, None, dispR))\n",
    "                    dispL[dispL < 0] = 0\n",
    "                    dispL = dispL.astype(np.float32) / 16.\n",
    "                    \n",
    "                    points_3d = cv2.reprojectImageTo3D(dispL, Q)\n",
    "                    points_3d = np.asarray(points_3d, dtype=np.float32)\n",
    "                    \n",
    "                    nbeasy_widget_display(rectify_image, w_video)\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    camera = StereoCamera(camera_source[0], is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "\n",
    "    \n",
    "on_stop_matcher = on_stop_collect_samples\n",
    "\n",
    "\n",
    "def on_previous_sample(ctx, w_btn, w_sample_list):\n",
    "    if w_sample_list.index > 0:\n",
    "        w_sample_list.index -= 1\n",
    "\n",
    "\n",
    "def on_next_sample(ctx, w_btn, w_sample_list):\n",
    "    if w_sample_list.index < len(w_sample_list.options):\n",
    "        w_sample_list.index += 1\n",
    "\n",
    "\n",
    "def on_remove_sample(ctx, w_btn, w_sample_list):\n",
    "    sample_path = w_sample_list.value\n",
    "    ctx.logger(f'on_remove_sample({sample_path})')\n",
    "    if os.path.exists(sample_path):\n",
    "        os.remove(sample_path)\n",
    "        if 'binocular' in sample_path:\n",
    "            os.remove(sample_path.replace('left', 'right'))\n",
    "    options = [(_key, _val) for _key, _val in w_sample_list.options if _val != sample_path]\n",
    "    w_sample_list.options = options\n",
    "\n",
    "\n",
    "def on_refresh_sample(ctx, w_btn, w_sample_list, save_dir):\n",
    "    ctx.logger(f'on_refresh_sample({save_dir})')\n",
    "    \n",
    "    options = []\n",
    "    if 'binocular' in save_dir:\n",
    "        left_sample_list = sorted(glob.glob(f'{save_dir}/left_chess_*.png'))\n",
    "        right_sample_list = sorted(glob.glob(f'{save_dir}/right_chess_*.png'))\n",
    "        ctx.logger(f'left samples count: {len(left_sample_list)}, right samples count: {len(right_sample_list)}')\n",
    "        assert len(left_sample_list) == len(right_sample_list)\n",
    "        for imgpath in left_sample_list:\n",
    "            imgfile = os.path.basename(imgpath)\n",
    "            options.append((imgfile[5:-4], imgpath))\n",
    "    else:\n",
    "        sample_list = sorted(glob.glob(f'{save_dir}/chess_*.png'))\n",
    "        for imgpath in sample_list:\n",
    "            imgfile = os.path.basename(imgpath)\n",
    "            options.append((imgfile[:-4], imgpath))\n",
    "    \n",
    "    w_sample_list.options = options\n",
    "\n",
    "\n",
    "def on_update_sample_dir(\n",
    "    ctx, w_save_dir, w_calibration_result, w_rectification_result,\n",
    "    camera_source, squares_x, squares_y, square_size, win_size, term_iters, term_eps):\n",
    "    save_dir = f'out/{camera_source[1]}/chessboard/{squares_x}_{squares_y}_{square_size}_{win_size}_{term_iters}_{term_eps}'\n",
    "    w_save_dir.value = save_dir\n",
    "    ctx.logger(f'on_update_sample_dir({save_dir})')\n",
    "    \n",
    "    on_load_calibration_result(ctx, None, w_calibration_result, save_dir)\n",
    "    if camera_source[1] == 'binocular':\n",
    "        on_load_rectification_result(ctx, None, w_rectification_result, save_dir)\n",
    "\n",
    "\n",
    "def on_update_sample_list(ctx, w_sample_list, save_dir):\n",
    "    ctx.logger(f'on_update_sample_list({save_dir})')\n",
    "    if not os.path.isdir(save_dir):\n",
    "        return\n",
    "    on_refresh_sample(ctx, None, w_sample_list, save_dir)\n",
    "\n",
    "\n",
    "def on_update_sample_image(ctx, w_video_frame, sample_path):\n",
    "    ctx.logger(f'on_update_sample_image({sample_path})')\n",
    "    if sample_path is None or not os.path.exists(sample_path):\n",
    "        ctx.logger(f'not found {sample_path}')\n",
    "        return\n",
    "    if 'binocular' in sample_path:\n",
    "        imgL = cv2.imread(sample_path)\n",
    "        imgR = cv2.imread(sample_path.replace('left', 'right'))\n",
    "        nbeasy_widget_display({'L': imgL, 'R': imgR}, w_video_frame)\n",
    "    else:\n",
    "        img = cv2.imread(sample_path)\n",
    "        nbeasy_widget_display(img, w_video_frame)\n",
    "\n",
    "\n",
    "def on_start_calibration(ctx, w_btn, w_sample_list, w_calibration_result):\n",
    "    try:\n",
    "        w_btn.disabled = True\n",
    "        w_calibration_result.value = ''\n",
    "        options = w_sample_list.options\n",
    "        ctx.logger(f'on_start_calibration({len(options)})')\n",
    "        if len(options) == 0:\n",
    "            return\n",
    "\n",
    "        save_dir = os.path.dirname(options[0][1])\n",
    "        segs = os.path.basename(save_dir).split('_')\n",
    "        squares_x, squares_y, square_size, win_size, term_iters, term_eps = *list(map(int, segs[:-1])), float(segs[-1])\n",
    "\n",
    "        pattern_size = (squares_x - 1, squares_y - 1)\n",
    "        world_point = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "        world_point[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "        world_point = world_point * square_size\n",
    "\n",
    "        win_size = (win_size, win_size)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "\n",
    "        image_files = [x[1].replace('copy', 'orig') for x in options]\n",
    "        if 'binocular' in save_dir:\n",
    "            image_L_files = image_files\n",
    "            image_R_files = [x.replace('left', 'right') for x in image_L_files]\n",
    "            image_size, error, K1, D1, K2, D2, R, T, E, F = calibrate_binocular_camera(\n",
    "                ctx, image_L_files, image_R_files, world_point, pattern_size, criteria, win_size)\n",
    "            result = {\n",
    "                'image_size': image_size,\n",
    "                'error': error,\n",
    "                'K1': K1, 'D1': D1,\n",
    "                'K2': K2, 'D2': D2,\n",
    "                'R': R, 'T': T, 'E': E, 'F': F\n",
    "            }\n",
    "        else:\n",
    "            image_size, error, mtx, dist = calibrate_monocular_camera(ctx, image_files, world_point, pattern_size, criteria, win_size)\n",
    "            result = {\n",
    "                'image_size': image_size,\n",
    "                'error': error,\n",
    "                'K': mtx, 'D': dist\n",
    "            }\n",
    "        w_calibration_result.value = json.dumps(result, indent=4)\n",
    "    finally:\n",
    "        w_btn.disabled = False\n",
    "        \n",
    "\n",
    "def on_save_calibration_result(ctx, w_btn, calibration_result, save_dir):\n",
    "    ctx.logger(f'on_save_calibration_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    with open(f'{save_dir}/{prefix}_calibration.json', 'w') as f:\n",
    "        f.write(calibration_result)\n",
    "        \n",
    "    \n",
    "def on_load_calibration_result(ctx, w_btn, w_calibration_result, save_dir):\n",
    "    ctx.logger(f'on_load_calibration_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    try:\n",
    "        file = f'{save_dir}/{prefix}_calibration.json'\n",
    "        with open(file, 'r') as f:\n",
    "            w_calibration_result.value = f.read()\n",
    "    except Exception:\n",
    "        w_calibration_result.value = f'Open {file} Error'\n",
    "        \n",
    "        \n",
    "def on_start_rectify(ctx, w_btn, calibration_result, w_rectify_result, save_dir):\n",
    "    ctx.logger('on_start_rectify')\n",
    "    try:\n",
    "        w_btn.disabled = True \n",
    "        w_rectify_result.value = ''\n",
    "        params = json.loads(calibration_result)\n",
    "        K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "        K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "        image_size, R, T = params['image_size'], np.asarray(params['R']), np.asarray(params['T'])\n",
    "        l_map_x, l_map_y, r_map_x, r_map_y, R1, R2, P1, P2, Q = rectify_binocular_camera(\n",
    "            ctx, K1, D1, K2, D2, image_size, R, T)\n",
    "        \n",
    "        np.savez(f'{save_dir}/l_map.npz', l_map_x=l_map_x, l_map_y=l_map_y)\n",
    "        np.savez(f'{save_dir}/r_map.npz', r_map_x=r_map_x, r_map_y=r_map_y)\n",
    "        \n",
    "        result = {\n",
    "            **params,\n",
    "            'l_map_npz': f'{save_dir}/l_map.npz',\n",
    "            'r_map_npz': f'{save_dir}/r_map.npz',\n",
    "            'R1': R1, 'R2': R2, 'P1': P1, 'P2': P2, 'Q': Q\n",
    "        }\n",
    "        w_rectify_result.value = json.dumps(result, indent=4)\n",
    "    except Exception:\n",
    "        ctx.logger(f'{traceback.format_exc(limit=6)}')\n",
    "    finally:\n",
    "        w_btn.disabled = False\n",
    "    \n",
    "\n",
    "def on_save_rectification_result(ctx, w_btn, rectification_result, save_dir):\n",
    "    ctx.logger(f'on_save_rectification_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    with open(f'{save_dir}/{prefix}_rectification.json', 'w') as f:\n",
    "        f.write(rectification_result)\n",
    "        \n",
    "    \n",
    "def on_load_rectification_result(ctx, w_btn, w_rectification_result, save_dir):\n",
    "    ctx.logger(f'on_load_rectification_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    try:\n",
    "        file = f'{save_dir}/{prefix}_rectification.json'\n",
    "        with open(file, 'r') as f:\n",
    "            w_rectification_result.value = f.read()\n",
    "    except Exception:\n",
    "        w_rectification_result.value = f'Open {file} Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947bd2e",
   "metadata": {},
   "source": [
    "### Template Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beadc288",
   "metadata": {
    "code_folding": [
     2,
     8,
     157,
     220,
     280,
     289,
     307,
     317,
     327,
     337,
     358
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50424a1374bd40aa82e7a520704ae789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HTML(value=\"<b><font color='black'>Che…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# _IMPORT('./easy_widget.py')\n",
    "\n",
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'name': 'Capture',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Chessboard',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_int('cfg.chessboard_squares_x', 'Squares X', 9),\n",
    "                                        nbeasy_widget_int('cfg.chessboard_squares_y', 'Squares Y', 7),\n",
    "                                        nbeasy_widget_int('cfg.chessboard_square_size', 'Square Size(mm)', 30)        \n",
    "                                    ],\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_int('cfg.chessboard_win_size', 'Win Size', default=5),\n",
    "                                        nbeasy_widget_int('cfg.chessboard_term_iters', 'Term Iters', default=500),\n",
    "                                        nbeasy_widget_float('cfg.chessboard_term_eps', 'Term EPS', default=0.0001),\n",
    "                                    ]\n",
    "                                },\n",
    "                            ]\n",
    "                        }, # end Chessboard\n",
    "                        { 'type': 'html', 'text': '<hr>'},\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Samples',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_stringenum('cfg.select_camera_source', 'Select Camera', enums=_get_cameras()),\n",
    "                                        nbeasy_widget_int('cfg.sample_size', 'Sample Size', 32),\n",
    "                                        nbeasy_widget_stringenum('cfg.select_flip', 'Flip Type', enums=[\n",
    "                                            ('None', -2),\n",
    "                                            ('Horizontal', 1),\n",
    "                                            ('Vertical', 0),\n",
    "                                            ('Both', -1)]),\n",
    "                                    ]\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_string('cfg.sample_save_dir', 'Save Dir', \"\", width=605, readonly=True),\n",
    "                                        nbeasy_widget_bool('cfg.rm_out', '<font color=\"red\">Clear Images</font>', False),\n",
    "                                    ]\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.btn_start_collect_samples', 'Start', style='success', icon='camera'),\n",
    "                                                nbeasy_widget_button('__cfg.btn_stop_collect_samples', 'Stop', style='success', icon='stop-circle'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        nbeasy_widget_image('__cfg.video_frame_capture', 'Frame', '', width=640, height=480),\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.btn_previous_sample', 'Previous', style='info', icon='arrow-left', width=100),\n",
    "                                                nbeasy_widget_button('__cfg.btn_next_sample', 'Next', style='info', icon='arrow-right', width=100),\n",
    "                                                nbeasy_widget_stringenum('cfg.sample_list', '', default=0, enums=['NONE'], width=200, description_width=0),\n",
    "                                                nbeasy_widget_button('__cfg.btn_del_sample', 'Remove', style='danger', icon='trash', width=100),\n",
    "                                                nbeasy_widget_button('__cfg.btn_refresh_sample', 'Refresh', style='info', icon='refresh', width=100),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        }\n",
    "                                    ],\n",
    "                                    'align_items': 'center'\n",
    "                                },\n",
    "                            ],\n",
    "                        }, # end Samples\n",
    "                    ]\n",
    "                }, # end tab Capture\n",
    "                {\n",
    "                    'name': 'Calibrate',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.start_calibration', 'Calibrate', style='success', icon='check'),\n",
    "                                                nbeasy_widget_button('__cfg.save_calibration_result', 'Save', style='success', icon='floppy-o'),\n",
    "                                                nbeasy_widget_button('__cfg.load_calibration_result', 'Load', style='success', icon='spinner'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        }, \n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_text('cfg.calibration_result', '', width=500, height=300)\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                    ],\n",
    "                                    'width': '50%'\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.start_rectification', 'Rectify', style='success', icon='check'),\n",
    "                                                nbeasy_widget_button('__cfg.save_rectification_result', 'Save', style='success', icon='floppy-o'),\n",
    "                                                nbeasy_widget_button('__cfg.load_rectification_result', 'Load', style='success', icon='spinner'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_text('cfg.rectification_result', '', width=520, height=300)\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                    ],\n",
    "                                    'width': '50%'\n",
    "                                },\n",
    "                            ],\n",
    "                        }, # end H\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('__cfg.btn_start_c_test',  'Test Calibration', style='success', icon='camera'),\n",
    "                                        nbeasy_widget_button('__cfg.btn_stop_test', 'Stop Test', style='success', icon='stop-circle'),\n",
    "                                        nbeasy_widget_button('__cfg.btn_start_r_test', 'Test Rectification', style='success', icon='camera'),\n",
    "                                    ],\n",
    "                                    'justify_content': 'center'\n",
    "                                },\n",
    "                                nbeasy_widget_image('__cfg.video_frame_test', 'Frame', '', width=640, height=480),\n",
    "                            ],\n",
    "                            'align_items': 'center'\n",
    "                        },\n",
    "                    ]\n",
    "                }, # end tab Calibration\n",
    "                {\n",
    "                    'name': 'Matcher',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.btn_start_matcher', 'Start', style='success', icon='camera'),\n",
    "                                                nbeasy_widget_button('__cfg.btn_stop_matcher', 'Stop', style='success', icon='stop-circle'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        nbeasy_widget_image('__cfg.video_frame_matcher', 'Frame', '', width=640, height=480),\n",
    "                                    ],\n",
    "                                    'align_items': 'center'\n",
    "                                },\n",
    "                            ],\n",
    "                        },\n",
    "                    ]\n",
    "                }, # end tab Matcher\n",
    "            ]\n",
    "        }, # end tab\n",
    "    ], # end pages\n",
    "    'evts': [\n",
    "        {\n",
    "            'type': 'jsdlink',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_matcher:disabled'\n",
    "                },\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_c_test:disabled'\n",
    "                },\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_r_test:disabled'\n",
    "                }\n",
    "            ]\n",
    "        }, # end jsdlink\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': on_start_collect_samples,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_collect_samples'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.sample_size:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.rm_out:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            '__cfg.video_frame_capture',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start collect samples\n",
    "                {\n",
    "                    'handler': on_stop_collect_samples,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_collect_samples'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop collect samplesn\n",
    "                {\n",
    "                    'handler': on_start_calibrition_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_c_test'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.calibration_result:value',\n",
    "                            '__cfg.video_frame_test',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start c test\n",
    "                {\n",
    "                    'handler': on_stop_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_test'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop c test\n",
    "                {\n",
    "                    'handler': on_start_rectification_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_r_test'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.rectification_result:value',\n",
    "                            '__cfg.video_frame_test',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start c test\n",
    "                {\n",
    "                    'handler': on_start_matcher,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_matcher'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.rectification_result:value',\n",
    "                            '__cfg.video_frame_matcher',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start matcher\n",
    "                {\n",
    "                    'handler': on_stop_matcher,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_matcher'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop matcher\n",
    "                {\n",
    "                    'handler': on_previous_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_previous_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event previous sample\n",
    "                {\n",
    "                    'handler': on_next_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_next_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end even next sample\n",
    "                {\n",
    "                    'handler': on_remove_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_del_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list' \n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event remove sample\n",
    "                {\n",
    "                    'handler': on_refresh_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_refresh_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ] \n",
    "                    }\n",
    "                }, # end event refresh sample\n",
    "                {\n",
    "                    'handler': on_start_calibration,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.start_calibration'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list',\n",
    "                            'cfg.calibration_result',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event calibrator\n",
    "                {\n",
    "                    'handler': on_save_calibration_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.save_calibration_result'],\n",
    "                        'targets': [\n",
    "                            'cfg.calibration_result:value',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on save calibration result\n",
    "                {\n",
    "                    'handler': on_load_calibration_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.load_calibration_result'],\n",
    "                        'targets': [\n",
    "                            'cfg.calibration_result',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on load calibration result\n",
    "                {\n",
    "                    'handler': on_start_rectify,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.start_rectification'],\n",
    "                        'targets': [\n",
    "                            'cfg.calibration_result:value',\n",
    "                            'cfg.rectification_result',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event rectify\n",
    "                {\n",
    "                    'handler': on_save_rectification_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.save_rectification_result'],\n",
    "                        'targets': [\n",
    "                            'cfg.rectification_result:value',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on save rectification result\n",
    "                {\n",
    "                    'handler': on_load_rectification_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.load_rectification_result'],\n",
    "                        'targets': [\n",
    "                            'cfg.rectification_result',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on load rectification result\n",
    "            ]\n",
    "        }, # end onclick events\n",
    "        {\n",
    "            'type': 'interactiveX',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': on_update_sample_dir,\n",
    "                    'params': {\n",
    "                        'w_save_dir': 'cfg.sample_save_dir',\n",
    "                        'w_calibration_result': 'cfg.calibration_result',\n",
    "                        'w_rectification_result': 'cfg.rectification_result',\n",
    "                        'camera_source': 'cfg.select_camera_source',\n",
    "                        'squares_x': 'cfg.chessboard_squares_x',\n",
    "                        'squares_y': 'cfg.chessboard_squares_y',\n",
    "                        'square_size': 'cfg.chessboard_square_size',\n",
    "                        'win_size': 'cfg.chessboard_win_size',\n",
    "                        'term_iters': 'cfg.chessboard_term_iters',\n",
    "                        'term_eps': 'cfg.chessboard_term_eps',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': on_update_sample_list,\n",
    "                    'params': {\n",
    "                        'w_sample_list': 'cfg.sample_list',\n",
    "                        'save_dir': 'cfg.sample_save_dir',\n",
    "                    }\n",
    "                }, \n",
    "                {\n",
    "                    'handler': on_update_sample_image,\n",
    "                    'params': {\n",
    "                        'w_video_frame': '__cfg.video_frame_capture',\n",
    "                        'sample_path': 'cfg.sample_list'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        } # end interactiveX\n",
    "    ] # end events\n",
    "}\n",
    "\n",
    "if g_ctx:\n",
    "    on_stop_collect_samples(g_ctx)\n",
    "g_ctx = nbeasy_schema_parse(schema, debug=True, border=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceff26c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b066a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## UnD-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc30ffe",
   "metadata": {
    "code_folding": [
     168
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def nbon_start_camera(ctx, sbtn,\n",
    "                      w_bgsub_method, w_bgsub_history, w_det_shadow, \n",
    "                      w_rmn_shadow_threshold, w_rmn_morpho_kernel, rmn_erode_iter, rmn_dilate_iter,\n",
    "                      w_cnt_area_threshold,\n",
    "                      w_cam_frame):\n",
    "    method = str.lower(w_bgsub_method.value)\n",
    "    history_length = w_bgsub_history.value\n",
    "    detect_shadows = w_det_shadow.value\n",
    "    \n",
    "    shadow_thresh = w_rmn_shadow_threshold.value\n",
    "    kernel = np.ones((w_rmn_morpho_kernel.value, w_rmn_morpho_kernel.value), np.uint8)\n",
    "    \n",
    "    erode_iter = rmn_erode_iter.value\n",
    "    dilate_iter = rmn_dilate_iter.value\n",
    "    \n",
    "    area_threshold = w_cnt_area_threshold.value\n",
    "    \n",
    "    ctx.logger(f'nbon_start_camera({method}, {history_length}, {detect_shadows}, {shadow_thresh}, {w_rmn_morpho_kernel.value})')\n",
    "    \n",
    "    import threading\n",
    "    \n",
    "    def _video_capture():\n",
    "        sbtn.disabled = True\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)\n",
    "        pixel_cm_ratio_1, pixel_cm_ratio_2 = -1, -1\n",
    "        marker_corner_1, marker_corner_2 = None, None\n",
    "        try:\n",
    "            bg_object = None\n",
    "            if method == 'knn':\n",
    "                bg_object = cv2.createBackgroundSubtractorKNN(history=history_length, detectShadows=detect_shadows)\n",
    "            elif method == 'mog2':\n",
    "                bg_object = cv2.createBackgroundSubtractorMOG2(history=history_length, detectShadows=detect_shadows)\n",
    "\n",
    "            camera = cv2.VideoCapture(0)\n",
    "            width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = ctx.camera.isOpened()\n",
    "            while ctx.camera_is_running:\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "                # Detect Aruco markers 5cm x 5cm\n",
    "                corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "                if corners is None or len(corners) == 0: \n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                    \n",
    "                frame_copy = frame_bgr.copy()\n",
    "                    \n",
    "                for (marker_corner, marker_ID) in zip(corners, ids):\n",
    "                    (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "                    rect = cv2.minAreaRect(marker_corner[0])\n",
    "                    if marker_ID == 1:\n",
    "                        pixel_cm_ratio_1 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target left\n",
    "                        marker_corner_1 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:1 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_1[0][0], marker_corner_1[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                    elif marker_ID == 2:\n",
    "                        pixel_cm_ratio_2 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target right\n",
    "                        marker_corner_2 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:2 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_2[0][0], marker_corner_2[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                        \n",
    "                if marker_corner_1 is None and marker_corner_2 is None:\n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                                                             \n",
    "                cv2.aruco.drawDetectedMarkers(frame_copy, corners, ids, borderColor=(255, 0, 0))\n",
    "\n",
    "                if bg_object:\n",
    "                    # Apply the background object on the frame to get the segmented mask.     \n",
    "                    fgmask = bg_object.apply(frame_bgr)\n",
    "\n",
    "                    # Perform thresholding to get rid of the shadows.\n",
    "                    _, fgmask = cv2.threshold(fgmask, shadow_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                    # Apply some morphological operations to make sure you have a good mask\n",
    "                    fgmask = cv2.erode(fgmask, kernel, iterations=erode_iter)\n",
    "                    fgmask = cv2.dilate(fgmask, kernel, iterations=dilate_iter)\n",
    "\n",
    "                    # Get foreground object\n",
    "                    foreground = cv2.bitwise_and(frame_bgr, frame_bgr, mask=fgmask)\n",
    "                    \n",
    "                    frame_mid = foreground\n",
    "                    frame_dst = fgmask\n",
    "                else:\n",
    "                    # Grayscale & Guassian blur\n",
    "                    frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY) \n",
    "                    frame_blur = cv2.GaussianBlur(frame_gray, (3, 3), 0)\n",
    "\n",
    "                    # # Divide gray by morphology image\n",
    "                    # frame_div = cv2.divide(frame_gray, frame_blur, scale=255)\n",
    "\n",
    "                    # Sharpen using unsharp masking\n",
    "                    # frame_sharp = filters.unsharp_mask(frame_div, radius=1.5, amount=1.5, channel_axis=None, preserve_range=False)\n",
    "                    # frame_sharp = (255 * frame_sharp).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "                    # Otsu Filter\n",
    "                    # _, frame_otsu = cv2.threshold(frame_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    _, frame_otsu = cv2.threshold(frame_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "                    # Detect edge by candy\n",
    "                    # frame_canny = cv2.Canny(frame_blur, 200, 250)\n",
    "                    \n",
    "                    frame_mid = cv2.cvtColor(frame_otsu, cv2.COLOR_GRAY2BGR)\n",
    "                    frame_dst = frame_otsu\n",
    "\n",
    "                contours, _ = cv2.findContours(frame_dst, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for cnt in contours:\n",
    "                    if cv2.contourArea(cnt) > area_threshold:\n",
    "                        x1, y1, width, height = cv2.boundingRect(cnt)\n",
    "                        x2, y2 = x1 + width, y1 + height\n",
    "                        \n",
    "                        cv2.rectangle(frame_copy, (x1, y1), (x2, y2),(0, 0, 255), 2)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    '{}x{}'.format(round(width, 2), round(height, 2)),\n",
    "                                    (x2, y2),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                        \n",
    "                        if marker_corner_1:\n",
    "                            if x1 < marker_corner_1[1][0] or x1 < marker_corner_1[2][0]:\n",
    "                                continue\n",
    "                        if marker_corner_2:\n",
    "                            if x2 > marker_corner_2[0][0] or x2 > marker_corner_2[3][0]:\n",
    "                                continue\n",
    "                        \n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (cx, cy), (cw, ch), angle = rect\n",
    "                        \n",
    "                        if marker_corner_1 and marker_corner_2:\n",
    "                            ow = round(0.5 * cw / pixel_cm_ratio_1 + 0.5 * cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(0.5 * ch / pixel_cm_ratio_1 + 0.5 * ch / pixel_cm_ratio_2, 2)\n",
    "                        elif marker_corner_1:\n",
    "                            ow = round(cw / pixel_cm_ratio_1, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_1, 2)\n",
    "                        else:\n",
    "                            ow = round(cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_2, 2)\n",
    "                        \n",
    "                        cv2.circle(frame_copy, (int(cx), int(cy)), 10, (255, 0, 0), -1)\n",
    "                        cv2.polylines(frame_copy, [np.int0(cv2.boxPoints(rect))], True, (255, 0, 0), 2)\n",
    "                        cv2.putText(frame_copy, \"{}x{}\".format(ow, oh), (int(cx - 100), int(cy - 20)), cv2.FONT_HERSHEY_PLAIN, 0.5, (100, 200, 0), 1)\n",
    "\n",
    "                stacked = np.hstack((frame_bgr, frame_mid, frame_copy))\n",
    "                w_cam_frame.value = io.BytesIO(cv2.imencode('.png', stacked)[1]).getvalue()\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}')\n",
    "        finally:\n",
    "            sbtn.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "    \n",
    "def nbon_stop_camera(ctx, sbtn):\n",
    "    ctx.logger('nbon_stop_camera()')\n",
    "    if ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c511f",
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'name': 'Configuration',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Background Subtraction',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_stringenum('cfg.bgsub_method', 'BG Sub Method', 1, enums=['None', 'MOG2', 'KNN'], width=300),\n",
    "                                nbeasy_widget_int('cfg.bgsub_history', 'History Length', '300', min_=100, max_=600),\n",
    "                                nbeasy_widget_bool('cfg.bgsub_det_shadow', 'Detect Shadows', True)\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Remove Noise',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_int('cfg.rmn_shadow_threshold', 'Shadow Threshold', 250, min_=1, max_=255),\n",
    "                                nbeasy_widget_stringenum('cfg.rmn_morpho_kernel', 'Morpho Kernel', 0, enums=[('3', 3), ('5', 5), ('7', 7), ('9', 9)], width=300),\n",
    "                                nbeasy_widget_int('cfg.rmn_erode_iter', 'Erode Iters', 1),\n",
    "                                nbeasy_widget_int('cfg.rmn_dilate_iter', 'Dilate Iters', 1),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Find Contours',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_float('cfg.cnt_area_threshold', 'Area Threshold', 2000),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Camera',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('cfg.btn_start_camera', 'Start', width=200, style='success'),\n",
    "                                        nbeasy_widget_button('cfg.btn_stop_camera', 'Stop', width=200, style='success')\n",
    "                                    ],\n",
    "                                    'justify_content': 'center'\n",
    "                                },\n",
    "                                nbeasy_widget_image('__cfg.camera_frame', 'Frame', '', height=480)\n",
    "                            ],\n",
    "                            'align_items': 'center'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': nbon_start_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.bgsub_method',\n",
    "                            'cfg.bgsub_history',\n",
    "                            'cfg.bgsub_det_shadow',\n",
    "                            'cfg.rmn_shadow_threshold',\n",
    "                            'cfg.rmn_morpho_kernel',\n",
    "                            'cfg.rmn_erode_iter',\n",
    "                            'cfg.rmn_dilate_iter',\n",
    "                            'cfg.cnt_area_threshold',\n",
    "                            '__cfg.camera_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': nbon_stop_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "if G:\n",
    "    if hasattr(easy, 'camera') and easy.camera:\n",
    "        easy.camera_is_running = False\n",
    "        time.sleep(1)\n",
    "        if easy.camera:\n",
    "            easy.camera.release()\n",
    "easy = nbeasy_schema_parse(schema, debug=True)\n",
    "G = easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193eb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "usb0.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c3e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca199c97",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## UnDef-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746986",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889a715",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0a7cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "display_handle = display(None, display_id=True)\n",
    "\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(width, height)\n",
    "    ret, prev_frame= cap.read()\n",
    "    while True:\n",
    "        _, frame_bgr = cap.read()\n",
    "        \n",
    "        # frame_diff = cv2.absdiff(frame_bgr, prev_frame)\n",
    "        # prev_frame = frame_bgr.copy()\n",
    "        # gray = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "        # blur = cv2.GaussianBlur(gray, (5, 5), 0)   \n",
    "        # thresh = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "        # dilate = cv2.dilate(thresh, None, iterations=5)\n",
    "        # contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        # cv2.drawContours(frame_bgr, contours, -1, (0, 0, 0), 3)\n",
    "\n",
    "        motion = 0\n",
    "        # for cnt in contours:\n",
    "        #     mask = np.zeros([height, width], dtype=np.uint8)\n",
    "        #     area = cv2.contourArea(cnt)\n",
    "        #     if area > 10000:\n",
    "        #         motion += 1\n",
    "        #         # rect = cv2.minAreaRect(cnt)\n",
    "        #         # (x, y), (w, h), angle = rect\n",
    "        #         # object_width = w / pixel_cm_ratio\n",
    "        #         # object_height = h / pixel_cm_ratio\n",
    "        #         x, y, w, h = cv2.boundingRect(cnt)\n",
    "        #         x1 = x if x < 5 else x - 5\n",
    "        #         y1 = y if y < 5 else y - 5\n",
    "        #         x2 = x + w if (x + w + 5) > width else x + w + 5\n",
    "        #         y2 = y + h if (y + h + 5) > height else y + h + 5\n",
    "        #         # cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
    "        #         mask[y1:y2, x1:x2] = 255\n",
    "        #         frame_mask = cv2.add(frame_bgr, np.zeros_like(frame_bgr, dtype=np.uint8), mask=mask)\n",
    "                  \n",
    "        if motion > -1:\n",
    "            corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "            # cv2.aruco.drawDetectedMarkers(frame_bgr, corners, ids)\n",
    "            if corners and len(corners) > 0: \n",
    "                aruco_perimeter = cv2.arcLength(corners[0], True)\n",
    "                pixel_cm_ratio = aruco_perimeter / 20\n",
    "                frame_gray = cv2.cvtColor(frame_bgr.copy(), cv2.COLOR_BGR2GRAY)\n",
    "                img_blur = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "                img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "                img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "                img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "                # frame_thresh = cv2.adaptiveThreshold(frame_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 19, 5)\n",
    "                contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "                for cnt in contours:\n",
    "                    area = cv2.contourArea(cnt)\n",
    "                    # if area > 5000 and area < 153600:\n",
    "                    if area > 1000 and area < 20000:\n",
    "                        # cv2.drawContours(frame_bgr, [cnt], 0, color=(0, 0, 0), thickness=4)\n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (x, y), (w, h), angle = rect\n",
    "                        object_width = w / pixel_cm_ratio\n",
    "                        object_height = h / pixel_cm_ratio\n",
    "                        box = cv2.boxPoints(rect)\n",
    "                        box = np.int0(box)\n",
    " \n",
    "                        cv2.circle(frame_bgr, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "                        cv2.polylines(frame_bgr, [box], True, (100, 10, 0), 2)\n",
    "                        # cv2.putText(frame_bgr, \"{} cm\".format(round(object_width, 2)), (int(x - 100), int(y - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "                        cv2.putText(frame_bgr, \"{} cm\".format(round(object_height, 2)), (int(x - 50), int(y + 15)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame_bgr)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cap.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c5d3c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f392edd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "- [旋转矩阵](https://slash-honeydew-c53.notion.site/a88e94293aeb4b54a729ceeb2f40a353)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b131a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "1. Part 1: Image formation and pinhole model of the camera - https://towardsdatascience.com/image-formation-and-pinhole-model-of-the-camera-53872ee4ee92\n",
    "2. Part 2: Camera Extrinsic Matrix in Python - https://towardsdatascience.com/camera-extrinsic-matrix-with-example-in-python-cfe80acab8dd\n",
    "3. Part 3: Camera Intrinsic Matrix in Python - https://towardsdatascience.com/camera-intrinsic-matrix-with-example-in-python-d79bf2478c12\n",
    "4. Part 4: Find the Minimum Stretching Direction of Positive Definite Matrices - https://towardsdatascience.com/find-the-minimum-stretching-direction-of-positive-definite-matrices-79c2a3b397fc\n",
    "5. Part 5: Camera Calibration in Python - https://towardsdatascience.com/camera-calibration-with-example-in-python-5147e945cdeb\n",
    "You can also find all the code in the GitHub repository - https://github.com/wingedrasengan927/Image-formation-and-camera-calibration\n",
    "\n",
    "\n",
    "https://programtalk.com/vs4/python/OteRobotics/realant/pose_estimation.py/\n",
    "\n",
    "https://its201.com/article/libo1004/110851205"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603ea73",
   "metadata": {},
   "source": [
    "https://string.quest/read/6034570"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "291.688px",
    "left": "1581px",
    "top": "130.125px",
    "width": "315px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
