{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89569e73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %watermark -p numpy,sklearn,pandas\n",
    "# %watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "# %watermark -p torch,torchvision,torchaudio\n",
    "# %watermark -p tensorflow,tensorboard,tflite\n",
    "# %watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "# from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "# from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import argparse, shlex, signal, traceback\n",
    "import numpy as np\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x, debug=False):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/' or x[1] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                x = 'https://' + x\n",
    "                x = requests.get(x)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                x = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = x.split('/')\n",
    "                for s in ['/main/', '/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    if debug:\n",
    "                        print(x)\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        if debug:\n",
    "            return x\n",
    "        else:\n",
    "            exec(x, globals())\n",
    "    except Exception as err:\n",
    "        # sys.stderr.write(f'request {x} : {err}')\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "    \n",
    "\n",
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT('import pandas as pd')\n",
    "_IMPORT('import cv2')\n",
    "_IMPORT('from PIL import Image')\n",
    "_IMPORT('import matplotlib.pyplot as plt')\n",
    "_IMPORT('import plotly')\n",
    "_IMPORT('import plotly.graph_objects as go')\n",
    "_IMPORT('import ipywidgets as widgets')\n",
    "_IMPORT('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n",
    "\n",
    "\n",
    "class COLORS(object):\n",
    "    # BGR\n",
    "    BLUE       = (255 , 0   , 0)\n",
    "    GREEN      = (0   , 255 , 0)\n",
    "    RED        = (0   , 0   , 255)\n",
    "    BLACK      = (0   , 0   , 0)\n",
    "    YELLOW     = (0   , 255 , 255)\n",
    "    WHITE      = (255 , 255 , 255)\n",
    "    CYAN       = (255 , 255 , 0)\n",
    "    MAGENTA    = (255 , 0   , 242)\n",
    "    GOLDEN     = (32  , 218 , 165)\n",
    "    LIGHT_BLUE = (255 , 9   , 2)\n",
    "    PURPLE     = (128 , 0   , 128)\n",
    "    CHOCOLATE  = (30  , 105 , 210)\n",
    "    PINK       = (147 , 20  , 255)\n",
    "    ORANGE     = (0   , 69  , 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d76a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import json, functools, datetime\n",
    "\n",
    "class __JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.datetime, datetime.timedelta)):\n",
    "            return '{}'.format(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps = functools.partial(json.dumps, cls=__JsonEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9c9826",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import skimage.filters as filters\n",
    "import threading\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "from enum import IntEnum\n",
    "# _IMPORT('gitee.com/qrsforever/nb_easy/easy_widget')\n",
    "_IMPORT('./easy_widget.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b017b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ctx = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef665d7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate Grid Aurco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1243849",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 7\n"
     ]
    }
   ],
   "source": [
    "# A4_width_mm, A4_height_mm, printer_dpi = 210, 297, 600\n",
    "printer_dpi = 600\n",
    "printer_dpmm = printer_dpi / 25.4\n",
    "marker_size_mm, gap_size_mm = 25, 3\n",
    "aurco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)\n",
    "\n",
    "landscape = True # portrait\n",
    "\n",
    "if landscape:\n",
    "    A4_width_mm, A4_height_mm, printer_dpi = 280, 210, 600\n",
    "else:\n",
    "    A4_width_mm, A4_height_mm, printer_dpi = 210, 280, 600\n",
    "    \n",
    "markersX = (A4_width_mm - gap_size_mm) // (marker_size_mm + gap_size_mm)\n",
    "markersY = (A4_height_mm - gap_size_mm) // (marker_size_mm + gap_size_mm)\n",
    "\n",
    "aruco_gridboard = cv2.aruco.GridBoard_create(markersX, markersY, marker_size_mm, gap_size_mm, aurco_dict)\n",
    "\n",
    "width = markersX * marker_size_mm  + (markersX - 1) * gap_size_mm\n",
    "height =  markersY * marker_size_mm + (markersY - 1) * gap_size_mm\n",
    "\n",
    "cv2.imwrite(\"aruco_gridboard.png\", aruco_gridboard.draw((int(printer_dpmm * width), int(printer_dpmm * height))))\n",
    "print(markersX, markersY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43151a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a52e82a7",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8e0aa5c",
   "metadata": {
    "code_folding": [
     0,
     6,
     17,
     23
    ]
   },
   "outputs": [],
   "source": [
    "class CalibrateState(IntEnum):\n",
    "    COLLECT = 1\n",
    "    READIMAGE = 2\n",
    "    CALIBRATE = 3\n",
    "    COMPLETED = 4\n",
    "\n",
    "def stop_camera_calibrate(ctx, w_btn_source=None):\n",
    "    ctx.logger('stop_camera_calibrate()')\n",
    "    if hasattr(ctx, 'camera') and ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()\n",
    "\n",
    "def save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir):\n",
    "    cv_file = cv2.FileStorage(f'{out_dir}/intrinsics.yaml', cv2.FILE_STORAGE_WRITE)\n",
    "    cv_file.write('camera_matrix', camera_matrix)\n",
    "    cv_file.write('dist_coeffs', dist_coeffs)\n",
    "    cv_file.release()\n",
    "\n",
    "def load_calibration_intrinsics(out_dir):\n",
    "    cv_file = cv2.FileStorage(f'{out_dir}/intrinsics.yaml', cv2.FILE_STORAGE_READ)\n",
    "    camera_matrix = cv_file.getNode('camera_matrix').mat()\n",
    "    dist_coeffs = cv_file.getNode('dist_coeffs').mat()\n",
    "    return camera_matrix, dist_coeffs\n",
    " \n",
    "def start_calibrate_camera_with_good_flags(ctx, calibrate, img_size):\n",
    "    flags = 0\n",
    "    K = np.array([[max(img_size), 0, img_size[1]/2],[0, max(img_size), img_size[0]/2], [0, 0, 1]])\n",
    "    D = np.zeros((5, 1))\n",
    "    \n",
    "    retval, mat, dist, rvecs, tvecs, \\\n",
    "    std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "\n",
    "    ctx.logger(json.dumps({\n",
    "        're-project-error': retval, \n",
    "        'mat': str(mat.round(3).tolist()),\n",
    "        'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    aspect_ratio = mat[0][0] / mat[1][1]\n",
    "    if 1.0 - min(aspect_ratio, 1.0/aspect_ratio) < 0.01:\n",
    "        flags += cv2.CALIB_FIX_ASPECT_RATIO\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    center_point_reldiff = max(abs(np.array(mat[0, 2], mat[1][2]) - np.array(img_size)/2) / np.array(img_size))\n",
    "    if center_point_reldiff < 0.05:\n",
    "        flags += cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'center_point_reldiff': center_point_reldiff,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    error_threshold = 1.25 * retval\n",
    "    camera_matrix = mat\n",
    "    dist_coeffs = dist\n",
    "\n",
    "    ignore_flags = {\n",
    "        'ignore_tangential_distortion': cv2.CALIB_ZERO_TANGENT_DIST,\n",
    "        'ignore_k3': cv2.CALIB_FIX_K3,\n",
    "        'ignore_k2': cv2.CALIB_FIX_K2,\n",
    "        'ignore_k1': cv2.CALIB_FIX_K1\n",
    "    }\n",
    "\n",
    "    for k, v in ignore_flags.items():\n",
    "        flags += v\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'ignore_type': k,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "        if retval > error_threshold:\n",
    "            break\n",
    "        camera_matrix = mat\n",
    "        dist_coeffs = dist\n",
    "    \n",
    "    return camera_matrix, dist_coeffs\n",
    "\n",
    "def is_rotation_matrix(R):\n",
    "    shouldBeIdentity = np.dot(np.transpose(R), R)\n",
    "    return np.linalg.norm(np.identity(3, dtype=R.dtype) - shouldBeIdentity) < 1e-6\n",
    "\n",
    "def rotation_matrix2euler_angles(R):\n",
    "    assert(is_rotation_matrix(R))\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def euler_angles2rotation_matrix(theta):\n",
    "    # Rotation on x-axis\n",
    "    r_pitch = np.array([\n",
    "        [1, 0,                  0],\n",
    "        [0, math.cos(theta[0]), -math.sin(theta[0])],\n",
    "        [0, math.sin(theta[0]), math.cos(theta[0])]\n",
    "    ])\n",
    "\n",
    "    # Rotation on y-axis\n",
    "    r_yaw = np.array([\n",
    "        [math.cos(theta[1]),  0, math.sin(theta[1])],\n",
    "        [0,                   1, 0],\n",
    "        [-math.sin(theta[1]), 0, math.cos(theta[1])]\n",
    "    ])\n",
    "\n",
    "    # Rotation on z-axis\n",
    "    r_roll = np.array([\n",
    "        [math.cos(theta[2]), -math.sin(theta[2]), 0],\n",
    "        [math.sin(theta[2]), math.cos(theta[2]),  0],\n",
    "        [0,                  0,                   1]\n",
    "    ])\n",
    "    return np.dot(r_roll, np.dot(r_yaw, r_pitch))\n",
    "\n",
    "def pixel_to_world(intrinsics_matrix, extrinsics_matrix, x, y):\n",
    "    pseudo_inv_extrinsics = np.linalg.pinv(extrinsics_matrix)\n",
    "    intrinsics_inv = np.linalg.inv(intrinsics_matrix)\n",
    "    pixels_matrix = np.array((x, y, 1))\n",
    "    ans = np.matmul(intrinsics_inv, pixels_matrix) # intrinsics_inv @ pixels_matrix\n",
    "    ans = np.matmul(pseudo_inv_extrinsics, ans)  # pseudo_inv_extrinsics @ ans\n",
    "    ans /= ans[-1] \n",
    "    return ans\n",
    "\n",
    "def measure_by_point(camera_matrix, extrinsics_matrix, point):\n",
    "    tl, tr, br, bl = point\n",
    "    p1 = pixel_to_world(camera_matrix, extrinsics_matrix, tl[0], tl[1])\n",
    "    p2 = pixel_to_world(camera_matrix, extrinsics_matrix, tr[0], tr[1])\n",
    "    p3 = pixel_to_world(camera_matrix, extrinsics_matrix, bl[0], bl[1])\n",
    "    W, H = p1 - p2, p1 - p3\n",
    "    width = np.sqrt(W[0]**2 + W[1]**2)\n",
    "    height = np.sqrt(H[0]**2 + H[1]**2)   \n",
    "    return width, height\n",
    "\n",
    "def single_aruco_estimate_pose(ctx, image, aruco_dict, camera_matrix, dist_coeffs):\n",
    "    # marker_length = 1.0 * 26\n",
    "    # aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)\n",
    "    marker_corners, marker_ids, _ = cv2.aruco.detectMarkers(image, aruco_dict)\n",
    "    if np.all(marker_ids is not None):\n",
    "        for (marker_corner, marker_id) in zip(marker_corners, marker_ids):\n",
    "            # corner: [[[306. 237.]\n",
    "            #          [440. 218.]\n",
    "            #          [477. 359.]\n",
    "            #          [344. 389.]]]\n",
    "            marker_length = 1.0 * (marker_id[0] - 60) # unit: mm\n",
    "            if marker_length < 0:\n",
    "                continue\n",
    "            rvecs, tvecs, marker_points = cv2.aruco.estimatePoseSingleMarkers(marker_corner, marker_length, camera_matrix, dist_coeffs)\n",
    "\n",
    "            # calculate the height/width (2D to 3D)\n",
    "            (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "\n",
    "            # X (red color), Y (green color), Z (blue color)\n",
    "            cv2.drawFrameAxes(image, camera_matrix, dist_coeffs, rvecs, tvecs, 10)  # Draw Axis\n",
    "\n",
    "            # rvecs: [[[ 0.18987504  2.79373027 -0.9026566 ]]]\n",
    "            # tvecs: [[[ 8.25180397  2.28427923 39.30899197]]]\n",
    "            # rotation_matrix: [[-0.97191346,  0.18216257,  0.14900011],\n",
    "            #                   [ 0.06054155,  0.80535491, -0.5896933 ],\n",
    "            #                   [-0.22741802, -0.56411016, -0.79376368]]\n",
    "            rotation_matrix, _ = cv2.Rodrigues(rvecs[0])\n",
    "            extrinsics_matrix = np.concatenate([rotation_matrix, tvecs[0].T], axis=1) \n",
    "            width, height = measure_by_point(camera_matrix, extrinsics_matrix, marker_corner[0])\n",
    "            distance = np.linalg.norm(tvecs[0])\n",
    "            # ctx.logger('width: {}, height: {}, distance: {}'.format(width, height, distance))\n",
    "            # angles = cv2.decomposeProjectionMatrix(extrinsics_matrix)[6].flatten()\n",
    "            angles = rotation_matrix2euler_angles(rotation_matrix)\n",
    "            roll, pitch, yaw = [math.degrees(angle) for angle in angles]\n",
    "            cv2.putText(image,\n",
    "                        'size {} x {} D:{}'.format(round(width, 1), round(height, 1), round(distance, 1)),\n",
    "                        (tl[0], tl[1] + 15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.BLUE, 1)\n",
    "            cv2.putText(image,\n",
    "                        'roll:{} pitch:{} yaw:{}'.format(round(roll, 1), round(pitch, 1), round(yaw, 1)),\n",
    "                        (bl[0], bl[1] - 15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.BLUE, 1)\n",
    "            \n",
    "            if ctx._aruco_tags_info:\n",
    "                grid_extrinsics_matrix = ctx._aruco_tags_info.get_grid_extrinsics()\n",
    "                gr_width, gr_height = measure_by_point(camera_matrix, grid_extrinsics_matrix, marker_corner[0])\n",
    "                p1 = pixel_to_world(camera_matrix, ctx._aruco_tags_info.get_nearest_extrinsics(tl[0], tl[1]), tl[0], tl[1])\n",
    "                p2 = pixel_to_world(camera_matrix, ctx._aruco_tags_info.get_nearest_extrinsics(tr[0], tr[1]), tr[0], tr[1])\n",
    "                p3 = pixel_to_world(camera_matrix, ctx._aruco_tags_info.get_nearest_extrinsics(bl[0], bl[1]), bl[0], bl[1])\n",
    "                W, H = p1 - p2, p1 - p3\n",
    "                width = round(np.sqrt(W[0]**2 + W[1]**2), 1)\n",
    "                height = round(np.sqrt(H[0]**2 + H[1]**2), 1)\n",
    "                cv2.putText(image,\n",
    "                            'size {} x {} vs {} x {}'.format(round(gr_width, 1), round(gr_height, 1), width, height),\n",
    "                            (tl[0], tl[1] - 15),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.BLUE, 1)\n",
    "            break # test only one\n",
    "        cv2.aruco.drawDetectedMarkers(image, marker_corners, marker_ids, borderColor=COLORS.CHOCOLATE)\n",
    "    return image\n",
    "\n",
    "def girdaruco_estimate_poses(ctx, image, board, aruco_dict, camera_matrix, dist_coeffs):\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    marker_corners, marker_ids, rejected_points = cv2.aruco.detectMarkers(img_gray, aruco_dict)\n",
    "    # Refine detected markers\n",
    "    # Eliminates markers not part of our board, adds missing markers to the board\n",
    "    marker_corners, marker_ids, rejectedImgPoints, recoveredIds = cv2.aruco.refineDetectedMarkers(\n",
    "            image = img_gray,\n",
    "            board = board,\n",
    "            detectedCorners = marker_corners,\n",
    "            detectedIds = marker_ids,\n",
    "            rejectedCorners = rejected_points,\n",
    "            cameraMatrix = camera_matrix,\n",
    "            distCoeffs = dist_coeffs)\n",
    "    image = cv2.aruco.drawDetectedMarkers(image, marker_corners, borderColor=COLORS.CHOCOLATE)\n",
    "    if marker_ids is None or len(marker_ids) < 20:\n",
    "        raise\n",
    "    # Estimate the posture of the gridboard, which is a construction of 3D space\n",
    "    pose, rvec, tvec = cv2.aruco.estimatePoseBoard(marker_corners, marker_ids, board, camera_matrix, dist_coeffs, None, None)\n",
    "    if pose:\n",
    "        # Draw the camera posture calculated from the gridboard\n",
    "        image = cv2.drawFrameAxes(image, camera_matrix, dist_coeffs, rvec, tvec, 20)\n",
    "    return image, marker_corners, marker_ids, rvec, tvec\n",
    "\n",
    "class ArucoTagsInfo(object):\n",
    "            \n",
    "    def __init__(self, grid_extrinsics_matrix, cx_map, cy_map, gap):\n",
    "        self._grid_extrinsics_matrix = grid_extrinsics_matrix\n",
    "        self._gap = gap\n",
    "        self._cx_map_ordered = collections.OrderedDict(sorted(cx_map.items(), key=lambda kv: kv[0]))\n",
    "        self._cy_map_ordered = collections.OrderedDict(sorted(cy_map.items(), key=lambda kv: kv[0]))\n",
    "        self._cx_keys_list = list(self._cx_map_ordered.keys())\n",
    "        self._cy_keys_list = list(self._cy_map_ordered.keys())\n",
    "        \n",
    "    def get_grid_extrinsics(self):\n",
    "        return self._grid_extrinsics_matrix \n",
    "    \n",
    "    def get_nearest_extrinsics(self, x, y):\n",
    "        x_min, x_max = x - self._gap, x + self._gap\n",
    "        y_min, y_max = y - self._gap, y + self._gap\n",
    "        setx, sety = set(), set()\n",
    "        for i, key in enumerate(self._cx_keys_list):\n",
    "            if key > x_min and key < x_max:\n",
    "                setx.add(self._cx_map_ordered[key])\n",
    "        for i, key in enumerate(self._cy_keys_list):\n",
    "            if key > y_min and key < y_max:\n",
    "                sety.add(self._cy_map_ordered[key])\n",
    "        balls = list(setx.intersection(sety))\n",
    "        if len(balls) == 0:\n",
    "            return self._grid_extrinsics_matrix\n",
    "        if len(balls) == 1:\n",
    "            return balls[0]._e\n",
    "        k, b = 2 * self._gap, balls[0]\n",
    "        for ball in balls[1:]:\n",
    "            d = abs(ball._x - x) + abs(ball._y - y)\n",
    "            if d < k:\n",
    "                k, b = d, ball\n",
    "        return b._e\n",
    "                 \n",
    "def detect_object_and_measure(ctx, image, dettype, camera_matrix, dist_coeffs):\n",
    "    result = {}\n",
    "    if dettype == 'aruco-6x6': # Detect 6x6 ArUco Marker\n",
    "        dict_id = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_1000)\n",
    "        result['aruco'] = single_aruco_estimate_pose(ctx, image, dict_id, camera_matrix, dist_coeffs)\n",
    "    elif dettype == 'grid-26mm-3mm-9x7-4x4':\n",
    "        markersX, markersY, marker_size_mm, gap_size_mm = 9, 7, 26, 3\n",
    "        axis_length = int(0.5 * marker_size_mm)\n",
    "        dict_id = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)\n",
    "        board = cv2.aruco.GridBoard_create(\n",
    "            markersX=markersX,\n",
    "            markersY=markersY,\n",
    "            markerLength=marker_size_mm,\n",
    "            markerSeparation=gap_size_mm,\n",
    "            dictionary=dict_id)\n",
    "        try:\n",
    "            class _Ball(object):\n",
    "                def __init__(self, x, y, e):\n",
    "                    self._x = x\n",
    "                    self._y = y\n",
    "                    self._e = e\n",
    "            img_gird_pose, marker_corners, marker_ids, rvec, tvec = girdaruco_estimate_poses(ctx, image.copy(), board, dict_id, camera_matrix, dist_coeffs)\n",
    "            result['grid_pose'] = img_gird_pose\n",
    "            if len(marker_corners) == markersX * markersY:\n",
    "                grid_extrinsics_matrix = np.concatenate([cv2.Rodrigues(rvec)[0], tvec], axis=1) \n",
    "                rvecs, tvecs, marker_points = cv2.aruco.estimatePoseSingleMarkers(marker_corners, marker_size_mm, camera_matrix, dist_coeffs)\n",
    "                xs_map, ys_map, length = {}, {}, -1\n",
    "                for mc, mid, rvec, tvec in zip(marker_corners, marker_ids, rvecs, tvecs):\n",
    "                    extrinsics_matrix = np.concatenate([cv2.Rodrigues(rvec)[0], tvec.T], axis=1) \n",
    "                    if length < 0:\n",
    "                        length = max(abs(mc[0][0][0] - mc[0][2][0]), abs(mc[0][0][1] - mc[0][2][1]))\n",
    "                    center = np.mean(mc[0], axis=0, dtype=np.int32).tolist()\n",
    "                    ball = _Ball(center[0], center[1], extrinsics_matrix)\n",
    "                    xs_map[center[0]], ys_map[center[1]] = ball, ball\n",
    "                    width, _ = measure_by_point(camera_matrix, extrinsics_matrix, mc[0])\n",
    "                    cv2.putText(image, f'{mid} {round(width, 1)}', (center[0] - 5, center[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.3, COLORS.BLUE, 1)                \n",
    "                    cv2.drawFrameAxes(image, camera_matrix, dist_coeffs, rvec, tvec, axis_length)\n",
    "                ctx._aruco_tags_info = ArucoTagsInfo(grid_extrinsics_matrix, xs_map, ys_map, length)\n",
    "            result['markers'] = image\n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        \n",
    "    elif dettype == 'black_edge_carton':\n",
    "        if ctx._aruco_tags_info is None:\n",
    "            cv2.putText(image, 'no extrinsics matrix', (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.LIGHT_BLUE, 1)\n",
    "        \n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "        img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "        img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "        img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "        contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # cv2.drawContours(image, contours, -1, color=(0, 0, 255), thickness=4)\n",
    "        # for cnt in contours:\n",
    "        #     area = cv2.contourArea(cnt)\n",
    "        #     if area > 1000 and area < 20000:\n",
    "        #         rect = cv2.minAreaRect(cnt)\n",
    "        #         (x, y), (w, h), angle = rect\n",
    "        #         box = cv2.boxPoints(rect)\n",
    "        #         box = np.int0(box)\n",
    "        #         cv2.circle(image, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "        #         cv2.polylines(image, [box], True, (100, 10, 0), 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bbd10",
   "metadata": {},
   "source": [
    "### Calibration By ChessBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b642cdad",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def start_calibrate_by_chessboard(\n",
    "    ctx, w_btn_source, squares_x, squares_y, square_size, win_size, term_iters, term_eps,\n",
    "    sample_size, use_file, w_det_objtype, w_sample_list, w_cam_frame):\n",
    "    \n",
    "    ctx.logger(f'start: {squares_x}, {squares_y}, {square_size}mm, {sample_size}', clear=1)\n",
    "    \n",
    "    # Object points for a chessboard\n",
    "    pattern_size = (squares_x - 1, squares_y - 1)\n",
    "    objp = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "    objp = objp * square_size\n",
    "        \n",
    "    win_size, zero_zone = (win_size, win_size), (-1, -1)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "\n",
    "    def _video_capture():\n",
    "        w_btn_source.disabled = True\n",
    "        out_dir = f'out/chessboard/{squares_x}x{squares_y}_{square_size}'\n",
    "        try:\n",
    "            obj_points, img_points = [], []\n",
    "            samples = []\n",
    "            options = [('Camera', 0)]\n",
    "            if sample_size is None: \n",
    "                image_list = glob.glob(f'{out_dir}/*.png')\n",
    "                display_images = {}\n",
    "                for path in image_list:\n",
    "                    name = os.path.basename(path)\n",
    "                    img = cv2.imread(path)\n",
    "                    # img = cv2.flip(img, 1)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    found, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "                    better_chess_corners = cv2.cornerSubPix(gray, corners, win_size, zero_zone, criteria)\n",
    "                    obj_points.append(objp)\n",
    "                    img_points.append(better_chess_corners)\n",
    "                    display_images['orig_corners'] = cv2.drawChessboardCorners(img.copy(), pattern_size, corners, found)\n",
    "                    display_images['best_corners'] = cv2.drawChessboardCorners(img.copy(), pattern_size, better_chess_corners, found)\n",
    "                    options.append((name, int(name.split('.')[0])))\n",
    "                    samples.append(nbeasy_widget_display(display_images))\n",
    "                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                state = CalibrateState.CALIBRATE\n",
    "            else:\n",
    "                shutil.rmtree(out_dir, ignore_errors=True)\n",
    "                state = CalibrateState.COLLECT\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "                \n",
    "            camera = cv2.VideoCapture(0)\n",
    "            frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            frame_irate = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "            \n",
    "            ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = camera.isOpened()\n",
    "\n",
    "            ctx._aruco_tags_info = None\n",
    "            camera_matrix, dist_coeffs = None, None\n",
    "\n",
    "            frame_idx, iter_idx = 0, 0\n",
    "            while ctx.camera_is_running:\n",
    "                if w_sample_list.value != 0:\n",
    "                    w_cam_frame.value = samples[w_sample_list.value - 1]\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # frame_bgr = cv2.flip(frame_bgr, 1)\n",
    "                display_frames = {'raw': frame_bgr}\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if state == CalibrateState.COLLECT:\n",
    "                    found, corners = cv2.findChessboardCorners(frame_gray, pattern_size)\n",
    "                    if found:\n",
    "                        # Find better sub pix position for the corners in the roof corners neighbourhood\n",
    "                        better_chess_corners = cv2.cornerSubPix(frame_gray, corners, win_size, zero_zone, criteria)\n",
    "                        display_frames['orig_corners'] = cv2.drawChessboardCorners(frame_bgr.copy(), pattern_size, corners, found)\n",
    "                        display_frames['best_corners'] = cv2.drawChessboardCorners(frame_bgr.copy(), pattern_size, better_chess_corners, found)\n",
    "\n",
    "                        if frame_idx % frame_irate == 0:\n",
    "                            obj_points.append(objp)\n",
    "                            img_points.append(better_chess_corners)\n",
    "                            iter_idx += 1\n",
    "                            \n",
    "                            box = cv2.boxPoints(cv2.minAreaRect(better_chess_corners.reshape(-1, 2)))\n",
    "                            cv2.drawContours(display_frames['best_corners'], [np.int0(box)], 0, COLORS.ORANGE, 2)\n",
    "                            \n",
    "                            # Draw and display the corners\n",
    "                            options.append((str(iter_idx) + '.png', iter_idx))\n",
    "                            samples.append(io.BytesIO(cv2.imencode('.png', display_frames['best_corners'])[1]).getvalue())\n",
    "                            if iter_idx == sample_size:\n",
    "                                state = CalibrateState.CALIBRATE\n",
    "                                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                            cv2.imwrite(f'{out_dir}/{iter_idx}.png', frame_bgr)\n",
    "                    cv2.putText(display_frames['best_corners'], f'Count: {iter_idx}', (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, COLORS.LIGHT_BLUE, 2)\n",
    "                elif state == CalibrateState.CALIBRATE and not use_file:\n",
    "                    camera_matrix, dist_coeffs = start_calibrate_camera_with_good_flags(\n",
    "                        ctx, functools.partial(\n",
    "                            cv2.calibrateCameraExtended, objectPoints=obj_points, imagePoints=img_points),\n",
    "                        img_size=frame_gray.shape[::-1],\n",
    "                    )\n",
    "\n",
    "                    save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir)\n",
    "                    \n",
    "                    # obj_points, img_points = obj_points[-1], img_points[-1]\n",
    "                    # # Calculating extrinsics by last imgage (rotation vector)\n",
    "                    # retval, rvec, tvec = cv2.solvePnP(obj_points, img_points, camera_matrix, dist_coeffs)                    \n",
    "                    # # rvec, tvec = np.mean(np.array(rvecs), axis=0), np.mean(np.array(tvecs), axis=0)\n",
    "                    # # transform rotation vector to ratation matrix\n",
    "                    # rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "                    # extrinsics_matrix = np.concatenate([rotation_matrix, tvec], 1) \n",
    "                    \n",
    "                    # calculate the re-project points error.  == reval\n",
    "                    # mean_error = 0\n",
    "                    # for obj_point, img_point, rvec, tvec in zip(obj_points, img_points, rvecs, tvecs):\n",
    "                    #     img_point_proj, _ = cv2.projectPoints(obj_point, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "                    #     error = cv2.norm(img_point, img_point_proj, cv2.NORM_L2) / len(img_point_proj)\n",
    "                    #     mean_error += error\n",
    "                    # ctx.logger('total error: {}'.format(mean_error / len(obj_points)))\n",
    "             \n",
    "                    state = CalibrateState.COMPLETED\n",
    "                else: \n",
    "                    # load from file\n",
    "                    if camera_matrix is None and use_file:\n",
    "                        camera_matrix, dist_coeffs = load_calibration_intrinsics(out_dir)\n",
    "                        \n",
    "                    display_frames['undist'] = cv2.undistort(frame_bgr.copy(), camera_matrix, dist_coeffs)\n",
    "                    result = detect_object_and_measure(ctx, frame_bgr.copy(), w_det_objtype.value, camera_matrix, dist_coeffs)\n",
    "                    for title, image in result.items():\n",
    "                        display_frames[title] = image\n",
    "\n",
    "                # display image\n",
    "                nbeasy_widget_display(display_frames, w_cam_frame)\n",
    "                frame_idx += 1\n",
    "\n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        finally:\n",
    "            w_btn_source.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "\n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "stop_calibrate_by_chessboard = stop_camera_calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbd7df2",
   "metadata": {
    "code_folding": [
     0,
     13,
     92,
     118
    ]
   },
   "outputs": [],
   "source": [
    "def start_calibrate_by_charucoboard(\n",
    "    ctx, w_btn_source, squares_x, squares_y, square_size, marker_size, win_size, term_iters, term_eps,\n",
    "    aruco_id, sample_size, use_file, w_det_objtype, w_sample_list, w_cam_frame):\n",
    "    \n",
    "    ctx.logger(f'start: {squares_x}, {squares_y}, {square_size}mm, {marker_size}mm, {aruco_id}, {sample_size}', clear=1)\n",
    "    \n",
    "    charuco_dict = cv2.aruco.getPredefinedDictionary(aruco_id)\n",
    "    charuco_board = cv2.aruco.CharucoBoard_create(squares_x, squares_y, 0.001 * square_size, 0.001 * marker_size, charuco_dict)\n",
    "    \n",
    "    pattern_size = (squares_x, squares_y)\n",
    "    win_size, zero_zone = (win_size, win_size), (-1, -1)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, term_iters, term_eps)\n",
    "        \n",
    "    def _detect_charuco_corners(frame_gray, charuco_board, charuco_dict, win_size, zero_zone, criteria):\n",
    "        # corner detection\n",
    "        marker_corners, marker_ids, rejected_points = cv2.aruco.detectMarkers(frame_gray, charuco_dict)\n",
    "        if marker_corners is not None and len(marker_corners) > 0:\n",
    "            # corner refine \n",
    "            # marker_corners, marker_ids, refusd, recoverd = cv2.aruco.refineDetectedMarkers(\n",
    "            #     frame_gray, charuco_board, marker_corners, marker_ids, rejectedCorners=rejected_points) \n",
    "            # corner interpolation (get charuco corners and ids from detected aruco markers)\n",
    "            retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(marker_corners, marker_ids, frame_gray, charuco_board)\n",
    "            charuco_corners is not None and len(charuco_corners) > 5\n",
    "            if charuco_corners is not None and len(charuco_corners) > 5:\n",
    "                if win_size:\n",
    "                    better_charuco_corners = cv2.cornerSubPix(frame_gray, charuco_corners, win_size, zero_zone, criteria)\n",
    "                else:\n",
    "                    better_charuco_corners  = charuco_corners\n",
    "                return retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids \n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    def _video_capture():\n",
    "        w_btn_source.disabled = True\n",
    "        result = {}\n",
    "        obj_points, img_points = [], []\n",
    "        all_charuco_corners, all_charuco_ids = [], []\n",
    "        out_dir = f'out/chessaruco/{squares_x}x{squares_y}_{square_size}_{marker_size}'\n",
    "            \n",
    "        try:\n",
    "            samples = []\n",
    "            options = [('Camera', 0)]\n",
    "            if sample_size is None: \n",
    "                image_list = glob.glob(f'{out_dir}/*.png')\n",
    "                for path in image_list:\n",
    "                    name = os.path.basename(path)\n",
    "                    img = cv2.imread(path)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids = _detect_charuco_corners(\n",
    "                            gray, charuco_board, charuco_dict, win_size, zero_zone, criteria)\n",
    "                    if retval:\n",
    "                        all_charuco_corners.append(better_charuco_corners)\n",
    "                        all_charuco_ids.append(charuco_ids)\n",
    "                        cv2.aruco.drawDetectedCornersCharuco(img, better_charuco_corners, charuco_ids)\n",
    "                        options.append((name, int(name.split('.')[0])))\n",
    "                        samples.append(io.BytesIO(cv2.imencode('.png', img)[1]).getvalue())\n",
    "                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                state = CalibrateState.CALIBRATE\n",
    "            else:\n",
    "                shutil.rmtree(out_dir, ignore_errors=True)\n",
    "                state = CalibrateState.COLLECT\n",
    "                \n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "                \n",
    "            camera = cv2.VideoCapture(0)\n",
    "            frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            frame_irate = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "            \n",
    "            ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = camera.isOpened()\n",
    "            \n",
    "            ctx._aruco_tags_info = None\n",
    "            camera_matrix, dist_coeffs = None, None,\n",
    "            \n",
    "            frame_idx, iter_idx = 0, 0\n",
    "            \n",
    "            while ctx.camera_is_running:\n",
    "                if w_sample_list.value != 0:\n",
    "                    if w_cam_frame.layout.width != frame_width:\n",
    "                        w_cam_frame.layout.width = f'{frame_width}px'\n",
    "                        w_cam_frame.layout.height = f'{frame_height}px'\n",
    "                    w_cam_frame.value = samples[w_sample_list.value]\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # frame_bgr = cv2.flip(frame_bgr, 1)\n",
    "                display_frames = {'raw': frame_bgr}\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if state == CalibrateState.COLLECT:\n",
    "                    retval, marker_corners, marker_ids, charuco_corners, better_charuco_corners, charuco_ids = _detect_charuco_corners(\n",
    "                        frame_gray, charuco_board, charuco_dict, win_size, zero_zone, criteria)\n",
    "                    \n",
    "                    if retval:\n",
    "                        display_frames['markers'] = cv2.aruco.drawDetectedMarkers(frame_bgr.copy(), marker_corners, marker_ids)                        \n",
    "                        display_frames['orig_corners'] = cv2.aruco.drawDetectedCornersCharuco(frame_bgr.copy(), charuco_corners, charuco_ids)\n",
    "                        display_frames['best_corners'] = cv2.aruco.drawDetectedCornersCharuco(frame_bgr.copy(), better_charuco_corners, charuco_ids)\n",
    "\n",
    "                        if frame_idx % frame_irate == 0:\n",
    "                            # Draw and Display markers and corners\n",
    "                            # objp = charuco_board.chessboardCorners[all_charuco_ids.flatten()]\n",
    "                            all_charuco_corners.append(better_charuco_corners)\n",
    "                            all_charuco_ids.append(charuco_ids)\n",
    "                            iter_idx += 1\n",
    "\n",
    "                            box = cv2.boxPoints(cv2.minAreaRect(better_charuco_corners.reshape(-1, 2)))\n",
    "                            cv2.drawContours(display_frames['best_corners'], [np.int0(box)], 0, COLORS.ORANGE, 2)\n",
    "\n",
    "                            options.append((str(iter_idx) + '.png', iter_idx))\n",
    "                            samples.append(io.BytesIO(cv2.imencode('.png', display_frames['best_corners'])[1]).getvalue())\n",
    "                            if iter_idx == sample_size:\n",
    "                                state = CalibrateState.CALIBRATE\n",
    "                                w_sample_list.options = sorted(options, key=lambda item: item[1])\n",
    "                            cv2.imwrite(f'{out_dir}/{iter_idx}.png', frame_bgr)\n",
    "                        cv2.putText(display_frames['best_corners'], f'Count: {iter_idx}', (200, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.2, COLORS.GOLDEN, 2)\n",
    "                elif state == CalibrateState.CALIBRATE and not use_file:\n",
    "                    camera_matrix, dist_coeffs = start_calibrate_camera_with_good_flags(\n",
    "                        ctx, functools.partial(\n",
    "                            cv2.aruco.calibrateCameraCharucoExtended,\n",
    "                            charucoCorners=all_charuco_corners, charucoIds=all_charuco_ids,\n",
    "                            board=charuco_board),\n",
    "                        img_size=frame_gray.shape[::-1]\n",
    "                    )\n",
    "                        \n",
    "                    save_calibration_intrinsics(camera_matrix, dist_coeffs, out_dir)\n",
    "                    \n",
    "                    # total_error = 0.0\n",
    "                    # for k, (charuco_corners, c_ids, rvec, tvec) in enumerate(zip(all_charuco_corners, all_charuco_ids, rvecs, tvecs)):\n",
    "                    #     obj_points, img_points = cv2.aruco.getBoardObjectAndImagePoints(charuco_board, charuco_corners, c_ids)\n",
    "                    #     prj_points, _ = cv2.projectPoints(obj_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "                    #     error = cv2.norm(img_points, prj_points, cv2.NORM_L2) / len(obj_points)\n",
    "                    #     total_error += error\n",
    "                    # ctx.logger(f'mean total error: {total_error / len(all_charuco_corners)}')\n",
    "                    state = CalibrateState.COMPLETED\n",
    "                else: \n",
    "                    # load from file\n",
    "                    if camera_matrix is None and use_file:\n",
    "                        camera_matrix, dist_coeffs = load_calibration_intrinsics(out_dir)\n",
    "                                                \n",
    "                    display_frames['undist'] = cv2.undistort(frame_bgr.copy(), camera_matrix, dist_coeffs)\n",
    "                    result = detect_object_and_measure(ctx, frame_bgr.copy(), w_det_objtype.value, camera_matrix, dist_coeffs)\n",
    "                    for title, image in result.items():\n",
    "                        display_frames[title] = image\n",
    "                    \n",
    "                # display image\n",
    "                nbeasy_widget_display(display_frames, w_cam_frame)\n",
    "                frame_idx += 1\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        finally:\n",
    "            w_btn_source.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "stop_calibrate_by_charucoboard = stop_camera_calibrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e52d1",
   "metadata": {},
   "source": [
    "### Template Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75985614",
   "metadata": {
    "code_folding": [
     0,
     29,
     39,
     60,
     102,
     165,
     197,
     226
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c725e34ea54e04acb295d8a4cf9ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(VBox(children=(Dropdown(description='B"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nbeasy_widget_display(images, img_wid=None):\n",
    "    C = len(images)\n",
    "    show_ncol, show_nrow = 1, 1\n",
    "    if C > 1:\n",
    "        show_ncol = 2\n",
    "        for i in range(C % show_ncol):\n",
    "            images[f'placehold-{i}'] = images[list(images.keys())[-1]].copy() # 255 * np.ones_like(images[list(images.keys())[0]])\n",
    "        show_nrow = len(images) // show_ncol\n",
    "        row_images = []\n",
    "        col_images = []\n",
    "        for key, img in images.items():\n",
    "            cv2.putText(img, key, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.LIGHT_BLUE, 1)\n",
    "            col_images.append(img)\n",
    "            if len(col_images) == show_ncol:\n",
    "                row_images.append(np.hstack(col_images))\n",
    "                col_images = []\n",
    "                \n",
    "        display_image = np.vstack(row_images)\n",
    "    else:\n",
    "        display_image = images.popitem()[1]\n",
    "    \n",
    "    imgbytes = io.BytesIO(cv2.imencode('.png', display_image)[1]).getvalue()\n",
    "    if img_wid:\n",
    "        img_wid.layout.width = f'{int(img_wid.width) * show_ncol}px'\n",
    "        img_wid.layout.height = f'{int(img_wid.height) * show_nrow}px'\n",
    "        img_wid.value = imgbytes\n",
    "    else:\n",
    "        return imgbytes\n",
    "    \n",
    "def nbeasy_chessboard_choice_objs(nrow, ncol, square_size, width=300, ro=True):\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': [\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_x', 'Squares X', nrow, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_y', 'Squares Y', ncol, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_square_size', 'Square Size(mm)', square_size, width=width, readonly=ro)        \n",
    "        ]\n",
    "    }\n",
    "\n",
    "def nbeasy_charucoboard_choice_objs(nrow, ncol, square_size, marker_size, aruco_dict_id, width=300, ro=True):\n",
    "    enums = [\n",
    "        ('4x4', cv2.aruco.DICT_4X4_1000),\n",
    "        ('5x5', cv2.aruco.DICT_5X5_1000),\n",
    "    ]\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': [\n",
    "            nbeasy_widget_int('cfg.charucoboard_squares_x', 'Squares X', nrow, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.charucoboard_squares_y', 'Squares Y', ncol, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.charucoboard_square_size', 'Square Size(mm)', square_size, width=width, readonly=ro),\n",
    "            nbeasy_widget_float('cfg.charucoboard_marker_size', 'Marker Size CM', marker_size, width=width, readonly=ro),\n",
    "            nbeasy_widget_stringenum(\n",
    "                'cfg.charucoboard_aruco_dict', 'ArUco Dict', default=aruco_dict_id,\n",
    "                enums=enums,\n",
    "                width=width,\n",
    "                readonly=ro\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def nbeasy_common_shared_by_tagtype(tag):\n",
    "    return {\n",
    "        'type': 'V',\n",
    "        'objs': [\n",
    "            {\n",
    "                'type': 'H',\n",
    "                'objs': [\n",
    "                    nbeasy_widget_int(f'cfg.{tag}_win_size', 'Win Size', default=5),\n",
    "                    nbeasy_widget_int(f'cfg.{tag}_term_iters', 'Term Iters', default=500),\n",
    "                    nbeasy_widget_float(f'cfg.{tag}_term_eps', 'Term EPS', default=0.0001),\n",
    "                ]\n",
    "            },\n",
    "            nbeasy_widget_booltrigger(f'_cfg.{tag}_is_online', 'Online', default=False, triggers=[\n",
    "                {\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_bool(f'cfg.{tag}_use_file', 'Use File', default=True)\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_int(f'cfg.{tag}_sample_size', 'Sample Size', 32, width=333)\n",
    "                    ]\n",
    "                }\n",
    "            ], width=200),\n",
    "            {\n",
    "                'type': 'V',\n",
    "                'name': 'Camera',\n",
    "                'objs': [\n",
    "                    {\n",
    "                        'type': 'H',\n",
    "                        'objs': [\n",
    "                            nbeasy_widget_button(f'cfg.__btn_{tag}_start_camera', 'Start', width=200, style='success'),\n",
    "                            nbeasy_widget_button(f'cfg.__btn_{tag}_stop_camera', 'Stop', width=200, style='success'),\n",
    "                        ],\n",
    "                        'justify_content': 'center'\n",
    "                    },\n",
    "                ],\n",
    "                'align_items': 'center'\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "\n",
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'type': 'V',\n",
    "                    'name': 'ChessBoard',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenumtrigger(\n",
    "                            '_cfg.chessboard_choice', 'Board Choise', default=1,\n",
    "                            enums = ['A4-15mm-11x8', 'A4-30mm-9x7', 'A3-25mm-16x11'],\n",
    "                            triggers = [\n",
    "                                nbeasy_chessboard_choice_objs(11, 8, 15),\n",
    "                                nbeasy_chessboard_choice_objs(9, 7, 30),\n",
    "                                nbeasy_chessboard_choice_objs(16, 11, 25),\n",
    "                            ],\n",
    "                            width=333),\n",
    "                        nbeasy_common_shared_by_tagtype('chessboard'),\n",
    "                    ],\n",
    "                }, # end chessboard\n",
    "                {\n",
    "                    'type': 'V',\n",
    "                    'name': 'CharucoBoard',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenumtrigger(\n",
    "                            '_cfg.charucoboard_choice', 'Board Choise', default=1,\n",
    "                            enums = ['A3-20mm-16mm-19x13-4x4', 'A4-30mm-23mm-9x6-4x4', 'A4-25mm-19mm-11x8-5x5', 'A4-15mm-12mm-11x8-5x5'],\n",
    "                            triggers = [\n",
    "                                nbeasy_charucoboard_choice_objs(19, 13, 20, 16, 0),\n",
    "                                nbeasy_charucoboard_choice_objs(9, 6, 30, 23, 0),\n",
    "                                nbeasy_charucoboard_choice_objs(11, 8, 25, 19, 1),\n",
    "                                nbeasy_charucoboard_choice_objs(11, 8, 15, 12, 1),\n",
    "                            ],\n",
    "                            width=333),\n",
    "                        nbeasy_common_shared_by_tagtype('charucoboard'),\n",
    "                    ],\n",
    "                }, # end charucoboard\n",
    "            ], # end tab objs\n",
    "        },\n",
    "        {\n",
    "            'type': 'V',\n",
    "            'objs': [\n",
    "                nbeasy_widget_image('__cfg.video_frame', 'Frame', '', width=640, height=480),\n",
    "                {\n",
    "                    'type': 'H',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_stringenum(\n",
    "                            'cfg.det_object_type', 'Detect Object', default=0,\n",
    "                            enums=['aruco-6x6', 'grid-26mm-3mm-9x7-4x4', 'black_edge_carton'],\n",
    "                            width=300),\n",
    "                        nbeasy_widget_stringenum(\n",
    "                            'cfg.sample_list', 'Sample List', default=0,\n",
    "                            enums=[('Camera', 0)],\n",
    "                            width=300)\n",
    "                    ],\n",
    "                    'justify_content': 'center'\n",
    "                }\n",
    "            ],\n",
    "            'align_items': 'center'\n",
    "        }, # end video\n",
    "    ], # end page objs\n",
    "    'evts': [\n",
    "        {\n",
    "            'type': 'jsdlink',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'source': 'cfg.__btn_chessboard_start_camera:disabled',\n",
    "                    'target': 'cfg.__btn_charucoboard_start_camera:disabled'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': start_calibrate_by_chessboard,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_chessboard_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.chessboard_squares_x:value',\n",
    "                            'cfg.chessboard_squares_y:value',\n",
    "                            'cfg.chessboard_square_size:value',\n",
    "                            'cfg.chessboard_win_size:value',\n",
    "                            'cfg.chessboard_term_iters:value',\n",
    "                            'cfg.chessboard_term_eps:value',\n",
    "                            'cfg.chessboard_sample_size:value',\n",
    "                            'cfg.chessboard_use_file:value',\n",
    "                            'cfg.det_object_type',\n",
    "                            'cfg.sample_list',\n",
    "                            '__cfg.video_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': stop_calibrate_by_chessboard,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_chessboard_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': start_calibrate_by_charucoboard,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_charucoboard_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.charucoboard_squares_x:value',\n",
    "                            'cfg.charucoboard_squares_y:value',\n",
    "                            'cfg.charucoboard_square_size:value',\n",
    "                            'cfg.charucoboard_marker_size:value',\n",
    "                            'cfg.charucoboard_win_size:value',\n",
    "                            'cfg.charucoboard_term_iters:value',\n",
    "                            'cfg.charucoboard_term_eps:value',\n",
    "                            'cfg.charucoboard_aruco_dict:value',\n",
    "                            'cfg.charucoboard_sample_size:value',\n",
    "                            'cfg.charucoboard_use_file:value',\n",
    "                            'cfg.det_object_type',\n",
    "                            'cfg.sample_list',\n",
    "                            '__cfg.video_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': stop_calibrate_by_charucoboard,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_charucoboard_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ], # end event\n",
    "}\n",
    "\n",
    "if g_ctx:\n",
    "    stop_camera_calibrate(g_ctx)\n",
    "g_ctx = nbeasy_schema_parse(schema, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa423c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b066a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## UnD-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc30ffe",
   "metadata": {
    "code_folding": [
     168
    ],
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def nbon_start_camera(ctx, sbtn,\n",
    "                      w_bgsub_method, w_bgsub_history, w_det_shadow, \n",
    "                      w_rmn_shadow_threshold, w_rmn_morpho_kernel, rmn_erode_iter, rmn_dilate_iter,\n",
    "                      w_cnt_area_threshold,\n",
    "                      w_cam_frame):\n",
    "    method = str.lower(w_bgsub_method.value)\n",
    "    history_length = w_bgsub_history.value\n",
    "    detect_shadows = w_det_shadow.value\n",
    "    \n",
    "    shadow_thresh = w_rmn_shadow_threshold.value\n",
    "    kernel = np.ones((w_rmn_morpho_kernel.value, w_rmn_morpho_kernel.value), np.uint8)\n",
    "    \n",
    "    erode_iter = rmn_erode_iter.value\n",
    "    dilate_iter = rmn_dilate_iter.value\n",
    "    \n",
    "    area_threshold = w_cnt_area_threshold.value\n",
    "    \n",
    "    ctx.logger(f'nbon_start_camera({method}, {history_length}, {detect_shadows}, {shadow_thresh}, {w_rmn_morpho_kernel.value})')\n",
    "    \n",
    "    import threading\n",
    "    \n",
    "    def _video_capture():\n",
    "        sbtn.disabled = True\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)\n",
    "        pixel_cm_ratio_1, pixel_cm_ratio_2 = -1, -1\n",
    "        marker_corner_1, marker_corner_2 = None, None\n",
    "        try:\n",
    "            bg_object = None\n",
    "            if method == 'knn':\n",
    "                bg_object = cv2.createBackgroundSubtractorKNN(history=history_length, detectShadows=detect_shadows)\n",
    "            elif method == 'mog2':\n",
    "                bg_object = cv2.createBackgroundSubtractorMOG2(history=history_length, detectShadows=detect_shadows)\n",
    "\n",
    "            camera = cv2.VideoCapture(0)\n",
    "            width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = ctx.camera.isOpened()\n",
    "            while ctx.camera_is_running:\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "                # Detect Aruco markers 5cm x 5cm\n",
    "                corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "                if corners is None or len(corners) == 0: \n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                    \n",
    "                frame_copy = frame_bgr.copy()\n",
    "                    \n",
    "                for (marker_corner, marker_ID) in zip(corners, ids):\n",
    "                    (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "                    rect = cv2.minAreaRect(marker_corner[0])\n",
    "                    if marker_ID == 1:\n",
    "                        pixel_cm_ratio_1 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target left\n",
    "                        marker_corner_1 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:1 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_1[0][0], marker_corner_1[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                    elif marker_ID == 2:\n",
    "                        pixel_cm_ratio_2 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target right\n",
    "                        marker_corner_2 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:2 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_2[0][0], marker_corner_2[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                        \n",
    "                if marker_corner_1 is None and marker_corner_2 is None:\n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                                                             \n",
    "                cv2.aruco.drawDetectedMarkers(frame_copy, corners, ids, borderColor=(255, 0, 0))\n",
    "\n",
    "                if bg_object:\n",
    "                    # Apply the background object on the frame to get the segmented mask.     \n",
    "                    fgmask = bg_object.apply(frame_bgr)\n",
    "\n",
    "                    # Perform thresholding to get rid of the shadows.\n",
    "                    _, fgmask = cv2.threshold(fgmask, shadow_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                    # Apply some morphological operations to make sure you have a good mask\n",
    "                    fgmask = cv2.erode(fgmask, kernel, iterations=erode_iter)\n",
    "                    fgmask = cv2.dilate(fgmask, kernel, iterations=dilate_iter)\n",
    "\n",
    "                    # Get foreground object\n",
    "                    foreground = cv2.bitwise_and(frame_bgr, frame_bgr, mask=fgmask)\n",
    "                    \n",
    "                    frame_mid = foreground\n",
    "                    frame_dst = fgmask\n",
    "                else:\n",
    "                    # Grayscale & Guassian blur\n",
    "                    frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY) \n",
    "                    frame_blur = cv2.GaussianBlur(frame_gray, (3, 3), 0)\n",
    "\n",
    "                    # # Divide gray by morphology image\n",
    "                    # frame_div = cv2.divide(frame_gray, frame_blur, scale=255)\n",
    "\n",
    "                    # Sharpen using unsharp masking\n",
    "                    # frame_sharp = filters.unsharp_mask(frame_div, radius=1.5, amount=1.5, channel_axis=None, preserve_range=False)\n",
    "                    # frame_sharp = (255 * frame_sharp).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "                    # Otsu Filter\n",
    "                    # _, frame_otsu = cv2.threshold(frame_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    _, frame_otsu = cv2.threshold(frame_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "                    # Detect edge by candy\n",
    "                    # frame_canny = cv2.Canny(frame_blur, 200, 250)\n",
    "                    \n",
    "                    frame_mid = cv2.cvtColor(frame_otsu, cv2.COLOR_GRAY2BGR)\n",
    "                    frame_dst = frame_otsu\n",
    "\n",
    "                contours, _ = cv2.findContours(frame_dst, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for cnt in contours:\n",
    "                    if cv2.contourArea(cnt) > area_threshold:\n",
    "                        x1, y1, width, height = cv2.boundingRect(cnt)\n",
    "                        x2, y2 = x1 + width, y1 + height\n",
    "                        \n",
    "                        cv2.rectangle(frame_copy, (x1, y1), (x2, y2),(0, 0, 255), 2)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    '{}x{}'.format(round(width, 2), round(height, 2)),\n",
    "                                    (x2, y2),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                        \n",
    "                        if marker_corner_1:\n",
    "                            if x1 < marker_corner_1[1][0] or x1 < marker_corner_1[2][0]:\n",
    "                                continue\n",
    "                        if marker_corner_2:\n",
    "                            if x2 > marker_corner_2[0][0] or x2 > marker_corner_2[3][0]:\n",
    "                                continue\n",
    "                        \n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (cx, cy), (cw, ch), angle = rect\n",
    "                        \n",
    "                        if marker_corner_1 and marker_corner_2:\n",
    "                            ow = round(0.5 * cw / pixel_cm_ratio_1 + 0.5 * cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(0.5 * ch / pixel_cm_ratio_1 + 0.5 * ch / pixel_cm_ratio_2, 2)\n",
    "                        elif marker_corner_1:\n",
    "                            ow = round(cw / pixel_cm_ratio_1, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_1, 2)\n",
    "                        else:\n",
    "                            ow = round(cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_2, 2)\n",
    "                        \n",
    "                        cv2.circle(frame_copy, (int(cx), int(cy)), 10, (255, 0, 0), -1)\n",
    "                        cv2.polylines(frame_copy, [np.int0(cv2.boxPoints(rect))], True, (255, 0, 0), 2)\n",
    "                        cv2.putText(frame_copy, \"{}x{}\".format(ow, oh), (int(cx - 100), int(cy - 20)), cv2.FONT_HERSHEY_PLAIN, 0.5, (100, 200, 0), 1)\n",
    "\n",
    "                stacked = np.hstack((frame_bgr, frame_mid, frame_copy))\n",
    "                w_cam_frame.value = io.BytesIO(cv2.imencode('.png', stacked)[1]).getvalue()\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}')\n",
    "        finally:\n",
    "            sbtn.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "    \n",
    "def nbon_stop_camera(ctx, sbtn):\n",
    "    ctx.logger('nbon_stop_camera()')\n",
    "    if ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c511f",
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'name': 'Configuration',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Background Subtraction',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_stringenum('cfg.bgsub_method', 'BG Sub Method', 1, enums=['None', 'MOG2', 'KNN'], width=300),\n",
    "                                nbeasy_widget_int('cfg.bgsub_history', 'History Length', '300', min_=100, max_=600),\n",
    "                                nbeasy_widget_bool('cfg.bgsub_det_shadow', 'Detect Shadows', True)\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Remove Noise',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_int('cfg.rmn_shadow_threshold', 'Shadow Threshold', 250, min_=1, max_=255),\n",
    "                                nbeasy_widget_stringenum('cfg.rmn_morpho_kernel', 'Morpho Kernel', 0, enums=[('3', 3), ('5', 5), ('7', 7), ('9', 9)], width=300),\n",
    "                                nbeasy_widget_int('cfg.rmn_erode_iter', 'Erode Iters', 1),\n",
    "                                nbeasy_widget_int('cfg.rmn_dilate_iter', 'Dilate Iters', 1),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Find Contours',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_float('cfg.cnt_area_threshold', 'Area Threshold', 2000),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Camera',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('cfg.btn_start_camera', 'Start', width=200, style='success'),\n",
    "                                        nbeasy_widget_button('cfg.btn_stop_camera', 'Stop', width=200, style='success')\n",
    "                                    ],\n",
    "                                    'justify_content': 'center'\n",
    "                                },\n",
    "                                nbeasy_widget_image('__cfg.camera_frame', 'Frame', '', height=480)\n",
    "                            ],\n",
    "                            'align_items': 'center'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': nbon_start_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.bgsub_method',\n",
    "                            'cfg.bgsub_history',\n",
    "                            'cfg.bgsub_det_shadow',\n",
    "                            'cfg.rmn_shadow_threshold',\n",
    "                            'cfg.rmn_morpho_kernel',\n",
    "                            'cfg.rmn_erode_iter',\n",
    "                            'cfg.rmn_dilate_iter',\n",
    "                            'cfg.cnt_area_threshold',\n",
    "                            '__cfg.camera_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': nbon_stop_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "if G:\n",
    "    if hasattr(easy, 'camera') and easy.camera:\n",
    "        easy.camera_is_running = False\n",
    "        time.sleep(1)\n",
    "        if easy.camera:\n",
    "            easy.camera.release()\n",
    "easy = nbeasy_schema_parse(schema, debug=True)\n",
    "G = easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae611e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca199c97",
   "metadata": {},
   "source": [
    "## UnDef-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746986",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889a715",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0a7cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "display_handle = display(None, display_id=True)\n",
    "\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(width, height)\n",
    "    ret, prev_frame= cap.read()\n",
    "    while True:\n",
    "        _, frame_bgr = cap.read()\n",
    "        \n",
    "        # frame_diff = cv2.absdiff(frame_bgr, prev_frame)\n",
    "        # prev_frame = frame_bgr.copy()\n",
    "        # gray = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "        # blur = cv2.GaussianBlur(gray, (5, 5), 0)   \n",
    "        # thresh = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "        # dilate = cv2.dilate(thresh, None, iterations=5)\n",
    "        # contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        # cv2.drawContours(frame_bgr, contours, -1, (0, 0, 0), 3)\n",
    "\n",
    "        motion = 0\n",
    "        # for cnt in contours:\n",
    "        #     mask = np.zeros([height, width], dtype=np.uint8)\n",
    "        #     area = cv2.contourArea(cnt)\n",
    "        #     if area > 10000:\n",
    "        #         motion += 1\n",
    "        #         # rect = cv2.minAreaRect(cnt)\n",
    "        #         # (x, y), (w, h), angle = rect\n",
    "        #         # object_width = w / pixel_cm_ratio\n",
    "        #         # object_height = h / pixel_cm_ratio\n",
    "        #         x, y, w, h = cv2.boundingRect(cnt)\n",
    "        #         x1 = x if x < 5 else x - 5\n",
    "        #         y1 = y if y < 5 else y - 5\n",
    "        #         x2 = x + w if (x + w + 5) > width else x + w + 5\n",
    "        #         y2 = y + h if (y + h + 5) > height else y + h + 5\n",
    "        #         # cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
    "        #         mask[y1:y2, x1:x2] = 255\n",
    "        #         frame_mask = cv2.add(frame_bgr, np.zeros_like(frame_bgr, dtype=np.uint8), mask=mask)\n",
    "                  \n",
    "        if motion > -1:\n",
    "            corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "            # cv2.aruco.drawDetectedMarkers(frame_bgr, corners, ids)\n",
    "            if corners and len(corners) > 0: \n",
    "                aruco_perimeter = cv2.arcLength(corners[0], True)\n",
    "                pixel_cm_ratio = aruco_perimeter / 20\n",
    "                frame_gray = cv2.cvtColor(frame_bgr.copy(), cv2.COLOR_BGR2GRAY)\n",
    "                img_blur = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "                img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "                img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "                img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "                # frame_thresh = cv2.adaptiveThreshold(frame_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 19, 5)\n",
    "                contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "                for cnt in contours:\n",
    "                    area = cv2.contourArea(cnt)\n",
    "                    # if area > 5000 and area < 153600:\n",
    "                    if area > 1000 and area < 20000:\n",
    "                        # cv2.drawContours(frame_bgr, [cnt], 0, color=(0, 0, 0), thickness=4)\n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (x, y), (w, h), angle = rect\n",
    "                        object_width = w / pixel_cm_ratio\n",
    "                        object_height = h / pixel_cm_ratio\n",
    "                        box = cv2.boxPoints(rect)\n",
    "                        box = np.int0(box)\n",
    " \n",
    "                        cv2.circle(frame_bgr, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "                        cv2.polylines(frame_bgr, [box], True, (100, 10, 0), 2)\n",
    "                        # cv2.putText(frame_bgr, \"{} cm\".format(round(object_width, 2)), (int(x - 100), int(y - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "                        cv2.putText(frame_bgr, \"{} cm\".format(round(object_height, 2)), (int(x - 50), int(y + 15)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame_bgr)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cap.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c5d3c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f392edd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "- [](https://slash-honeydew-c53.notion.site/a88e94293aeb4b54a729ceeb2f40a353)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b131a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "1. Part 1: Image formation and pinhole model of the camera - https://towardsdatascience.com/image-formation-and-pinhole-model-of-the-camera-53872ee4ee92\n",
    "2. Part 2: Camera Extrinsic Matrix in Python - https://towardsdatascience.com/camera-extrinsic-matrix-with-example-in-python-cfe80acab8dd\n",
    "3. Part 3: Camera Intrinsic Matrix in Python - https://towardsdatascience.com/camera-intrinsic-matrix-with-example-in-python-d79bf2478c12\n",
    "4. Part 4: Find the Minimum Stretching Direction of Positive Definite Matrices - https://towardsdatascience.com/find-the-minimum-stretching-direction-of-positive-definite-matrices-79c2a3b397fc\n",
    "5. Part 5: Camera Calibration in Python - https://towardsdatascience.com/camera-calibration-with-example-in-python-5147e945cdeb\n",
    "You can also find all the code in the GitHub repository - https://github.com/wingedrasengan927/Image-formation-and-camera-calibration\n",
    "\n",
    "\n",
    "https://programtalk.com/vs4/python/OteRobotics/realant/pose_estimation.py/\n",
    "\n",
    "https://its201.com/article/libo1004/110851205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7d5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "350px",
    "left": "1593px",
    "top": "66px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
