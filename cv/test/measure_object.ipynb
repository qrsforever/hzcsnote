{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89569e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %watermark -p numpy,sklearn,pandas\n",
    "# %watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "# %watermark -p torch,torchvision,torchaudio\n",
    "# %watermark -p tensorflow,tensorboard,tflite\n",
    "# %watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "# from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "# from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import argparse, shlex, signal, traceback\n",
    "import numpy as np\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x, debug=False):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/' or x[1] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                x = 'https://' + x\n",
    "                x = requests.get(x)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                x = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = x.split('/')\n",
    "                for s in ['/main/', '/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    if debug:\n",
    "                        print(x)\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        if debug:\n",
    "            return x\n",
    "        else:\n",
    "            exec(x, globals())\n",
    "    except Exception as err:\n",
    "        # sys.stderr.write(f'request {x} : {err}')\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "    \n",
    "\n",
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT('import pandas as pd')\n",
    "_IMPORT('import cv2')\n",
    "_IMPORT('from PIL import Image')\n",
    "_IMPORT('import matplotlib.pyplot as plt')\n",
    "_IMPORT('import plotly')\n",
    "_IMPORT('import plotly.graph_objects as go')\n",
    "_IMPORT('import ipywidgets as widgets')\n",
    "_IMPORT('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n",
    "\n",
    "\n",
    "class COLORS(object):\n",
    "    # BGR\n",
    "    GREEN      = (0   , 255 , 0)\n",
    "    RED        = (0   , 0   , 255)\n",
    "    BLACK      = (0   , 0   , 0)\n",
    "    YELLOW     = (0   , 255 , 255)\n",
    "    WHITE      = (255 , 255 , 255)\n",
    "    CYAN       = (255 , 255 , 0)\n",
    "    MAGENTA    = (255 , 0   , 242)\n",
    "    GOLDEN     = (32  , 218 , 165)\n",
    "    LIGHT_BLUE = (255 , 9   , 2)\n",
    "    PURPLE     = (128 , 0   , 128)\n",
    "    CHOCOLATE  = (30  , 105 , 210)\n",
    "    PINK       = (147 , 20  , 255)\n",
    "    ORANGE     = (0   , 69  , 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, functools, datetime\n",
    "\n",
    "class __JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.datetime, datetime.timedelta)):\n",
    "            return '{}'.format(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps = functools.partial(json.dumps, cls=__JsonEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9c9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.filters as filters\n",
    "import threading\n",
    "from enum import IntEnum\n",
    "_IMPORT('import gitee.com/qrsforever/nb_easy/easy_widget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b017b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ctx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5057461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "if g_ctx is None:\n",
    "    ax = 10\n",
    "else:\n",
    "    ax = 20\n",
    "    \n",
    "print(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e82a7",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbd7df2",
   "metadata": {
    "code_folding": [
     0,
     181
    ]
   },
   "outputs": [],
   "source": [
    "class CalibrateState(IntEnum):\n",
    "    COLLECT = 1\n",
    "    CALIBRATE = 2\n",
    "    COMPLETED = 3\n",
    "    \n",
    "\n",
    "def start_camera_calibrate(\n",
    "    ctx, w_btn_source, nrow, ncol, square_size, marker_size, aruto_dict,\n",
    "    sample_size, w_det_objtype, w_cam_frame):\n",
    "    \n",
    "    ctx.logger(f'start: {nrow}, {ncol}, {square_size}, {marker_size}, {aruto_dict}, {sample_size}', clear=1)\n",
    "    \n",
    "    use_charuco = marker_size is not None\n",
    "    if use_charuco: \n",
    "        if aruto_dict == '4x4':\n",
    "            dict_id = cv2.aruco.DICT_4X4_1000\n",
    "        elif aruto_dict == '5x5':\n",
    "            dict_id = cv2.aruco.DICT_5X5_1000\n",
    "        else:\n",
    "            dict_id = cv2.aruco.DICT_6x6_1000\n",
    "        charuco_dict = cv2.aruco.Dictionary_get(dict_id)\n",
    "        charuco_board = cv2.aruco.CharucoBoard_create(nrow, ncol, square_size, marker_size, charuco_dict)\n",
    "    else:\n",
    "        # Object points for a chessboard\n",
    "        objp = np.zeros((nrow * ncol, 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:nrow, 0:ncol].T.reshape(-1, 2)\n",
    "        objp = objp * square_size\n",
    "        \n",
    "    pattern_size = (nrow, ncol)\n",
    "    win_size, zero_zone = (5, 5), (-1, -1)\n",
    "    flags=(cv2.CALIB_RATIONAL_MODEL + cv2.CALIB_THIN_PRISM_MODEL + cv2.CALIB_TILTED_MODEL)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    \n",
    "    detector_parameters = cv2.aruco.DetectorParameters_create()\n",
    "    aruco_dict_6x6 = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_1000)\n",
    "    \n",
    "    def _video_capture():\n",
    "        w_btn_source.disabled = True\n",
    "        state = CalibrateState.COLLECT\n",
    "        result = {}\n",
    "        obj_points, img_points = [], []\n",
    "        if use_charuco:\n",
    "            charuco_corners, charuco_ids = [], []\n",
    "        try:\n",
    "            camera = cv2.VideoCapture(0)\n",
    "            frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            frame_irate = int(camera.get(cv2.CAP_PROP_FPS))\n",
    "            \n",
    "            ctx.logger(f'frame_width:{frame_width} frame_height:{frame_height} display: {w_cam_frame.width}')\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = ctx.camera.isOpened()\n",
    "            \n",
    "            camera_matrix, dist_coeffs, extrinsics_matrix = None, None, None\n",
    "            \n",
    "            def pixel_to_world(intrinsics_matrix, extrinsics_matrix, x, y):\n",
    "                pseudo_inv_extrinsics = np.linalg.pinv(extrinsics_matrix)\n",
    "                intrinsics_inv = np.linalg.inv(intrinsics_matrix)\n",
    "                pixels_matrix = np.array((x, y, 1))\n",
    "                ans = np.matmul(intrinsics_inv, pixels_matrix)\n",
    "                ans = np.matmul(pseudo_inv_extrinsics, ans)\n",
    "                ans /= ans[-1] \n",
    "                return ans\n",
    "            \n",
    "            frame_idx, iter_idx, display_frames_count = 0, 0, 1\n",
    "            while ctx.camera_is_running:\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                display_frames = {'raw': frame_bgr.copy()}\n",
    "                frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n",
    "                if state == CalibrateState.COLLECT:\n",
    "                    if use_charuco:\n",
    "                        # corner detection\n",
    "                        marker_corners, marker_Ids, rejected_points = cv2.aruco.detectMarkers(frame_gray, charuco_dict, parameters=detector_parameters)\n",
    "                        if marker_corners is not None and len(marker_corners) > 0:\n",
    "                            # coner refine \n",
    "                            marker_corners, marker_Ids, refusd, recoverd = cv2.aruco.refineDetectedMarkers(\n",
    "                                frame_gray, charuco_board, marker_corners, marker_Ids, rejectedCorners=rejected_points) \n",
    "                            # corner interpolation (get charuco corners and ids from detected aruco markers)\n",
    "                            retval, c_corners, c_Ids = cv2.aruco.interpolateCornersCharuco(\n",
    "                                marker_corners, marker_Ids, frame_gray, charuco_board)\n",
    "                            if retval > 20:\n",
    "                                # Find better\n",
    "                                better_charucoCorners = cv2.cornerSubPix(frame_gray, c_corners, win_size, zero_zone, criteria)                               \n",
    "                                # Draw and Display markers and corners\n",
    "                                frame_copy = frame_bgr.copy()\n",
    "                                display_frames['det_markers'] = cv2.aruco.drawDetectedMarkers(frame_copy, marker_corners, marker_Ids)\n",
    "                                frame_copy = frame_bgr.copy()\n",
    "                                display_frames['det_charuco'] = cv2.aruco.drawDetectedCornersCharuco(frame_copy, better_charucoCorners, c_Ids)\n",
    "\n",
    "                                if frame_idx % frame_irate == 0:\n",
    "                                    # objp = charuco_board.chessboardCorners[charuco_Ids.flatten()]\n",
    "                                    charuco_corners.append(better_charucoCorners)\n",
    "                                    charuco_ids.append(c_Ids)\n",
    "                                    iter_idx += 1\n",
    "                                    if iter_idx == sample_size:\n",
    "                                        state = CalibrateState.CALIBRATE\n",
    "                    else:\n",
    "                        found, corners = cv2.findChessboardCorners(frame_gray, pattern_size, flags=flags)\n",
    "\n",
    "                        if found:\n",
    "                            # Find better sub pix position for the corners in the roof corners neighbourhood\n",
    "                            better_chess_corners = cv2.cornerSubPix(frame_gray, corners, win_size, zero_zone, criteria)\n",
    "                            # Draw and display the corners\n",
    "                            frame_copy = frame_bgr.copy()\n",
    "                            frame_bgr = cv2.drawChessboardCorners(frame_copy, pattern_size, better_chess_corners, found)\n",
    "                            display_frames['det_chessboard'] = frame_copy\n",
    "\n",
    "                            if frame_idx % frame_irate == 0:\n",
    "                                obj_points.append(objp)\n",
    "                                img_points.append(better_chess_corners)\n",
    "                                \n",
    "                                iter_idx += 1\n",
    "                                if iter_idx == sample_size:\n",
    "                                    state = CalibrateState.CALIBRATE\n",
    "                    cv2.putText(display_frames['raw'], f'Count: {iter_idx}', (70, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.GOLDEN, 1)\n",
    "                    \n",
    "                elif state == CalibrateState.CALIBRATE:\n",
    "                    if use_charuco:\n",
    "                        retval, camera_matrix, dist_coeffs, rvecs, tvecs, \\\n",
    "                        std_intrinsics, std_extrinsics, errors = cv2.aruco.calibrateCameraCharucoExtended(\n",
    "                            charuco_corners, charuco_ids, charuco_board, frame_bgr.shape[:2], cameraMatrix=None, distCoeffs=None, flags=flags)\n",
    "                        total_error = 0.0\n",
    "                        for k, (c_corners, c_ids, rvec, tvec) in enumerate(zip(charuco_corners, charuco_ids, rvecs, tvecs)):\n",
    "                            obj_points, img_points = cv2.aruco.getBoardObjectAndImagePoints(charuco_board, c_corners, c_ids)\n",
    "                            prj_points, _ = cv2.projectPoints(obj_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "                            error = cv2.norm(img_points, prj_points, cv2.NORM_L2) / len(obj_points)\n",
    "                            total_error += error\n",
    "                            print(f'{k} error: {errors[k]} vs {round(error, 6)} vs {round(error**2, 6)}')\n",
    "                        print(f'mean total error: {total_error / len(charuco_corners)}')\n",
    "                        \n",
    "                        rvec, tvec = rvecs[-1], tvecs[-1]\n",
    "                    else: \n",
    "                        retval, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, frame_gray.shape[::-1], None, None)\n",
    "                        obj_points, img_points = obj_points[-1], img_points[-1]\n",
    "\n",
    "                        # Calculating extrinsics by last imgage (rotation vector)\n",
    "                        retval, rvec, tvec = cv2.solvePnP(obj_points, img_points, camera_matrix, dist_coeffs)                    \n",
    "                        # rvec, tvec = np.mean(np.array(rvecs), axis=0), np.mean(np.array(tvecs), axis=0)\n",
    "\n",
    "                    # transform rotation vector to ratation matrix\n",
    "                    rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "                    extrinsics_matrix = np.concatenate([rotation_matrix, tvec], 1) \n",
    "\n",
    "                    result['camera_matrix'] = camera_matrix\n",
    "                    result['distortion_coefficients'] = dist_coeffs\n",
    "                    result['extrinsics_matrix'] = extrinsics_matrix\n",
    "\n",
    "                    print(json.dumps(result, indent=4))\n",
    "                    state = CalibrateState.COMPLETED\n",
    "                else: \n",
    "                    frame_copy = frame_bgr.copy()\n",
    "                    display_frames['frame_undist'] = cv2.undistort(frame_bgr, camera_matrix, dist_coeffs)\n",
    "\n",
    "                    rect = cv2.minAreaRect(img_points.reshape(-1, 2))\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    frame_copy = frame_bgr.copy()\n",
    "                    display_frames['img_points_box'] = cv2.drawContours(frame_copy, [box], 0, COLORS.ORANGE, 2)\n",
    "\n",
    "\n",
    "                    if w_det_objtype.value == 'ArUco_6x6': # Detect 6x6 ArUco Marker\n",
    "                        marker_corners, marker_ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict_6x6, parameters=detector_parameters)\n",
    "                        if np.all(marker_ids is not None):\n",
    "                            frame_copy = frame_bgr.copy()\n",
    "                            for (marker_corner, marker_id) in zip(marker_corners, marker_ids):\n",
    "                                marker_length = 0.01 * (marker_id[0] - 60)\n",
    "                                rvec, tvec, marker_points = cv2.aruco.estimatePoseSingleMarkers(marker_corner, marker_length, camera_matrix, dist_coeffs)\n",
    "                                (rvec - tvec).any()\n",
    "                                cv2.drawFrameAxes(frame_copy, camera_matrix, dist_coeffs, rvec, tvec, 0.1)  # Draw Axis\n",
    "\n",
    "                                # calculate the height/width (2D to 3D)\n",
    "                                (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "\n",
    "                                p1 = pixel_to_world(camera_matrix, extrinsics_matrix, tl[0], tl[1])\n",
    "                                p2 = pixel_to_world(camera_matrix, extrinsics_matrix, tr[0], tr[1])\n",
    "                                p3 = pixel_to_world(camera_matrix, extrinsics_matrix, bl[0], bl[1])\n",
    "                                p4 = pixel_to_world(camera_matrix, extrinsics_matrix, br[0], br[1])\n",
    "                                W = p1 - p2\n",
    "                                H = p3 - p4\n",
    "                                width = np.sqrt(W[0]**2 + W[1]**2)\n",
    "                                height = np.sqrt(H[0]**2 + H[1]**2)\n",
    "\n",
    "                                cv2.putText(frame_copy,\n",
    "                                            'size {} x {}'.format(round(width, 3), round(height, 3)),\n",
    "                                            (tl[0], tl[1] - 15),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "                            cv2.aruco.drawDetectedMarkers(frame_copy, marker_corners, marker_ids, borderColor=COLORS.CHOCOLATE)\n",
    "                            display_frames['det_markers'] = frame_copy\n",
    "                \n",
    "                # display image\n",
    "                C = len(display_frames)\n",
    "                if C > 1:\n",
    "                    show_ncol = 2\n",
    "                    for i in range(C % show_ncol):\n",
    "                        display_frames[f'placehold-{i}'] = 255 * np.ones_like(frame_bgr)\n",
    "                    show_nrow = len(display_frames) // show_ncol\n",
    "                    row_images = []\n",
    "                    col_images = []\n",
    "                    for key, img in display_frames.items():\n",
    "                        cv2.putText(img, key, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS.ORANGE, 1)\n",
    "                        col_images.append(img)\n",
    "                        if len(col_images) == show_ncol:\n",
    "                            row_images.append(np.hstack(col_images))\n",
    "                            col_images = []\n",
    "                    else:\n",
    "                        display_image = np.vstack(row_images)\n",
    "                        if C != display_frames_count:\n",
    "                            w_cam_frame.layout.width = f'{int(w_cam_frame.width) * show_ncol}px'\n",
    "                            w_cam_frame.layout.height = f'{int(w_cam_frame.height) * show_nrow}px'\n",
    "                else:\n",
    "                    display_image = display_frames.popitem()[1]\n",
    "                    if C != display_frames_count:\n",
    "                        w_cam_frame.layout.width = f'{w_cam_frame.width}px'\n",
    "                        w_cam_frame.layout.height = f'{w_cam_frame.height}px'\n",
    "                display_frames_count = C\n",
    "                w_cam_frame.value = io.BytesIO(cv2.imencode('.png', display_image)[1]).getvalue()\n",
    "                frame_idx += 1\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}: {traceback.format_exc()}')\n",
    "        finally:\n",
    "            w_btn_source.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "    \n",
    "    \n",
    "def stop_camera_calibrate(ctx, w_btn_source):\n",
    "    ctx.logger('stop_camera_calibrate()')\n",
    "    if hasattr(ctx, 'camera') and ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cb0515",
   "metadata": {
    "code_folding": [
     2,
     34
    ]
   },
   "outputs": [],
   "source": [
    "# _IMPORT('./easy_widget.py')\n",
    "\n",
    "def nbeasy_chess_choice_objs(nrow, ncol, square_size, marker_size=-1, arUto_dict='4x4'):\n",
    "    ro = True\n",
    "    width = 333\n",
    "    objs = [\n",
    "        {\n",
    "            'type': 'H',\n",
    "            'objs': [\n",
    "                nbeasy_widget_int('cfg.chessb_rows', 'Chess Borad Rows', nrow, width=width, readonly=ro),\n",
    "                nbeasy_widget_int('cfg.chessb_cols', 'Chess Borad Cols', ncol, width=width, readonly=ro),\n",
    "                nbeasy_widget_float('cfg.square_size', 'Square Size CM', square_size, width=width, readonly=ro)        \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    if marker_size > 0:\n",
    "        enums = ['4x4', '5x5']\n",
    "        objs.append({\n",
    "            'type': 'H',\n",
    "            'objs': [\n",
    "                nbeasy_widget_float('cfg.marker_size', 'Marker Size CM', marker_size, width=width, readonly=ro),\n",
    "                nbeasy_widget_stringenum(\n",
    "                    'cfg.aruto_dict', 'ArUto Dict', default=enums.index(arUto_dict),\n",
    "                    enums=enums,\n",
    "                    width=width\n",
    "                )\n",
    "            ]\n",
    "        })\n",
    "        objs = [{'type': 'V', 'objs': objs}]\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': objs\n",
    "    }\n",
    "    \n",
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'V',\n",
    "            'name': 'Camera Calibration',\n",
    "            'objs': [\n",
    "                nbeasy_widget_stringenumtrigger(\n",
    "                    '_cfg.chess_choice', 'Chess Choise', default=5,\n",
    "                    enums = ['A4-30mm-8x6', 'A4-30mm-6x8', 'A3-25mm-15x10', 'A3-25mm-10x15', 'A3-20mm-16mm-13x19-4x4', 'A4-25mm-19mm-8x11-5x5'],\n",
    "                    triggers = [\n",
    "                        nbeasy_chess_choice_objs(8, 6, 3.0),\n",
    "                        nbeasy_chess_choice_objs(6, 8, 3.0),\n",
    "                        nbeasy_chess_choice_objs(15, 10, 2.5),\n",
    "                        nbeasy_chess_choice_objs(10, 15, 2.5),\n",
    "                        nbeasy_chess_choice_objs(13, 19, 2.0, 1.6, '4x4'),\n",
    "                        nbeasy_chess_choice_objs(8, 11, 2.5, 1.9, '5x5')\n",
    "                    ],\n",
    "                    width=333),\n",
    "                nbeasy_widget_int('cfg.sample_size', 'Sample Size', 8, width=333)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'V',\n",
    "            'name': 'Camera',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'type': 'H',\n",
    "                    'objs': [\n",
    "                        nbeasy_widget_button('cfg.__btn_start_camera', 'Start', width=200, style='success'),\n",
    "                        nbeasy_widget_button('cfg.__btn_stop_camera', 'Stop', width=200, style='success'),\n",
    "                        nbeasy_widget_stringenum(\n",
    "                            'cfg.det_object_type', 'Detect Object', default=0,\n",
    "                            enums=['ArUco_6x6'],\n",
    "                            width=333)\n",
    "                    ],\n",
    "                    'justify_content': 'center'\n",
    "                },\n",
    "                nbeasy_widget_image('__cfg.camera_frame', 'Frame', '', width=640, height=480)\n",
    "            ],\n",
    "            'align_items': 'center'\n",
    "        },\n",
    "    ],\n",
    "    'evts': [\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': start_camera_calibrate,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.chessb_rows:value',\n",
    "                            'cfg.chessb_cols:value',\n",
    "                            'cfg.square_size:value',\n",
    "                            'cfg.marker_size:value',\n",
    "                            'cfg.aruto_dict:value',\n",
    "                            'cfg.sample_size:value',\n",
    "                            'cfg.det_object_type',\n",
    "                            '__cfg.camera_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': stop_camera_calibrate,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.__btn_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7fc93ac",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80556a64c9004f6987ba64fd495888c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(HTML(value=\"<b><font color='black'>Camera Calibration :</b>\"), VBoxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if g_ctx:\n",
    "    if hasattr(g_ctx, 'camera') and g_ctx.camera:\n",
    "        g_ctx.camera_is_running = False\n",
    "        time.sleep(1)\n",
    "        if g_ctx.camera:\n",
    "            g_ctx.camera.release()\n",
    "g_ctx = nbeasy_schema_parse(schema, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0a0ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b066a9",
   "metadata": {},
   "source": [
    "## UnD-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc30ffe",
   "metadata": {
    "code_folding": [
     168
    ]
   },
   "outputs": [],
   "source": [
    "def nbon_start_camera(ctx, sbtn,\n",
    "                      w_bgsub_method, w_bgsub_history, w_det_shadow, \n",
    "                      w_rmn_shadow_threshold, w_rmn_morpho_kernel, rmn_erode_iter, rmn_dilate_iter,\n",
    "                      w_cnt_area_threshold,\n",
    "                      w_cam_frame):\n",
    "    method = str.lower(w_bgsub_method.value)\n",
    "    history_length = w_bgsub_history.value\n",
    "    detect_shadows = w_det_shadow.value\n",
    "    \n",
    "    shadow_thresh = w_rmn_shadow_threshold.value\n",
    "    kernel = np.ones((w_rmn_morpho_kernel.value, w_rmn_morpho_kernel.value), np.uint8)\n",
    "    \n",
    "    erode_iter = rmn_erode_iter.value\n",
    "    dilate_iter = rmn_dilate_iter.value\n",
    "    \n",
    "    area_threshold = w_cnt_area_threshold.value\n",
    "    \n",
    "    ctx.logger(f'nbon_start_camera({method}, {history_length}, {detect_shadows}, {shadow_thresh}, {w_rmn_morpho_kernel.value})')\n",
    "    \n",
    "    import threading\n",
    "    \n",
    "    def _video_capture():\n",
    "        sbtn.disabled = True\n",
    "        parameters = cv2.aruco.DetectorParameters_create()\n",
    "        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)\n",
    "        pixel_cm_ratio_1, pixel_cm_ratio_2 = -1, -1\n",
    "        marker_corner_1, marker_corner_2 = None, None\n",
    "        try:\n",
    "            bg_object = None\n",
    "            if method == 'knn':\n",
    "                bg_object = cv2.createBackgroundSubtractorKNN(history=history_length, detectShadows=detect_shadows)\n",
    "            elif method == 'mog2':\n",
    "                bg_object = cv2.createBackgroundSubtractorMOG2(history=history_length, detectShadows=detect_shadows)\n",
    "\n",
    "            camera = cv2.VideoCapture(0)\n",
    "            width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "            ctx.camera = camera\n",
    "            ctx.camera_is_running = ctx.camera.isOpened()\n",
    "            while ctx.camera_is_running:\n",
    "                ret, frame_bgr = camera.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                    \n",
    "                # Detect Aruco markers 5cm x 5cm\n",
    "                corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "                if corners is None or len(corners) == 0: \n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                    \n",
    "                frame_copy = frame_bgr.copy()\n",
    "                    \n",
    "                for (marker_corner, marker_ID) in zip(corners, ids):\n",
    "                    (tl, tr, br, bl) = [(int(x[0]), int(x[1])) for x in marker_corner.reshape((4, 2))]\n",
    "                    rect = cv2.minAreaRect(marker_corner[0])\n",
    "                    if marker_ID == 1:\n",
    "                        pixel_cm_ratio_1 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target left\n",
    "                        marker_corner_1 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:1 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_1[0][0], marker_corner_1[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                    elif marker_ID == 2:\n",
    "                        pixel_cm_ratio_2 = cv2.arcLength(marker_corner, True) / (4 * 5) # place it on the target right\n",
    "                        marker_corner_2 = (tl, tr, br, bl)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    'id:2 {}x{}'.format(round(rect[1][0], 2), round(rect[1][1], 2)),\n",
    "                                    (marker_corner_2[0][0], marker_corner_2[0][1] - 15),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                        \n",
    "                if marker_corner_1 is None and marker_corner_2 is None:\n",
    "                    w_cam_frame.value = io.BytesIO(cv2.imencode('.png', frame_bgr)[1]).getvalue()\n",
    "                    continue\n",
    "                                                             \n",
    "                cv2.aruco.drawDetectedMarkers(frame_copy, corners, ids, borderColor=(255, 0, 0))\n",
    "\n",
    "                if bg_object:\n",
    "                    # Apply the background object on the frame to get the segmented mask.     \n",
    "                    fgmask = bg_object.apply(frame_bgr)\n",
    "\n",
    "                    # Perform thresholding to get rid of the shadows.\n",
    "                    _, fgmask = cv2.threshold(fgmask, shadow_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                    # Apply some morphological operations to make sure you have a good mask\n",
    "                    fgmask = cv2.erode(fgmask, kernel, iterations=erode_iter)\n",
    "                    fgmask = cv2.dilate(fgmask, kernel, iterations=dilate_iter)\n",
    "\n",
    "                    # Get foreground object\n",
    "                    foreground = cv2.bitwise_and(frame_bgr, frame_bgr, mask=fgmask)\n",
    "                    \n",
    "                    frame_mid = foreground\n",
    "                    frame_dst = fgmask\n",
    "                else:\n",
    "                    # Grayscale & Guassian blur\n",
    "                    frame_gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY) \n",
    "                    frame_blur = cv2.GaussianBlur(frame_gray, (3, 3), 0)\n",
    "\n",
    "                    # # Divide gray by morphology image\n",
    "                    # frame_div = cv2.divide(frame_gray, frame_blur, scale=255)\n",
    "\n",
    "                    # Sharpen using unsharp masking\n",
    "                    # frame_sharp = filters.unsharp_mask(frame_div, radius=1.5, amount=1.5, channel_axis=None, preserve_range=False)\n",
    "                    # frame_sharp = (255 * frame_sharp).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "                    # Otsu Filter\n",
    "                    # _, frame_otsu = cv2.threshold(frame_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    _, frame_otsu = cv2.threshold(frame_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "                    # Detect edge by candy\n",
    "                    # frame_canny = cv2.Canny(frame_blur, 200, 250)\n",
    "                    \n",
    "                    frame_mid = cv2.cvtColor(frame_otsu, cv2.COLOR_GRAY2BGR)\n",
    "                    frame_dst = frame_otsu\n",
    "\n",
    "                contours, _ = cv2.findContours(frame_dst, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                for cnt in contours:\n",
    "                    if cv2.contourArea(cnt) > area_threshold:\n",
    "                        x1, y1, width, height = cv2.boundingRect(cnt)\n",
    "                        x2, y2 = x1 + width, y1 + height\n",
    "                        \n",
    "                        cv2.rectangle(frame_copy, (x1, y1), (x2, y2),(0, 0, 255), 2)\n",
    "                        cv2.putText(frame_copy,\n",
    "                                    '{}x{}'.format(round(width, 2), round(height, 2)),\n",
    "                                    (x2, y2),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                        \n",
    "                        if marker_corner_1:\n",
    "                            if x1 < marker_corner_1[1][0] or x1 < marker_corner_1[2][0]:\n",
    "                                continue\n",
    "                        if marker_corner_2:\n",
    "                            if x2 > marker_corner_2[0][0] or x2 > marker_corner_2[3][0]:\n",
    "                                continue\n",
    "                        \n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (cx, cy), (cw, ch), angle = rect\n",
    "                        \n",
    "                        if marker_corner_1 and marker_corner_2:\n",
    "                            ow = round(0.5 * cw / pixel_cm_ratio_1 + 0.5 * cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(0.5 * ch / pixel_cm_ratio_1 + 0.5 * ch / pixel_cm_ratio_2, 2)\n",
    "                        elif marker_corner_1:\n",
    "                            ow = round(cw / pixel_cm_ratio_1, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_1, 2)\n",
    "                        else:\n",
    "                            ow = round(cw / pixel_cm_ratio_2, 2)\n",
    "                            oh = round(ch / pixel_cm_ratio_2, 2)\n",
    "                        \n",
    "                        cv2.circle(frame_copy, (int(cx), int(cy)), 10, (255, 0, 0), -1)\n",
    "                        cv2.polylines(frame_copy, [np.int0(cv2.boxPoints(rect))], True, (255, 0, 0), 2)\n",
    "                        cv2.putText(frame_copy, \"{}x{}\".format(ow, oh), (int(cx - 100), int(cy - 20)), cv2.FONT_HERSHEY_PLAIN, 0.5, (100, 200, 0), 1)\n",
    "\n",
    "                stacked = np.hstack((frame_bgr, frame_mid, frame_copy))\n",
    "                w_cam_frame.value = io.BytesIO(cv2.imencode('.png', stacked)[1]).getvalue()\n",
    "                \n",
    "        except Exception as err:\n",
    "            ctx.logger(f'{err}')\n",
    "        finally:\n",
    "            sbtn.disabled = False\n",
    "            ctx.camera.release()\n",
    "            ctx.camera_is_running = False\n",
    "            ctx.camera = None\n",
    "        \n",
    "    \n",
    "    camera_thread = threading.Thread(target=_video_capture, name='camera')\n",
    "    camera_thread.daemon = True\n",
    "    camera_thread.start()\n",
    "\n",
    "    \n",
    "def nbon_stop_camera(ctx, sbtn):\n",
    "    ctx.logger('nbon_stop_camera()')\n",
    "    if ctx.camera:\n",
    "        ctx.camera_is_running = False\n",
    "        for i in range(3):\n",
    "            if ctx.camera is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if ctx.camera:\n",
    "            ctx.camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c511f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'name': 'Configuration',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Background Subtraction',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_stringenum('cfg.bgsub_method', 'BG Sub Method', 1, enums=['None', 'MOG2', 'KNN'], width=300),\n",
    "                                nbeasy_widget_int('cfg.bgsub_history', 'History Length', '300', min_=100, max_=600),\n",
    "                                nbeasy_widget_bool('cfg.bgsub_det_shadow', 'Detect Shadows', True)\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Remove Noise',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_int('cfg.rmn_shadow_threshold', 'Shadow Threshold', 250, min_=1, max_=255),\n",
    "                                nbeasy_widget_stringenum('cfg.rmn_morpho_kernel', 'Morpho Kernel', 0, enums=[('3', 3), ('5', 5), ('7', 7), ('9', 9)], width=300),\n",
    "                                nbeasy_widget_int('cfg.rmn_erode_iter', 'Erode Iters', 1),\n",
    "                                nbeasy_widget_int('cfg.rmn_dilate_iter', 'Dilate Iters', 1),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'name': 'Find Contours',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_float('cfg.cnt_area_threshold', 'Area Threshold', 2000),\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Camera',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('cfg.btn_start_camera', 'Start', width=200, style='success'),\n",
    "                                        nbeasy_widget_button('cfg.btn_stop_camera', 'Stop', width=200, style='success')\n",
    "                                    ],\n",
    "                                    'justify_content': 'center'\n",
    "                                },\n",
    "                                nbeasy_widget_image('__cfg.camera_frame', 'Frame', '', height=480)\n",
    "                            ],\n",
    "                            'align_items': 'center'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': nbon_start_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_start_camera'],\n",
    "                        'targets': [\n",
    "                            'cfg.bgsub_method',\n",
    "                            'cfg.bgsub_history',\n",
    "                            'cfg.bgsub_det_shadow',\n",
    "                            'cfg.rmn_shadow_threshold',\n",
    "                            'cfg.rmn_morpho_kernel',\n",
    "                            'cfg.rmn_erode_iter',\n",
    "                            'cfg.rmn_dilate_iter',\n",
    "                            'cfg.cnt_area_threshold',\n",
    "                            '__cfg.camera_frame'\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': nbon_stop_camera,\n",
    "                    'params': {\n",
    "                        'sources': ['cfg.btn_stop_camera'],\n",
    "                        'targets': [\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "if G:\n",
    "    if hasattr(easy, 'camera') and easy.camera:\n",
    "        easy.camera_is_running = False\n",
    "        time.sleep(1)\n",
    "        if easy.camera:\n",
    "            easy.camera.release()\n",
    "easy = nbeasy_schema_parse(schema, debug=True)\n",
    "G = easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca199c97",
   "metadata": {},
   "source": [
    "## UnDef-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_handle = display(None, display_id=True)\n",
    "\n",
    "try:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(width, height)\n",
    "    ret, prev_frame= cap.read()\n",
    "    while True:\n",
    "        _, frame_bgr = cap.read()\n",
    "        \n",
    "        # frame_diff = cv2.absdiff(frame_bgr, prev_frame)\n",
    "        # prev_frame = frame_bgr.copy()\n",
    "        # gray = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "        # blur = cv2.GaussianBlur(gray, (5, 5), 0)   \n",
    "        # thresh = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "        # dilate = cv2.dilate(thresh, None, iterations=5)\n",
    "        # contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "        # cv2.drawContours(frame_bgr, contours, -1, (0, 0, 0), 3)\n",
    "\n",
    "        motion = 0\n",
    "        # for cnt in contours:\n",
    "        #     mask = np.zeros([height, width], dtype=np.uint8)\n",
    "        #     area = cv2.contourArea(cnt)\n",
    "        #     if area > 10000:\n",
    "        #         motion += 1\n",
    "        #         # rect = cv2.minAreaRect(cnt)\n",
    "        #         # (x, y), (w, h), angle = rect\n",
    "        #         # object_width = w / pixel_cm_ratio\n",
    "        #         # object_height = h / pixel_cm_ratio\n",
    "        #         x, y, w, h = cv2.boundingRect(cnt)\n",
    "        #         x1 = x if x < 5 else x - 5\n",
    "        #         y1 = y if y < 5 else y - 5\n",
    "        #         x2 = x + w if (x + w + 5) > width else x + w + 5\n",
    "        #         y2 = y + h if (y + h + 5) > height else y + h + 5\n",
    "        #         # cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
    "        #         mask[y1:y2, x1:x2] = 255\n",
    "        #         frame_mask = cv2.add(frame_bgr, np.zeros_like(frame_bgr, dtype=np.uint8), mask=mask)\n",
    "                  \n",
    "        if motion > -1:\n",
    "            corners, ids, _ = cv2.aruco.detectMarkers(frame_bgr, aruco_dict, parameters=parameters)\n",
    "            # cv2.aruco.drawDetectedMarkers(frame_bgr, corners, ids)\n",
    "            if corners and len(corners) > 0: \n",
    "                aruco_perimeter = cv2.arcLength(corners[0], True)\n",
    "                pixel_cm_ratio = aruco_perimeter / 20\n",
    "                frame_gray = cv2.cvtColor(frame_bgr.copy(), cv2.COLOR_BGR2GRAY)\n",
    "                img_blur = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "                img_edged = cv2.Canny(img_blur, 50, 100)\n",
    "                img_edged = cv2.dilate(img_edged, None, iterations=1)\n",
    "                img_edged = cv2.erode(img_edged, None, iterations=1)\n",
    "                # frame_thresh = cv2.adaptiveThreshold(frame_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 19, 5)\n",
    "                contours = cv2.findContours(img_edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "                for cnt in contours:\n",
    "                    area = cv2.contourArea(cnt)\n",
    "                    # if area > 5000 and area < 153600:\n",
    "                    if area > 1000 and area < 20000:\n",
    "                        # cv2.drawContours(frame_bgr, [cnt], 0, color=(0, 0, 0), thickness=4)\n",
    "                        rect = cv2.minAreaRect(cnt)\n",
    "                        (x, y), (w, h), angle = rect\n",
    "                        object_width = w / pixel_cm_ratio\n",
    "                        object_height = h / pixel_cm_ratio\n",
    "                        box = cv2.boxPoints(rect)\n",
    "                        box = np.int0(box)\n",
    " \n",
    "                        cv2.circle(frame_bgr, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "                        cv2.polylines(frame_bgr, [box], True, (100, 10, 0), 2)\n",
    "                        # cv2.putText(frame_bgr, \"{} cm\".format(round(object_width, 2)), (int(x - 100), int(y - 20)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "                        cv2.putText(frame_bgr, \"{} cm\".format(round(object_height, 2)), (int(x - 50), int(y + 15)), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame_bgr)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cap.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c5d3c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f392edd",
   "metadata": {},
   "source": [
    "- [æ—‹è½¬çŸ©é˜µ](https://slash-honeydew-c53.notion.site/a88e94293aeb4b54a729ceeb2f40a353)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b131a",
   "metadata": {},
   "source": [
    "1. Part 1: Image formation and pinhole model of the camera - https://towardsdatascience.com/image-formation-and-pinhole-model-of-the-camera-53872ee4ee92\n",
    "2. Part 2: Camera Extrinsic Matrix in Python - https://towardsdatascience.com/camera-extrinsic-matrix-with-example-in-python-cfe80acab8dd\n",
    "3. Part 3: Camera Intrinsic Matrix in Python - https://towardsdatascience.com/camera-intrinsic-matrix-with-example-in-python-d79bf2478c12\n",
    "4. Part 4: Find the Minimum Stretching Direction of Positive Definite Matrices - https://towardsdatascience.com/find-the-minimum-stretching-direction-of-positive-definite-matrices-79c2a3b397fc\n",
    "5. Part 5: Camera Calibration in Python - https://towardsdatascience.com/camera-calibration-with-example-in-python-5147e945cdeb\n",
    "You can also find all the code in the GitHub repository - https://github.com/wingedrasengan927/Image-formation-and-camera-calibration\n",
    "\n",
    "\n",
    "https://programtalk.com/vs4/python/OteRobotics/realant/pose_estimation.py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33827370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "137px",
    "left": "1720px",
    "top": "32px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
