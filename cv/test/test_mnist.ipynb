{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> Test Mnist </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:32:33.012143Z",
     "start_time": "2020-07-22T16:32:31.425410Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision import datasets\n",
    "from torch import optim\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from k12libs.utils.nb_easy import K12AI_PRETRAINED_ROOT, K12AI_DATASETS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:32:33.052105Z",
     "start_time": "2020-07-22T16:32:33.017303Z"
    }
   },
   "outputs": [],
   "source": [
    "def k12ai_init_project(task, dataset, use_cuda=True):\n",
    "    data_root = os.path.join(K12AI_DATASETS_ROOT, task, dataset) # 数据集的根目录\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") # 使用cpu还是gpu训练\n",
    "    return data_root, device\n",
    "\n",
    "def k12ai_load_dataset(data_root, json_file, resize=None, transform=None):\n",
    "    class JsonfileDataset(Dataset):\n",
    "        def __init__(self, data_root, json_file, resize=None, transform=None):\n",
    "            self.data_root = data_root\n",
    "            self.json_file = json_file\n",
    "            self.resize = resize\n",
    "            self.image_list, self.label_list = self.__read_jsonfile(json_file)\n",
    "            if transform:\n",
    "                self.transform = transform\n",
    "            else:\n",
    "                self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = Image.open(self.image_list[index]).convert('RGB')\n",
    "            if self.resize:\n",
    "                img = img.resize(self.resize)\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.label_list[index]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_list)\n",
    "\n",
    "        def __read_jsonfile(self, jsonfile):\n",
    "            image_list = []\n",
    "            label_list = []\n",
    "            with open(os.path.join(self.data_root, self.json_file)) as f:\n",
    "                items = json.load(f)\n",
    "                for item in items:\n",
    "                    image_list.append(os.path.join(self.data_root, item['image_path']))\n",
    "                    label_list.append(item['label'])\n",
    "            return image_list, label_list\n",
    "    return JsonfileDataset(data_root, json_file, resize, transform)\n",
    "    \n",
    "def k12ai_load_model(name, pretrained=True, device='cuda'):\n",
    "    if name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=False)\n",
    "        pretrained_file = 'vgg16-397923af.pth'\n",
    "    elif name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        pretrained_file = 'resnet50-19c8e357.pth'\n",
    "    elif name == 'resnet152':\n",
    "        model = models.resnet152(pretrained=False)\n",
    "        pretrained_file = 'resnet152-b121ed2d.pth'\n",
    "    elif name == 'alexnet':\n",
    "        model = models.alexnet(pretrained=False)\n",
    "        pretrained_file = 'alexnet-owt-4df8aa71.pth'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    if pretrained:\n",
    "        state = torch.load(os.path.join(K12AI_PRETRAINED_ROOT, 'cv', pretrained_file))\n",
    "        model.load_state_dict(state)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:32:35.360548Z",
     "start_time": "2020-07-22T16:32:35.354482Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root, device = k12ai_init_project(\n",
    "    task='cv',       # 任务类型\n",
    "    dataset='mnist', # 数据集\n",
    "    use_cuda=True,   # GPU训练\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T16:32:36.814564Z",
     "start_time": "2020-07-22T16:32:36.584503Z"
    }
   },
   "outputs": [],
   "source": [
    "### 加载数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.6),    # 数据增强: 对PIL Image数据做随机水平翻转\n",
    "    transforms.ToTensor(),                     # PIL Image格式转换为Tensor张量格式               \n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # 对数据归一化处理\n",
    "])\n",
    "train_dataset = k12ai_load_dataset(data_root, 'train.json', transform=transform)\n",
    "\n",
    "### 将数据集分割为80%用作训练(train), 20%用作校验(val)\n",
    "split_8_2 = int(0.8 * len(train_dataset))\n",
    "data_list = list(range(len(train_dataset)))\n",
    "train_idx, valid_idx = data_list[:split_8_2], data_list[split_8_2:]\n",
    "\n",
    "### 随机图片样本\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "### 采用批量(batch_size)随机的方式加载图片样本\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=train_sampler) \n",
    "valid_loader = DataLoader(train_dataset, batch_size=64, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法模型的选择与设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T07:45:48.390396Z",
     "start_time": "2020-07-23T07:45:47.400641Z"
    }
   },
   "outputs": [],
   "source": [
    "### 方式 1: 使用预置的模型resnet50\n",
    "pretrained = True # 使用预置权重训练\n",
    "resnet_model = k12ai_load_model('resnet50', pretrained, device=device)\n",
    "\n",
    "### 方式 2: 用户自定义模型\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)  # 卷积层, 图片特征提取\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)   # Dropout正则化, 减少模型过拟合\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)        # 全连接层, 图片线性变换\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1) # 每个分类的概率分布\n",
    "    \n",
    "custom_model = CustomNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T07:45:50.197503Z",
     "start_time": "2020-07-23T07:45:50.186211Z"
    }
   },
   "outputs": [],
   "source": [
    "### 设置训练轮回(max_epoch)\n",
    "max_epoch = 10\n",
    "\n",
    "### 设置损失函数(交叉熵CE)\n",
    "reduction = 'mean' # 约简方式为mean(张量各个维度上的元素的平均值)\n",
    "loss_func = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "### 设置优化器(随机梯度下降SGD)\n",
    "optimizer = SGD(custom_model.parameters(),\n",
    "                lr=0.01,           # 基础学习率\n",
    "                weight_decay=1e-6, # 权重衰减, 使得模型参数值更小, 有效防止过拟合\n",
    "                momentum=0.9,      # 动量因子, 更快局部收敛\n",
    "                nesterov=True      # 使用Nesterov动量, 加快收敛速度\n",
    "               )\n",
    "\n",
    "### 设置学习率衰减策略(可选, 固定步长衰减StepLR)\n",
    "scheduler = StepLR(optimizer,\n",
    "                   step_size=2, # 每间隔2次epoch进行一次LR调整\n",
    "                   gamma=0.6    # LR调整为原来0.6倍\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练及反馈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-23T07:45:51.985Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, device, data_loader, loss_func, optimizer, epoch):\n",
    "    ### 模型进入训练状态(启用 BN 和 Dropout)\n",
    "    model.train()\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(output.shape, target.shape)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print('Epoch:', epoch, ', Training Loss:', loss.item())\n",
    "        \n",
    "def valid_epoch(model, device, data_loader, epoch):\n",
    "    ### 模型进入评估模式(禁用 BN 和 Dropou)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, target)\n",
    "            pred = torch.max(output, 1)[1]\n",
    "            correct += (pred == target).sum().item()\n",
    "            # print('Epoch:', epoch, ', Validing Loss:', loss.item())\n",
    "    ### 计算正确率\n",
    "    acc = 100.0 * correct / len(data_loader.dataset)\n",
    "    if epoch % 5:\n",
    "        print(\"ACC:\", acc)\n",
    "    return acc\n",
    "    \n",
    "def train(epoch_num, model, train_loader, valid_loader, loss_func, optimizer, scheduler):\n",
    "    ### 获取模型训练所用设备(cpu或者gpu)\n",
    "    device = next(model.parameters()).device\n",
    "    for epoch in range(0, epoch_num): \n",
    "        ### 训练模型\n",
    "        train_epoch(model, device, train_loader, loss_func, optimizer, epoch)\n",
    "        ### 校验模型\n",
    "        valid_epoch(model, device, valid_loader, epoch)\n",
    "        ### 调整学习率\n",
    "        scheduler.step()\n",
    "\n",
    "    ### 保存模型\n",
    "    torch.save(model.state_dict(), \"last.pt\")\n",
    "        \n",
    "### 启动训练\n",
    "train(max_epoch, custom_model, train_loader, valid_loader, loss_func, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T14:00:30.236751Z",
     "start_time": "2020-06-23T14:00:24.780194Z"
    }
   },
   "outputs": [],
   "source": [
    "### 加载测试数据集\n",
    "test_dataset = k12ai_load_dataset(data_root, 'test.json')\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, num_workers=4)\n",
    "\n",
    "### 加载训练完成的模型\n",
    "last_model = CustomNet()\n",
    "last_model.load_state_dict(torch.load('last.pt'))\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            pred = torch.max(output, 1)[1]\n",
    "            correct += (pred == target).sum().item()\n",
    "    ### 计算正确率\n",
    "    acc = 100.0 * correct / len(data_loader.dataset)\n",
    "    return acc\n",
    "\n",
    "### 启动评估\n",
    "acc = evaluate(last_model, test_loader)\n",
    "print(\"Acc:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
