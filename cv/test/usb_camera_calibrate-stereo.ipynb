{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba752fc5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %watermark -p numpy,sklearn,pandas\n",
    "# %watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "# %watermark -p torch,torchvision,torchaudio\n",
    "# %watermark -p tensorflow,tensorboard,tflite\n",
    "# %watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "# from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "# from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import argparse, shlex, signal, traceback\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x, debug=False):\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/' or x[1] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                x = 'https://' + x\n",
    "                x = requests.get(x)\n",
    "                if x.status_code == 200:\n",
    "                    x = x.text\n",
    "            elif x.startswith('github.com'):\n",
    "                x = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = x.split('/')\n",
    "                for s in ['/main/', '/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[-3:])\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                for s in ['/raw/main/', '/raw/master/']:\n",
    "                    x = 'https://' + '/'.join(mod[:3]) + s + '/'.join(mod[3:])\n",
    "                    if debug:\n",
    "                        print(x)\n",
    "                    x = requests.get(x)\n",
    "                    if x.status_code == 200:\n",
    "                        x = x.text\n",
    "                        break\n",
    "        if debug:\n",
    "            return x\n",
    "        else:\n",
    "            exec(x, globals())\n",
    "    except Exception as err:\n",
    "        # sys.stderr.write(f'request {x} : {err}')\n",
    "        pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89569e73",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT('import pandas as pd')\n",
    "_IMPORT('import cv2')\n",
    "_IMPORT('from PIL import Image')\n",
    "_IMPORT('import matplotlib.pyplot as plt')\n",
    "_IMPORT('import plotly')\n",
    "_IMPORT('import plotly.graph_objects as go')\n",
    "_IMPORT('import ipywidgets as widgets')\n",
    "_IMPORT('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 2048:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<center><img %s %s src=\"%s\"/></center>' % (W, H, data_url))\n",
    "\n",
    "def nbeasy_widget_display(images, img_wid=None):\n",
    "    if isinstance(images, np.ndarray):\n",
    "        images = {'_': images}\n",
    "    elif isinstance(images, tuple) or isinstance(images, list):\n",
    "        images = {f'_{i}': img for i, img in enumerate(images)}\n",
    "    C = len(images)\n",
    "    if C == 0:\n",
    "        return None\n",
    "    show_ncol, show_nrow = 1, 1\n",
    "    if C > 1:\n",
    "        if img_wid:\n",
    "            show_ncol = 2 if int(img_wid.width) < 1280 else 1\n",
    "        for i in range(C % show_ncol):\n",
    "            images[f'placehold-{i}'] = images[list(images.keys())[-1]].copy()\n",
    "        show_nrow = len(images) // show_ncol\n",
    "        row_images = []\n",
    "        col_images = []\n",
    "        for key, img in images.items():\n",
    "            if not key.startswith('_'):\n",
    "                cv2.putText(img, key, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 9,2), 1)\n",
    "            col_images.append(img)\n",
    "            if len(col_images) == show_ncol:\n",
    "                row_images.append(np.hstack(col_images))\n",
    "                col_images = []\n",
    "\n",
    "        display_image = np.vstack(row_images)\n",
    "    else:\n",
    "        display_image = images.popitem()[1]\n",
    "    \n",
    "    if img_wid:\n",
    "        img_wid.layout.width = f'{display_image.shape[1]}px'\n",
    "        img_wid.layout.height = f'{display_image.shape[0]}px'\n",
    "        if isinstance(img_wid, widgets.Image):\n",
    "            img_wid.value = io.BytesIO(cv2.imencode('.png', display_image)[1]).getvalue()\n",
    "        else:\n",
    "            img_wid.height, img_wid.width = display_image.shape[0], display_image.shape[1]\n",
    "            img_wid.put_image_data(cv2.cvtColor(display_image, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        return imgbytes\n",
    "\n",
    "# https://www.webucator.com/article/python-color-constants-module/\n",
    "class COLORS(object):\n",
    "    # BGR\n",
    "    BLUE       = (255 , 0   , 0)\n",
    "    GREEN      = (0   , 255 , 0)\n",
    "    RED        = (0   , 0   , 255)\n",
    "    BLACK      = (0   , 0   , 0)\n",
    "    YELLOW     = (0   , 255 , 255)\n",
    "    WHITE      = (255 , 255 , 255)\n",
    "    CYAN       = (255 , 255 , 0)\n",
    "    MAGENTA    = (255 , 0   , 242)\n",
    "    GOLDEN     = (32  , 218 , 165)\n",
    "    LIGHT_BLUE  = (255 , 9   , 2)\n",
    "    PURPLE     = (128 , 0   , 128)\n",
    "    CHOCOLATE  = (30  , 105 , 210)\n",
    "    PINK       = (147 , 20  , 255)\n",
    "    ORANGE     = (0   , 69  , 255)\n",
    "    GRAY       = (125 , 125 , 125)\n",
    "    DARKGRAY   = (50  , 50  , 50)\n",
    "    DARKGREEN  = (0   , 100 , 0)\n",
    "    OLIVE      = (0   , 128 , 0)\n",
    "    SILVER     = (192 , 192 , 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5d76a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import json, functools, datetime\n",
    "\n",
    "class __JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (datetime.datetime, datetime.timedelta)):\n",
    "            return '{}'.format(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "json.dumps = functools.partial(json.dumps, cls=__JsonEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9c9826",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import skimage.filters as filters\n",
    "import threading\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "from enum import IntEnum\n",
    "\n",
    "_IMPORT('gitee.com/qrsforever/nb_easy/easy_widget')\n",
    "\n",
    "g_ctx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3faa7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMPORT('./easy_widget.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c0db5",
   "metadata": {},
   "source": [
    "## Binocular: Stereo Camera Calibration\n",
    "\n",
    "[理论参考](https://string.quest/read/6034570)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ade0a",
   "metadata": {},
   "source": [
    "### Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddb40aa",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def _get_cameras():\n",
    "    prefix = '/sys/class/video4linux/'\n",
    "    cameras = [('None', 'none')]\n",
    "    if os.path.isdir(prefix):\n",
    "        for dev in os.listdir(prefix):\n",
    "            with open(f'{prefix}/{dev}/name', 'r') as f:\n",
    "                name = f.readline().strip().split(':')[0]\n",
    "                ty = 'monocular'\n",
    "                if '3D' in name:\n",
    "                    ty = 'binocular'\n",
    "                cameras.append((name, (f'/dev/{dev}', ty)))\n",
    "    return cameras\n",
    "        \n",
    "    \n",
    "VIDEO_MAX_SIZE = 10000\n",
    "\n",
    "class StereoCamera(object):\n",
    "    def __init__(self, source, resolution, is_3d = False):\n",
    "        self.video_source = source\n",
    "        self.video_capture = None\n",
    "        self.is_running = False\n",
    "        self.width, self.height = resolution\n",
    "        self._is_3d = is_3d\n",
    "        # self.grabbed, self.frame = False, None\n",
    "        # self.read_lock, self.read_thread = threading.Lock(), None\n",
    "        \n",
    "    def is_3d(self):\n",
    "        return self._is_3d\n",
    "        \n",
    "    # def start(self):\n",
    "    #     if self.is_running:\n",
    "    #         return\n",
    "    #     self.grabbed, self.frame = self.video_capture.read()\n",
    "    #     if self.grabbed:\n",
    "    #         self.is_running = True\n",
    "    #         self.read_thread = threading.Thread(target=self._update_frame)\n",
    "    #         self.read_thread.start()\n",
    "    #         \n",
    "    # def stop(self):\n",
    "    #     if self.is_running:\n",
    "    #         self.is_running = False \n",
    "    #         if self.video_capture:\n",
    "    #             self.video_capture.release()\n",
    "    #         if self.read_thread:\n",
    "    #             self.read_thread.join()\n",
    "    #     self.video_capture, self.read_thread = None, None\n",
    "    #     \n",
    "    # def _update_frame(self):\n",
    "    #     try:\n",
    "    #         while self.is_running:\n",
    "    #             grabbed, frame = self.video_capture.read()\n",
    "    #             with self.read_lock:\n",
    "    #                 self.grabbed = grabbed\n",
    "    #                 self.frame = frame\n",
    "    #     finally:\n",
    "    #         self.stop()\n",
    "    #         \n",
    "    # def read(self):\n",
    "    #     with self.read_lock:\n",
    "    #         grabbed = self.grabbed\n",
    "    #         frame = self.frame.copy()\n",
    "    #     return grabbed, frame\n",
    "    # \n",
    "    # def read_left_right(self):\n",
    "    #     with self.read_lock:\n",
    "    #         frame = self.frame.copy()\n",
    "    #         grabbed = self.grabbed\n",
    "    #         frameL = frame[:, :int(self.width / 2), :]\n",
    "    #         frameR = frame[:, int(self.width / 2):, :]\n",
    "    #     return grabbed, frameL, frameL\n",
    "    \n",
    "    def open(self):\n",
    "        video_capture = cv2.VideoCapture(self.video_source)\n",
    "        if not video_capture.isOpened():\n",
    "            raise RuntimeError(f'Cannot open {self.video_source}')\n",
    "            \n",
    "        if self._is_3d:\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, VIDEO_MAX_SIZE) # 2560\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, VIDEO_MAX_SIZE) # 960\n",
    "            width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            if width != 2560:\n",
    "                video_capture.release()\n",
    "                raise RuntimeError(f'{self.video_source} is not stereo camera!')\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, self.width * 2)\n",
    "        else:\n",
    "            video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)\n",
    "        video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)\n",
    "            \n",
    "        self.width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        self.video_capture = video_capture\n",
    "        self.is_running = True\n",
    "        return self.video_capture.read()[1].shape\n",
    "        \n",
    "    def close(self):\n",
    "        self.is_running = False\n",
    "        for _ in range(10):\n",
    "            if self.video_capture is None:\n",
    "                break\n",
    "            time.sleep(0.3)\n",
    "    \n",
    "    def read(self, flip=None):\n",
    "        try:\n",
    "            idx = 0\n",
    "            while self.is_running:\n",
    "                grabbed, frame = self.video_capture.read()\n",
    "                if not grabbed:\n",
    "                    raise RuntimeError('Video read error!')\n",
    "                idx += 1\n",
    "                \n",
    "                if flip > -2:\n",
    "                    frame = cv2.flip(frame, flip)\n",
    "                if self._is_3d:\n",
    "                    # 分离左右摄像头\n",
    "                    frameL = frame[:, :int(self.width / 2), :]\n",
    "                    frameR = frame[:, int(self.width / 2):, :]\n",
    "                    yield idx, [frameL, frameR]\n",
    "                else:\n",
    "                    yield idx, [frame]\n",
    "        finally:\n",
    "            self.video_capture.release()\n",
    "            self.video_capture = None\n",
    "            \n",
    "        raise StopIteration\n",
    "        \n",
    "\n",
    "def start_calibrate_camera_with_good_flags(ctx, calibrate, img_size, thresh_rate=1.25):\n",
    "    flags = 0\n",
    "    K = np.array([[max(img_size), 0, img_size[1]/2],[0, max(img_size), img_size[0]/2], [0, 0, 1]])\n",
    "    D = np.zeros((5, 1))\n",
    "    \n",
    "    # An RMS error of 1.0 means that, on average, each of these projected points is 1.0 px away from its actual position. \n",
    "    # [0.0, 1.0] is good\n",
    "    retval, mat, dist, rvecs, tvecs, \\\n",
    "    std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "\n",
    "    ctx.logger(json.dumps({\n",
    "        're-project-error': retval, \n",
    "        'mat': str(mat.round(3).tolist()),\n",
    "        'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    aspect_ratio = mat[0][0] / mat[1][1]\n",
    "    if 1.0 - min(aspect_ratio, 1.0/aspect_ratio) < 0.01:\n",
    "        flags += cv2.CALIB_FIX_ASPECT_RATIO\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    center_point_reldiff = max(abs(np.array(mat[0, 2], mat[1][2]) - np.array(img_size)/2) / np.array(img_size))\n",
    "    if center_point_reldiff < 0.05:\n",
    "        flags += cv2.CALIB_FIX_PRINCIPAL_POINT\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'center_point_reldiff': center_point_reldiff,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "\n",
    "    error_threshold = thresh_rate * retval\n",
    "    camera_matrix = mat\n",
    "    dist_coeffs = dist\n",
    "    error = retval\n",
    "\n",
    "    ignore_flags = {\n",
    "        'ignore_tangential_distortion': cv2.CALIB_ZERO_TANGENT_DIST,\n",
    "        'ignore_k3': cv2.CALIB_FIX_K3,\n",
    "        'ignore_k2': cv2.CALIB_FIX_K2,\n",
    "        'ignore_k1': cv2.CALIB_FIX_K1\n",
    "    }\n",
    "\n",
    "    for k, v in ignore_flags.items():\n",
    "        flags += v\n",
    "        retval, mat, dist, rvecs, tvecs, \\\n",
    "        std_intrinsics, std_extrinsics, errors = calibrate(imageSize=img_size, cameraMatrix=K, distCoeffs=D, flags=flags)\n",
    "        ctx.logger(json.dumps({\n",
    "            'ignore_type': k,\n",
    "            're-project-error': retval, \n",
    "            'mat': str(mat.round(3).tolist()),\n",
    "            'dist': str(dist.round(3).tolist())}, indent=4))\n",
    "        if retval > error_threshold:\n",
    "            continue\n",
    "        camera_matrix = mat\n",
    "        dist_coeffs = dist\n",
    "        error = retval\n",
    "    \n",
    "    return error, camera_matrix, dist_coeffs\n",
    "\n",
    "            \n",
    "def detect_chessboard(image, pattern_size, criteria, win_size, draw=False):\n",
    "    # 检测棋盘格\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    better_corners = None\n",
    "    found, corners = cv2.findChessboardCorners(gray, pattern_size, flags=cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_FILTER_QUADS)\n",
    "    if found:\n",
    "        # 角点精检测 (亚像素)\n",
    "        better_corners = cv2.cornerSubPix(gray, corners, win_size, (-1, -1), criteria)\n",
    "        if draw:\n",
    "            cv2.drawChessboardCorners(image, pattern_size, better_corners, found)\n",
    "    return better_corners\n",
    "\n",
    "\n",
    "def calibrate_monocular_camera(ctx, imgfiles, world_point, pattern_size, criteria, win_size):        \n",
    "    image_size = None\n",
    "    world_points, pixel_points = [], []\n",
    "    for ifile in imgfiles:\n",
    "        image = cv2.imread(ifile)\n",
    "        if image_size is None:\n",
    "            image_size = image.shape[::-1][1:]\n",
    "        pixel_point = detect_chessboard(image, pattern_size, criteria, win_size)\n",
    "        if pixel_point is not None: \n",
    "            world_points.append(world_point)\n",
    "            pixel_points.append(pixel_point)\n",
    " \n",
    "    error, mtx, dist = start_calibrate_camera_with_good_flags(ctx,\n",
    "        functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points),\n",
    "        img_size=image_size)\n",
    "    \n",
    "    return image_size, error, mtx, dist\n",
    "\n",
    "\n",
    "def calibrate_binocular_camera(ctx, img_l_files, img_r_files, world_point, pattern_size, criteria, win_size, flags):\n",
    "    ctx.logger(f'calibrate_binocular_camera({flags})')\n",
    "    image_size = None\n",
    "    world_points, pixel_points_L, pixel_points_R = [], [], []\n",
    "    for lfile, rfile in zip(img_l_files, img_r_files):\n",
    "        image_L = cv2.imread(lfile)\n",
    "        image_R = cv2.imread(rfile)\n",
    "        if image_size is None:\n",
    "            image_size = image_L.shape[::-1][1:]\n",
    "            ctx.logger(f'{lfile}, {rfile}, {image_size}')\n",
    "        pixel_point_L = detect_chessboard(image_L, pattern_size, criteria, win_size)\n",
    "        pixel_point_R = detect_chessboard(image_R, pattern_size, criteria, win_size)\n",
    "        if pixel_point_L is not None and pixel_point_R is not None:\n",
    "            world_points.append(world_point)\n",
    "            pixel_points_L.append(pixel_point_L)\n",
    "            pixel_points_R.append(pixel_point_R)\n",
    " \n",
    "    #  error_L, mtx_L, dist_L = start_calibrate_camera_with_good_flags(ctx,\n",
    "    #      functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points_L),\n",
    "    #      img_size=image_size, thresh_rate=1.02)\n",
    "    #  \n",
    "    #  error_R, mtx_R, dist_R = start_calibrate_camera_with_good_flags(ctx,\n",
    "    #      functools.partial(cv2.calibrateCameraExtended, objectPoints=world_points, imagePoints=pixel_points_R),\n",
    "    #      img_size=image_size, thresh_rate=1.02)\n",
    "    \n",
    "    # expect: error less than 1.0\n",
    "    error_L, mtx_L, dist_L, _, _ = cv2.calibrateCamera(world_points, pixel_points_L, image_size, None, None)\n",
    "    error_R, mtx_R, dist_R, _, _ = cv2.calibrateCamera(world_points, pixel_points_R, image_size, None, None)\n",
    "    \n",
    "    ctx.logger(f'L: {error_L}\\n {mtx_L}\\n {dist_L}')\n",
    "    ctx.logger(f'R: {error_R}\\n {mtx_R}\\n {dist_R}')\n",
    "\n",
    "    # flags = CALIB_FIX_INTRINSIC # default\n",
    "    # flags = 0\n",
    "    # flags |= cv2.CALIB_FIX_INTRINSIC # fix the intrinsic camara matrixes so that only R, T, E and F are calculated\n",
    "    # flags |= cv2.CALIB_USE_INTRINSIC_GUESS # initial value of cameraMatrix and distCoeffs provided by the user\n",
    "    # flags |= cv2.CALIB_FIX_FOCAL_LENGTH # the focal length is not changed during the iteration\n",
    "    # flags |= cv2.CALIB_ZERO_TANGENT_DIST # the tangential distortion remains zero\n",
    "    error, K1, D1, K2, D2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        world_points, pixel_points_L, pixel_points_R,\n",
    "        mtx_L, dist_L, mtx_R, dist_R, image_size,\n",
    "        R=None, # 第一和第二个摄像机之间的旋转矩阵\n",
    "        T=None, # 第一和第二个摄像机之间的平移矩阵\n",
    "        E=None, # essential matrix本质矩阵\n",
    "        F=None, # fundamental matrix基本矩阵\n",
    "        flags=flags,\n",
    "        criteria=criteria\n",
    "    )\n",
    "    \n",
    "    # D1 = np.zeros((5, 1))\n",
    "    # D2 = np.zeros((5, 1))\n",
    "    \n",
    "    ctx.logger(f'error_L: {error_L} error_R: {error_R} error: {error}')\n",
    "\n",
    "    return image_size, error, K1, D1, K2, D2, R, T, E, F\n",
    "\n",
    "\n",
    "def rectify_binocular_camera(ctx, K1, D1, K2, D2, image_size, R, T, alpha):\n",
    "    \"\"\"\n",
    "    alpha  -1: 自动剪切 0: 没有黑边  1: 所有像素(有黑边)\n",
    "    \"\"\"\n",
    "    R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(\n",
    "        K1, D1, K2, D2, image_size, R, T,\n",
    "        R1=None, # 第一个摄像机的校正变换矩阵（旋转变换）\n",
    "        R2=None, # 第二个摄像机的校正变换矩阵（旋转变换）\n",
    "        P1=None, # 第一个摄像机在**新**坐标系下的投影矩阵\n",
    "        P2=None, # 第二个摄像机在**新**坐标系下的投影矩阵\n",
    "        Q=None,  # 4*4的视差图到深度图的映射矩阵(disparity-to-depth mapping matrix )\n",
    "        flags=cv2.CALIB_ZERO_DISPARITY, alpha=alpha, newImageSize=None)\n",
    "    \n",
    "    # 畸变校正和立体校正的映射矩阵, 计算像素空间坐标的重投影矩阵\n",
    "    l_map_x, l_map_y = cv2.initUndistortRectifyMap(K1, D1, R1, P1, image_size, cv2.CV_32FC1)\n",
    "    r_map_x, r_map_y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, image_size, cv2.CV_32FC1)\n",
    "    return l_map_x, l_map_y, r_map_x, r_map_y, R1, R2, P1, P2, Q\n",
    "\n",
    "\n",
    "def get_depth(disparity, Q, scale=1.0, method=False):\n",
    "    # Q: 重投影矩阵\n",
    "    # Q = [\n",
    "    #    [1,   0,       0,         -cx]\n",
    "    #    [0,   1,       0,         -cy]\n",
    "    #    [0,   0,       0,           f]\n",
    "    #    [1,   0,   -1/Tx, (cx-cx`)/Tx]\n",
    "    # ]\n",
    "    \n",
    "    if method:\n",
    "        points_3d = cv2.reprojectImageTo3D(disparity, Q)  # 单位是毫米(mm)\n",
    "        x, y, depth = cv2.split(points_3d)\n",
    "    else:\n",
    "        baseline = 1 / Q[3, 2]\n",
    "        fx = abs(Q[2, 3])\n",
    "        depth = (fx * baseline) / disparity\n",
    "\n",
    "    return np.asarray(depth * scale, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb5cd5",
   "metadata": {},
   "source": [
    "### Callback Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29551c17",
   "metadata": {},
   "source": [
    "#### On Click Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd3c247",
   "metadata": {
    "code_folding": [
     2,
     79,
     151,
     434
    ]
   },
   "outputs": [],
   "source": [
    "# folding\n",
    "\n",
    "def on_start_collect_samples(ctx, w_btn, camera_source, camera_resolution, sample_size, flip, rm_out, save_dir, win_size, term_iters, term_eps, w_video):\n",
    "    segs = os.path.basename(save_dir).split('_')\n",
    "    # squares_x, squares_y, square_size, win_size, term_iters, term_eps = *list(map(int, segs[:-1])), float(segs[-1])\n",
    "    squares_x, squares_y, square_size = list(map(int, segs))\n",
    "    ctx.logger('on_start_collect_samples(%s, %s, %d, %d, %d, %d, %d, %d, %f, %d)' % (\n",
    "        ':'.join(camera_source), camera_resolution, sample_size, squares_x, squares_y, square_size, win_size, term_iters, term_eps,\n",
    "    flip), clear=1)\n",
    "    \n",
    "    pattern_size = (squares_x - 1, squares_y - 1)\n",
    "    win_size = (win_size, win_size)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "    \n",
    "    if rm_out:\n",
    "        shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            count = 0\n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                if idx % camera.fps == 0:\n",
    "                    if len(frames) == 2:\n",
    "                        frameL_copied, frameR_copied = frames[0].copy(), frames[1].copy()\n",
    "                        cornersL = detect_chessboard(frameL_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        cornersR = detect_chessboard(frameR_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        if cornersL is not None and cornersR is not None:\n",
    "                            count += 1\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"left_ori_{:0=3d}.png\".format(count)), frames[0])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"left_out_{:0=3d}.png\".format(count)), frameL_copied)\n",
    "\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"right_ori_{:0=3d}.png\".format(count)), frames[1])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"right_out_{:0=3d}.png\".format(count)), frameR_copied)\n",
    "\n",
    "                            cv2.putText(frameL_copied, f'Count: {count}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                            nbeasy_widget_display({'L': frameL_copied, 'R': frameR_copied}, w_video, resize=\"auto\")\n",
    "\n",
    "                            if count == sample_size:\n",
    "                                break\n",
    "                        else:\n",
    "                            nbeasy_widget_display({'L': frameL_copied, 'R': frameR_copied}, w_video, resize=\"auto\")\n",
    "                            \n",
    "                    else:\n",
    "                        frame_copied = frames[0]\n",
    "                        corners = detect_chessboard(frame_copied, pattern_size, criteria, win_size, draw=True)\n",
    "                        if corners is not None:\n",
    "                            count += 1\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"ori_{:0=3d}.png\".format(count)), frames[0])\n",
    "                            cv2.imwrite(os.path.join(save_dir, \"out_{:0=3d}.png\".format(count)), frame_copied)\n",
    "                            cv2.putText(frame_copied, f'Count: {count}', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                            nbeasy_widget_display(frame_copied, w_video)\n",
    "\n",
    "                            if count == sample_size:\n",
    "                                break\n",
    "                        else:\n",
    "                            nbeasy_widget_display(frameL_copied, w_video)\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    w_video.width, w_video.height = camera_resolution\n",
    "    camera = StereoCamera(camera_source[0], camera_resolution, camera_source[1] == 'binocular')\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "\n",
    "\n",
    "def on_stop_collect_samples(ctx, w_btn = None):\n",
    "    ctx.logger(\"on_stop_collect_samples\")\n",
    "    if hasattr(ctx, 'stereo_camera'):\n",
    "        ctx.stereo_camera.close() \n",
    "\n",
    "        \n",
    "def on_start_calibrition_test(ctx, w_btn, camera_source, camera_resolution, flip, save_dir, calibration_result, w_video):\n",
    "    ctx.logger('on_start_calibrition_test(%s, %s, %s)' % (':'.join(camera_source), camera_resolution, save_dir), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(calibration_result)\n",
    "\n",
    "            K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "            K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "            mapxL, mapyL, mapxR, mapyR = None, None, None, None\n",
    "            newcameramtxL, roiL, newcameramtxR, roiR = None, None, None, None\n",
    "            alpha = 0\n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_frames = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    display_frames['L'] = imgL\n",
    "                    display_frames['R'] = imgR\n",
    "                    t1 = time.time() * 1000\n",
    "                    undistort_imgL = cv2.undistort(imgL.copy(), K1, D1)\n",
    "                    t2 = time.time() * 1000\n",
    "                    undistort_imgR = cv2.undistort(imgR.copy(), K2, D2)\n",
    "                    t3 = time.time() * 1000\n",
    "                    display_frames[f'undist L {int(t2 - t1)}'] = undistort_imgL \n",
    "                    display_frames[f'undist R {int(t3 - t2)}'] = undistort_imgR\n",
    "                    \n",
    "                    # fast than undistort (speedup 2x - 5x)\n",
    "                    if mapxL is None:\n",
    "                        h, w = imgL.shape[:2]\n",
    "                        newcameramtxL, roiL = cv2.getOptimalNewCameraMatrix(K1, D1, (w, h), alpha=alpha, newImgSize=(w, h))\n",
    "                        newcameramtxR, roiR = cv2.getOptimalNewCameraMatrix(K2, D2, (w, h), alpha=alpha, newImgSize=(w, h))\n",
    "                        mapxL, mapyL = cv2.initUndistortRectifyMap(K1, D1, None, newcameramtxL, (w, h), cv2.CV_32FC1)\n",
    "                        mapxR, mapyR = cv2.initUndistortRectifyMap(K2, D2, None, newcameramtxR, (w, h), cv2.CV_32FC1)                        \n",
    "                    t4 = time.time() * 1000\n",
    "                    remap_imgL = cv2.remap(imgL.copy(), mapxL, mapyL, cv2.INTER_LINEAR)\n",
    "                    if alpha != 0:\n",
    "                        remap_imgL = remap_imgL[roiL[1]: roiL[1] + roiL[3], roiL[0]: roiL[0] + roiL[2]]\n",
    "                    t5 = time.time() * 1000\n",
    "                    remap_imgR = cv2.remap(imgR.copy(), mapxR, mapyR, cv2.INTER_LINEAR)\n",
    "                    if alpha != 0:\n",
    "                        remap_imgR = remap_imgR[roiL[1]: roiR[1] + roiR[3], roiR[0]: roiR[0] + roiR[2]]\n",
    "                    t6 = time.time() * 1000\n",
    "                    display_frames[f'remap L {int(t5 - t4)}'] = cv2.resize(remap_imgL, (w, h))\n",
    "                    display_frames[f'remap R {int(t6 - t5)}'] = cv2.resize(remap_imgR, (w, h))\n",
    "                    nbeasy_widget_display(display_frames, w_video, resize=\"auto\", ctx=ctx)\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        except Exception:\n",
    "            ctx.logger(f'{traceback.format_exc(limit=3)}')\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    w_video.width, w_video.height = camera_resolution\n",
    "    camera = StereoCamera(camera_source[0], camera_resolution, is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "    \n",
    "    \n",
    "on_stop_test = on_stop_collect_samples\n",
    "\n",
    "\n",
    "def on_start_rectification_test(ctx, w_btn, camera_source, camera_resolution, flip, save_dir, rectification_result, w_video):\n",
    "    ctx.logger('on_start_rectification_test(%s, %s)' % (':'.join(camera_source), save_dir), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(rectification_result)\n",
    "\n",
    "            K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "            K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "            \n",
    "            l_map, r_map = np.load(params['l_map_npz']), np.load(params['r_map_npz'])\n",
    "            l_map_x, l_map_y = l_map['l_map_x'], l_map['l_map_y']\n",
    "            r_map_x, r_map_y = r_map['r_map_x'], r_map['r_map_y']\n",
    "            interval = 25\n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_frames = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    display_frames['undist L'] = cv2.undistort(imgL.copy(), K1, D1)\n",
    "                    display_frames['undist R'] = cv2.undistort(imgR.copy(), K2, D2)\n",
    "                    \n",
    "                    rectifiedL = cv2.remap(imgL, l_map_x, l_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    rectifiedR = cv2.remap(imgR, r_map_x, r_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    \n",
    "                    # H = max(rectifiedL.shape[0], rectifiedR.shape[0])\n",
    "                    # W = rectifiedL.shape[1] + rectifiedR.shape[1]\n",
    "                    # rectify_image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "                    # rectify_image[0:rectifiedL.shape[0], 0:rectifiedL.shape[1]] = rectifiedL\n",
    "                    # rectify_image[0:rectifiedR.shape[0],  rectifiedL.shape[1]:] = rectifiedR\n",
    "                    # # 绘制等间距平行线\n",
    "                    # for k in range(H // interval):\n",
    "                    #     cv2.line(rectify_image, (0, interval * (k + 1)), (2 * W, interval * (k + 1)), COLORS.RED, 1, lineType=cv2.LINE_AA)\n",
    "                    for k in range(rectifiedL.shape[0] // interval):\n",
    "                        y = interval * (k + 1)\n",
    "                        cv2.line(rectifiedL, (0, y), (rectifiedL.shape[1], y), COLORS.RED, 1, lineType=cv2.LINE_AA)\n",
    "                    for k in range(rectifiedR.shape[0] // interval):\n",
    "                        y = interval * (k + 1)\n",
    "                        cv2.line(rectifiedR, (0, y), (rectifiedR.shape[1], y), COLORS.RED, 1, lineType=cv2.LINE_AA)\n",
    "                        \n",
    "                    display_frames['rectified L'] = rectifiedL\n",
    "                    display_frames['rectified R'] = rectifiedR\n",
    "                    \n",
    "                    nbeasy_widget_display(display_frames, w_video, resize=\"auto\")\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    w_video.width, w_video.height = camera_resolution\n",
    "    camera = StereoCamera(camera_source[0], camera_resolution, is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "    \n",
    "    \n",
    "def on_start_matcher(\n",
    "    ctx, w_btn, camera_source, camera_resolution, flip, save_dir, rectification_result, w_video,\n",
    "    num_disparities, uniqueness_ratio, window_size, speckle_size, speckle_range,\n",
    "    w_enable_visual_depth, w_enable_collect, w_regdata, w_reg_M, w_x, w_y, w_disp):\n",
    "    \n",
    "    ctx.logger('on_start_matcher(%s, %s, %d, %d, %d, %d, %d)' % (\n",
    "        ':'.join(camera_source), save_dir, num_disparities, window_size, speckle_size, speckle_range, uniqueness_ratio), clear=1)\n",
    "    is_3d = camera_source[1] == 'binocular'\n",
    "    if not is_3d:\n",
    "        ctx.logger('not 3d camera')\n",
    "        return\n",
    "    \n",
    "    def _solving_M(value_pairs):\n",
    "        # depth = M * (1/disparity)\n",
    "        z = value_pairs[:, 0]\n",
    "        disp = value_pairs[:, 1]\n",
    "        disp_inv = 1 / disp\n",
    "        coeff = np.vstack([disp_inv, np.ones(len(disp_inv))]).T\n",
    "        ret, sol = cv2.solve(coeff, z, flags=cv2.DECOMP_QR)\n",
    "        M = np.round(sol[0, 0], 2)\n",
    "        return M\n",
    "    \n",
    "    def _distance_avg(x, y, disp, window_size=3):\n",
    "        average = []\n",
    "        m = int(window_size * 0.5)\n",
    "        for u in range (-1 * m, m + 1):\n",
    "            for v in range (-1 * m, m + 1):\n",
    "                average.append(disp[y+u, x+v])\n",
    "        return sum(average) / len(average)\n",
    "        \n",
    "    def _camera_capture(camera, w_video, save_dir):\n",
    "        try:\n",
    "            w_btn.disabled = True\n",
    "            params = json.loads(rectification_result)\n",
    "            l_map, r_map = np.load(params['l_map_npz']), np.load(params['r_map_npz'])\n",
    "            l_map_x, l_map_y = l_map['l_map_x'], l_map['l_map_y']\n",
    "            r_map_x, r_map_y = r_map['r_map_x'], r_map['r_map_y']\n",
    "            \n",
    "            Q = np.asarray(params['Q'])\n",
    "            M = params['M'] if 'M' in params else 0\n",
    "            if 'M' in params:\n",
    "                w_reg_M.value = params['M']\n",
    "            if w_enable_collect.value:\n",
    "                w_reg_M.value = 0\n",
    "            matcher = cv2.StereoSGBM_create(\n",
    "                minDisparity=0,\n",
    "                numDisparities=16*num_disparities,  # specify the acceptable range for which pixels can move\n",
    "                blockSize=window_size,              # to normalize brightness and enhance texture\n",
    "                P1=8 * 3 * (window_size ** 2),      # 惩罚系数 控制视差平滑度，一般：P1=8*通道数*SADWindowSize*SADWindowSize\n",
    "                P2=32 * 3 * (window_size ** 2),     # P2=4*P1, p2值越大，差异越平滑   \n",
    "                # disp12MaxDiff=1,                  # the maximum diff between the disparities calculated from left to right and those from right to left.\n",
    "                # preFilterCap=64,\n",
    "                uniquenessRatio=uniqueness_ratio,   # post processing: a threshold for the match value to remove false positives\n",
    "                speckleWindowSize=speckle_size,     # near the boundaries of objects, one picture can see “behind” while the other can’t\n",
    "                speckleRange=speckle_range,\n",
    "                mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "            matcherL = matcher\n",
    "            \n",
    "            if w_enable_visual_depth.value:\n",
    "                matcherR = cv2.ximgproc.createRightMatcher(matcherL)\n",
    "                wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=matcherL)\n",
    "                wls_filter.setLambda(80000)\n",
    "                wls_filter.setSigmaColor(1.3)\n",
    "            \n",
    "            point_pairs = None\n",
    "            focal_length = Q[2, 3]\n",
    "            baseline = 1 / Q[3, 2]\n",
    "            ctx.logger(f'baseline = {baseline} mm focal_length = {focal_length} pixel')\n",
    "            BF = round(baseline * focal_length, 2)\n",
    "            \n",
    "            minDisp = matcherL.getMinDisparity()\n",
    "            numDisp = matcherL.getNumDisparities()\n",
    "            ctx.logger(f'minDisp: {minDisp}, numDisp: {numDisp}, speckleWindowSize: {speckle_size}')\n",
    "            for idx, frames in camera.read(flip=flip):\n",
    "                display_images = {}\n",
    "                if len(frames) == 2:\n",
    "                    imgL, imgR = frames\n",
    "                    # 畸变校正和立体校正\n",
    "                    rectifiedL = cv2.remap(imgL, l_map_x, l_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    rectifiedR = cv2.remap(imgR, r_map_x, r_map_y, cv2.INTER_LINEAR, borderValue=cv2.BORDER_CONSTANT)\n",
    "                    \n",
    "                    grayL = cv2.cvtColor(rectifiedL, cv2.COLOR_BGR2GRAY)\n",
    "                    grayR = cv2.cvtColor(rectifiedR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    dispL = matcherL.compute(grayL, grayR)\n",
    "                    if w_enable_visual_depth.value:\n",
    "                        dispR = matcherR.compute(grayR, grayL)\n",
    "                        filter_depth = wls_filter.filter(dispL, imgL, None, dispR)\n",
    "                        filter_depth = filter_depth.astype(np.float32) / 16.\n",
    "                        ctx.logger(f'{filter_depth}')\n",
    "                        filter_depth[filter_depth < minDisp] = minDisp\n",
    "                        filter_depth[filter_depth > numDisp] = numDisp\n",
    "                        filter_depth = np.clip(filter_depth, 0, 6666)\n",
    "                        filter_depth = cv2.normalize(src=filter_depth, dst=filter_depth, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX);\n",
    "                        display_images['WFS Depth'] = cv2.applyColorMap(np.uint8(filter_depth), cv2.COLORMAP_JET)\n",
    "                        \n",
    "                    dispL = dispL.astype(np.float32) / 16.\n",
    "                    dispL[dispL < minDisp] = minDisp\n",
    "                    dispL[dispL > numDisp] = numDisp\n",
    "                    points_3d = cv2.reprojectImageTo3D(dispL, Q)\n",
    "                    \n",
    "                    # 9.26 \n",
    "                    # disparity[disparity <= 0] = disparity.max()\n",
    "                    # disparity = (disparity / 16.0 - minDisp) / numDisparities\n",
    "                    ## assert np.all(disparity > 0)\n",
    "                    \n",
    "                    ix, iy = w_x.value, w_y.value\n",
    "                    cv2.circle(rectifiedL, (ix, iy), radius=speckle_size, color=COLORS.ORANGE, thickness=-1)\n",
    "                    X, Y, Z = np.int16(points_3d[iy, ix]).tolist()\n",
    "                    # d = get_depth(disparity, Q)[ix, iy]\n",
    "                    cv2.putText(\n",
    "                        rectifiedL, \n",
    "                        f'{X}, {Y}, {Z}',\n",
    "                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                    display_images['L'] = rectifiedL\n",
    "                    \n",
    "                    nbeasy_widget_display(display_images, w_video, resize=\"auto\", ctx=ctx)\n",
    "                    \n",
    "                    # if w_enable_collect.value:\n",
    "                    #     w_disp.value = round(disparity[iy, ix], 5)\n",
    "                    #     cv2.putText(\n",
    "                    #         rectifiedL, \n",
    "                    #         f'Disp: {w_disp.value}',\n",
    "                    #         (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                    # else:\n",
    "                    #     if w_reg_M.value  == 0 and len(w_regdata.options) > 0:\n",
    "                    #         point_pairs = np.array([[o[0], o[1]] for _, o in w_regdata.options]).reshape((-1, 1, 2))\n",
    "                    #         value_pairs = np.array([[o[3], o[2]] for _, o in w_regdata.options])\n",
    "                    #         w_reg_M.value = _solving_M(value_pairs)\n",
    "# \n",
    "                    #     # if point_pairs is not None:\n",
    "                    #     #     rectifiedL = cv2.polylines(rectifiedL, [point_pairs], True, COLORS.WHITE, thickness=2)\n",
    "                    #         \n",
    "                    # if w_reg_M.value != 0:\n",
    "                    #     distances = w_reg_M.value / disparity\n",
    "                    #     D1 = _distance_avg(ix, iy, distances, window_size)\n",
    "                    #     D2 = distances[iy, ix]\n",
    "                    #     cv2.putText(\n",
    "                    #         rectifiedL, \n",
    "                    #         f'M:{w_reg_M.value}, BF:{BF} D1:{D1:.2f} D2:{D2:.2f}',\n",
    "                    #         (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                    #         \n",
    "                    # nbeasy_widget_display(display_images, w_video, resize=\"auto\")\n",
    "                    # \n",
    "                    # # disparity = matcherL.compute(rectifiedL, rectifiedR).astype(np.float32) / 16.0\n",
    "                    # # optimal_disparity = (disparity - minDisp) / numDisparities\n",
    "                    # # distance = baseline * focal_length / optimal_disparity\n",
    "                    # # distance = distance[int(0.5 * optimal_disparity.shape[0]), int(0.5 * optimal_disparity.shape[1])]\n",
    "                    # # # distance = -593.97*distance**(3) + 1506.8*distance**(2) - 1373.1*distance + 522.06\n",
    "                    # # cv2.putText(\n",
    "                    # #     rectify_image, \n",
    "                    # #     f'3D(center): {int(focal_length)} {int(baseline)} {distance}',\n",
    "                    # #     (int(0.2 * W), int(0.2 * H)), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "# \n",
    "                    # # dispL = np.uint16(matcherL.compute(grayL, grayR))\n",
    "                    # # dispR = np.uint16(matcherR.compute(grayR, grayL))\n",
    "                    # # dispL = np.uint16(filter_.filter(dispL, grayL, None, dispR))\n",
    "                    # # dispL[dispL < 0] = 0\n",
    "                    # # dispL = dispL.astype(np.float32) / 16.\n",
    "                    # # disparity = (disparity/16.0 - minDisparity)/numDisparities\n",
    "                    # # \n",
    "                    # # points_3d = cv2.reprojectImageTo3D(dispL, Q)\n",
    "                    # # points_3d = np.round(np.asarray(points_3d, dtype=np.float32), 2)\n",
    "                    # # \n",
    "                    # # distance = points_3d[int(0.5 * dispL.shape[0]), int(0.5 * dispL.shape[1])][2]\n",
    "                    # # \n",
    "                    # # cv2.putText(\n",
    "                    # #     rectify_image, \n",
    "                    # #     f'3D(center): {distance}',\n",
    "                    # #     (int(0.2 * W), int(0.7 * H)), cv2.FONT_HERSHEY_SIMPLEX, 1, COLORS.BLUE, 2)\n",
    "                    # # nbeasy_widget_display(rectify_image, w_video)\n",
    "                else:\n",
    "                    raise NotImplemented\n",
    "        except (StopIteration, RuntimeError):\n",
    "            pass\n",
    "        except Exception:\n",
    "            ctx.logger(traceback.format_exc(limit=3))\n",
    "        finally:\n",
    "            camera.close()\n",
    "            w_btn.disabled = False\n",
    "\n",
    "    w_video.width, w_video.height = camera_resolution\n",
    "    camera = StereoCamera(camera_source[0], camera_resolution, is_3d)\n",
    "    ctx.logger(f'video shape: {camera.open()}')\n",
    "    ctx.stereo_camera = camera\n",
    "    calibrate_thread = threading.Thread(target=_camera_capture, name='stereocamera', args=(camera, w_video, save_dir))\n",
    "    calibrate_thread.daemon = True\n",
    "    calibrate_thread.start()\n",
    "\n",
    "    \n",
    "on_stop_matcher = on_stop_collect_samples\n",
    "\n",
    "\n",
    "def on_remove_sample(ctx, w_btn, w_sample_list):\n",
    "    sample_path = w_sample_list.value\n",
    "    ctx.logger(f'on_remove_sample({sample_path})')\n",
    "    if os.path.exists(sample_path):\n",
    "        os.remove(sample_path)\n",
    "        if 'binocular' in sample_path:\n",
    "            os.remove(sample_path.replace('left', 'right'))\n",
    "    index = w_sample_list.index\n",
    "    options = list(copy.copy(w_sample_list.options))\n",
    "    ctx.logger(f'remove: {options.pop(index)}')\n",
    "    w_sample_list.options = options\n",
    "    w_sample_list.index = index if index < len(options) else index - 1\n",
    "\n",
    "\n",
    "def on_refresh_sample(ctx, w_btn, w_sample_list, save_dir):\n",
    "    ctx.logger(f'on_refresh_sample({save_dir})')\n",
    "    \n",
    "    options = []\n",
    "    if 'binocular' in save_dir:\n",
    "        left_sample_list = sorted(glob.glob(f'{save_dir}/left_out_*.png'))\n",
    "        right_sample_list = sorted(glob.glob(f'{save_dir}/right_out_*.png'))\n",
    "        ctx.logger(f'left samples count: {len(left_sample_list)}, right samples count: {len(right_sample_list)}')\n",
    "        assert len(left_sample_list) == len(right_sample_list)\n",
    "        for imgpath in left_sample_list:\n",
    "            imgfile = os.path.basename(imgpath)\n",
    "            options.append((imgfile[5:-4], imgpath))\n",
    "    else:\n",
    "        sample_list = sorted(glob.glob(f'{save_dir}/out_*.png'))\n",
    "        for imgpath in sample_list:\n",
    "            imgfile = os.path.basename(imgpath)\n",
    "            options.append((imgfile[:-4], imgpath))\n",
    "    \n",
    "    w_sample_list.options = options\n",
    "\n",
    "\n",
    "def on_start_calibration(ctx, w_btn, w_sample_list, w_calibration_result, win_size, term_iters, term_eps, flags):\n",
    "    try:\n",
    "        w_btn.disabled = True\n",
    "        w_calibration_result.value = ''\n",
    "        options = w_sample_list.options\n",
    "        ctx.logger(f'on_start_calibration({len(options)}, {flags})', clear=1)\n",
    "        if len(options) == 0:\n",
    "            return\n",
    "\n",
    "        save_dir = os.path.dirname(options[0][1])\n",
    "        segs = os.path.basename(save_dir).split('_')\n",
    "        squares_x, squares_y, square_size = list(map(int, segs))\n",
    "        pattern_size = (squares_x - 1, squares_y - 1) # Number of inner corners per a chessboard row and column\n",
    "        world_point = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "        world_point[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "        world_point = world_point * square_size\n",
    "\n",
    "        win_size = (win_size, win_size)\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, term_iters, term_eps)\n",
    "\n",
    "        ctx.logger(f'on_start_calibration({win_size}, {pattern_size}, {criteria})')\n",
    "        image_files = [x[1].replace('out_', 'ori_') for x in options]\n",
    "        if 'binocular' in save_dir:\n",
    "            image_L_files = image_files\n",
    "            image_R_files = [x.replace('left', 'right') for x in image_L_files]\n",
    "            image_size, error, K1, D1, K2, D2, R, T, E, F = calibrate_binocular_camera(\n",
    "                ctx, image_L_files, image_R_files, world_point, pattern_size, criteria, win_size, sum(flags))\n",
    "            result = {\n",
    "                'image_size': image_size,\n",
    "                'error': error,\n",
    "                'K1': K1, 'D1': D1,\n",
    "                'K2': K2, 'D2': D2,\n",
    "                'R': R, 'T': T, 'E': E, 'F': F\n",
    "            }\n",
    "        else:\n",
    "            image_size, error, mtx, dist = calibrate_monocular_camera(ctx, image_files, world_point, pattern_size, criteria, win_size)\n",
    "            result = {\n",
    "                'image_size': image_size,\n",
    "                'error': error,\n",
    "                'K': mtx, 'D': dist\n",
    "            }\n",
    "        w_calibration_result.value = json.dumps(result, indent=4)\n",
    "    finally:\n",
    "        w_btn.disabled = False\n",
    "\n",
    "\n",
    "def on_save_calibration_result(ctx, w_btn, calibration_result, save_dir):\n",
    "    ctx.logger(f'on_save_calibration_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    with open(f'{save_dir}/{prefix}_calibration.json', 'w') as f:\n",
    "        f.write(calibration_result)\n",
    "        \n",
    "    \n",
    "def on_load_calibration_result(ctx, w_btn, w_calibration_result, save_dir):\n",
    "    ctx.logger(f'on_load_calibration_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    try:\n",
    "        file = f'{save_dir}/{prefix}_calibration.json'\n",
    "        with open(file, 'r') as f:\n",
    "            w_calibration_result.value = f.read()\n",
    "    except Exception:\n",
    "        w_calibration_result.value = f'Open {file} Error'\n",
    "        \n",
    "\n",
    "def on_start_rectify(ctx, w_btn, calibration_result, w_rectify_result, save_dir, alpha):\n",
    "    ctx.logger(f'on_start_rectify({alpha})')\n",
    "    try:\n",
    "        w_btn.disabled = True \n",
    "        w_rectify_result.value = ''\n",
    "        params = json.loads(calibration_result)\n",
    "        K1, D1 = np.asarray(params['K1']), np.asarray(params['D1'])\n",
    "        K2, D2 = np.asarray(params['K2']), np.asarray(params['D2'])\n",
    "        image_size, R, T = params['image_size'], np.asarray(params['R']), np.asarray(params['T'])\n",
    "        l_map_x, l_map_y, r_map_x, r_map_y, R1, R2, P1, P2, Q = rectify_binocular_camera(\n",
    "            ctx, K1, D1, K2, D2, image_size, R, T, alpha)\n",
    "        \n",
    "        np.savez(f'{save_dir}/l_map.npz', l_map_x=l_map_x, l_map_y=l_map_y)\n",
    "        np.savez(f'{save_dir}/r_map.npz', r_map_x=r_map_x, r_map_y=r_map_y)\n",
    "        \n",
    "        result = {\n",
    "            **params,\n",
    "            'l_map_npz': f'{save_dir}/l_map.npz',\n",
    "            'r_map_npz': f'{save_dir}/r_map.npz',\n",
    "            'R1': R1, 'R2': R2, 'P1': P1, 'P2': P2, 'Q': Q\n",
    "        }\n",
    "        # ctx.logger(f'{Q[2, 3]}, {-1 / Q[3, 2]}, {T[0]}')\n",
    "        w_rectify_result.value = json.dumps(result, indent=4)\n",
    "    except Exception:\n",
    "        ctx.logger(f'{traceback.format_exc(limit=6)}')\n",
    "        ctx.logger(f'{calibration_result}')\n",
    "    finally:\n",
    "        w_btn.disabled = False\n",
    "\n",
    "\n",
    "def on_save_rectification_result(ctx, w_btn, rectification_result, save_dir, reg_M):\n",
    "    ctx.logger(f'on_save_rectification_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    data = json.loads(rectification_result)\n",
    "    data['M'] = reg_M\n",
    "    with open(f'{save_dir}/{prefix}_rectification.json', 'w') as f:\n",
    "        f.write(json.dumps(data, indent=4))\n",
    "\n",
    "\n",
    "def on_load_rectification_result(ctx, w_btn, w_rectification_result, save_dir):\n",
    "    ctx.logger(f'on_load_rectification_result({save_dir})')\n",
    "    prefix = 'binocular' if 'binocular' in save_dir else 'monocular'\n",
    "    try:\n",
    "        file = f'{save_dir}/{prefix}_rectification.json'\n",
    "        with open(file, 'r') as f:\n",
    "            w_rectification_result.value = f.read()\n",
    "    except Exception:\n",
    "        w_rectification_result.value = f'Open {file} Error'\n",
    "\n",
    "    \n",
    "def on_add_regression_data(ctx, w_btn, w_regdata, ix, iy, disp, wd):\n",
    "    ctx.logger(f'on_save_regression_data({ix}, {iy}, {disp}, {wd})')\n",
    "    options = list(w_regdata.options)\n",
    "    if wd == 0:\n",
    "        return\n",
    "    options.append([wd, (int(ix), int(iy), disp, wd)])\n",
    "    w_regdata.options = options\n",
    "    w_regdata.index = len(w_regdata.options) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21721d9",
   "metadata": {},
   "source": [
    "#### On Interactive Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e557e15",
   "metadata": {
    "code_folding": [
     0,
     14,
     19
    ]
   },
   "outputs": [],
   "source": [
    "def on_update_sample_dir(\n",
    "    ctx, w_save_dir, w_calibration_result, w_rectification_result, camera_source, chessboard):\n",
    "    squares_x, squares_y, square_size = chessboard\n",
    "    save_dir = f'out/{camera_source[1]}/chessboard/{squares_x}_{squares_y}_{square_size}'\n",
    "    w_save_dir.value = save_dir\n",
    "    ctx.logger(f'on_update_sample_dir({save_dir})')\n",
    "    \n",
    "    on_load_calibration_result(ctx, None, w_calibration_result, save_dir)\n",
    "    if camera_source[1] == 'binocular':\n",
    "        on_load_rectification_result(ctx, None, w_rectification_result, save_dir)\n",
    "\n",
    "\n",
    "def on_update_sample_list(ctx, w_sample_list, save_dir):\n",
    "    ctx.logger(f'on_update_sample_list({save_dir})')\n",
    "    if not os.path.isdir(save_dir):\n",
    "        return\n",
    "    on_refresh_sample(ctx, None, w_sample_list, save_dir)\n",
    "\n",
    "\n",
    "def on_update_sample_image(ctx, w_video_frame, sample_path):\n",
    "    ctx.logger(f'on_update_sample_image({sample_path})')\n",
    "    if sample_path is None or not os.path.exists(sample_path):\n",
    "        ctx.logger(f'not found {sample_path}')\n",
    "        return\n",
    "    if 'binocular' in sample_path:\n",
    "        imgL = cv2.imread(sample_path)\n",
    "        imgR = cv2.imread(sample_path.replace('left', 'right'))\n",
    "        nbeasy_widget_display({'L': imgL, 'R': imgR}, w_video_frame, resize='auto')\n",
    "    else:\n",
    "        img = cv2.imread(sample_path)\n",
    "        nbeasy_widget_display(img, w_video_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995bb09",
   "metadata": {},
   "source": [
    "#### On Canvas Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bbf6c8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def on_canvas_video_mouse_up(ctx, w_canvas, x, y, w_ix, w_iy):\n",
    "    ctx.logger(f'on_canvas_video_mouse_up({x, y})')\n",
    "    w_ix.value = int(x)\n",
    "    w_iy.value = int(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947bd2e",
   "metadata": {},
   "source": [
    "### Template Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb4acde",
   "metadata": {
    "code_folding": [
     2,
     12,
     282
    ]
   },
   "outputs": [],
   "source": [
    "# _IMPORT('./easy_widget.py')\n",
    "\n",
    "def nbeasy_chessboard_choice_objs(nrow, ncol, square_size, width=300, ro=True):\n",
    "    return {\n",
    "        'type': 'H',\n",
    "        'objs': [\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_x', 'Squares X', nrow, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_squares_y', 'Squares Y', ncol, width=width, readonly=ro),\n",
    "            nbeasy_widget_int('cfg.chessboard_square_size', 'Square Size(mm)', square_size, width=width, readonly=ro)        \n",
    "        ]\n",
    "    }\n",
    "\n",
    "FLAGS = [\n",
    "    'cv2.CALIB_FIX_INTRINSIC',\n",
    "    'cv2.CALIB_USE_INTRINSIC_GUESS',\n",
    "    'cv2.CALIB_FIX_ASPECT_RATIO',\n",
    "    'cv2.CALIB_ZERO_TANGENT_DIST',\n",
    "    'cv2.CALIB_SAME_FOCAL_LENGTH',\n",
    "    'cv2.CALIB_RATIONAL_MODEL',\n",
    "    'cv2.CALIB_FIX_K3',\n",
    "    'cv2.CALIB_FIX_K4',\n",
    "    'cv2.CALIB_FIX_K5'\n",
    "]\n",
    "\n",
    "W, H = 640, 480 \n",
    "\n",
    "schema = {\n",
    "    'type': 'page',\n",
    "    'objs': [\n",
    "        {\n",
    "            'type': 'tab',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'name': 'Capture',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Chessboard',\n",
    "                            'objs': [\n",
    "                                nbeasy_widget_stringenumtrigger(\n",
    "                                    '_cfg.chessboard_choice', 'Board', default=0,\n",
    "                                    enums = [('A4-30mm-9x7', (9, 7, 30)), ('A3-25mm-16x11', (16, 11, 25))],\n",
    "                                    triggers = [\n",
    "                                        nbeasy_chessboard_choice_objs(9, 7, 30),\n",
    "                                        nbeasy_chessboard_choice_objs(16, 11, 25),\n",
    "                                    ],\n",
    "                                    width=333),\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_int('cfg.chessboard_win_size', 'Win Size', default=5, tips='search area'),\n",
    "                                        nbeasy_widget_int('cfg.chessboard_term_iters', 'Term Iters', default=100, tips='number of iteration'),\n",
    "                                        nbeasy_widget_float('cfg.chessboard_term_eps', 'Term EPS', default=1e-5, tips='accuracy'),\n",
    "                                    ]\n",
    "                                },\n",
    "                            ]\n",
    "                        }, # end Chessboard\n",
    "                        { 'type': 'html', 'text': '<hr>'},\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'name': 'Samples',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_stringenum('cfg.select_camera_source', 'Select Camera', default=-1, enums=_get_cameras()),\n",
    "                                        nbeasy_widget_int('cfg.sample_size', 'Sample Size', 32),\n",
    "                                        nbeasy_widget_stringenum(\n",
    "                                            f'cfg.select_camera_resolution', 'Resolution', default=1,\n",
    "                                            enums=[('640x480', [640, 480]), ('1280x960', [1280, 960])],\n",
    "                                        ),\n",
    "                                        nbeasy_widget_stringenum(\n",
    "                                            'cfg.select_flip', 'Flip',\n",
    "                                            enums=[\n",
    "                                                ('None', -2),\n",
    "                                                ('Horizontal', 1),\n",
    "                                                ('Vertical', 0),\n",
    "                                                ('Both', -1)\n",
    "                                            ],\n",
    "                                        ),\n",
    "                                    ],\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_string('cfg.sample_save_dir', 'Save Dir', \"\", width=605, readonly=True),\n",
    "                                        nbeasy_widget_bool('cfg.rm_out', '<font color=\"red\">Clear Images</font>', False),\n",
    "                                    ]\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.btn_start_collect_samples', 'Start', style='success', icon='camera'),\n",
    "                                                nbeasy_widget_button('__cfg.btn_stop_collect_samples', 'Stop', style='success', icon='stop-circle'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        nbeasy_widget_image('__cfg.video_frame_capture', 'Frame', '', width=W, height=H),\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_stringenum('cfg.sample_list', 'Sample', width=200, description_width=0, btn_prev=True, btn_next=True),\n",
    "                                                nbeasy_widget_button('__cfg.btn_del_sample', 'Remove', style='danger', icon='trash', width=100),\n",
    "                                                nbeasy_widget_button('__cfg.btn_refresh_sample', 'Refresh', style='info', icon='refresh', width=100),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        }\n",
    "                                    ],\n",
    "                                    'align_items': 'center'\n",
    "                                },\n",
    "                            ],\n",
    "                        }, # end Samples\n",
    "                    ]\n",
    "                }, # end tab Capture\n",
    "                {\n",
    "                    'name': 'Calibrate',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'H',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.start_calibration', 'Calibrate', style='success', icon='check'),\n",
    "                                                nbeasy_widget_button('__cfg.save_calibration_result', 'Save', style='success', icon='floppy-o'),\n",
    "                                                nbeasy_widget_button('__cfg.load_calibration_result', 'Load', style='success', icon='spinner'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        }, \n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_text('__cfg.calibration_result', '', width=500, height=290)\n",
    "                                            ],\n",
    "                                            'justify_content': 'center',\n",
    "                                            'height': 310,\n",
    "                                        },\n",
    "                                    ],\n",
    "                                    'width': '40%',\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {'type': 'html', 'text': '<center><span><b>Flags</b></span></center>'},\n",
    "                                        nbeasy_widget_multiselect_simple(\n",
    "                                            'cfg.stereo_calibrate_flags', '',\n",
    "                                            default=[0],\n",
    "                                            enums=[('NONE', 0)] + [(x.split('.')[1], eval(x)) for x in FLAGS],\n",
    "                                            height=180,\n",
    "                                        ),\n",
    "                                        {'type': 'html', 'text': '<center><span><b>Alpha</b></span></center>'},\n",
    "                                        nbeasy_widget_float('cfg.rectify_alpha', '', default=0, min_=-1, max_=1, step=0.1)\n",
    "                                    ],\n",
    "                                    'width': '20%'\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.start_rectification', 'Rectify', style='success', icon='check'),\n",
    "                                                nbeasy_widget_button('__cfg.save_rectification_result', 'Save', style='success', icon='floppy-o'),\n",
    "                                                nbeasy_widget_button('__cfg.load_rectification_result', 'Load', style='success', icon='spinner'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_text('__cfg.rectification_result', '', width=520, height=290)\n",
    "                                            ],\n",
    "                                            'justify_content': 'center',\n",
    "                                            'height': 310,\n",
    "                                        },\n",
    "                                    ],\n",
    "                                    'width': '40%'\n",
    "                                },\n",
    "                            ],\n",
    "                            'align_items': 'center',\n",
    "                        }, # end H\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'H',\n",
    "                                    'objs': [\n",
    "                                        nbeasy_widget_button('__cfg.btn_start_c_test',  'Test Calibration', style='success', icon='camera'),\n",
    "                                        nbeasy_widget_button('__cfg.btn_stop_test', 'Stop Test', style='success', icon='stop-circle'),\n",
    "                                        nbeasy_widget_button('__cfg.btn_start_r_test', 'Test Rectification', style='success', icon='camera'),\n",
    "                                    ],\n",
    "                                    'justify_content': 'center'\n",
    "                                },\n",
    "                                nbeasy_widget_image('__cfg.video_frame_test', 'Frame', '', width=W, height=H),\n",
    "                            ],\n",
    "                            'align_items': 'center'\n",
    "                        },\n",
    "                    ]\n",
    "                }, # end tab Calibration\n",
    "                {\n",
    "                    'name': 'Matcher',\n",
    "                    'objs': [\n",
    "                        {\n",
    "                            'type': 'V',\n",
    "                            'objs': [\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_int('cfg.num_disp', 'Num Disparities', 16, min_=1, max_=16, width=280),\n",
    "                                                nbeasy_widget_int('cfg.uniqueness_ratio', 'Uniqueness Ratio', 10, min_=-1, max_=25, width=280),\n",
    "                                                nbeasy_widget_int('cfg.sad_winsize', 'SAD Window Size', 11, min_=3, max_=27, step=2, slider=True),\n",
    "                                                nbeasy_widget_int('cfg.speckle_size', 'Speckle Size', 15, min_=10, max_=200, step=5, slider=True),\n",
    "                                                nbeasy_widget_stringenum('cfg.speckle_range', 'Speckle Rang', 0, enums=[('1', 1), ('2', 2), ('3', 3)]),\n",
    "                                            ]\n",
    "                                        },\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_button('__cfg.btn_start_matcher', 'Start', style='success', icon='camera'),\n",
    "                                                nbeasy_widget_button('__cfg.btn_stop_matcher', 'Stop', style='success', icon='stop-circle'),\n",
    "                                                nbeasy_widget_bool('cfg.enable_visual_depth', 'Visual Depth', default=False, width=200, description_width=0),\n",
    "                                                nbeasy_widget_bool('cfg.enable_regression_samples', 'Collect D Samples', default=False, width=200, description_width=0),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        nbeasy_widget_canvas('__cfg.video_frame_matcher', width=W, height=H),\n",
    "                                    ],\n",
    "                                    'align_items': 'center'\n",
    "                                },\n",
    "                                {\n",
    "                                    'type': 'V',\n",
    "                                    'objs': [\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_int('cfg.image_x', 'Image X', width=250, readonly=True),\n",
    "                                                nbeasy_widget_int('cfg.image_y', 'Image Y', width=250, readonly=True),\n",
    "                                                nbeasy_widget_float('cfg.disp', 'Disp', width=250, readonly=True),\n",
    "                                                nbeasy_widget_float('cfg.world_d', 'World D', width=250),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                        {\n",
    "                                            'type': 'H',\n",
    "                                            'objs': [\n",
    "                                                nbeasy_widget_stringenum('cfg.regression_data', 'Regress Data', width=250, btn_delete=True),\n",
    "                                                nbeasy_widget_button('__cfg.btn_reg_data_add', 'Add', width=100, style='success', icon='add'),\n",
    "                                                nbeasy_widget_float('cfg.reg_M', 'M', default=0, width=250, readonly=False),\n",
    "                                                nbeasy_widget_button('__cfg.btn_reg_M_save', 'Save M', width=100, style='success', icon='save'),\n",
    "                                            ],\n",
    "                                            'justify_content': 'center'\n",
    "                                        },\n",
    "                                    ],\n",
    "                                    'align_items': 'center'\n",
    "                                },\n",
    "                            ],\n",
    "                        },\n",
    "                    ]\n",
    "                }, # end tab Matcher\n",
    "            ]\n",
    "        }, # end tab\n",
    "    ], # end pages\n",
    "    'evts': [\n",
    "        {\n",
    "            'type': 'jslink',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_matcher:disabled'\n",
    "                },\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_c_test:disabled'\n",
    "                },\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_collect_samples:disabled',\n",
    "                    'target': '__cfg.btn_start_r_test:disabled'\n",
    "                },\n",
    "                {\n",
    "                    'source': '__cfg.btn_start_r_test:disabled',\n",
    "                    'target': '__cfg.btn_start_c_test:disabled'\n",
    "                },\n",
    "            ]\n",
    "        }, # end jslink\n",
    "        {\n",
    "            'type': 'onclick',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': on_start_collect_samples,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_collect_samples'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_camera_resolution:value',\n",
    "                            'cfg.sample_size:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.rm_out:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.chessboard_win_size:value',\n",
    "                            'cfg.chessboard_term_iters:value',\n",
    "                            'cfg.chessboard_term_eps:value',\n",
    "                            '__cfg.video_frame_capture',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start collect samples\n",
    "                {\n",
    "                    'handler': on_stop_collect_samples,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_collect_samples'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop collect samplesn\n",
    "                {\n",
    "                    'handler': on_start_calibrition_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_c_test'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_camera_resolution:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            '__cfg.calibration_result:value',\n",
    "                            '__cfg.video_frame_test',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start c test\n",
    "                {\n",
    "                    'handler': on_stop_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_test'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop c test\n",
    "                {\n",
    "                    'handler': on_start_rectification_test,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_r_test'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_camera_resolution:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            '__cfg.rectification_result:value',\n",
    "                            '__cfg.video_frame_test',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start c test\n",
    "                {\n",
    "                    'handler': on_start_matcher,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_start_matcher'],\n",
    "                        'targets': [\n",
    "                            'cfg.select_camera_source:value',\n",
    "                            'cfg.select_camera_resolution:value',\n",
    "                            'cfg.select_flip:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            '__cfg.rectification_result:value',\n",
    "                            '__cfg.video_frame_matcher',\n",
    "                            'cfg.num_disp:value', 'cfg.uniqueness_ratio:value',\n",
    "                            'cfg.sad_winsize:value', 'cfg.speckle_size:value', 'cfg.speckle_range:value',\n",
    "                            'cfg.enable_visual_depth', 'cfg.enable_regression_samples',\n",
    "                            'cfg.regression_data',\n",
    "                            'cfg.reg_M',\n",
    "                            'cfg.image_x',\n",
    "                            'cfg.image_y',\n",
    "                            'cfg.disp'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event start matcher\n",
    "                {\n",
    "                    'handler': on_stop_matcher,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_stop_matcher'],\n",
    "                        'targets': []\n",
    "                    }\n",
    "                }, # end event stop matcher\n",
    "                {\n",
    "                    'handler': on_remove_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_del_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list' \n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event remove sample\n",
    "                {\n",
    "                    'handler': on_refresh_sample,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_refresh_sample'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ] \n",
    "                    }\n",
    "                }, # end event refresh sample\n",
    "                {\n",
    "                    'handler': on_start_calibration,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.start_calibration'],\n",
    "                        'targets': [\n",
    "                            'cfg.sample_list',\n",
    "                            '__cfg.calibration_result',\n",
    "                            'cfg.chessboard_win_size:value',\n",
    "                            'cfg.chessboard_term_iters:value',\n",
    "                            'cfg.chessboard_term_eps:value',\n",
    "                            'cfg.stereo_calibrate_flags:value',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event calibrator\n",
    "                {\n",
    "                    'handler': on_save_calibration_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.save_calibration_result'],\n",
    "                        'targets': [\n",
    "                            '__cfg.calibration_result:value',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on save calibration result\n",
    "                {\n",
    "                    'handler': on_load_calibration_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.load_calibration_result'],\n",
    "                        'targets': [\n",
    "                            '__cfg.calibration_result',\n",
    "                            'cfg.sample_save_dir:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on load calibration result\n",
    "                {\n",
    "                    'handler': on_start_rectify,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.start_rectification'],\n",
    "                        'targets': [\n",
    "                            '__cfg.calibration_result:value',\n",
    "                            '__cfg.rectification_result',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.rectify_alpha:value',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event rectify\n",
    "                {\n",
    "                    'handler': on_save_rectification_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.save_rectification_result', '__cfg.btn_reg_M_save'],\n",
    "                        'targets': [\n",
    "                            '__cfg.rectification_result:value',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                            'cfg.reg_M:value'\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on save rectification result\n",
    "                {\n",
    "                    'handler': on_load_rectification_result,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.load_rectification_result'],\n",
    "                        'targets': [\n",
    "                            '__cfg.rectification_result',\n",
    "                            'cfg.sample_save_dir:value',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on load rectification result\n",
    "                {\n",
    "                    'handler': on_add_regression_data,\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.btn_reg_data_add'],\n",
    "                        'targets': [\n",
    "                            'cfg.regression_data',\n",
    "                            'cfg.image_x:value',\n",
    "                            'cfg.image_y:value',\n",
    "                            'cfg.disp:value',\n",
    "                            'cfg.world_d:value',\n",
    "                        ]\n",
    "                    }\n",
    "                }, # end event on save regression data\n",
    "            ]\n",
    "        }, # end onclick events\n",
    "        {\n",
    "            'type': 'interactiveX',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': on_update_sample_dir,\n",
    "                    'params': {\n",
    "                        'w_save_dir': 'cfg.sample_save_dir',\n",
    "                        'w_calibration_result': '__cfg.calibration_result',\n",
    "                        'w_rectification_result': '__cfg.rectification_result',\n",
    "                        'camera_source': 'cfg.select_camera_source',\n",
    "                        'chessboard': '_cfg.chessboard_choice',\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'handler': on_update_sample_list,\n",
    "                    'params': {\n",
    "                        'w_sample_list': 'cfg.sample_list',\n",
    "                        'save_dir': 'cfg.sample_save_dir',\n",
    "                    }\n",
    "                }, \n",
    "                {\n",
    "                    'handler': on_update_sample_image,\n",
    "                    'params': {\n",
    "                        'w_video_frame': '__cfg.video_frame_capture',\n",
    "                        'sample_path': 'cfg.sample_list'\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }, # end interactiveX\n",
    "        {\n",
    "            'type': 'oncanvas',\n",
    "            'objs': [\n",
    "                {\n",
    "                    'handler': on_canvas_video_mouse_up,\n",
    "                    'evttype': 'mouse_up',\n",
    "                    'params': {\n",
    "                        'sources': ['__cfg.video_frame_matcher'],\n",
    "                        'targets': [\n",
    "                            'cfg.image_x',\n",
    "                            'cfg.image_y',\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "            ]\n",
    "        } # end oncanvas\n",
    "    ] # end events\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f329e",
   "metadata": {},
   "source": [
    "### Startup Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beadc288",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d72e704aab491f9611480332223c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(TabE(value=None, children=(VBox(children=(HTML(value=\"<b><font colo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if g_ctx:\n",
    "    on_stop_collect_samples(g_ctx)\n",
    "g_ctx = nbeasy_schema_parse(schema, debug=True, border=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceff26c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = g_ctx.get_widget_byid('__cfg.video_frame_capture')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c5d3c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b216082",
   "metadata": {},
   "source": [
    "- [Camera Intrinsic Matrix with Example in Python](https://towardsdatascience.com/camera-intrinsic-matrix-with-example-in-python-d79bf2478c12)\n",
    "- [What are Intrinsic and Extrinsic Camera Parameters in Computer Vision?](https://towardsdatascience.com/what-are-intrinsic-and-extrinsic-camera-parameters-in-computer-vision-7071b72fb8ec)\n",
    "- [How to select your Stereo Camera?](https://www.e-consystems.com/blog/camera/products/how-to-select-your-stereo-camera/)\n",
    "- [What is a stereo vision camera?](https://www.e-consystems.com/blog/camera/technology/what-is-a-stereo-vision-camera-2/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1a67d",
   "metadata": {},
   "source": [
    "- [Tutorial: Stereo 3D reconstruction with openCV using an iPhone camera. Part I.](https://becominghuman.ai/stereo-3d-reconstruction-with-opencv-using-an-iphone-camera-part-i-c013907d1ab5)\n",
    "- [Tutorial: Stereo 3D reconstruction with OpenCV using an iPhone camera. Part III.](https://medium.com/@omar.ps16/stereo-3d-reconstruction-with-opencv-using-an-iphone-camera-part-iii-95460d3eddf0)\n",
    "\n",
    "<div class=\"alert alert-success\"><p>\n",
    "Block matching focuses on high texture images (think a picture of a tree) and semi-global block matching will focus on sub pixel level matching and pictures with more smooth textures (think a picture of a hallway).\n",
    "</p></div>\n",
    "\n",
    "![](/notebooks/images/sgbm_num_disparity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5ae08",
   "metadata": {},
   "source": [
    "- [epipolar geometry & draw it](https://docs.opencv.org/3.4.4/da/de9/tutorial_py_epipolar_geometry.html)\n",
    "\n",
    "<div class=\"alert alert-success\"><p>\n",
    "Essential Matrix contains the information about translation and rotation, which describe the location of the second camera relative to the first in global coordinates. </br>\n",
    "Fundamental Matrix contains the same information as Essential Matrix in addition to the information about the intrinsics of both cameras so that we can relate the two cameras in pixel coordinates. (If we are using rectified images and normalize the point by dividing by the focal lengths, F=E).\n",
    "</p></div>\n",
    "\n",
    "- [Stereo Vision: Depth Estimation between object and camera](https://medium.com/analytics-vidhya/distance-estimation-cf2f2fd709d8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f340f3",
   "metadata": {},
   "source": [
    "[How Computers See Depth: Recent Advances in Deep Learning-Based Methods](https://towardsdatascience.com/how-computers-see-depth-deep-learning-based-methods-368581b244ed)\n",
    "\n",
    "![](/notebooks/images/stereo_vision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933bebe3",
   "metadata": {},
   "source": [
    "[3D视觉之立体匹配（Stereo Matching)](https://zhuanlan.zhihu.com/p/161276985)\n",
    "![](/notebooks/images/disparity_estimation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fde8b8",
   "metadata": {},
   "source": [
    "[JetSon](https://github.com/chawza/jetson-obstacle-avoidance.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25648f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 计算视差图\n",
    "    size = (left_image.shape[1], left_image.shape[0])\n",
    "    if down_scale == False:\n",
    "        disparity_left = left_matcher.compute(left_image, right_image)\n",
    "        disparity_right = right_matcher.compute(right_image, left_image)\n",
    "\n",
    "    else:\n",
    "        left_image_down = cv2.pyrDown(left_image)\n",
    "        right_image_down = cv2.pyrDown(right_image)\n",
    "        factor = left_image.shape[1] / left_image_down.shape[1]\n",
    "\n",
    "        disparity_left_half = left_matcher.compute(left_image_down, right_image_down)\n",
    "        disparity_right_half = right_matcher.compute(right_image_down, left_image_down)\n",
    "        disparity_left = cv2.resize(disparity_left_half, size, interpolation=cv2.INTER_AREA)\n",
    "        disparity_right = cv2.resize(disparity_right_half, size, interpolation=cv2.INTER_AREA)\n",
    "        disparity_left = factor * disparity_left\n",
    "        disparity_right = factor * disparity_right"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "296.688px",
    "left": "1512px",
    "top": "67.125px",
    "width": "231px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
