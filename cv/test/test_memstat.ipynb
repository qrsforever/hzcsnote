{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 自动统计训练过程CPU/GPU内存峰值信息 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, time\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import multiprocessing, threading\n",
    "from multiprocessing.queues import Empty\n",
    "from k12libs.utils.nb_easy import k12ai_train_execute\n",
    "from k12libs.utils.nb_easy import k12ai_get_data\n",
    "from k12libs.utils.nb_easy import k12ai_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_reserve_mem = 5000\n",
    "gpu_reserve_mem = 5000\n",
    "memstat_file = f'memstat/0316.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dogsVsCats', 'Boats'\n",
    "models = ('vgg11', 'vgg16', 'vgg19', 'vgg16_bn', 'vgg19_bn', 'resnet18', 'resnet50', 'resnet101', 'resnet152')\n",
    "datasets = ('Fruits360', 'cellular', 'kannada', 'FashionMNIST', 'EMNIST_Digits', 'cifar10', 'mnist', 'Chars74K', 'cactus', 'EMNIST_MNIST', 'Dogs', 'EMNIST_Letters', 'Animals', 'EMNIST_Balanced')\n",
    "batchsizes = (16, 32, 64, 128)\n",
    "inputsizes = (28, 32, 64, 96, 128, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_key(backbone, dataset, batchsize, inputsize=32):\n",
    "    return '%s-0' % hashlib.md5(f'cls{backbone}{dataset}{batchsize}{inputsize}'.encode()).hexdigest()[0:6]\n",
    "\n",
    "def check_exist(backbone, dataset, batchsize, inputsize):\n",
    "    ID = gen_key(backbone, dataset, batchsize, inputsize)\n",
    "    if os.path.exists(memstat_file):\n",
    "        memstat_df = pd.read_csv(memstat_file, index_col='id')\n",
    "        if ID in memstat_df.index:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def write_csv(backbone, dataset, batchsize, inputsize, uptime, memstat):\n",
    "    ID = gen_key(backbone, dataset, batchsize, inputsize)\n",
    "    if os.path.exists(memstat_file):\n",
    "        memstat_df = pd.read_csv(memstat_file)\n",
    "        if ID in memstat_df.set_index('id').index:\n",
    "            return memstat_df\n",
    "    else:\n",
    "        fieldnames = ['id', 'model', 'dataset', 'batchsize', 'inputsize', 'uptime']\n",
    "        fieldnames.extend(list(memstat.keys()))\n",
    "        memstat_df = pd.DataFrame(columns=fieldnames)\n",
    "    row = {\n",
    "        'id': ID,\n",
    "        'model': backbone,\n",
    "        'dataset': dataset,\n",
    "        'batchsize': batchsize,\n",
    "        'inputsize': inputsize,\n",
    "        'uptime': uptime,\n",
    "        **memstat\n",
    "    }\n",
    "    memstat_df = memstat_df.append(row, ignore_index=True)\n",
    "    memstat_df.to_csv(memstat_file, index=False)\n",
    "    return memstat_df\n",
    "\n",
    "# memstat_file = '/tmp/test.csv'\n",
    "# memstat_df = write_csv('cls', 'vgg11', 'Animals', 16, 32, 100, memstat={\n",
    "#     'app_cpu_memory_usage_MB': 1.0,\n",
    "#     'app_gpu_memory_usage_MB': 1.0,\n",
    "#     'sys_cpu_memory_free_MB': 1.0,\n",
    "#     'sys_gpu_memory_free_MB': 1.0,\n",
    "#     'app_cpu_max_memory_children_MB': 1.0,\n",
    "#     'app_gpu_max_memory_cached_MB': 1.0,\n",
    "#     'app_gpu_memory_allocated_MB': 1.0,\n",
    "#     'app_gpu_memory_cached_MB': 1.0,\n",
    "# })\n",
    "# memstat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_queue = multiprocessing.Queue()\n",
    "\n",
    "tasks_running = []\n",
    "tasks_waiting = []\n",
    "\n",
    "def tasks_generator(models, datasets, batchsizes, inputsizes):\n",
    "    tasks = []\n",
    "    for m in models:\n",
    "        for d in datasets:\n",
    "            for b in batchsizes:\n",
    "                for i in inputsizes:\n",
    "                    if check_exist(m, d, b, i):\n",
    "                        continue\n",
    "                    tasks.append({'backbone': m, 'dataset': d, 'batchsize': b, 'inputsize': i})\n",
    "    return tasks\n",
    "\n",
    "def waiting2running():\n",
    "    global tasks_running, tasks_waiting\n",
    "    if len(tasks_waiting) == 0:\n",
    "        print(\"no waiting task to run\")\n",
    "        return False\n",
    "    task = tasks_waiting.pop(0)\n",
    "    key = k12ai_train_execute('k12cv', 'cls', 'base_model', **task)[0]\n",
    "    tasks_running.append((key, task))\n",
    "    print('waiting[%d] running[%d] execute: %s' % (len(tasks_waiting), len(tasks_running), task))\n",
    "    return True\n",
    "                \n",
    "def tasks_queue_work():\n",
    "    print('start tasks_queue_work')\n",
    "    waiting2running()\n",
    "    waiting2running()\n",
    "    waiting2running()\n",
    "    while True:\n",
    "        try:\n",
    "            cpu_free, gpu_free = monitor_queue.get(True, timeout=10)\n",
    "            if cpu_free >= cpu_reserve_mem and gpu_free >= gpu_reserve_mem:\n",
    "                if not waiting2running():\n",
    "                    return\n",
    "                if gpu_free > 15000:\n",
    "                    if not waiting2running():\n",
    "                        return\n",
    "            else:\n",
    "                print(f'[Low Memory] cpu_free: {cpu_free}, gpu_free: {gpu_free}')\n",
    "        except Empty:\n",
    "            pass\n",
    "\n",
    "def tasks_result_work():\n",
    "    print(\"start tasks_result_work\")\n",
    "    global tasks_running, tasks_waiting\n",
    "    while True:\n",
    "        for key, task in tasks_running:\n",
    "            data = k12ai_get_data(key, 'error', rm=True)\n",
    "            data = data[0]['value']['data']['expand'] if data else None\n",
    "            if not data or data['status'] in ('starting', 'running'):\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            tasks_running.remove((key, task))\n",
    "            if data['status'] == 'finish':\n",
    "                print('key:%s, task:%s Finished' % (key, task))\n",
    "                cpu_free = data['memstat']['sys_cpu_memory_free_MB']\n",
    "                gpu_free = data['memstat']['sys_gpu_memory_free_MB'][0] # GPU-0\n",
    "                monitor_queue.put((cpu_free, gpu_free))\n",
    "                write_csv(**task, uptime=data['uptime'], memstat=data['memstat'])\n",
    "                if len(tasks_running) == 0 and len(tasks_waiting) == 0:\n",
    "                    print(\"no task!\")\n",
    "                    return\n",
    "            else:\n",
    "                print('key:%s, task:%s Error[%s]' % (key, task, data['errinfo']['err_text']))\n",
    "                tasks_waiting.append(task)\n",
    "                if len(tasks_running) == 0:\n",
    "                    monitor_queue.put((cpu_reserve_mem, gpu_reserve_mem))\n",
    "                    if tasks_waiting[0]['batchsize'] <= 64:\n",
    "                        monitor_queue.put((cpu_reserve_mem, gpu_reserve_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_memstat(models, datasets, batchsizes, inputsizes):\n",
    "    global tasks_waiting\n",
    "    tasks_waiting = tasks_generator(models, datasets, batchsizes, inputsizes)\n",
    "    if len(tasks_waiting) == 0:\n",
    "        print(f'already record, see {mamstat_file}')\n",
    "        return\n",
    "    t1 = threading.Thread(target=tasks_queue_work, args=())\n",
    "    t1.start()\n",
    "    time.sleep(1)\n",
    "    t2 = threading.Thread(target=tasks_result_work, args=())\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tasks_queue_work\n",
      "start tasks_result_work\n"
     ]
    }
   ],
   "source": [
    "test_memstat(models, datasets, batchsizes, inputsizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vgg11 + vgg16 + vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_memstat(['vgg11', 'vgg16', 'vgg19'], datasets, bses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet18 + resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_memstat(['resnet18', 'resnet50'], datasets, bses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet101 + resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_memstat(['resnet101', 'resnet152'], datasets, bses)\n",
    "task = {'backbone': 'resnet152', 'dataset': 'dogsVsCats', 'batchsize': 64}\n",
    "k12ai_train_execute('k12cv', 'cls', 'base_model', **task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vgg16_bn + vgg19_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_memstat(['vgg16_bn', 'vgg19_bn'], datasets, bses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memstat_df = pd.read_csv(memstat_file)\n",
    "memstat_df = memstat_df.set_index('id')\n",
    "memstat_df[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
