{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.704429Z",
     "start_time": "2020-07-22T06:07:27.624754Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'k12ai_build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c7cc17d6a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mk12libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_easy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMDURL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mk12libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_easy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mk12ai_build_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'k12ai_build_model'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer as EasyTrainer\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from k12libs.utils.nb_easy import k12ai_start_html\n",
    "from k12libs.utils.nb_easy import MDURL\n",
    "\n",
    "from k12libs.utils.nb_easy import k12ai_build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.709208Z",
     "start_time": "2020-07-22T06:07:27.574Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '/data/datasets'\n",
    "\n",
    "def k12ai_start_viznet(height):\n",
    "    url = f'{MDURL}?jfile=simple&flask=http://116.85.5.40:8117/k12ai/notebook/message&tag=cls_custom_base_mnist'\n",
    "    return k12ai_start_html(url, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.710706Z",
     "start_time": "2020-07-22T06:07:27.576Z"
    }
   },
   "outputs": [],
   "source": [
    "## 4行代码即可训练\n",
    "dataset = k12ai_load_dataset('mnist', num_workers=4)\n",
    "model   = k12ai_load_model('mnist', pretrained=True)\n",
    "trainer = k12ai_trainer(max_epochs=100)\n",
    "trainer.fit(model, Dataloader(dataset, batch_size=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "# <div align=\"center\"> Code-1 </dvi>\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.712575Z",
     "start_time": "2020-07-22T06:07:27.578Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root=None, phase=None, transforms=None):\n",
    "        self.transforms = transforms            # 数据变换\n",
    "        self.img_list, self.label_list = [], [] # 分类任务的图片和标签列表\n",
    "        \n",
    "        # 读取json数据集文件\n",
    "        with open(os.path.join(data_root, '{}.json'.format(phase)), 'r') as f:\n",
    "            items = json.load(f)\n",
    "            for item in items:\n",
    "                img_path = os.path.join(data_root, item['image_path'])\n",
    "                if not os.path.exists(img_path):\n",
    "                    continue\n",
    "                self.img_list.append(img_path)\n",
    "                self.label_list.append(item['label'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = ImageHelper.read_image(self.img_list[index])\n",
    "        label = self.label_list[index]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return dict(\n",
    "            img=DataContainer(img, stack=True),\n",
    "            label=DataContainer(label, stack=True)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.714072Z",
     "start_time": "2020-07-22T06:07:27.581Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    'train': torchvision.transforms.Compose( # 训练阶段的数据变换\n",
    "        [\n",
    "            torchvision.transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
    "            torchvision.transforms.Resize((256, 256)),     # 图片缩放变换\n",
    "            torchvision.transforms.ToTensor(),             # PIL转为张量\n",
    "            torchvision.transforms.Normalize(              # 图片标准化\n",
    "                mean=[0.485, 0.456, 0.406],  # 数据集样本的均值\n",
    "                std=[0.229, 0.224, 0.225]    # 数据集样本的方差 \n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    'valid': torchvision.transforms.Compose( # 验证阶段的数据变换\n",
    "        [\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.Resize((256, 256)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    'test': torchvision.transforms.Compose( # 测试阶段的数据变换\n",
    "        [\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.Resize((256, 256)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.715250Z",
     "start_time": "2020-07-22T06:07:27.584Z"
    }
   },
   "outputs": [],
   "source": [
    "### 设置训练轮回(max_epoch)\n",
    "max_epoch = 10\n",
    "\n",
    "### 设置损失函数(交叉熵CE)\n",
    "reduction = 'mean' # 约简方式为mean(张量各个维度上的元素的平均值)\n",
    "criterion = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "### 设置优化器(随机梯度下降SGD)\n",
    "optimizer = SGD(custom_model.parameters(),\n",
    "                lr=0.01,           # 基础学习率\n",
    "                weight_decay=1e-6, # 权重衰减, 使得模型参数值更小, 有效防止过拟合\n",
    "                momentum=0.9,      # 动量因子, 更快局部收敛\n",
    "                nesterov=True      # 使用Nesterov动量, 加快收敛速度\n",
    "               )\n",
    "\n",
    "### 设置学习率衰减策略(可选, 固定步长衰减StepLR)\n",
    "scheduler = StepLR(optimizer,\n",
    "                   step_size=2, # 每间隔2次epoch进行一次LR调整\n",
    "                   gamma=0.6    # LR调整为原来0.6倍\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.716763Z",
     "start_time": "2020-07-22T06:07:27.587Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EasyNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)  # 卷积层, 图片特征提取\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)   # Dropout正则化, 减少模型过拟合\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)        # 全连接层, 图片线性变换\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1) # 每个分类的概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.719853Z",
     "start_time": "2020-07-22T06:07:27.590Z"
    }
   },
   "outputs": [],
   "source": [
    "### 设置数据集\n",
    "datasets = {\n",
    "    'train': EasyDataset(DATA_ROOT, 'train', transforms['train']), # 训练数据集\n",
    "    'valid': EasyDataset(DATA_ROOT, 'valid', transforms['valid']), # 验证数据集\n",
    "    'test' : EasyDataset(DATA_ROOT, 'test',  transforms['test']),  # 测试数据集\n",
    "}\n",
    "\n",
    "### 设置超参数\n",
    "hyparams = {\n",
    "    'optimizer': optimizer, # 梯度优化方法\n",
    "    'scheduler': scheduler, # 学习率调度策略\n",
    "    'criterion': criterion, # 损失函数\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.721485Z",
     "start_time": "2020-07-22T06:07:27.593Z"
    }
   },
   "outputs": [],
   "source": [
    "class EasyModule(LightningModule)\n",
    "    def __init__(self, datasets, hyparams, model):\n",
    "        super(EasyModel, self).__init__()\n",
    "        self.datasets = datasets\n",
    "        self.hyparams = hyparams\n",
    "        self.model = model\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.datasets['train'], batch_size=64, num_workers=4)\n",
    "\n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(self.datasets['valid'], batch_size=64, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.datasets['test'], batch_size=64)\n",
    "    \n",
    "    # 启动前配置优化器和学习率策略\n",
    "    def configure_optimizers(self):\n",
    "        return self.hyparams['optimizer'], self.hyparams['scheduler']\n",
    "\n",
    "    # 训练时每次迭代回调\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        outputs = self.model(images, targets)\n",
    "        criterion = self.hyparams['criterion'](outputs, targets)\n",
    "        losses = sum(loss for loss in criterion.values())\n",
    "        return {'loss': losses}\n",
    "    \n",
    "    # 验证时每次迭代回调\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        outputs = self.model(images, targets)\n",
    "        criterion = self.hyparams['criterion'](outputs, targets)\n",
    "        losses = sum(loss for loss in criterion.values())\n",
    "        return {'val_loss': losses}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练启动/测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.723199Z",
     "start_time": "2020-07-22T06:07:27.596Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = k12ai_trainer(\n",
    "    max_epochs=100,        # 训练最大循环次数\n",
    "    val_check_interval=10, # 验证网络模型的周期, 每10次验证一次.\n",
    "    early_stop_callback=EarlyStopping(monitor='val_loss', min_delta=1.0), # 监控loss, 用来提前终止训练\n",
    "    checkpoint_callback=ModelCheckpoint('/cache') # 模型检查点, 保存模型\n",
    ")\n",
    "\n",
    "model = EasyModel(datasets, hyparams, EasyNetwork())\n",
    "\n",
    "# 启动训练\n",
    "trainer.fit(model)\n",
    "\n",
    "# 启动测试\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "# <div align=\"center\"> Code-2 </dvi>\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 面罩探测数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.724533Z",
     "start_time": "2020-07-22T06:07:27.598Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskDetectionDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, phase='train', transforms=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_names = dataframe[\"name\"].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # 获取图片名字及图片相关记录信息\n",
    "        image_name = self.image_names[index]\n",
    "        records = self.df[self.df[\"name\"] == image_name]\n",
    "        \n",
    "        # 加载图片\n",
    "        image = cv2.imread(self.image_dir + image_name, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "                    \n",
    "        # 从记录中取出口罩(mask)所在的坐标boxes信息\n",
    "        boxes = records[['x1', 'y1', 'x2', 'y2']].values\n",
    "\n",
    "        # 获取口罩边框的标签信息\n",
    "        temp_labels = records[['classname']].values\n",
    "        labels = []\n",
    "        for label in temp_labels:\n",
    "            label = class_to_int[label[0]]\n",
    "            labels.append(label)\n",
    "\n",
    "        # 将数据类型转换为张量类型\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target, image_name\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采用预制的fast_rcnn模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.726262Z",
     "start_time": "2020-07-22T06:07:27.601Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载预制模型\n",
    "model = k12ai_load_model('fasterrcnn_resnet50', pretrained=True)\n",
    "head  = k12ai_load_model('fasterrcnn_predictor')\n",
    "\n",
    "# 获取分类器的输入特征\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# 替换预制模型的head\n",
    "model.roi_heads.box_predictor = head(in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.728368Z",
     "start_time": "2020-07-22T06:07:27.604Z"
    }
   },
   "outputs": [],
   "source": [
    "class FasterRCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, configer):\n",
    "        super(FasterRCNN, self).__init__()\n",
    "        self.configer = configer\n",
    "        self.backbone, self.classifier = VGGModel(configer)()\n",
    "        self.rpn = NaiveRPN(configer)\n",
    "        self.rpn_target_assigner = RPNTargetAssigner(configer)\n",
    "        self.roi_generator = FRROIGenerator(configer)\n",
    "        self.roi_sampler = FRROISampler(configer)\n",
    "        self.bbox_head = BBoxHead(configer, self.classifier)\n",
    "        self.valid_loss_dict = configer.get('loss', 'loss_weights', configer.get('loss.loss_type'))\n",
    "\n",
    "    def forward(self, data_dict):\n",
    "        out_dict = dict()\n",
    "        x = self.backbone(data_dict['img'])\n",
    "        feat_list, rpn_locs, rpn_scores = self.rpn(x)\n",
    "        if not self.training:\n",
    "            indices_and_rois, test_rois_num = self.roi_generator(feat_list, rpn_locs, rpn_scores,\n",
    "                                                                 self.configer.get('rpn', 'n_test_pre_nms'),\n",
    "                                                                 self.configer.get('rpn', 'n_test_post_nms'),\n",
    "                                                                 data_dict['meta'])\n",
    "            roi_cls_locs, roi_scores = self.bbox_head(x, indices_and_rois, data_dict['meta'])\n",
    "            out_dict['test_group'] = [indices_and_rois, roi_cls_locs, roi_scores, test_rois_num]\n",
    "\n",
    "        if self.configer.get('phase') == 'test':\n",
    "            return out_dict\n",
    "\n",
    "        gt_rpn_locs, gt_rpn_labels = self.rpn_target_assigner(feat_list, data_dict['bboxes'], data_dict['meta'])\n",
    "        train_indices_and_rois, _ = self.roi_generator(feat_list, rpn_locs, rpn_scores,\n",
    "                                                       self.configer.get('rpn', 'n_train_pre_nms'),\n",
    "                                                       self.configer.get('rpn', 'n_train_post_nms'),\n",
    "                                                       data_dict['meta'])\n",
    "        sample_rois, gt_roi_bboxes, gt_roi_labels = self.roi_sampler(train_indices_and_rois,\n",
    "                                                                     data_dict['bboxes'],\n",
    "                                                                     data_dict['labels'],\n",
    "                                                                     data_dict['meta'])\n",
    "\n",
    "        sample_roi_locs, sample_roi_scores = self.bbox_head(x, sample_rois, data_dict['meta'])\n",
    "        sample_roi_locs = sample_roi_locs.contiguous().view(-1, self.configer.get('data', 'num_classes'), 4)\n",
    "        sample_roi_locs = sample_roi_locs[\n",
    "            torch.arange(0, sample_roi_locs.size()[0]).long().to(sample_roi_locs.device),\n",
    "            gt_roi_labels.long().to(sample_roi_locs.device)].contiguous().view(-1, 4)\n",
    "        out_dict['train_group'] = [sample_rois, sample_roi_locs, sample_roi_scores]\n",
    "        loss_dict = dict()\n",
    "        if 'rpn_loc_loss' in self.valid_loss_dict:\n",
    "            loss_dict['rpn_loc_loss'] = dict(\n",
    "                params=[rpn_locs, gt_rpn_locs, gt_rpn_labels, self.configer.get('loss.params.rpn_sigma')],\n",
    "                type=torch.cuda.LongTensor([BASE_LOSS_DICT['smooth_l1_loss']]),\n",
    "                weight=torch.cuda.FloatTensor([self.valid_loss_dict['rpn_loc_loss']])\n",
    "            )\n",
    "        if 'rpn_cls_loss' in self.valid_loss_dict:\n",
    "            loss_dict['rpn_cls_loss'] = dict(\n",
    "                params=[rpn_scores, gt_rpn_labels],\n",
    "                type=torch.cuda.LongTensor([BASE_LOSS_DICT['ce_loss']]),\n",
    "                weight=torch.cuda.FloatTensor([self.valid_loss_dict['rpn_cls_loss']])\n",
    "            )\n",
    "        if 'roi_loc_loss' in self.valid_loss_dict:\n",
    "            loss_dict['roi_loc_loss'] = dict(\n",
    "                params=[sample_roi_locs, gt_roi_bboxes, gt_roi_labels, self.configer.get('loss.params.roi_sigma')],\n",
    "                type=torch.cuda.LongTensor([BASE_LOSS_DICT['smooth_l1_loss']]),\n",
    "                weight=torch.cuda.FloatTensor([self.valid_loss_dict['roi_loc_loss']])\n",
    "            )\n",
    "        if 'roi_cls_loss' in self.valid_loss_dict:\n",
    "            loss_dict['roi_cls_loss'] = dict(\n",
    "                params=[sample_roi_scores, gt_roi_labels],\n",
    "                type=torch.cuda.LongTensor([BASE_LOSS_DICT['ce_loss']]),\n",
    "                weight=torch.cuda.FloatTensor([self.valid_loss_dict['roi_cls_loss']])\n",
    "            )\n",
    "        return out_dict, loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.729828Z",
     "start_time": "2020-07-22T06:07:27.607Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型训练过程中, 没有改善时提前终止\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', # 监控指标\n",
    "    mode='min',         # auto, min(指标值下降), max(指标值上升)\n",
    "    patience=2,         # 容忍度, 当n(2)个epoch指标没有改善时, 停止训练\n",
    "    min_delta=0.2       # 最小该变量\n",
    ")\n",
    "\n",
    "# 模型检查点相关参数设置\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='/cache/det',     # 检查点目录\n",
    "    save_last=True,            # 是否保存最后一次epoch模型\n",
    "    save_weights_only=False,   # 是否只保存模型权重\n",
    "    save_top_k=2,              # 0: 无模型保存, -1: 模型都保存, 其他: 正常保存\n",
    "    period=10,                 # 模型保存周期\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.731386Z",
     "start_time": "2020-07-22T06:07:27.609Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = k12ai_trainer(\n",
    "    max_epochs=100,     # 训练外循环最大次数\n",
    "    max_steps=10000,    # 训练迭代最大步数\n",
    "    resume_from_checkpoint='/cache/det/best.pk', # 恢复训练\n",
    "    early_stop_callback=early_stopping,\n",
    "    checkpoint_callback=model_checkpoint,\n",
    ")\n",
    "\n",
    "# 从磁盘读取数据集\n",
    "df = pd.read_csv(DATA_ROOT + \"train.csv\")\n",
    "\n",
    "trainloader = Dataloader(\n",
    "    MaskDetectionDataset(df), \n",
    "    batch_size = 32,  # 一次进入模型的数据量\n",
    "    shuffle = True,   # 数据是否重新排序\n",
    "    num_workers = 4   # 读取数据的进程数\n",
    ")\n",
    "\n",
    "trainer.fit(model, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "# <div align=\"center\"> Code-3 </dvi>\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.732704Z",
     "start_time": "2020-07-22T06:07:27.615Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k12ai_start_viznet(height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.734348Z",
     "start_time": "2020-07-22T06:07:27.618Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_model_str = '''plain_net {\n",
    " name: \"hproject_model_name\"\n",
    "\n",
    "layer{\n",
    "  conv{\n",
    "    name : \"Conv2d_6831\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : CONV2D\n",
    "    inputs : \"x\"\n",
    "    outputs : \"Conv2d_7510\"\n",
    "    layer_params {\n",
    "      in_channels : \"3\"\n",
    "      out_channels : \"30\"\n",
    "      kernel_size : \"3\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  conv{\n",
    "    name : \"Conv2d_7510\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : CONV2D\n",
    "    inputs : \"Conv2d_6831\"\n",
    "    outputs : \"Conv2d_5900\"\n",
    "    layer_params {\n",
    "      in_channels : \"30\"\n",
    "      out_channels : \"30\"\n",
    "      kernel_size : \"3\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  conv{\n",
    "    name : \"Conv2d_5900\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : CONV2D\n",
    "    inputs : \"Conv2d_7510\"\n",
    "    outputs : \"MaxPool2d_7843\"\n",
    "    layer_params {\n",
    "      in_channels : \"30\"\n",
    "      out_channels : \"30\"\n",
    "      kernel_size : \"3\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  pool{\n",
    "    name : \"MaxPool2d_7843\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : MAXPOOL2D\n",
    "    inputs : \"Conv2d_5900\"\n",
    "    outputs : \"Conv2d_4074\"\n",
    "    layer_params {\n",
    "      kernel_size : \"3\"\n",
    "      stride : \"1\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  conv{\n",
    "    name : \"Conv2d_4074\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : CONV2D\n",
    "    inputs : \"MaxPool2d_7843\"\n",
    "    outputs : \"MaxPool2d_5315\"\n",
    "    layer_params {\n",
    "      in_channels : \"30\"\n",
    "      out_channels : \"50\"\n",
    "      kernel_size : \"3\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  pool{\n",
    "    name : \"MaxPool2d_5315\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : MAXPOOL2D\n",
    "    inputs : \"Conv2d_4074\"\n",
    "    outputs : \"Flatten_5235\"\n",
    "    layer_params {\n",
    "      kernel_size : \"3\"\n",
    "      stride : \"1\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  vulkan{\n",
    "    name : \"Flatten_5235\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : FLATTEN\n",
    "    inputs : \"MaxPool2d_5315\"\n",
    "    outputs : \"Linear_2653\"\n",
    "    layer_params {\n",
    "      start_dim : \"1\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  linear{\n",
    "    name : \"Linear_2653\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : LINEAR\n",
    "    inputs : \"Flatten_5235\"\n",
    "    outputs : \"Linear_5215\"\n",
    "    layer_params {\n",
    "      in_features : \"12800\"\n",
    "      out_features : \"1000\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  linear{\n",
    "    name : \"Linear_5215\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : LINEAR\n",
    "    inputs : \"Linear_2653\"\n",
    "    outputs : \"Linear_9970\"\n",
    "    layer_params {\n",
    "      in_features : \"1000\"\n",
    "      out_features : \"100\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  linear{\n",
    "    name : \"Linear_9970\"\n",
    "    layer_builder : \"NNTorchLayer\"\n",
    "    layer_mode : LINEAR\n",
    "    inputs : \"Linear_5215\"\n",
    "    outputs : \"Output_6954\"\n",
    "    layer_params {\n",
    "      in_features : \"100\"\n",
    "      out_features : \"10\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.735567Z",
     "start_time": "2020-07-22T06:07:27.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将用户模型配置翻译成模型对象\n",
    "custom_model = k12ai_build_model(custom_model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.736917Z",
     "start_time": "2020-07-22T06:07:27.623Z"
    }
   },
   "outputs": [],
   "source": [
    "# 根据自己需要配置数据集预处理方式\n",
    "class MaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    0 = '无面罩'\n",
    "    1 = '戴面罩'\n",
    "    \"\"\"\n",
    "    def __init__(self, dataFrame, transforms=None):\n",
    "        self.dataFrame = dataFrame\n",
    "        \n",
    "        if transforms is None:\n",
    "            self.transforms = Compose([\n",
    "                ToTensor() # 输入模型前必须转换为Tensor\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        row = self.dataFrame.iloc[key]\n",
    "        return {\n",
    "            'image': self.transforms(row['image']),\n",
    "            'mask': tensor([row['mask']], dtype=long),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataFrame.index)\n",
    "    \n",
    "# 可以实现自己的模型框架    \n",
    "class MaskModelWrapper(LightningModule):\n",
    "    \n",
    "    def __init__(self, model, phase='train'):\n",
    "        super(MaskModelWrapper, self).__init__()\n",
    "        self.df = pd.read_csv(DATA_ROOT + f\"{phase}.csv\")\n",
    "        self.model = model\n",
    "        self.phase = phase\n",
    "        self.trainDF, self.validDF, self.testDF = None, None, None\n",
    "    \n",
    "    def prepare_data(self) -> None:\n",
    "        # 分割数据train/val\n",
    "        if self.phase == 'train':\n",
    "            train, valid = train_test_split(\n",
    "                self.df,\n",
    "                test_size=0.3,           # 7(train) vs 3(test)\n",
    "                random_state=41,         # 随机\n",
    "                stratify=self.df['mask'] # 数据集不平衡, 在分割数据时需要指定stratify\n",
    "            )\n",
    "            self.trainDF = MaskDataset(train)\n",
    "            self.validDF = MaskDataset(valid)\n",
    "        else:\n",
    "            self.testDF = MaskDataset(self.df)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.trainDF, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.validateDF, batch_size=32, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.validateDF, batch_size=32, num_workers=4)\n",
    "    \n",
    "    def configure_optimizers(self) -> Optimizer:\n",
    "        return Adam(self.parameters(), lr=0.00001)\n",
    "    \n",
    "    # 训练时, 每次迭代会有一批(batchsize)样本数据送入模型, 计算损失\n",
    "    def training_step(self, batch: dict, _batch_idx: int) -> Dict[str, Tensor]:\n",
    "        inputs, labels = batch['image'], batch['mask']\n",
    "        labels = labels.flatten()\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.crossEntropyLoss(outputs, labels)\n",
    "\n",
    "        tensorboardLogs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboardLogs}\n",
    "    \n",
    "    # 验证时, 每次迭代会有一批(batchsize)本数据送入模型, 计算损失, 可以计算相应的metrics如准确率等.\n",
    "    def validation_step(self, batch: dict, _batch_idx: int) -> Dict[str, Tensor]:\n",
    "        inputs, labels = batch['image'], batch['mask']\n",
    "        labels = labels.flatten()\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.crossEntropyLoss(outputs, labels)\n",
    "\n",
    "        _, outputs = torch.max(outputs, dim=1)\n",
    "        valAcc = accuracy_score(outputs.cpu(), labels.cpu())\n",
    "        valAcc = torch.tensor(valAcc)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc':valAcc}\n",
    "    \n",
    "    # 验证结束时, 输入为最后的模型的输出, 在此函数可以实现自己的metrics.\n",
    "    def validation_epoch_end(self, outputs: List[Dict[str, Tensor]]) \\\n",
    "            -> Dict[str, Union[Tensor, Dict[str, Tensor]]]:\n",
    "        avgLoss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avgAcc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        tensorboardLogs = {'val_loss': avgLoss, 'val_acc':avgAcc}\n",
    "        return {'val_loss': avgLoss, 'log': tensorboardLogs}\n",
    "    \n",
    "    # 定义自己的优化方式\n",
    "    def configure_optimizers(self) -> Optimizer:\n",
    "        return Adam(self.parameters(), lr=0.00001)\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.738080Z",
     "start_time": "2020-07-22T06:07:27.626Z"
    }
   },
   "outputs": [],
   "source": [
    "## 训练\n",
    "tb_logger = TensorBoardLogger(save_dir='/cache/logdir')\n",
    "trainer = k12ai_trainer(\n",
    "    logger=[tb_logger], # 日志\n",
    "    gpus=1, # 选用哪个GPU训练\n",
    "    max_epochs=100\n",
    ")\n",
    "trainer.fit(MaskModelWrapper(custom_model, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T06:07:29.739624Z",
     "start_time": "2020-07-22T06:07:27.629Z"
    }
   },
   "outputs": [],
   "source": [
    "## 测试\n",
    "trainer.test(MaskModelWrapper(custom_model, 'test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
