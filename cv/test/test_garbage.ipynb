{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> Test Garbage </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:20:55.226059Z",
     "start_time": "2020-11-03T12:20:55.212746Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision import datasets\n",
    "from torch import optim\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from k12libs.utils.nb_easy import K12AI_PRETRAINED_ROOT, K12AI_DATASETS_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T11:56:26.497654Z",
     "start_time": "2020-11-03T11:56:26.493359Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'rgarbage'\n",
    "data_root = os.path.join(K12AI_DATASETS_ROOT, 'cv', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:00:20.420396Z",
     "start_time": "2020-11-03T12:00:19.832917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"num_records\": 11073,\r\n",
      "    \"num_classes\": 4,\r\n",
      "    \"label_names\": [\r\n",
      "        \"其他垃圾\",\r\n",
      "        \"厨余垃圾\",\r\n",
      "        \"可回收物\",\r\n",
      "        \"有害垃圾\"\r\n",
      "    ],\r\n",
      "    \"mean\": [\r\n",
      "        0.6535,\r\n",
      "        0.6132,\r\n",
      "        0.5643\r\n",
      "    ],\r\n",
      "    \"std\": [\r\n",
      "        0.2165,\r\n",
      "        0.2244,\r\n",
      "        0.2416\r\n",
      "    ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat $data_root/info.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:02:31.614372Z",
     "start_time": "2020-11-03T12:02:31.603485Z"
    }
   },
   "outputs": [],
   "source": [
    "### \n",
    "with open(os.path.join(data_root, 'info.json'), 'r') as fr:\n",
    "    items = json.load(fr)\n",
    "\n",
    "### \n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),    # 数据增强: 对PIL Image数据做随机水平翻转\n",
    "    transforms.ToTensor(),                     # PIL Image格式转换为Tensor张量格式               \n",
    "    transforms.Normalize(items['mean'], items['std']) # 对数据归一化处理\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:03:15.608035Z",
     "start_time": "2020-11-03T12:03:15.538286Z"
    }
   },
   "outputs": [],
   "source": [
    "class JsonfileDataset(Dataset):\n",
    "    def __init__(self, data_root, json_file, resize=None, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.json_file = json_file\n",
    "        self.resize = resize\n",
    "        self.image_list, self.label_list = self.__read_jsonfile(json_file)\n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_list[index]).convert('RGB')\n",
    "        if self.resize:\n",
    "            img = img.resize(self.resize)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.label_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __read_jsonfile(self, jsonfile):\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "        with open(os.path.join(self.data_root, self.json_file)) as f:\n",
    "            items = json.load(f)\n",
    "            for item in items:\n",
    "                image_list.append(os.path.join(self.data_root, item['image_path']))\n",
    "                label_list.append(item['label'])\n",
    "        return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:09:24.792158Z",
     "start_time": "2020-11-03T12:09:24.723497Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = JsonfileDataset(data_root, 'train.json', transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True) \n",
    "\n",
    "valid_data = JsonfileDataset(data_root, 'val.json', transform=transform)\n",
    "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=True, drop_last=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T12:15:47.668541Z",
     "start_time": "2020-11-03T12:15:46.729725Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "state = torch.load(os.path.join(K12AI_PRETRAINED_ROOT, 'cv', 'resnet50-19c8e357.pth'))\n",
    "model.load_state_dict(state)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T12:34:01.243Z"
    }
   },
   "outputs": [],
   "source": [
    "### 设置训练轮回(max_epoch)\n",
    "max_epoch = 50\n",
    "\n",
    "### 设置损失函数(交叉熵CE)\n",
    "reduction = 'mean' # 约简方式为mean(张量各个维度上的元素的平均值)\n",
    "criterion = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "### 设置优化器(随机梯度下降SGD)\n",
    "# optimizer = SGD(custom_model.parameters(),\n",
    "#    lr=0.01,           # 基础学习率\n",
    "#    weight_decay=1e-6, # 权重衰减, 使得模型参数值更小, 有效防止过拟合\n",
    "#    momentum=0.9,      # 动量因子, 更快局部收敛\n",
    "#    nesterov=True      # 使用Nesterov动量, 加快收敛速度\n",
    "# )  \n",
    "\n",
    "### 亚当\n",
    "optimizer = Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), # 过程出可更新的层(参数)\n",
    "    lr=0.001,           # 基础学习率\n",
    "    betas=(0.9, 0.999), # 计算梯度的均值(0.9)和平方(0.999)的系数\n",
    "    eps=1e-8,           # 为了防止分母除零, 分母加上非常小的值\n",
    "    weight_decay=0,     # 权重衰减\n",
    "    amsgrad=False,      # 是否使用AmsGrad变体\n",
    ")\n",
    "\n",
    "### 设置学习率衰减策略(可选, 固定步长衰减StepLR)\n",
    "# scheduler = StepLR(optimizer,\n",
    "#    step_size=2, # 每间隔2次epoch进行一次LR调整\n",
    "#    gamma=0.6    # LR调整为原来0.6倍\n",
    "# )                 \n",
    " \n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,   # 优化器\n",
    "    mode='min',  # 指定指标不再下降\n",
    "    factor=0.1,  # 衰减因子\n",
    "    patience=3,  # 容忍多少次(指标不改变)\n",
    "    eps=1e-6,    # 学习率衰减到的最小值eps时,学习率不再改变\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练及反馈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T12:31:14.079Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , Training Loss: 0.33040550351142883\n",
      "Epoch: 0 , Training Loss: 0.4162968099117279\n",
      "Epoch: 0 , Training Loss: 0.4626573324203491\n",
      "Epoch: 0 , Training Loss: 0.6340612173080444\n",
      "Epoch: 0 , Training Loss: 0.40035709738731384\n",
      "Epoch: 0 , Validing Loss: 0.5449092984199524\n",
      "Epoch: 0 , Validing Loss: 0.4412495791912079\n",
      "Epoch: 0 , Validing Loss: 0.49853211641311646 ACC 76.56391659111515\n",
      "Epoch: 1 , Training Loss: 0.392650842666626\n",
      "Epoch: 1 , Training Loss: 0.4689213037490845\n",
      "Epoch: 1 , Training Loss: 0.41451287269592285\n",
      "Epoch: 1 , Training Loss: 0.4308861494064331\n",
      "Epoch: 1 , Training Loss: 0.5866461396217346\n",
      "Epoch: 1 , Validing Loss: 0.6984360218048096\n",
      "Epoch: 1 , Validing Loss: 0.5036810636520386\n",
      "Epoch: 1 , Validing Loss: 0.7667464017868042 ACC 73.52674524025386\n",
      "Epoch: 2 , Training Loss: 0.5381112098693848\n",
      "Epoch: 2 , Training Loss: 0.3231768012046814\n",
      "Epoch: 2 , Training Loss: 0.6217946410179138\n",
      "Epoch: 2 , Training Loss: 0.4079105257987976\n",
      "Epoch: 2 , Training Loss: 0.2976001501083374\n",
      "Epoch: 2 , Validing Loss: 0.6958367228507996\n",
      "Epoch: 2 , Validing Loss: 0.7680759429931641\n",
      "Epoch: 2 , Validing Loss: 1.4770715236663818 ACC 72.8921124206709\n",
      "Epoch: 3 , Training Loss: 0.2978036403656006\n",
      "Epoch: 3 , Training Loss: 0.23330441117286682\n",
      "Epoch: 3 , Training Loss: 0.2435905933380127\n",
      "Epoch: 3 , Training Loss: 0.366824209690094\n",
      "Epoch: 3 , Training Loss: 0.4174600839614868\n",
      "Epoch: 3 , Validing Loss: 0.8204955458641052\n",
      "Epoch: 3 , Validing Loss: 0.5871174335479736\n",
      "Epoch: 3 , Validing Loss: 0.9868298172950745 ACC 77.33454215775159\n",
      "Epoch: 4 , Training Loss: 0.20003367960453033\n",
      "Epoch: 4 , Training Loss: 0.21250863373279572\n",
      "Epoch: 4 , Training Loss: 0.5371226668357849\n",
      "Epoch: 4 , Training Loss: 0.3444981276988983\n",
      "Epoch: 4 , Training Loss: 0.4735778570175171\n",
      "Epoch: 4 , Validing Loss: 0.35815784335136414\n",
      "Epoch: 4 , Validing Loss: 0.5022789239883423\n",
      "Epoch: 4 , Validing Loss: 0.8455539345741272 ACC 80.73436083408885\n",
      "Epoch: 5 , Training Loss: 0.27174851298332214\n",
      "Epoch: 5 , Training Loss: 0.265725702047348\n",
      "Epoch: 5 , Training Loss: 0.3221553862094879\n",
      "Epoch: 5 , Training Loss: 0.3306775987148285\n",
      "Epoch: 5 , Training Loss: 0.28679370880126953\n",
      "Epoch: 5 , Validing Loss: 0.7946106791496277\n",
      "Epoch: 5 , Validing Loss: 0.47249311208724976\n",
      "Epoch: 5 , Validing Loss: 0.7134802937507629 ACC 79.60108794197643\n",
      "Epoch: 6 , Training Loss: 0.23484967648983002\n",
      "Epoch: 6 , Training Loss: 0.31007111072540283\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, device, data_loader, criterion, optimizer, epoch):\n",
    "    ### 模型进入训练状态(启用 BN 和 Dropout)\n",
    "    model.train()\n",
    "    for i, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "        if i % 30 == 0:\n",
    "            print('Epoch:', epoch, ', Training Loss:', loss.item())\n",
    "    print('Epoch:', epoch, ', Training Loss:', loss.item())\n",
    "        \n",
    "def valid_epoch(model, device, data_loader, criterion, epoch):\n",
    "    ### 模型进入评估模式(禁用 BN 和 Dropou)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            pred = torch.max(output, 1)[1]\n",
    "            correct += (pred == target).sum().item()\n",
    "            if i % 30 == 0:\n",
    "                print('Epoch:', epoch, ', Validing Loss:', loss.item())\n",
    "        ### 调整学习率\n",
    "        scheduler.step(loss)\n",
    "    ### 计算正确率\n",
    "    acc = 100.0 * correct / len(data_loader.dataset)\n",
    "    print('Epoch:', epoch, ', Validing Loss:', loss.item(), 'ACC', acc)\n",
    "    return acc\n",
    "    \n",
    "def train(epoch_num, model, train_loader, valid_loader, criterion, optimizer, scheduler):\n",
    "    ### 获取模型训练所用设备(cpu或者gpu)\n",
    "    device = next(model.parameters()).device\n",
    "    for epoch in range(0, epoch_num): \n",
    "        ### 训练模型\n",
    "        train_epoch(model, device, train_loader, criterion, optimizer, epoch)\n",
    "        ### 校验模型\n",
    "        valid_epoch(model, device, valid_loader, criterion, epoch)\n",
    "\n",
    "    ### 保存模型\n",
    "    torch.save(model.state_dict(), \"last.pt\")\n",
    "        \n",
    "### 启动训练\n",
    "train(max_epoch, model, train_loader, valid_loader, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T14:00:30.236751Z",
     "start_time": "2020-06-23T14:00:24.780194Z"
    }
   },
   "outputs": [],
   "source": [
    "### 加载测试数据集\n",
    "test_dataset = k12ai_load_dataset(data_root, 'test.json')\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, num_workers=4)\n",
    "\n",
    "### 加载训练完成的模型\n",
    "model.load_state_dict(torch.load('last.pt'))\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            pred = torch.max(output, 1)[1]\n",
    "            correct += (pred == target).sum().item()\n",
    "    ### 计算正确率\n",
    "    acc = 100.0 * correct / len(data_loader.dataset)\n",
    "    return acc\n",
    "\n",
    "### 启动评估\n",
    "acc = evaluate(last_model, test_loader)\n",
    "print(\"Acc:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
