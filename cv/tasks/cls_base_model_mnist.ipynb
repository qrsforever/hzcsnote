{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 分类任务测试 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:44:12.394699Z",
     "start_time": "2021-07-09T12:44:07.261594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.19.5\n",
      "sklearn 0.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.3\n",
      "PIL 8.3.1\n",
      "matplotlib 3.3.4\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.1+cu101\n",
      "torchvision 0.9.1+cu101\n",
      "torchaudio not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:44:13.937354Z",
     "start_time": "2021-07-09T12:44:12.402718Z"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Common ###\n",
    "###\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "\n",
    "_IMPORT_('import numpy as np')\n",
    "_IMPORT_('import pandas as pd')\n",
    "_IMPORT_('from tqdm.notebook import tqdm')\n",
    "\n",
    "def print_progress_bar(x):\n",
    "    print('\\r', end='')\n",
    "    print('Progress: {}%:'.format(x), '%s%s' % ('▋'*(x//2), '.'*((100-x)//2)), end='')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def img2b64(x):\n",
    "    if isinstance(x, bytes):\n",
    "        return base64.b64encode(x).decode()\n",
    "    elif isinstance(x, str):\n",
    "        if x.startswith('http'):\n",
    "            return base64.b64encode(requests.get(x).content).decode()\n",
    "        with open(x, 'rb') as fr:\n",
    "            return base64.b64encode(fr.read()).decode()\n",
    "    raise\n",
    "\n",
    "###\n",
    "### Display ###\n",
    "###\n",
    "\n",
    "_IMPORT_('import cv2')\n",
    "_IMPORT_('from PIL import Image')\n",
    "_IMPORT_('from torchvision.utils import make_grid')\n",
    "_IMPORT_('import matplotlib.pyplot as plt')\n",
    "_IMPORT_('import plotly')\n",
    "_IMPORT_('import plotly.graph_objects as go')\n",
    "_IMPORT_('import ipywidgets as widgets')\n",
    "_IMPORT_('from ipywidgets import interact, interactive, fixed, interact_manual')\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "def show_table(headers, data, width=900):\n",
    "    ncols = len(headers)\n",
    "    width = int(width / ncols)\n",
    "    lralign = []\n",
    "    caption = []\n",
    "    for item in headers:\n",
    "        astr = ''\n",
    "        if item[0] == ':':\n",
    "            astr = ':'\n",
    "            item = item[1:]\n",
    "        astr += '---'\n",
    "        if item[-1] == ':':\n",
    "            astr += ':'\n",
    "            item = item[:-1]\n",
    "        lralign.append(astr)\n",
    "        caption.append(item)\n",
    "    captionstr = '|'.join(caption) + chr(10)\n",
    "    lralignstr = '|'.join(lralign) + chr(10)\n",
    "    imgholdstr = '|'.join(['<img width=%d/>' % width] * ncols) + chr(10)\n",
    "    table = captionstr + lralignstr + imgholdstr\n",
    "    is_dict = isinstance(data[0], dict)\n",
    "    for row in data:\n",
    "        if is_dict:\n",
    "            table += '|'.join([f'{row[c]}' for c in caption]) + chr(10)\n",
    "        else:\n",
    "            table += '|'.join([f'{col}' for col in row]) + chr(10)\n",
    "    return Markdown(table)\n",
    "\n",
    "def show_video(vidsrc, width=None, height=None):\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if vidsrc.startswith('http'):\n",
    "        data_url = vidsrc\n",
    "    else:\n",
    "        mp4 = open(vidsrc, 'rb').read()\n",
    "        data_url = 'data:video/mp4;base64,' + base64.b64encode(mp4).decode()\n",
    "    return HTML('<video %s %s controls src=\"%s\" type=\"video/mp4\"/>' % (W, H, data_url))\n",
    "\n",
    "def show_image(imgsrc, width=None, height=None):\n",
    "    if isinstance(imgsrc, np.ndarray):\n",
    "        img = imgsrc\n",
    "        if width or height:\n",
    "            if width and height:\n",
    "                size = (width, height)\n",
    "            else:\n",
    "                rate = img.shape[1] / img.shape[0]\n",
    "                if width:\n",
    "                    size = (width, int(width/rate))\n",
    "                else:\n",
    "                    size = (int(height*rate), height)\n",
    "            img = cv2.resize(img, size)\n",
    "            plt.figure(figsize=(3*int(size[0]/80+1), 3*int(size[1]/80+1)), dpi=80)\n",
    "        plt.axis('off')\n",
    "        if len(img.shape) > 2:\n",
    "            plt.imshow(img);\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray');\n",
    "        return\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if imgsrc.startswith('http'):\n",
    "        data_url = imgsrc\n",
    "    else:\n",
    "        if len(imgsrc) > 512:\n",
    "            data_url = 'data:image/jpg;base64,' + imgsrc\n",
    "        else:\n",
    "            img = open(imgsrc, 'rb').read()\n",
    "            data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<img %s %s src=\"%s\"/>' % (W, H, data_url))\n",
    "\n",
    "    W, H = '', ''\n",
    "    if width:\n",
    "        W = 'width=%d' % width\n",
    "    if height:\n",
    "        H = 'height=%d' % height\n",
    "    if image_path.startswith('http'):\n",
    "        data_url = image_path\n",
    "    else:\n",
    "        img = open(image_path, 'rb').read()\n",
    "        data_url = 'data:image/jpg;base64,' + base64.b64encode(img).decode()\n",
    "    return HTML('<img %s %s src=\"%s\"/>' % (W, H, data_url))\n",
    "\n",
    "def im_read(url, rgb=True, size=None):\n",
    "    if url.startswith('http'):\n",
    "        response = requests.get(url)\n",
    "        if response:\n",
    "            imgmat = np.frombuffer(response.content, dtype=np.uint8)\n",
    "            img = cv2.imdecode(imgmat, cv2.IMREAD_COLOR)\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        img = cv2.imread(url)\n",
    "        \n",
    "    if rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if size:\n",
    "        if isinstance(size, int):\n",
    "            size = (size, size)\n",
    "        img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:45:19.016260Z",
     "start_time": "2021-07-09T12:45:18.349652Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault('HOST_IP', '172.21.0.16')\n",
    "os.environ.setdefault('NET_IP', '81.70.134.138')\n",
    "from k12libs.utils.nb_easy import k12ai_run_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:45:19.929229Z",
     "start_time": "2021-07-09T12:45:19.799109Z"
    }
   },
   "outputs": [],
   "source": [
    "backbones = [\n",
    "    'resnet18',           # 0\n",
    "    'resnet50',           # 1\n",
    "    'densenet121',        # 2\n",
    "    'mobilenet_v2',       # 3\n",
    "    'squeezenet1_0',      # 4\n",
    "    'squeezenet1_1',      # 5\n",
    "    'shufflenet_v2_x0_5', # 6\n",
    "    'shufflenet_v2_x1_0', # 7\n",
    "]\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64]\n",
    "input_sizes = [28, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:45:40.221769Z",
     "start_time": "2021-07-09T12:45:21.432020Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae83a8337234f0aa9a7469d7c3ba9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='cls', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = k12ai_run_project(\n",
    "    debug=True, # tb_port=9002,\n",
    "    framework='k12cv', task='cls',\n",
    "    network=backbones[1], dataset='rmnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:46:14.110136Z",
     "start_time": "2021-07-09T12:46:13.997579Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"task\": \"cls\",\n",
      "    \"method\": \"image_classifier\",\n",
      "    \"data.include_val\": false,\n",
      "    \"dataset\": \"listdir\",\n",
      "    \"data.workers\": 1,\n",
      "    \"data.drop_last\": false,\n",
      "    \"data.image_tool\": \"cv2\",\n",
      "    \"data.input_mode\": \"BGR\",\n",
      "    \"solver.display_iter\": 10,\n",
      "    \"solver.test_interval\": 20,\n",
      "    \"solver.save_iters\": 1024,\n",
      "    \"train.batch_size\": 32,\n",
      "    \"val.batch_size\": 32,\n",
      "    \"test.batch_size\": 32,\n",
      "    \"train.data_transformer.fit_stride\": 1,\n",
      "    \"train.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"train.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"train.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"train.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.train.random_border.bool\": false,\n",
      "    \"_k12.train.random_brightness.bool\": false,\n",
      "    \"_k12.train.random_contrast.bool\": false,\n",
      "    \"_k12.train.random_crop.bool\": false,\n",
      "    \"_k12.train.random_det_crop.bool\": false,\n",
      "    \"_k12.train.random_gauss_blur.bool\": false,\n",
      "    \"_k12.train.random_hsv.bool\": false,\n",
      "    \"_k12.train.random_hue.bool\": false,\n",
      "    \"_k12.train.random_pad.bool\": false,\n",
      "    \"_k12.train.random_perm.bool\": false,\n",
      "    \"_k12.train.random_resize.bool\": false,\n",
      "    \"_k12.train.random_resized_crop.bool\": false,\n",
      "    \"_k12.train.random_rotate.bool\": false,\n",
      "    \"_k12.train.random_saturation.bool\": false,\n",
      "    \"val.data_transformer.fit_stride\": 1,\n",
      "    \"val.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"val.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"val.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"val.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.val.random_border.bool\": false,\n",
      "    \"_k12.val.random_brightness.bool\": false,\n",
      "    \"_k12.val.random_contrast.bool\": false,\n",
      "    \"_k12.val.random_crop.bool\": false,\n",
      "    \"_k12.val.random_det_crop.bool\": false,\n",
      "    \"_k12.val.random_gauss_blur.bool\": false,\n",
      "    \"_k12.val.random_hsv.bool\": false,\n",
      "    \"_k12.val.random_hue.bool\": false,\n",
      "    \"_k12.val.random_pad.bool\": false,\n",
      "    \"_k12.val.random_perm.bool\": false,\n",
      "    \"_k12.val.random_resize.bool\": false,\n",
      "    \"_k12.val.random_resized_crop.bool\": false,\n",
      "    \"_k12.val.random_rotate.bool\": false,\n",
      "    \"_k12.val.random_saturation.bool\": false,\n",
      "    \"test.data_transformer.fit_stride\": 1,\n",
      "    \"test.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"test.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"test.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"test.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.test.random_border.bool\": false,\n",
      "    \"_k12.test.random_brightness.bool\": false,\n",
      "    \"_k12.test.random_contrast.bool\": false,\n",
      "    \"_k12.test.random_crop.bool\": false,\n",
      "    \"_k12.test.random_det_crop.bool\": false,\n",
      "    \"_k12.test.random_gauss_blur.bool\": false,\n",
      "    \"_k12.test.random_hsv.bool\": false,\n",
      "    \"_k12.test.random_hue.bool\": false,\n",
      "    \"_k12.test.random_pad.bool\": false,\n",
      "    \"_k12.test.random_perm.bool\": false,\n",
      "    \"_k12.test.random_resize.bool\": false,\n",
      "    \"_k12.test.random_resized_crop.bool\": false,\n",
      "    \"_k12.test.random_rotate.bool\": false,\n",
      "    \"_k12.test.random_saturation.bool\": false,\n",
      "    \"_k12.data.dataset_name\": \"rmnist\",\n",
      "    \"data.data_dir\": \"oss://data-platform/datasets/user01/uuid01/mnist01\",\n",
      "    \"data.num_records\": 10000,\n",
      "    \"data.num_classes\": 10,\n",
      "    \"data.normalize.mean\": [\n",
      "        0.1307,\n",
      "        0.1307,\n",
      "        0.1307\n",
      "    ],\n",
      "    \"data.normalize.std\": [\n",
      "        0.3081,\n",
      "        0.3081,\n",
      "        0.3081\n",
      "    ],\n",
      "    \"_k12.detail.name_seq\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\",\n",
      "        \"4\",\n",
      "        \"5\",\n",
      "        \"6\",\n",
      "        \"7\",\n",
      "        \"8\",\n",
      "        \"9\"\n",
      "    ],\n",
      "    \"network.model_name\": \"base_model\",\n",
      "    \"network.distributed\": false,\n",
      "    \"network.resume_continue\": false,\n",
      "    \"network.backbone\": \"resnet18\",\n",
      "    \"network.pretrained\": false,\n",
      "    \"network.resume_strict\": false,\n",
      "    \"network.norm_type\": \"batchnorm\",\n",
      "    \"network.syncbn\": false,\n",
      "    \"network.resume_val\": false,\n",
      "    \"network.checkpoints_root\": \"/cache/output\",\n",
      "    \"network.checkpoints_dir\": \"ckpts\",\n",
      "    \"_k12.network.pretrained_path\": \"/pretrained\",\n",
      "    \"solver.lr.metric\": \"epoch\",\n",
      "    \"solver.max_epoch\": 160,\n",
      "    \"solver.lr.base_lr\": 0.01,\n",
      "    \"solver.lr.lr_policy\": \"step\",\n",
      "    \"solver.lr.step.gamma\": 0.1,\n",
      "    \"solver.lr.step.step_size\": 30,\n",
      "    \"solver.lr.is_warm\": false,\n",
      "    \"loss.loss_type\": \"ce_loss\",\n",
      "    \"loss.loss_weights.ce_loss.ce_loss\": 1.0,\n",
      "    \"loss.params.ce_loss.reduction\": \"mean\",\n",
      "    \"loss.params.ce_loss.ignore_index\": -1,\n",
      "    \"solver.optim.optim_method\": \"adam\",\n",
      "    \"solver.optim.adam.weight_decay\": 0.0001,\n",
      "    \"solver.optim.adam.betas\": [\n",
      "        0.9,\n",
      "        0.999\n",
      "    ],\n",
      "    \"solver.optim.adam.eps\": 1e-08,\n",
      "    \"metrics.raw_vs_aug\": false,\n",
      "    \"metrics.train_speed\": false,\n",
      "    \"metrics.train_lr\": false,\n",
      "    \"metrics.val_speed\": false,\n",
      "    \"metrics.confusion_matrix\": true,\n",
      "    \"metrics.top10_images\": false,\n",
      "    \"metrics.top10_errors\": false,\n",
      "    \"metrics.precision\": true,\n",
      "    \"metrics.recall\": true,\n",
      "    \"metrics.fscore\": false,\n",
      "    \"metrics.model_autograd\": false,\n",
      "    \"metrics.model_graph\": false,\n",
      "    \"metrics.feature_maps\": false,\n",
      "    \"metrics.filters_maps\": false,\n",
      "    \"metrics.vbp\": false,\n",
      "    \"metrics.gbp\": false,\n",
      "    \"metrics.deconv\": false,\n",
      "    \"metrics.gcam\": false,\n",
      "    \"metrics.ggcam\": false,\n",
      "    \"metrics.predict_images\": false,\n",
      "    \"metrics.predict_probs\": false,\n",
      "    \"_k12.tb_logdir\": \"/data/tblogs/16601548608/140686\",\n",
      "    \"data.dataset\": \"mnist01\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "op = 'train.start'\n",
    "appId = 'k12ai.popkey'\n",
    "user = 'user01'\n",
    "uuid = 'uuid01'\n",
    "dataset_name = 'mnist01'\n",
    "host = '116.85.5.40'\n",
    "port = 8119\n",
    "uri = 'k12ai/framework/execute'\n",
    "popapi = f'http://{host}:{port}/k12ai/private/popmsg'\n",
    "params = project.get_all_kv()\n",
    "params['data.data_dir'] = f'oss://data-platform/datasets/{user}/{uuid}/{dataset_name}'\n",
    "params['dataset'] = 'listdir'\n",
    "params['data.dataset'] = dataset_name\n",
    "params['solver.max_epoch'] = 160\n",
    "params['solver.display_iter'] = 10\n",
    "params['solver.test_interval'] = 20\n",
    "params = json.dumps(params, indent=4)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:47:23.595751Z",
     "start_time": "2021-07-09T12:47:23.318603Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "{'op': 'train.start', 'token': '123456', 'appId': 'k12ai.popkey', 'user': 'user01', 'service_name': 'k12cv', 'service_uuid': 'uuid01', 'service_params': {'task': 'cls', 'method': 'image_classifier', 'data.include_val': False, 'dataset': 'listdir', 'data.workers': 1, 'data.drop_last': False, 'data.image_tool': 'cv2', 'data.input_mode': 'BGR', 'solver.display_iter': 10, 'solver.test_interval': 20, 'solver.save_iters': 1024, 'train.batch_size': 32, 'val.batch_size': 32, 'test.batch_size': 32, 'train.data_transformer.fit_stride': 1, 'train.data_transformer.size_mode': 'fix_size', 'train.data_transformer.input_size': [28, 28], 'train.data_transformer.align_method': 'scale_and_pad', 'train.data_transformer.pad_mode': 'pad_border', '_k12.train.random_border.bool': False, '_k12.train.random_brightness.bool': False, '_k12.train.random_contrast.bool': False, '_k12.train.random_crop.bool': False, '_k12.train.random_det_crop.bool': False, '_k12.train.random_gauss_blur.bool': False, '_k12.train.random_hsv.bool': False, '_k12.train.random_hue.bool': False, '_k12.train.random_pad.bool': False, '_k12.train.random_perm.bool': False, '_k12.train.random_resize.bool': False, '_k12.train.random_resized_crop.bool': False, '_k12.train.random_rotate.bool': False, '_k12.train.random_saturation.bool': False, 'val.data_transformer.fit_stride': 1, 'val.data_transformer.size_mode': 'fix_size', 'val.data_transformer.input_size': [28, 28], 'val.data_transformer.align_method': 'scale_and_pad', 'val.data_transformer.pad_mode': 'pad_border', '_k12.val.random_border.bool': False, '_k12.val.random_brightness.bool': False, '_k12.val.random_contrast.bool': False, '_k12.val.random_crop.bool': False, '_k12.val.random_det_crop.bool': False, '_k12.val.random_gauss_blur.bool': False, '_k12.val.random_hsv.bool': False, '_k12.val.random_hue.bool': False, '_k12.val.random_pad.bool': False, '_k12.val.random_perm.bool': False, '_k12.val.random_resize.bool': False, '_k12.val.random_resized_crop.bool': False, '_k12.val.random_rotate.bool': False, '_k12.val.random_saturation.bool': False, 'test.data_transformer.fit_stride': 1, 'test.data_transformer.size_mode': 'fix_size', 'test.data_transformer.input_size': [28, 28], 'test.data_transformer.align_method': 'scale_and_pad', 'test.data_transformer.pad_mode': 'pad_border', '_k12.test.random_border.bool': False, '_k12.test.random_brightness.bool': False, '_k12.test.random_contrast.bool': False, '_k12.test.random_crop.bool': False, '_k12.test.random_det_crop.bool': False, '_k12.test.random_gauss_blur.bool': False, '_k12.test.random_hsv.bool': False, '_k12.test.random_hue.bool': False, '_k12.test.random_pad.bool': False, '_k12.test.random_perm.bool': False, '_k12.test.random_resize.bool': False, '_k12.test.random_resized_crop.bool': False, '_k12.test.random_rotate.bool': False, '_k12.test.random_saturation.bool': False, '_k12.data.dataset_name': 'rmnist', 'data.data_dir': 'oss://data-platform/datasets/user01/uuid01/mnist01', 'data.num_records': 10000, 'data.num_classes': 10, 'data.normalize.mean': [0.1307, 0.1307, 0.1307], 'data.normalize.std': [0.3081, 0.3081, 0.3081], '_k12.detail.name_seq': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'network.model_name': 'base_model', 'network.distributed': False, 'network.resume_continue': False, 'network.backbone': 'resnet18', 'network.pretrained': False, 'network.resume_strict': False, 'network.norm_type': 'batchnorm', 'network.syncbn': False, 'network.resume_val': False, 'network.checkpoints_root': '/cache/output', 'network.checkpoints_dir': 'ckpts', '_k12.network.pretrained_path': '/pretrained', 'solver.lr.metric': 'epoch', 'solver.max_epoch': 160, 'solver.lr.base_lr': 0.01, 'solver.lr.lr_policy': 'step', 'solver.lr.step.gamma': 0.1, 'solver.lr.step.step_size': 30, 'solver.lr.is_warm': False, 'loss.loss_type': 'ce_loss', 'loss.loss_weights.ce_loss.ce_loss': 1.0, 'loss.params.ce_loss.reduction': 'mean', 'loss.params.ce_loss.ignore_index': -1, 'solver.optim.optim_method': 'adam', 'solver.optim.adam.weight_decay': 0.0001, 'solver.optim.adam.betas': [0.9, 0.999], 'solver.optim.adam.eps': 1e-08, 'metrics.raw_vs_aug': False, 'metrics.train_speed': False, 'metrics.train_lr': False, 'metrics.val_speed': False, 'metrics.confusion_matrix': True, 'metrics.top10_images': False, 'metrics.top10_errors': False, 'metrics.precision': True, 'metrics.recall': True, 'metrics.fscore': False, 'metrics.model_autograd': False, 'metrics.model_graph': False, 'metrics.feature_maps': False, 'metrics.filters_maps': False, 'metrics.vbp': False, 'metrics.gbp': False, 'metrics.deconv': False, 'metrics.gcam': False, 'metrics.ggcam': False, 'metrics.predict_images': False, 'metrics.predict_probs': False, '_k12.tb_logdir': '/data/tblogs/16601548608/140686', 'data.dataset': 'mnist01'}}\n",
      "\n",
      "\n",
      "\n",
      "Progress: 100%: ▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋"
     ]
    }
   ],
   "source": [
    "data = json.loads('''{\n",
    "    \"op\":\"%s\",\n",
    "    \"token\": \"123456\",\n",
    "    \"appId\": \"%s\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (op, appId, user, uuid, params))\n",
    "\n",
    "api = 'http://%s:%d/%s' % (host, port, uri)\n",
    "print(\"Input:\\n\")\n",
    "print(data)\n",
    "json.loads(requests.post(url=api, json=data).text)\n",
    "def show_progress(popapi, msgkey, waitcnt=10):\n",
    "    cnt = 1\n",
    "    while True:\n",
    "        result = json.loads(requests.get(url=f'{popapi}?key={msgkey}').text)\n",
    "        for r in result:\n",
    "            r = json.loads(r)\n",
    "            for d in r['data']:\n",
    "                if d['type'] == 'text':\n",
    "                    p = d['data']\n",
    "                    if 'progress' in p['title']:\n",
    "                        v = int(float(p['payload']))\n",
    "                        print_progress_bar(v)\n",
    "                        if v >= 100:\n",
    "                            return\n",
    "            cnt = 0\n",
    "        cnt += 1\n",
    "        time.sleep(1)\n",
    "        if cnt > waitcnt:\n",
    "            print('timeout')\n",
    "            break\n",
    "print(\"\\n\\n\")\n",
    "show_progress(popapi, appId + '.metrics', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[metrics doc](http://116.85.5.40:8118/notebooks/docs/metrics_types.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持3种输入格式, `http/ftp`, `oss`, `base64str`\n",
    "\n",
    "输入样例:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_k12.predict_images\": [\n",
    "        {\n",
    "            \"name\": \"1-35582.jpg\",\n",
    "            \"content\": \"https://data-platform.s3.didiyunapi.com/datasets/user01/uuid01/mnist01/train/1/35582.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"6-49837.jpg\",\n",
    "            \"content\": \"oss://data-platform/datasets/user01/uuid01/mnist01/train/6/49837.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"5-16451.jpg\",\n",
    "            \"content\": \"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+uw8OfDfWfEmk/wBqLdabp1kzmOGbUbjyRO46hODn09OvpWb4j8GeIPCk5j1jTJoE3YWcDdE+emHHB6dOtYNKoBYAnAzyfSvX/il4W8R6jrmn6doWg31zoWm2EUVjLawF45AQGZ8qMbiT06nGa4i+1Pxlofh+fw7qq6la6deFWNtfQMudrBgU3jI5A6Vy1Feq6R4N+KDafE91rF7oOlRIrCa+1NoEjQ8fdDZHToQO1R+OvGGnHwXB4QtNYvPEdwlwLifVbonajAY2RZ5I68nPU4znjy6ir+o67q+sCManqt9fCPhBc3Dy7fpuJxVCiv/Z\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "输出样例:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "         'version': '0.1.0',\n",
    "         'server': 'localhost:8119',\n",
    "         'type': 'metrics',\n",
    "         'appId': 'k12ai.popkey',\n",
    "         'token': '123456',\n",
    "         'user': 'user01',\n",
    "         'op': 'predict.start',\n",
    "         'service_name': 'k12cv',\n",
    "         'service_uuid': 'uuid01',\n",
    "         'timestamp': 1626060328328,\n",
    "         'datetime': '20210712112528',\n",
    "         'data': [\n",
    "             {\n",
    "                   '_id_': 'd02280eaf0363a36',\n",
    "                   'category': 'predict',\n",
    "                   'type': 'text',\n",
    "                   'data': {\n",
    "                       'title': 'predict_target-0', \n",
    "                       'payload': '1-35582.jpg: 1'     // 1-35582.jpg 为输入时`name`属性, 1 为最终的输出标签\n",
    "                   }\n",
    "             }\n",
    "         ]\n",
    "    }\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T03:41:52.996794Z",
     "start_time": "2021-07-12T03:41:52.786513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "{'op': 'predict.start', 'token': '123456', 'appId': 'k12ai.popkey', 'user': 'user01', 'service_name': 'k12cv', 'service_uuid': 'uuid01', 'service_params': {'_k12.predict_images': [{'name': '1-35582.jpg', 'content': 'https://data-platform.s3.didiyunapi.com/datasets/user01/uuid01/mnist01/train/1/35582.jpg'}, {'name': '6-49837.jpg', 'content': 'oss://data-platform/datasets/user01/uuid01/mnist01/train/6/49837.jpg'}, {'name': '5-16451.jpg', 'content': '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+uw8OfDfWfEmk/wBqLdabp1kzmOGbUbjyRO46hODn09OvpWb4j8GeIPCk5j1jTJoE3YWcDdE+emHHB6dOtYNKoBYAnAzyfSvX/il4W8R6jrmn6doWg31zoWm2EUVjLawF45AQGZ8qMbiT06nGa4i+1Pxlofh+fw7qq6la6deFWNtfQMudrBgU3jI5A6Vy1Feq6R4N+KDafE91rF7oOlRIrCa+1NoEjQ8fdDZHToQO1R+OvGGnHwXB4QtNYvPEdwlwLifVbonajAY2RZ5I68nPU4znjy6ir+o67q+sCManqt9fCPhBc3Dy7fpuJxVCiv/Z'}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'code': 100000, 'message': {'en': 'success', 'cn': '成功'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = {\n",
    "    '_k12.predict_images': [\n",
    "        {\n",
    "            'name': '1-35582.jpg',\n",
    "            'content': 'https://data-platform.s3.didiyunapi.com/datasets/user01/uuid01/mnist01/train/1/35582.jpg'\n",
    "        },\n",
    "        {\n",
    "            'name': '6-49837.jpg',\n",
    "            'content': 'oss://data-platform/datasets/user01/uuid01/mnist01/train/6/49837.jpg'\n",
    "        },\n",
    "        {\n",
    "            'name': '5-16451.jpg',\n",
    "            'content': img2b64('https://data-platform.s3.didiyunapi.com/datasets/user01/uuid01/mnist01/train/5/16451.jpg')\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "data = json.loads('''{\n",
    "    \"op\":\"predict.start\",\n",
    "    \"token\": \"123456\",\n",
    "    \"appId\": \"%s\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (appId, user, uuid, json.dumps(test_params)))\n",
    "\n",
    "api = 'http://%s:%d/%s' % (host, port, uri)\n",
    "print(\"Input:\\n\")\n",
    "print(data)\n",
    "json.loads(requests.post(url=api, json=data).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T03:42:09.051831Z",
     "start_time": "2021-07-12T03:41:53.672371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"version\": \"0.1.0\", \"server\": \"localhost:8119\", \"type\": \"metrics\", \"appId\": \"k12ai.popkey\", \"token\": \"123456\", \"user\": \"user01\", \"op\": \"predict.start\", \"service_name\": \"k12cv\", \"service_uuid\": \"uuid01\", \"timestamp\": 1626061328031, \"datetime\": \"20210712114208\", \"data\": [{\"_id_\": \"d02280eaf0363a36\", \"category\": \"predict\", \"type\": \"text\", \"data\": {\"title\": \"predict_target-0\", \"payload\": \"1-35582.jpg: 1\"}}]}', '{\"version\": \"0.1.0\", \"server\": \"localhost:8119\", \"type\": \"metrics\", \"appId\": \"k12ai.popkey\", \"token\": \"123456\", \"user\": \"user01\", \"op\": \"predict.start\", \"service_name\": \"k12cv\", \"service_uuid\": \"uuid01\", \"timestamp\": 1626061328112, \"datetime\": \"20210712114208\", \"data\": [{\"_id_\": \"830ea7d91a60485d\", \"category\": \"predict\", \"type\": \"text\", \"data\": {\"title\": \"predict_target-1\", \"payload\": \"5-16451.jpg: 5\"}}]}', '{\"version\": \"0.1.0\", \"server\": \"localhost:8119\", \"type\": \"metrics\", \"appId\": \"k12ai.popkey\", \"token\": \"123456\", \"user\": \"user01\", \"op\": \"predict.start\", \"service_name\": \"k12cv\", \"service_uuid\": \"uuid01\", \"timestamp\": 1626061328186, \"datetime\": \"20210712114208\", \"data\": [{\"_id_\": \"537f37f10249350e\", \"category\": \"predict\", \"type\": \"text\", \"data\": {\"title\": \"predict_target-2\", \"payload\": \"6-49837.jpg: 6\"}}]}']\n"
     ]
    }
   ],
   "source": [
    "for _ in range(30):\n",
    "    result = requests.get(url=f'{popapi}?key={appId}.metrics').text\n",
    "    result = json.loads(result)\n",
    "    if len(result) >= 3:\n",
    "        print(result)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 压测 (P40 跑10个任务)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:44:14.878779Z",
     "start_time": "2021-07-09T12:44:07.218Z"
    }
   },
   "outputs": [],
   "source": [
    "# from k12libs.utils.nb_easy import k12ai_train_execute\n",
    "# keys = k12ai_train_execute(\n",
    "#     framework='k12cv', task='cls',\n",
    "#     network=backbones[-1], dataset='rmnist',\n",
    "#     batchsize=32, inputsize=32, epoch_num=20, run_num=10)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
