{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 分类任务测试 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T10:15:39.233179Z",
     "start_time": "2021-07-08T10:15:36.230023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.19.4\n",
      "sklearn 0.24.0\n",
      "pandas 1.1.5\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "cv2 4.5.1\n",
      "PIL 6.2.2\n",
      "matplotlib 3.3.3\n",
      "CPython 3.6.9\n",
      "IPython 7.16.1\n",
      "\n",
      "torch 1.8.0.dev20210103+cu101\n",
      "torchvision 0.9.0.dev20210103+cu101\n",
      "torchaudio not installed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -v -p numpy,sklearn,pandas\n",
    "%watermark -v -p cv2,PIL,matplotlib\n",
    "%watermark -v -p torch,torchvision,torchaudio\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.use_jedi = False\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "display(HTML('<style>.container { width:%d%% !important; }</style>' % 80))\n",
    "\n",
    "def _IMPORT_(x):\n",
    "    try:\n",
    "        exec(x, globals())\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T10:27:06.476637Z",
     "start_time": "2021-07-08T10:27:06.347217Z"
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### Common ###\n",
    "###\n",
    "\n",
    "import sys, os, io, time, random, math\n",
    "import json, base64, requests\n",
    "import os.path as osp\n",
    "\n",
    "_IMPORT_('import numpy as np')\n",
    "_IMPORT_('import pandas as pd')\n",
    "_IMPORT_('from tqdm.notebook import tqdm')\n",
    "\n",
    "def print_progress_bar(x):\n",
    "    print('\\r', end='')\n",
    "    print('Progress: {}%:'.format(x), '%s%s' % ('▋'*(x//2), '.'*((100-x)//2)), end='')\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T10:15:50.394183Z",
     "start_time": "2021-07-08T10:15:50.280226Z"
    }
   },
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_run_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T09:00:59.785011Z",
     "start_time": "2021-07-08T09:00:59.769718Z"
    }
   },
   "outputs": [],
   "source": [
    "backbones = [\n",
    "    'resnet18',           # 0\n",
    "    'resnet50',           # 1\n",
    "    'densenet121',        # 2\n",
    "    'mobilenet_v2',       # 3\n",
    "    'squeezenet1_0',      # 4\n",
    "    'squeezenet1_1',      # 5\n",
    "    'shufflenet_v2_x0_5', # 6\n",
    "    'shufflenet_v2_x1_0', # 7\n",
    "]\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64]\n",
    "input_sizes = [28, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T09:22:01.466702Z",
     "start_time": "2021-07-08T09:21:42.681755Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda3696f2001486a9d450a0d91aad83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='cls', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = k12ai_run_project(\n",
    "    debug=True, tb_port=9002,\n",
    "    framework='k12cv', task='cls',\n",
    "    network=backbones[0], dataset='rmnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:17:25.692377Z",
     "start_time": "2021-07-08T14:17:25.560124Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"task\": \"cls\",\n",
      "    \"method\": \"image_classifier\",\n",
      "    \"data.include_val\": false,\n",
      "    \"dataset\": \"listdir\",\n",
      "    \"data.workers\": 1,\n",
      "    \"data.drop_last\": false,\n",
      "    \"data.image_tool\": \"cv2\",\n",
      "    \"data.input_mode\": \"BGR\",\n",
      "    \"solver.display_iter\": 10,\n",
      "    \"solver.test_interval\": 20,\n",
      "    \"solver.save_iters\": 1024,\n",
      "    \"train.batch_size\": 32,\n",
      "    \"val.batch_size\": 32,\n",
      "    \"test.batch_size\": 32,\n",
      "    \"train.data_transformer.fit_stride\": 1,\n",
      "    \"train.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"train.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"train.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"train.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.train.random_border.bool\": false,\n",
      "    \"_k12.train.random_brightness.bool\": false,\n",
      "    \"_k12.train.random_contrast.bool\": false,\n",
      "    \"_k12.train.random_crop.bool\": false,\n",
      "    \"_k12.train.random_det_crop.bool\": false,\n",
      "    \"_k12.train.random_gauss_blur.bool\": false,\n",
      "    \"_k12.train.random_hsv.bool\": false,\n",
      "    \"_k12.train.random_hue.bool\": false,\n",
      "    \"_k12.train.random_pad.bool\": false,\n",
      "    \"_k12.train.random_perm.bool\": false,\n",
      "    \"_k12.train.random_resize.bool\": false,\n",
      "    \"_k12.train.random_resized_crop.bool\": false,\n",
      "    \"_k12.train.random_rotate.bool\": false,\n",
      "    \"_k12.train.random_saturation.bool\": false,\n",
      "    \"val.data_transformer.fit_stride\": 1,\n",
      "    \"val.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"val.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"val.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"val.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.val.random_border.bool\": false,\n",
      "    \"_k12.val.random_brightness.bool\": false,\n",
      "    \"_k12.val.random_contrast.bool\": false,\n",
      "    \"_k12.val.random_crop.bool\": false,\n",
      "    \"_k12.val.random_det_crop.bool\": false,\n",
      "    \"_k12.val.random_gauss_blur.bool\": false,\n",
      "    \"_k12.val.random_hsv.bool\": false,\n",
      "    \"_k12.val.random_hue.bool\": false,\n",
      "    \"_k12.val.random_pad.bool\": false,\n",
      "    \"_k12.val.random_perm.bool\": false,\n",
      "    \"_k12.val.random_resize.bool\": false,\n",
      "    \"_k12.val.random_resized_crop.bool\": false,\n",
      "    \"_k12.val.random_rotate.bool\": false,\n",
      "    \"_k12.val.random_saturation.bool\": false,\n",
      "    \"test.data_transformer.fit_stride\": 1,\n",
      "    \"test.data_transformer.size_mode\": \"fix_size\",\n",
      "    \"test.data_transformer.input_size\": [\n",
      "        28,\n",
      "        28\n",
      "    ],\n",
      "    \"test.data_transformer.align_method\": \"scale_and_pad\",\n",
      "    \"test.data_transformer.pad_mode\": \"pad_border\",\n",
      "    \"_k12.test.random_border.bool\": false,\n",
      "    \"_k12.test.random_brightness.bool\": false,\n",
      "    \"_k12.test.random_contrast.bool\": false,\n",
      "    \"_k12.test.random_crop.bool\": false,\n",
      "    \"_k12.test.random_det_crop.bool\": false,\n",
      "    \"_k12.test.random_gauss_blur.bool\": false,\n",
      "    \"_k12.test.random_hsv.bool\": false,\n",
      "    \"_k12.test.random_hue.bool\": false,\n",
      "    \"_k12.test.random_pad.bool\": false,\n",
      "    \"_k12.test.random_perm.bool\": false,\n",
      "    \"_k12.test.random_resize.bool\": false,\n",
      "    \"_k12.test.random_resized_crop.bool\": false,\n",
      "    \"_k12.test.random_rotate.bool\": false,\n",
      "    \"_k12.test.random_saturation.bool\": false,\n",
      "    \"_k12.data.dataset_name\": \"rmnist\",\n",
      "    \"data.data_dir\": \"oss://data-platform/datasets/user01/uuid01/mnist01\",\n",
      "    \"data.num_records\": 10000,\n",
      "    \"data.num_classes\": 10,\n",
      "    \"data.normalize.mean\": [\n",
      "        0.1307,\n",
      "        0.1307,\n",
      "        0.1307\n",
      "    ],\n",
      "    \"data.normalize.std\": [\n",
      "        0.3081,\n",
      "        0.3081,\n",
      "        0.3081\n",
      "    ],\n",
      "    \"_k12.detail.name_seq\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\",\n",
      "        \"4\",\n",
      "        \"5\",\n",
      "        \"6\",\n",
      "        \"7\",\n",
      "        \"8\",\n",
      "        \"9\"\n",
      "    ],\n",
      "    \"network.model_name\": \"base_model\",\n",
      "    \"network.distributed\": false,\n",
      "    \"network.resume_continue\": false,\n",
      "    \"network.backbone\": \"resnet18\",\n",
      "    \"network.pretrained\": false,\n",
      "    \"network.resume_strict\": false,\n",
      "    \"network.norm_type\": \"batchnorm\",\n",
      "    \"network.syncbn\": false,\n",
      "    \"network.resume_val\": false,\n",
      "    \"network.checkpoints_root\": \"/cache/output\",\n",
      "    \"network.checkpoints_dir\": \"ckpts\",\n",
      "    \"_k12.network.pretrained_path\": \"/pretrained\",\n",
      "    \"solver.lr.metric\": \"epoch\",\n",
      "    \"solver.max_epoch\": 160,\n",
      "    \"solver.lr.base_lr\": 0.01,\n",
      "    \"solver.lr.lr_policy\": \"step\",\n",
      "    \"solver.lr.step.gamma\": 0.1,\n",
      "    \"solver.lr.step.step_size\": 30,\n",
      "    \"solver.lr.is_warm\": false,\n",
      "    \"loss.loss_type\": \"ce_loss\",\n",
      "    \"loss.loss_weights.ce_loss.ce_loss\": 1.0,\n",
      "    \"loss.params.ce_loss.reduction\": \"mean\",\n",
      "    \"loss.params.ce_loss.ignore_index\": -1,\n",
      "    \"solver.optim.optim_method\": \"adam\",\n",
      "    \"solver.optim.adam.weight_decay\": 0.0001,\n",
      "    \"solver.optim.adam.betas\": [\n",
      "        0.9,\n",
      "        0.999\n",
      "    ],\n",
      "    \"solver.optim.adam.eps\": 1e-08,\n",
      "    \"metrics.raw_vs_aug\": false,\n",
      "    \"metrics.train_speed\": false,\n",
      "    \"metrics.train_lr\": false,\n",
      "    \"metrics.val_speed\": false,\n",
      "    \"metrics.confusion_matrix\": true,\n",
      "    \"metrics.top10_images\": false,\n",
      "    \"metrics.top10_errors\": false,\n",
      "    \"metrics.precision\": true,\n",
      "    \"metrics.recall\": true,\n",
      "    \"metrics.fscore\": false,\n",
      "    \"metrics.model_autograd\": false,\n",
      "    \"metrics.model_graph\": false,\n",
      "    \"metrics.feature_maps\": false,\n",
      "    \"metrics.filters_maps\": false,\n",
      "    \"metrics.vbp\": false,\n",
      "    \"metrics.gbp\": false,\n",
      "    \"metrics.deconv\": false,\n",
      "    \"metrics.gcam\": false,\n",
      "    \"metrics.ggcam\": false,\n",
      "    \"metrics.predict_images\": false,\n",
      "    \"metrics.predict_probs\": false,\n",
      "    \"_k12.tb_logdir\": \"/data/tblogs/16601548608/139674\",\n",
      "    \"data.dataset\": \"mnist01\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "op = 'train.start'\n",
    "appId = 'k12ai.popkey'\n",
    "user = 'user01'\n",
    "uuid = 'uuid01'\n",
    "dataset_name = 'mnist01'\n",
    "host = '116.85.5.40'\n",
    "port = 8119\n",
    "uri = 'k12ai/framework/execute'\n",
    "popapi = f'http://{host}:{port}/k12ai/private/popmsg'\n",
    "params = project.get_all_kv()\n",
    "params['data.data_dir'] = f'oss://data-platform/datasets/{user}/{uuid}/{dataset_name}'\n",
    "params['dataset'] = 'listdir'\n",
    "params['data.dataset'] = dataset_name\n",
    "params['solver.max_epoch'] = 160\n",
    "params['solver.display_iter'] = 10\n",
    "params['solver.test_interval'] = 20\n",
    "params = json.dumps(params, indent=4)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:19:49.161113Z",
     "start_time": "2021-07-08T14:18:59.232620Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "\n",
      "{'op': 'train.start', 'token': '123456', 'appId': 'k12ai.popkey', 'user': 'user01', 'service_name': 'k12cv', 'service_uuid': 'uuid01', 'service_params': {'task': 'cls', 'method': 'image_classifier', 'data.include_val': False, 'dataset': 'listdir', 'data.workers': 1, 'data.drop_last': False, 'data.image_tool': 'cv2', 'data.input_mode': 'BGR', 'solver.display_iter': 10, 'solver.test_interval': 20, 'solver.save_iters': 1024, 'train.batch_size': 32, 'val.batch_size': 32, 'test.batch_size': 32, 'train.data_transformer.fit_stride': 1, 'train.data_transformer.size_mode': 'fix_size', 'train.data_transformer.input_size': [28, 28], 'train.data_transformer.align_method': 'scale_and_pad', 'train.data_transformer.pad_mode': 'pad_border', '_k12.train.random_border.bool': False, '_k12.train.random_brightness.bool': False, '_k12.train.random_contrast.bool': False, '_k12.train.random_crop.bool': False, '_k12.train.random_det_crop.bool': False, '_k12.train.random_gauss_blur.bool': False, '_k12.train.random_hsv.bool': False, '_k12.train.random_hue.bool': False, '_k12.train.random_pad.bool': False, '_k12.train.random_perm.bool': False, '_k12.train.random_resize.bool': False, '_k12.train.random_resized_crop.bool': False, '_k12.train.random_rotate.bool': False, '_k12.train.random_saturation.bool': False, 'val.data_transformer.fit_stride': 1, 'val.data_transformer.size_mode': 'fix_size', 'val.data_transformer.input_size': [28, 28], 'val.data_transformer.align_method': 'scale_and_pad', 'val.data_transformer.pad_mode': 'pad_border', '_k12.val.random_border.bool': False, '_k12.val.random_brightness.bool': False, '_k12.val.random_contrast.bool': False, '_k12.val.random_crop.bool': False, '_k12.val.random_det_crop.bool': False, '_k12.val.random_gauss_blur.bool': False, '_k12.val.random_hsv.bool': False, '_k12.val.random_hue.bool': False, '_k12.val.random_pad.bool': False, '_k12.val.random_perm.bool': False, '_k12.val.random_resize.bool': False, '_k12.val.random_resized_crop.bool': False, '_k12.val.random_rotate.bool': False, '_k12.val.random_saturation.bool': False, 'test.data_transformer.fit_stride': 1, 'test.data_transformer.size_mode': 'fix_size', 'test.data_transformer.input_size': [28, 28], 'test.data_transformer.align_method': 'scale_and_pad', 'test.data_transformer.pad_mode': 'pad_border', '_k12.test.random_border.bool': False, '_k12.test.random_brightness.bool': False, '_k12.test.random_contrast.bool': False, '_k12.test.random_crop.bool': False, '_k12.test.random_det_crop.bool': False, '_k12.test.random_gauss_blur.bool': False, '_k12.test.random_hsv.bool': False, '_k12.test.random_hue.bool': False, '_k12.test.random_pad.bool': False, '_k12.test.random_perm.bool': False, '_k12.test.random_resize.bool': False, '_k12.test.random_resized_crop.bool': False, '_k12.test.random_rotate.bool': False, '_k12.test.random_saturation.bool': False, '_k12.data.dataset_name': 'rmnist', 'data.data_dir': 'oss://data-platform/datasets/user01/uuid01/mnist01', 'data.num_records': 10000, 'data.num_classes': 10, 'data.normalize.mean': [0.1307, 0.1307, 0.1307], 'data.normalize.std': [0.3081, 0.3081, 0.3081], '_k12.detail.name_seq': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], 'network.model_name': 'base_model', 'network.distributed': False, 'network.resume_continue': False, 'network.backbone': 'resnet18', 'network.pretrained': False, 'network.resume_strict': False, 'network.norm_type': 'batchnorm', 'network.syncbn': False, 'network.resume_val': False, 'network.checkpoints_root': '/cache/output', 'network.checkpoints_dir': 'ckpts', '_k12.network.pretrained_path': '/pretrained', 'solver.lr.metric': 'epoch', 'solver.max_epoch': 160, 'solver.lr.base_lr': 0.01, 'solver.lr.lr_policy': 'step', 'solver.lr.step.gamma': 0.1, 'solver.lr.step.step_size': 30, 'solver.lr.is_warm': False, 'loss.loss_type': 'ce_loss', 'loss.loss_weights.ce_loss.ce_loss': 1.0, 'loss.params.ce_loss.reduction': 'mean', 'loss.params.ce_loss.ignore_index': -1, 'solver.optim.optim_method': 'adam', 'solver.optim.adam.weight_decay': 0.0001, 'solver.optim.adam.betas': [0.9, 0.999], 'solver.optim.adam.eps': 1e-08, 'metrics.raw_vs_aug': False, 'metrics.train_speed': False, 'metrics.train_lr': False, 'metrics.val_speed': False, 'metrics.confusion_matrix': True, 'metrics.top10_images': False, 'metrics.top10_errors': False, 'metrics.precision': True, 'metrics.recall': True, 'metrics.fscore': False, 'metrics.model_autograd': False, 'metrics.model_graph': False, 'metrics.feature_maps': False, 'metrics.filters_maps': False, 'metrics.vbp': False, 'metrics.gbp': False, 'metrics.deconv': False, 'metrics.gcam': False, 'metrics.ggcam': False, 'metrics.predict_images': False, 'metrics.predict_probs': False, '_k12.tb_logdir': '/data/tblogs/16601548608/139674', 'data.dataset': 'mnist01'}}\n",
      "Progress:\n",
      "\n",
      "Progress: 100%: ▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋▋"
     ]
    }
   ],
   "source": [
    "data = json.loads('''{\n",
    "    \"op\":\"%s\",\n",
    "    \"token\": \"123456\",\n",
    "    \"appId\": \"%s\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (op, appId, user, uuid, params))\n",
    "\n",
    "api = 'http://%s:%d/%s' % (host, port, uri)\n",
    "print(\"Input:\\n\")\n",
    "print(data)\n",
    "json.loads(requests.post(url=api, json=data).text)\n",
    "def show_progress(popapi, msgkey, waitcnt=10):\n",
    "    cnt = 1\n",
    "    while True:\n",
    "        result = json.loads(requests.get(url=f'{popapi}?key={msgkey}').text)\n",
    "        for r in result:\n",
    "            r = json.loads(r)\n",
    "            for d in r['data']:\n",
    "                if d['type'] == 'text':\n",
    "                    p = d['data']\n",
    "                    if 'progress' in p['title']:\n",
    "                        v = int(float(p['payload']))\n",
    "                        print_progress_bar(v)\n",
    "                        if v >= 100:\n",
    "                            return\n",
    "            cnt = 0\n",
    "        cnt += 1\n",
    "        time.sleep(1)\n",
    "        if cnt > waitcnt:\n",
    "            print('timeout')\n",
    "            break\n",
    "print(\"\\n\\n\")\n",
    "show_progress(API_POPMSG, appId + '.metrics', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[metrics doc](http://116.85.5.40:8118/notebooks/docs/metrics_types.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 压测 (P40 跑10个任务)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T11:19:38.457443Z",
     "start_time": "2020-11-03T11:19:30.082Z"
    }
   },
   "outputs": [],
   "source": [
    "# from k12libs.utils.nb_easy import k12ai_train_execute\n",
    "# keys = k12ai_train_execute(\n",
    "#     framework='k12cv', task='cls',\n",
    "#     network=backbones[-1], dataset='rmnist',\n",
    "#     batchsize=32, inputsize=32, epoch_num=20, run_num=10)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
