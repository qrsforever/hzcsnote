{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 分类任务测试 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_run_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979b7da0327e48789e17291734254de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(VBox(children=(Dropdown(description='Framework', layout=Layout(max_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = k12ai_run_project(lan='cn', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a619ba3b534d3e9861dc2ea34dce0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(Tab(children=(VBox(children=(HBox(children=(Text(value='cls', conti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"request\": {\n",
      "        \"op\": \"train.start\",\n",
      "        \"user\": \"15801310416\",\n",
      "        \"service_name\": \"k12cv\",\n",
      "        \"service_uuid\": \"1\",\n",
      "        \"service_params\": {\n",
      "            \"task\": \"cls\",\n",
      "            \"method\": \"image_classifier\",\n",
      "            \"data.include_val\": false,\n",
      "            \"dataset\": \"default\",\n",
      "            \"data.workers\": 4,\n",
      "            \"data.drop_last\": false,\n",
      "            \"data.image_tool\": \"pil\",\n",
      "            \"data.input_mode\": \"RGB\",\n",
      "            \"solver.display_iter\": 20,\n",
      "            \"solver.save_iters\": 2000,\n",
      "            \"solver.test_interval\": 100,\n",
      "            \"train.batch_size\": 32,\n",
      "            \"val.batch_size\": 32,\n",
      "            \"test.batch_size\": 32,\n",
      "            \"train.data_transformer.fit_stride\": 1,\n",
      "            \"train.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"train.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"train.data_transformer.align_method\": \"only_pad\",\n",
      "            \"train.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.train.random_border.bool\": false,\n",
      "            \"_k12.train.random_brightness.bool\": false,\n",
      "            \"_k12.train.random_contrast.bool\": false,\n",
      "            \"_k12.train.random_crop.bool\": false,\n",
      "            \"_k12.train.random_det_crop.bool\": false,\n",
      "            \"_k12.train.random_gauss_blur.bool\": false,\n",
      "            \"_k12.train.random_hsv.bool\": false,\n",
      "            \"_k12.train.random_hue.bool\": false,\n",
      "            \"_k12.train.random_pad.bool\": false,\n",
      "            \"_k12.train.random_perm.bool\": false,\n",
      "            \"_k12.train.random_resize.bool\": false,\n",
      "            \"_k12.train.random_resized_crop.bool\": false,\n",
      "            \"_k12.train.random_rotate.bool\": false,\n",
      "            \"_k12.train.random_saturation.bool\": false,\n",
      "            \"val.data_transformer.fit_stride\": 1,\n",
      "            \"val.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"val.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"val.data_transformer.align_method\": \"only_pad\",\n",
      "            \"val.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.val.random_border.bool\": false,\n",
      "            \"_k12.val.random_brightness.bool\": false,\n",
      "            \"_k12.val.random_contrast.bool\": false,\n",
      "            \"_k12.val.random_crop.bool\": false,\n",
      "            \"_k12.val.random_det_crop.bool\": false,\n",
      "            \"_k12.val.random_gauss_blur.bool\": false,\n",
      "            \"_k12.val.random_hsv.bool\": false,\n",
      "            \"_k12.val.random_hue.bool\": false,\n",
      "            \"_k12.val.random_pad.bool\": false,\n",
      "            \"_k12.val.random_perm.bool\": false,\n",
      "            \"_k12.val.random_resize.bool\": false,\n",
      "            \"_k12.val.random_resized_crop.bool\": false,\n",
      "            \"_k12.val.random_rotate.bool\": false,\n",
      "            \"_k12.val.random_saturation.bool\": false,\n",
      "            \"test.data_transformer.fit_stride\": 1,\n",
      "            \"test.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"test.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"test.data_transformer.align_method\": \"only_pad\",\n",
      "            \"test.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.data.dataset_name\": \"cifar10\",\n",
      "            \"data.data_dir\": \"/datasets/cifar10\",\n",
      "            \"data.num_records\": 60000,\n",
      "            \"data.num_classes\": 10,\n",
      "            \"data.normalize.mean\": [\n",
      "                0.485,\n",
      "                0.456,\n",
      "                0.406\n",
      "            ],\n",
      "            \"data.normalize.std\": [\n",
      "                0.229,\n",
      "                0.224,\n",
      "                0.225\n",
      "            ],\n",
      "            \"data.normalize.div_value\": 255,\n",
      "            \"network.model_name\": \"base_model\",\n",
      "            \"network.distributed\": true,\n",
      "            \"network.resume_continue\": false,\n",
      "            \"network.backbone\": \"vgg19\",\n",
      "            \"network.pretrained\": false,\n",
      "            \"network.resume_strict\": false,\n",
      "            \"network.norm_type\": \"batchnorm\",\n",
      "            \"network.syncbn\": false,\n",
      "            \"network.resume_val\": false,\n",
      "            \"network.checkpoints_root\": \"/cache\",\n",
      "            \"network.checkpoints_dir\": \"ckpts\",\n",
      "            \"_k12.network.pretrained_path\": \"/pretrained\",\n",
      "            \"solver.lr.metric\": \"epoch\",\n",
      "            \"solver.max_epoch\": 30,\n",
      "            \"solver.lr.base_lr\": 0.001,\n",
      "            \"solver.lr.lr_policy\": \"multistep\",\n",
      "            \"solver.lr.multistep.gamma\": 0.1,\n",
      "            \"solver.lr.multistep.stepvalue\": [\n",
      "                90,\n",
      "                120\n",
      "            ],\n",
      "            \"solver.lr.is_warm\": false,\n",
      "            \"loss.loss_type\": \"ce_loss\",\n",
      "            \"loss.loss_weights.ce_loss.ce_loss\": 1.0,\n",
      "            \"loss.params.ce_loss.reduction\": \"mean\",\n",
      "            \"loss.params.ce_loss.ignore_index\": -1,\n",
      "            \"solver.optim.optim_method\": \"adam\",\n",
      "            \"solver.optim.adam.weight_decay\": 0.001,\n",
      "            \"solver.optim.adam.betas\": [\n",
      "                0.5,\n",
      "                0.999\n",
      "            ],\n",
      "            \"solver.optim.adam.eps\": 1e-08\n",
      "        }\n",
      "    },\n",
      "    \"response\": {\n",
      "        \"code\": 100000,\n",
      "        \"message\": \"success\"\n",
      "    },\n",
      "    \"key\": \"framework/15801310416/1/train.start\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cifar10 = k12ai_run_project(framework='k12cv', task='cls', network='base_model', dataset='cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
