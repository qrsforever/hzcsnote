{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align='center'> 探测任务测试 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k12libs.utils.nb_easy import k12ai_run_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd7ef64c93e48fcb7da84ab24abda5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(VBox(children=(Dropdown(description='Framework', layout=Layout(max_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"request\": {\n",
      "        \"op\": \"train.start\",\n",
      "        \"user\": \"16601548608\",\n",
      "        \"service_name\": \"k12cv\",\n",
      "        \"service_uuid\": \"123456\",\n",
      "        \"service_params\": {\n",
      "            \"task\": \"cls\",\n",
      "            \"method\": \"image_classifier\",\n",
      "            \"data.include_val\": false,\n",
      "            \"dataset\": \"default\",\n",
      "            \"data.workers\": 4,\n",
      "            \"data.drop_last\": false,\n",
      "            \"data.image_tool\": \"pil\",\n",
      "            \"data.input_mode\": \"RGB\",\n",
      "            \"solver.display_iter\": 20,\n",
      "            \"solver.save_iters\": 2000,\n",
      "            \"solver.test_interval\": 100,\n",
      "            \"train.batch_size\": 64,\n",
      "            \"val.batch_size\": 64,\n",
      "            \"test.batch_size\": 64,\n",
      "            \"train.data_transformer.fit_stride\": 1,\n",
      "            \"train.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"train.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"train.data_transformer.align_method\": \"only_pad\",\n",
      "            \"train.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.train.random_border.bool\": false,\n",
      "            \"_k12.train.random_brightness.bool\": false,\n",
      "            \"_k12.train.random_contrast.bool\": false,\n",
      "            \"_k12.train.random_crop.bool\": false,\n",
      "            \"_k12.train.random_det_crop.bool\": false,\n",
      "            \"_k12.train.random_gauss_blur.bool\": false,\n",
      "            \"_k12.train.random_hsv.bool\": false,\n",
      "            \"_k12.train.random_hue.bool\": false,\n",
      "            \"_k12.train.random_pad.bool\": false,\n",
      "            \"_k12.train.random_perm.bool\": false,\n",
      "            \"_k12.train.random_resize.bool\": false,\n",
      "            \"_k12.train.random_resized_crop.bool\": false,\n",
      "            \"_k12.train.random_rotate.bool\": false,\n",
      "            \"_k12.train.random_saturation.bool\": false,\n",
      "            \"val.data_transformer.fit_stride\": 1,\n",
      "            \"val.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"val.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"val.data_transformer.align_method\": \"only_pad\",\n",
      "            \"val.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.val.random_border.bool\": false,\n",
      "            \"_k12.val.random_brightness.bool\": false,\n",
      "            \"_k12.val.random_contrast.bool\": false,\n",
      "            \"_k12.val.random_crop.bool\": false,\n",
      "            \"_k12.val.random_det_crop.bool\": false,\n",
      "            \"_k12.val.random_gauss_blur.bool\": false,\n",
      "            \"_k12.val.random_hsv.bool\": false,\n",
      "            \"_k12.val.random_hue.bool\": false,\n",
      "            \"_k12.val.random_pad.bool\": false,\n",
      "            \"_k12.val.random_perm.bool\": false,\n",
      "            \"_k12.val.random_resize.bool\": false,\n",
      "            \"_k12.val.random_resized_crop.bool\": false,\n",
      "            \"_k12.val.random_rotate.bool\": false,\n",
      "            \"_k12.val.random_saturation.bool\": false,\n",
      "            \"test.data_transformer.fit_stride\": 1,\n",
      "            \"test.data_transformer.size_mode\": \"fix_size\",\n",
      "            \"test.data_transformer.input_size\": [\n",
      "                32,\n",
      "                32\n",
      "            ],\n",
      "            \"test.data_transformer.align_method\": \"only_pad\",\n",
      "            \"test.data_transformer.pad_mode\": \"random\",\n",
      "            \"_k12.data.dataset_name\": \"cifar10\",\n",
      "            \"data.data_dir\": \"/datasets/cifar10\",\n",
      "            \"data.num_records\": 60000,\n",
      "            \"data.num_classes\": 10,\n",
      "            \"data.normalize.mean\": [\n",
      "                0.485,\n",
      "                0.456,\n",
      "                0.406\n",
      "            ],\n",
      "            \"data.normalize.std\": [\n",
      "                0.229,\n",
      "                0.224,\n",
      "                0.225\n",
      "            ],\n",
      "            \"data.normalize.div_value\": 255,\n",
      "            \"network.model_name\": \"base_model\",\n",
      "            \"network.distributed\": true,\n",
      "            \"network.resume_continue\": false,\n",
      "            \"network.backbone\": \"vgg19\",\n",
      "            \"network.pretrained\": false,\n",
      "            \"network.resume_strict\": false,\n",
      "            \"network.norm_type\": \"batchnorm\",\n",
      "            \"network.syncbn\": false,\n",
      "            \"network.resume_val\": false,\n",
      "            \"network.checkpoints_root\": \"/cache\",\n",
      "            \"network.checkpoints_dir\": \"ckpts\",\n",
      "            \"_k12.network.pretrained_path\": \"/pretrained\",\n",
      "            \"solver.lr.metric\": \"epoch\",\n",
      "            \"solver.max_epoch\": 360,\n",
      "            \"solver.lr.base_lr\": 0.001,\n",
      "            \"solver.lr.lr_policy\": \"multistep\",\n",
      "            \"solver.lr.multistep.gamma\": 0.1,\n",
      "            \"solver.lr.multistep.stepvalue\": [\n",
      "                90,\n",
      "                120\n",
      "            ],\n",
      "            \"solver.lr.is_warm\": false,\n",
      "            \"loss.loss_type\": \"ce_loss\",\n",
      "            \"loss.loss_weights.ce_loss.ce_loss\": 1.0,\n",
      "            \"loss.params.ce_loss.reduction\": \"mean\",\n",
      "            \"loss.params.ce_loss.ignore_index\": -1,\n",
      "            \"solver.optim.optim_method\": \"adam\",\n",
      "            \"solver.optim.adam.weight_decay\": 0.001,\n",
      "            \"solver.optim.adam.betas\": [\n",
      "                0.5,\n",
      "                0.999\n",
      "            ],\n",
      "            \"solver.optim.adam.eps\": 1e-08\n",
      "        }\n",
      "    },\n",
      "    \"response\": {\n",
      "        \"code\": 100000,\n",
      "        \"message\": \"success\",\n",
      "        \"data\": {\n",
      "            \"task\": \"cls\",\n",
      "            \"method\": \"image_classifier\",\n",
      "            \"data\": {\n",
      "                \"include_val\": false,\n",
      "                \"workers\": 4,\n",
      "                \"drop_last\": false,\n",
      "                \"image_tool\": \"pil\",\n",
      "                \"input_mode\": \"RGB\",\n",
      "                \"data_dir\": \"/datasets/cifar10\",\n",
      "                \"num_records\": 60000,\n",
      "                \"num_classes\": 10,\n",
      "                \"normalize\": {\n",
      "                    \"mean\": [\n",
      "                        0.485,\n",
      "                        0.456,\n",
      "                        0.406\n",
      "                    ],\n",
      "                    \"std\": [\n",
      "                        0.229,\n",
      "                        0.224,\n",
      "                        0.225\n",
      "                    ],\n",
      "                    \"div_value\": 255\n",
      "                }\n",
      "            },\n",
      "            \"dataset\": \"default\",\n",
      "            \"solver\": {\n",
      "                \"display_iter\": 20,\n",
      "                \"save_iters\": 2000,\n",
      "                \"test_interval\": 100,\n",
      "                \"lr\": {\n",
      "                    \"metric\": \"epoch\",\n",
      "                    \"base_lr\": 0.001,\n",
      "                    \"lr_policy\": \"multistep\",\n",
      "                    \"multistep\": {\n",
      "                        \"gamma\": 0.1,\n",
      "                        \"stepvalue\": [\n",
      "                            90,\n",
      "                            120\n",
      "                        ]\n",
      "                    },\n",
      "                    \"is_warm\": false\n",
      "                },\n",
      "                \"max_epoch\": 360,\n",
      "                \"optim\": {\n",
      "                    \"optim_method\": \"adam\",\n",
      "                    \"adam\": {\n",
      "                        \"weight_decay\": 0.001,\n",
      "                        \"betas\": [\n",
      "                            0.5,\n",
      "                            0.999\n",
      "                        ],\n",
      "                        \"eps\": 1e-08\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"train\": {\n",
      "                \"batch_size\": 64,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                },\n",
      "                \"aug_trans\": {\n",
      "                    \"trans_seq\": []\n",
      "                }\n",
      "            },\n",
      "            \"val\": {\n",
      "                \"batch_size\": 64,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                },\n",
      "                \"aug_trans\": {\n",
      "                    \"trans_seq\": []\n",
      "                }\n",
      "            },\n",
      "            \"test\": {\n",
      "                \"batch_size\": 64,\n",
      "                \"data_transformer\": {\n",
      "                    \"fit_stride\": 1,\n",
      "                    \"size_mode\": \"fix_size\",\n",
      "                    \"input_size\": [\n",
      "                        32,\n",
      "                        32\n",
      "                    ],\n",
      "                    \"align_method\": \"only_pad\",\n",
      "                    \"pad_mode\": \"random\"\n",
      "                }\n",
      "            },\n",
      "            \"network\": {\n",
      "                \"model_name\": \"base_model\",\n",
      "                \"distributed\": true,\n",
      "                \"resume_continue\": false,\n",
      "                \"backbone\": \"vgg19\",\n",
      "                \"resume_strict\": false,\n",
      "                \"norm_type\": \"batchnorm\",\n",
      "                \"syncbn\": false,\n",
      "                \"resume_val\": false,\n",
      "                \"checkpoints_root\": \"/cache\",\n",
      "                \"checkpoints_dir\": \"ckpts\",\n",
      "                \"checkpoints_name\": \"base_model_vgg19_cifar10\"\n",
      "            },\n",
      "            \"loss\": {\n",
      "                \"loss_type\": \"ce_loss\",\n",
      "                \"loss_weights\": {\n",
      "                    \"ce_loss\": {\n",
      "                        \"ce_loss\": 1.0\n",
      "                    }\n",
      "                },\n",
      "                \"params\": {\n",
      "                    \"ce_loss\": {\n",
      "                        \"reduction\": \"mean\",\n",
      "                        \"ignore_index\": -1\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"key\": \"framework/16601548608/123456/train.start\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"request\": {\n",
      "        \"op\": \"train.stop\",\n",
      "        \"user\": \"16601548608\",\n",
      "        \"service_name\": \"k12cv\",\n",
      "        \"service_uuid\": \"123456\"\n",
      "    },\n",
      "    \"response\": {\n",
      "        \"code\": 100000,\n",
      "        \"message\": \"success\"\n",
      "    },\n",
      "    \"key\": \"framework/16601548608/123456/train.stop\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "project = k12ai_run_project(lan='cn', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "voc = k12ai_run_project(framework='k12cv', task='det', network='vgg16_ssd300', dataset='VOC07+12_DET')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
