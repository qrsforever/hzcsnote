{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> CV Api Test </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import consul\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = 'gamma'\n",
    "host = '10.255.20.227'\n",
    "port = 8129\n",
    "\n",
    "user = 'test'\n",
    "uuid = 'abcdef'\n",
    "\n",
    "consul_addr = host\n",
    "consul_port = 8500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API异步接口将过程中产出的数据同步到consul数据中心, 调用该接口可从中心获取数据 (数据中心仅供开发使用)\n",
    "def query_async_data(key, trycnt=3):\n",
    "    i = 0\n",
    "    while i < trycnt:\n",
    "        try:\n",
    "            client = consul.Consul(consul_addr, consul_port)\n",
    "            _, data = client.kv.get(key)\n",
    "            return str(data['Value'], encoding=\"utf-8\")\n",
    "        except:\n",
    "            i = i + 1\n",
    "            time.sleep(2)\n",
    "            print('Query nothing! try:', i)\n",
    "    return 'Query nothing!!!'\n",
    "    \n",
    "# 格式化打印json字符串\n",
    "def print_json(text):\n",
    "    if isinstance(text, str):\n",
    "        print(json.dumps(json.loads(text), indent=4))\n",
    "    else:\n",
    "        print(json.dumps(text, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_template_config = '''{\n",
    "    \"dataset\": \"cifar10\", \n",
    "    \"task\": \"cls\", \n",
    "    \"method\": \"image_classifier\", \n",
    "    \"data\": {\n",
    "        \"num_classes\": 10, \n",
    "        \"data_dir\": \"/data/datasets/cv/cifar10\", \n",
    "        \"image_tool\": \"pil\", \n",
    "        \"input_mode\": \"RGB\", \n",
    "        \"workers\": 1, \n",
    "        \"mean_value\": [\n",
    "            124, \n",
    "            116, \n",
    "            104\n",
    "        ], \n",
    "        \"normalize\": {\n",
    "            \"div_value\": 255, \n",
    "            \"mean\": [\n",
    "                0.485, \n",
    "                0.456, \n",
    "                0.406\n",
    "            ], \n",
    "            \"std\": [\n",
    "                0.229, \n",
    "                0.224, \n",
    "                0.225\n",
    "            ]\n",
    "        }\n",
    "    }, \n",
    "    \"train\": {\n",
    "        \"batch_size\": 32, \n",
    "        \"aug_trans\": {\n",
    "            \"trans_seq\": [\n",
    "                \"random_hflip\", \n",
    "                \"random_border\", \n",
    "                \"random_crop\"\n",
    "            ], \n",
    "            \"random_hflip\": {\n",
    "                \"ratio\": 0.5, \n",
    "                \"swap_pair\": [ ]\n",
    "            }, \n",
    "            \"random_border\": {\n",
    "                \"ratio\": 1, \n",
    "                \"pad\": [\n",
    "                    4, \n",
    "                    4, \n",
    "                    4, \n",
    "                    4\n",
    "                ], \n",
    "                \"allow_outside_center\": false\n",
    "            }, \n",
    "            \"random_crop\": {\n",
    "                \"ratio\": 1, \n",
    "                \"crop_size\": [\n",
    "                    32, \n",
    "                    32\n",
    "                ], \n",
    "                \"method\": \"random\", \n",
    "                \"allow_outside_center\": false\n",
    "            }\n",
    "        }, \n",
    "        \"data_transformer\": {\n",
    "            \"size_mode\": \"fix_size\", \n",
    "            \"input_size\": [\n",
    "                32, \n",
    "                32\n",
    "            ], \n",
    "            \"align_method\": \"only_pad\"\n",
    "        }\n",
    "    }, \n",
    "    \"val\": {\n",
    "        \"batch_size\": 32, \n",
    "        \"aug_trans\": {\n",
    "            \"trans_seq\": [ ]\n",
    "        }, \n",
    "        \"data_transformer\": {\n",
    "            \"size_mode\": \"fix_size\", \n",
    "            \"input_size\": [\n",
    "                32, \n",
    "                32\n",
    "            ], \n",
    "            \"align_method\": \"only_pad\"\n",
    "        }\n",
    "    }, \n",
    "    \"test\": { }, \n",
    "    \"details\": {\n",
    "        \"name_seq\": [\n",
    "            \"plane\", \n",
    "            \"car\", \n",
    "            \"bird\", \n",
    "            \"cat\", \n",
    "            \"deer\", \n",
    "            \"dog\", \n",
    "            \"frog\", \n",
    "            \"horse\", \n",
    "            \"ship\", \n",
    "            \"truck\"\n",
    "        ], \n",
    "        \"color_list\": [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0],\n",
    "                     [85, 255, 0], [0, 255, 0], [0, 255, 85], [0, 255, 170], [0, 255, 255],\n",
    "                     [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], [170, 0, 255],\n",
    "                     [255, 0, 255], [255, 0, 170], [255, 0, 85], [255, 0, 170], [255, 0, 85]]\n",
    "    }, \n",
    "    \"network\": {\n",
    "        \"model_name\": \"cls_model\", \n",
    "        \"backbone\": \"vgg19\", \n",
    "        \"pooled_size\": [\n",
    "            1, \n",
    "            1\n",
    "        ],\n",
    "        \"checkpoints_name\": \"ic_vgg19_cifar10_cls\", \n",
    "        \"checkpoints_dir\": \"checkpoints/cls/cifar10\"\n",
    "    }, \n",
    "    \"solver\": {\n",
    "        \"lr\": {\n",
    "            \"metric\": \"epoch\", \n",
    "            \"base_lr\": 0.1, \n",
    "            \"lr_policy\": \"multistep\", \n",
    "            \"step\": {\n",
    "                \"gamma\": 0.1, \n",
    "                \"step_size\": 30\n",
    "            }, \n",
    "            \"multistep\": {\n",
    "                \"gamma\": 0.1, \n",
    "                \"stepvalue\": [\n",
    "                    150, \n",
    "                    250, \n",
    "                    350\n",
    "                ]\n",
    "            }\n",
    "        }, \n",
    "        \"optim\": {\n",
    "            \"optim_method\": \"sgd\", \n",
    "            \"adam\": {\n",
    "                \"betas\": [\n",
    "                    0.9, \n",
    "                    0.999\n",
    "                ], \n",
    "                \"eps\": 1e-8, \n",
    "                \"weight_decay\": 0.0001\n",
    "            }, \n",
    "            \"sgd\": {\n",
    "                \"weight_decay\": 0.00004, \n",
    "                \"momentum\": 0.9, \n",
    "                \"nesterov\": false\n",
    "            }\n",
    "        }, \n",
    "        \"display_iter\": 20, \n",
    "        \"save_iters\": 2000, \n",
    "        \"test_interval\": 100, \n",
    "        \"max_epoch\": 360\n",
    "    }, \n",
    "    \"loss\": {\n",
    "        \"loss_type\": \"ce_loss\", \n",
    "        \"loss_weights\": {\n",
    "            \"ce_loss\": {\n",
    "                \"ce_loss\": 1\n",
    "            }, \n",
    "            \"soft_ce_loss\": {\n",
    "                \"soft_ce_loss\": 1\n",
    "            }, \n",
    "            \"mixup_ce_loss\": {\n",
    "                \"mixup_ce_loss\": 1\n",
    "            }, \n",
    "            \"mixup_soft_ce_loss\": {\n",
    "                \"mixup_soft_ce_loss\": 1\n",
    "            }\n",
    "        }, \n",
    "        \"params\": {\n",
    "            \"ce_loss\": {\n",
    "                \"reduction\": \"mean\", \n",
    "                \"ignore_index\": -1\n",
    "            }, \n",
    "            \"soft_ce_loss\": {\n",
    "                \"reduction\": \"batchmean\", \n",
    "                \"label_smooth\": 0.1\n",
    "            }, \n",
    "            \"mixup_ce_loss\": {\n",
    "                \"reduction\": \"mean\", \n",
    "                \"ignore_index\": -1\n",
    "            }, \n",
    "            \"mixup_soft_ce_loss\": {\n",
    "                \"reduction\": \"batchmean\", \n",
    "                \"label_smooth\": 0.1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}'''\n",
    "\n",
    "cls_template_config_dict = json.loads(cls_template_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 cls_vgg19_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_config = cls_template_config_dict\n",
    "\n",
    "cls_config['dataset'] = 'cifar10'\n",
    "cls_config['data']['data_dir'] = '/data/datasets/cifar10'\n",
    "cls_config['train']['batch_size'] = 32\n",
    "cls_config['details']['name_seq'] = [\n",
    "    \"plane\", \n",
    "    \"car\", \n",
    "    \"bird\", \n",
    "    \"cat\", \n",
    "    \"deer\", \n",
    "    \"dog\", \n",
    "    \"frog\", \n",
    "    \"horse\", \n",
    "    \"ship\", \n",
    "    \"truck\"\n",
    "]\n",
    "cls_config['solver']['max_epoch'] = 2\n",
    "cls_config['solver']['optim']['optim_method'] = 'sgd'\n",
    "cls_config['loss']['loss_type'] = 'ce_loss'\n",
    "cls_config['network']['backbone'] = 'vgg19'\n",
    "cls_config['network']['checkpoints_name'] = 'ic_vgg19_cifar10_cls'\n",
    "cls_config['network']['checkpoints_dir'] = 'checkpoints'\n",
    "conf = json.dumps(cls_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\",\n",
      "    \"message\": \"train.start task cache directory: /data/users/test/abcdef\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "uuid = 'cls_vgg19_cifar10'\n",
    "data = '''{\n",
    "    \"op\":\"train.start\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (user, uuid, conf)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异步输出样例:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"version\": \"0.1.0\",\n",
    "    \"type\": \"metrics\",\n",
    "    \"tag\": \"framework\",\n",
    "    \"op\": \"train.start\",\n",
    "    \"user\": \"test\",\n",
    "    \"service_uuid\": \"abcdef\",\n",
    "    \"timestamp\": 1574939332062,\n",
    "    \"datetime\": \"2019-11-28 19:08:52\",\n",
    "    \"metrics\": {\n",
    "        \"training_epochs\": 1,\n",
    "        \"training_loss\": 2.3058,\n",
    "        \"training_speed\": 0.105,\n",
    "        \"lr\": [\n",
    "            0.1,\n",
    "            0.1\n",
    "        ],\n",
    "        \"validation_loss\": 2.3041,\n",
    "        \"validation_accuracy\": 0.10519999710842967,\n",
    "        \"validation_accuracy3\": 0.3018999940156937,\n",
    "        \"validation_accuracy5\": 0.49709998607635497\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"version\": \"0.1.0\",\n",
      "    \"type\": \"metrics\",\n",
      "    \"tag\": \"framework\",\n",
      "    \"op\": \"train.start\",\n",
      "    \"user\": \"test\",\n",
      "    \"service_uuid\": \"abcdef\",\n",
      "    \"timestamp\": 1574942562414,\n",
      "    \"datetime\": \"2019-11-28 20:02:42\",\n",
      "    \"metrics\": {\n",
      "        \"training_epochs\": 2,\n",
      "        \"training_loss\": 2.3036,\n",
      "        \"training_speed\": 0.056,\n",
      "        \"lr\": [\n",
      "            0.1,\n",
      "            0.1\n",
      "        ],\n",
      "        \"validation_loss\": 2.3168,\n",
      "        \"validation_accuracy\": 0.105,\n",
      "        \"validation_accuracy3\": 0.295,\n",
      "        \"validation_accuracy5\": 0.5011\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(query_async_data('framework/%s/%s/train.start/metrics'%(user, uuid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = '''{\n",
    "    \"op\":\"train.stop\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": {}\n",
    "}''' % (user, uuid)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 cls_resnet18_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_config = template_config_dict\n",
    "\n",
    "cls_config['dataset'] = 'mnist'\n",
    "cls_config['data']['data_dir'] = '/data/datasets/cv/mnist'\n",
    "cls_config['train']['batch_size'] = 32\n",
    "cls_config['details']['name_seq'] = [\n",
    "    \"0\", \n",
    "    \"1\", \n",
    "    \"2\", \n",
    "    \"3\", \n",
    "    \"4\", \n",
    "    \"5\", \n",
    "    \"6\", \n",
    "    \"7\", \n",
    "    \"8\", \n",
    "    \"9\"\n",
    "]\n",
    "cls_config['solver']['max_epoch'] = 2\n",
    "cls_config['solver']['optim']['optim_method'] = 'adam'\n",
    "cls_config['loss']['loss_type'] = 'soft_ce_loss'\n",
    "cls_config['network']['backbone'] = 'resnet18'\n",
    "cls_config['network']['checkpoints_name'] = 'ic_resnet18_mnist_cls'\n",
    "cls_config['network']['checkpoints_dir'] = 'checkpoints'\n",
    "conf = json.dumps(cls_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\",\n",
      "    \"message\": \"train.start task cache directory: /data/users/test/cls_resnet18_mnist\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "uuid = 'cls_resnet18_mnist'\n",
    "data = '''{\n",
    "    \"op\":\"train.start\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (user, uuid, conf)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"version\": \"0.1.0\",\n",
      "    \"type\": \"metrics\",\n",
      "    \"tag\": \"framework\",\n",
      "    \"op\": \"train.start\",\n",
      "    \"user\": \"test\",\n",
      "    \"service_uuid\": \"cls_resnet18_mnist\",\n",
      "    \"timestamp\": 1574946168637,\n",
      "    \"datetime\": \"2019-11-28 21:02:48\",\n",
      "    \"metrics\": {\n",
      "        \"training_epochs\": 1,\n",
      "        \"training_loss\": 1.49,\n",
      "        \"training_speed\": 0.06,\n",
      "        \"lr\": [\n",
      "            0.1,\n",
      "            0.1\n",
      "        ],\n",
      "        \"validation_loss\": 1.7414,\n",
      "        \"validation_accuracy\": 0.11791666666666667,\n",
      "        \"validation_accuracy3\": 0.32258333333333333,\n",
      "        \"validation_accuracy5\": 0.5316666666666666\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(query_async_data('framework/%s/%s/train.start/metrics'%(user, uuid), trycnt=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = '''{\n",
    "    \"op\":\"train.stop\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": {}\n",
    "}''' % (user, uuid)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_template_config = '''{\n",
    "    \"dataset\": \"voc\",\n",
    "    \"task\": \"det\",\n",
    "    \"method\": \"single_shot_detector\",\n",
    "    \"data\": {\n",
    "      \"num_classes\": 21,\n",
    "      \"data_dir\": \"~/DataSet/VOC07+12_DET\",\n",
    "      \"image_tool\": \"cv2\",\n",
    "      \"input_mode\": \"BGR\",\n",
    "      \"keep_difficult\": false,\n",
    "      \"workers\": 1,\n",
    "      \"mean_value\": [104, 117, 123],\n",
    "      \"normalize\": {\n",
    "        \"div_value\": 1,\n",
    "        \"mean\": [104.0, 117.0, 123.0],\n",
    "        \"std\": [1.0, 1.0, 1.0]\n",
    "      }\n",
    "    },\n",
    "    \"train\": {\n",
    "      \"batch_size\": 16,\n",
    "      \"aug_trans\": {\n",
    "        \"shuffle_trans_seq\": [\"random_contrast\", \"random_hue\", \"random_saturation\", \"random_brightness\", \"random_perm\"],\n",
    "        \"trans_seq\": [\"random_hflip\", \"random_pad\", \"random_det_crop\"],\n",
    "        \"random_saturation\": {\n",
    "          \"ratio\": 0.5,\n",
    "          \"lower\": 0.5,\n",
    "          \"upper\": 1.5\n",
    "        },\n",
    "        \"random_hue\": {\n",
    "          \"ratio\": 0.5,\n",
    "          \"delta\": 18\n",
    "        },\n",
    "        \"random_contrast\": {\n",
    "          \"ratio\": 0.5,\n",
    "          \"lower\": 0.5,\n",
    "          \"upper\": 1.5\n",
    "        },\n",
    "        \"random_pad\": {\n",
    "          \"ratio\": 0.6,\n",
    "          \"up_scale_range\": [1.0, 4.0]\n",
    "        },\n",
    "        \"random_brightness\": {\n",
    "          \"ratio\": 0.5,\n",
    "          \"shift_value\": 32\n",
    "        },\n",
    "        \"random_perm\": {\n",
    "          \"ratio\": 0.5\n",
    "        },\n",
    "        \"random_hflip\": {\n",
    "          \"ratio\": 0.5,\n",
    "          \"swap_pair\": []\n",
    "        },\n",
    "        \"random_det_crop\":{\n",
    "          \"ratio\": 1.0\n",
    "        }\n",
    "      },\n",
    "      \"data_transformer\": {\n",
    "        \"size_mode\": \"fix_size\",\n",
    "        \"input_size\": [300, 300],\n",
    "        \"align_method\": \"only_scale\"\n",
    "      }\n",
    "    },\n",
    "    \"val\": {\n",
    "      \"batch_size\": 16,\n",
    "      \"use_07_metric\": true,\n",
    "      \"aug_trans\": {\n",
    "        \"trans_seq\": []\n",
    "      },\n",
    "      \"data_transformer\": {\n",
    "        \"size_mode\": \"fix_size\",\n",
    "        \"input_size\": [300, 300],\n",
    "        \"align_method\": \"only_scale\"\n",
    "      }\n",
    "    },\n",
    "    \"test\": {\n",
    "      \"batch_size\": 16,\n",
    "      \"aug_trans\": {\n",
    "        \"trans_seq\": []\n",
    "      },\n",
    "      \"data_transformer\": {\n",
    "        \"size_mode\": \"fix_size\",\n",
    "        \"input_size\": [300, 300],\n",
    "        \"align_method\": \"only_scale\"\n",
    "      }\n",
    "    },\n",
    "    \"anchor\": {\n",
    "      \"anchor_method\": \"ssd\",\n",
    "      \"iou_threshold\": 0.5,\n",
    "      \"num_anchor_list\": [4, 6, 6, 6, 4, 4],\n",
    "      \"feature_maps_wh\": [[38, 38], [19, 19], [10, 10], [5, 5], [3, 3], [1, 1]],\n",
    "      \"cur_anchor_sizes\": [30, 60, 111, 162, 213, 264, 315],\n",
    "      \"aspect_ratio_list\": [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
    "    },\n",
    "    \"details\": {\n",
    "      \"color_list\": [[255, 170, 30], [0, 0, 70], [244, 35, 232]],\n",
    "      \"name_id_dict\": {\n",
    "        \"aeroplane\": 1, \"bicycle\": 2, \"bird\": 3, \"boat\": 4, \"bottle\": 5, \"bus\": 6, \"car\": 7,\n",
    "        \"cat\": 8, \"chair\": 9, \"cow\": 10, \"diningtable\": 11, \"dog\": 12, \"horse\": 13, \"motorbike\": 14,\n",
    "        \"person\": 15, \"pottedplant\": 16, \"sheep\": 17, \"sofa\": 18, \"train\": 19, \"tvmonitor\": 20\n",
    "      },\n",
    "      \"name_seq\": [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\",\n",
    "                   \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "                   \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "    },\n",
    "    \"network\":{\n",
    "      \"backbone\": \"vgg16\",\n",
    "      \"model_name\": \"vgg300_ssd\",\n",
    "      \"num_feature_list\": [512, 1024, 512, 256, 256, 256],\n",
    "      \"stride_list\": [8, 16, 30, 60, 100, 300],\n",
    "      \"head_index_list\": [0, 1, 2, 3, 4, 5],\n",
    "      \"checkpoints_name\": \"ssd_vgg300_voc_det\",\n",
    "      \"checkpoints_dir\": \"checkpoints\"\n",
    "    },\n",
    "    \"solver\": {\n",
    "      \"lr\": {\n",
    "        \"metric\": \"epoch\",\n",
    "        \"is_warm\": true,\n",
    "        \"warm\": {\n",
    "          \"warm_iters\": 1000,\n",
    "          \"power\": 1.0,\n",
    "          \"freeze_backbone\": false\n",
    "        },\n",
    "        \"base_lr\": 0.001,\n",
    "        \"lr_policy\": \"multistep\",\n",
    "        \"multistep\": {\n",
    "          \"gamma\": 0.1,\n",
    "          \"stepvalue\": [156, 195, 234]\n",
    "        }\n",
    "      },\n",
    "      \"optim\": {\n",
    "        \"optim_method\": \"sgd\",\n",
    "        \"adam\": {\n",
    "          \"betas\": [0.9, 0.999],\n",
    "          \"eps\": 1e-08,\n",
    "          \"weight_decay\": 0.0001\n",
    "        },\n",
    "        \"sgd\":{\n",
    "          \"weight_decay\": 0.0005,\n",
    "          \"momentum\": 0.9,\n",
    "          \"nesterov\": false\n",
    "        }\n",
    "      },\n",
    "      \"display_iter\": 100,\n",
    "      \"save_iters\": 5000,\n",
    "      \"test_interval\": 5000,\n",
    "      \"max_epoch\": 2\n",
    "    },\n",
    "    \"res\": {\n",
    "      \"nms\": {\n",
    "        \"mode\": \"union\",\n",
    "        \"max_threshold\": 0.45,\n",
    "        \"pre_nms\": 1000\n",
    "      },\n",
    "      \"val_conf_thre\": 0.01,\n",
    "      \"vis_conf_thre\": 0.5,\n",
    "      \"max_per_image\": 200,\n",
    "      \"cls_keep_num\": 50\n",
    "    },\n",
    "    \"loss\": {\n",
    "      \"loss_type\": \"multibox_loss\",\n",
    "      \"loss_weights\": {\n",
    "        \"multibox_loss\": {\n",
    "            \"multibox_loss\": 1.0\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}'''\n",
    "det_template_config_dict = json.loads(det_template_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_config = det_template_config_dict\n",
    "\n",
    "det_config['dataset'] = 'voc'\n",
    "det_config['data']['data_dir'] = '/data/datasets/cv/VOC07+12_DET'\n",
    "det_config['network']['model_name'] = 'vgg16_ssd300'\n",
    "\n",
    "conf = json.dumps(det_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\",\n",
      "    \"message\": \"train.start task cache directory: /data/users/test/vgg300_ssd_voc\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "uuid = 'vgg300_ssd_voc'\n",
    "data = '''{\n",
    "    \"op\":\"train.start\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": %s\n",
    "}''' % (user, uuid, conf)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": 100200,\n",
      "    \"descr\": \"task service success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = '''{\n",
    "    \"op\":\"train.stop\",\n",
    "    \"user\": \"%s\",\n",
    "    \"service_name\": \"k12cv\",\n",
    "    \"service_uuid\": \"%s\",\n",
    "    \"service_params\": {}\n",
    "}''' % (user, uuid)\n",
    "\n",
    "api = 'http://%s:%d/k12ai/framework/train' % (host, port)\n",
    "print_json(requests.post(url=api, json=json.loads(data)).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
